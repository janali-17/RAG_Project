{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ82Bz4O/UGCdDMFCniOfH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e34e6dc6d6c43fdb212185a70633f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91f351a68b944226879e5b02a1549b90",
              "IPY_MODEL_51e355281ca648bf81d98f516301f894",
              "IPY_MODEL_646756d67520440bab9b02f409196a83"
            ],
            "layout": "IPY_MODEL_15d12ad0d1804143bcee3ccdf7941a1d"
          }
        },
        "91f351a68b944226879e5b02a1549b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7472072d6e4d08b545ef7dc9a4c042",
            "placeholder": "​",
            "style": "IPY_MODEL_ae4988e99ff24f17811ebe49aa3a5b8e",
            "value": "modules.json: 100%"
          }
        },
        "51e355281ca648bf81d98f516301f894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75dc50be29564b788ad92d67658f63ce",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c60a0648614cfab699d470c1811273",
            "value": 349
          }
        },
        "646756d67520440bab9b02f409196a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2eed6c12db543e095d0b035e3efce79",
            "placeholder": "​",
            "style": "IPY_MODEL_adcae626857b4cd1a83aed965c33a5f4",
            "value": " 349/349 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "15d12ad0d1804143bcee3ccdf7941a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7472072d6e4d08b545ef7dc9a4c042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae4988e99ff24f17811ebe49aa3a5b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75dc50be29564b788ad92d67658f63ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c60a0648614cfab699d470c1811273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2eed6c12db543e095d0b035e3efce79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adcae626857b4cd1a83aed965c33a5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "818c4c1f9c3146ea8a6e3c50ef3da441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cce8a354bc5c4627a226c921d17aa15e",
              "IPY_MODEL_240f04c172fe41fbba842b91221868eb",
              "IPY_MODEL_8f0023440f984e56ace57c88160ed44b"
            ],
            "layout": "IPY_MODEL_98dafb247c8a4f61b5e53e39377ed9d6"
          }
        },
        "cce8a354bc5c4627a226c921d17aa15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58fbe1d8a6241dab2b2b3e0952593a9",
            "placeholder": "​",
            "style": "IPY_MODEL_5315ccc350f34fe982b69235ae5c3261",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "240f04c172fe41fbba842b91221868eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f04258a729044295aa68632c4af0705e",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b4ec2631aae44d0a3c69da847e7e89f",
            "value": 116
          }
        },
        "8f0023440f984e56ace57c88160ed44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb419e52ed944fabad27682ff3258840",
            "placeholder": "​",
            "style": "IPY_MODEL_0c5e587f0ccb43df8e030ed13d97595a",
            "value": " 116/116 [00:00&lt;00:00, 6.54kB/s]"
          }
        },
        "98dafb247c8a4f61b5e53e39377ed9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58fbe1d8a6241dab2b2b3e0952593a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5315ccc350f34fe982b69235ae5c3261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f04258a729044295aa68632c4af0705e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4ec2631aae44d0a3c69da847e7e89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb419e52ed944fabad27682ff3258840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5e587f0ccb43df8e030ed13d97595a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75ac90b8b4a04a929a02500d8b4cc7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6955a5f909014b68813b695a5cc7ccde",
              "IPY_MODEL_4fa8f11da08e4b99a25ea2b0b9d5b71d",
              "IPY_MODEL_9a14fb1ad8c44780921742c5fdda5f6d"
            ],
            "layout": "IPY_MODEL_8ab5958284df424f88354f13f155d4aa"
          }
        },
        "6955a5f909014b68813b695a5cc7ccde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e630aa0179445f9396a3fb9ebdccea",
            "placeholder": "​",
            "style": "IPY_MODEL_73ac8547444f44a5a6db217c9e4663f9",
            "value": "README.md: 100%"
          }
        },
        "4fa8f11da08e4b99a25ea2b0b9d5b71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9d6027fe784dbe8feb59785e1238b7",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c86a2669b097433db25bfb32e9444dd9",
            "value": 10659
          }
        },
        "9a14fb1ad8c44780921742c5fdda5f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_defbff37dca94a0093d30d5f1b95603b",
            "placeholder": "​",
            "style": "IPY_MODEL_14bf7340a5144738b1b126078d5c1802",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 419kB/s]"
          }
        },
        "8ab5958284df424f88354f13f155d4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e630aa0179445f9396a3fb9ebdccea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ac8547444f44a5a6db217c9e4663f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff9d6027fe784dbe8feb59785e1238b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86a2669b097433db25bfb32e9444dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "defbff37dca94a0093d30d5f1b95603b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bf7340a5144738b1b126078d5c1802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73ff832c933e4d4c90ae2f1d508f1e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c270415fe9d042249e110613e013a884",
              "IPY_MODEL_47136c72318049dc9880f8823e9fb610",
              "IPY_MODEL_3869528639c747d0b33d737bf19faa3f"
            ],
            "layout": "IPY_MODEL_e0bdc67ac7ac488dbea0cb4b47cfb80e"
          }
        },
        "c270415fe9d042249e110613e013a884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a8db6387fe4ba7bb66644b7e6cf852",
            "placeholder": "​",
            "style": "IPY_MODEL_ef17724c8e3e4103942013cf6bb51ee4",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "47136c72318049dc9880f8823e9fb610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd445ee6ccfb4716962ad62e70369aeb",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8707464250974b2d909793a8f6edf1b7",
            "value": 53
          }
        },
        "3869528639c747d0b33d737bf19faa3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4db1b0f1424da7b52efb60b5fe8489",
            "placeholder": "​",
            "style": "IPY_MODEL_ca85ef360f0249518f0ea21ebc2874f1",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.72kB/s]"
          }
        },
        "e0bdc67ac7ac488dbea0cb4b47cfb80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a8db6387fe4ba7bb66644b7e6cf852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef17724c8e3e4103942013cf6bb51ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd445ee6ccfb4716962ad62e70369aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8707464250974b2d909793a8f6edf1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b4db1b0f1424da7b52efb60b5fe8489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca85ef360f0249518f0ea21ebc2874f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b624fbb245949c59cd6a10fef4bce95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7f0ec4ba6bb4122a220b43fc2eb2d80",
              "IPY_MODEL_ec3fff1b2b9f46b7a14bf0e71d470b0f",
              "IPY_MODEL_e060765442634fcc942d3a0cff1ebd6e"
            ],
            "layout": "IPY_MODEL_1b1faeb413494ca3b6ea40725d2707cd"
          }
        },
        "b7f0ec4ba6bb4122a220b43fc2eb2d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2332bf9316349c5bd435c1783b3304e",
            "placeholder": "​",
            "style": "IPY_MODEL_436ddf12ed7d40ac8e5a78bc1af3e378",
            "value": "config.json: 100%"
          }
        },
        "ec3fff1b2b9f46b7a14bf0e71d470b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52cfca8fc08642be8aa4547a19f1a3d8",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_022557768cc24e55a364c8d9174d07c7",
            "value": 612
          }
        },
        "e060765442634fcc942d3a0cff1ebd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876316aa7428401c8e5b246d8a66e761",
            "placeholder": "​",
            "style": "IPY_MODEL_0a750ab0ec5a40bc84510566dbc91bfa",
            "value": " 612/612 [00:00&lt;00:00, 34.1kB/s]"
          }
        },
        "1b1faeb413494ca3b6ea40725d2707cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2332bf9316349c5bd435c1783b3304e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436ddf12ed7d40ac8e5a78bc1af3e378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cfca8fc08642be8aa4547a19f1a3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022557768cc24e55a364c8d9174d07c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "876316aa7428401c8e5b246d8a66e761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a750ab0ec5a40bc84510566dbc91bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d351b76040649f79e58d03c60a31c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ca7c0057dfb44c1aabe587ff33eae6a",
              "IPY_MODEL_1be159d0246e4411931a9b5df45fd6d3",
              "IPY_MODEL_a25026e10574414a85f1de087ff22d5e"
            ],
            "layout": "IPY_MODEL_a40aec6a53c643fc88c6592398962710"
          }
        },
        "6ca7c0057dfb44c1aabe587ff33eae6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dce5053944545c4aac9c81ef15f344f",
            "placeholder": "​",
            "style": "IPY_MODEL_faf2a8f887334520b431098b79e268bf",
            "value": "model.safetensors: 100%"
          }
        },
        "1be159d0246e4411931a9b5df45fd6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_108ee39e417b4fd3927614d830446f24",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea3e5a08c5b047728d98ac15d73c567f",
            "value": 90868376
          }
        },
        "a25026e10574414a85f1de087ff22d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2148f1ea4a44483a8802fa838c2c6627",
            "placeholder": "​",
            "style": "IPY_MODEL_8c2b22556906477882063f5e4af085f9",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 113MB/s]"
          }
        },
        "a40aec6a53c643fc88c6592398962710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dce5053944545c4aac9c81ef15f344f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf2a8f887334520b431098b79e268bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "108ee39e417b4fd3927614d830446f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3e5a08c5b047728d98ac15d73c567f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2148f1ea4a44483a8802fa838c2c6627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2b22556906477882063f5e4af085f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73abca324aa24a37b6496538fd12e7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a730c57ee1274e19a920a3f86c861494",
              "IPY_MODEL_84ced0da0a9f415fb05ae07974cedf5d",
              "IPY_MODEL_23834ad576584284b94366743845648c"
            ],
            "layout": "IPY_MODEL_10839830da7645a189a3c1c080528fdc"
          }
        },
        "a730c57ee1274e19a920a3f86c861494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813f57bba264403c9e39ccd94b53cb84",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2232742b3f4ed99028436151ec19c4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "84ced0da0a9f415fb05ae07974cedf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087b7202c8cf4f3ca296095eed851419",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_125d6b1be7e24e8789b9f2a9de4f9dba",
            "value": 350
          }
        },
        "23834ad576584284b94366743845648c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e631b1f978b4ee48291724efcdd5288",
            "placeholder": "​",
            "style": "IPY_MODEL_e4498075497f49a4bf76bea372cf481b",
            "value": " 350/350 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "10839830da7645a189a3c1c080528fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813f57bba264403c9e39ccd94b53cb84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2232742b3f4ed99028436151ec19c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087b7202c8cf4f3ca296095eed851419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125d6b1be7e24e8789b9f2a9de4f9dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e631b1f978b4ee48291724efcdd5288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4498075497f49a4bf76bea372cf481b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6457e7301b545539d33ceeca0c18021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09f6e497bcf44e9c8a697a7778dabeec",
              "IPY_MODEL_711244e120964547a130ceb7ae5fab6f",
              "IPY_MODEL_7a70f51fd6df4ca7a2cee4be87e2f3f0"
            ],
            "layout": "IPY_MODEL_39e2702dc1c34c22a0497625d58962b1"
          }
        },
        "09f6e497bcf44e9c8a697a7778dabeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d901de693e14cdb939c530d0377bda8",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b236ebaca749cfa91235c8aa6e8867",
            "value": "vocab.txt: 100%"
          }
        },
        "711244e120964547a130ceb7ae5fab6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b92c1d6657c4e8ca873696a0ae3ac51",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87297bfd79a449d782081f33f22a0678",
            "value": 231508
          }
        },
        "7a70f51fd6df4ca7a2cee4be87e2f3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da683948b3484038aa392570064a5818",
            "placeholder": "​",
            "style": "IPY_MODEL_4b55ece2bc1546a1b012dc9f8f47630e",
            "value": " 232k/232k [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "39e2702dc1c34c22a0497625d58962b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d901de693e14cdb939c530d0377bda8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b236ebaca749cfa91235c8aa6e8867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b92c1d6657c4e8ca873696a0ae3ac51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87297bfd79a449d782081f33f22a0678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da683948b3484038aa392570064a5818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b55ece2bc1546a1b012dc9f8f47630e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4513e1f8119044a78aa5d67dea29166c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_167cf0e27f3b4c89bab78a95227c9838",
              "IPY_MODEL_5fa5cb8ecafb4041bb37b5cf3fdbf2e4",
              "IPY_MODEL_26adb5ffbbbb416987b313aa37892e80"
            ],
            "layout": "IPY_MODEL_f45a329a2d0741e3b63b936196b24ea2"
          }
        },
        "167cf0e27f3b4c89bab78a95227c9838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14f972ee9304161ba233edc377fde5c",
            "placeholder": "​",
            "style": "IPY_MODEL_38a6308279b4483b98755abc6a4e85fd",
            "value": "tokenizer.json: 100%"
          }
        },
        "5fa5cb8ecafb4041bb37b5cf3fdbf2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f270a4a31b434339bcb212b71e3673f2",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_132aa53ded5f4f3bb1670e7b0b43c178",
            "value": 466247
          }
        },
        "26adb5ffbbbb416987b313aa37892e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf14d3b428c442ceb400c1f1c6261de9",
            "placeholder": "​",
            "style": "IPY_MODEL_5b916d1b987549478518ffc301a41c03",
            "value": " 466k/466k [00:00&lt;00:00, 6.30MB/s]"
          }
        },
        "f45a329a2d0741e3b63b936196b24ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14f972ee9304161ba233edc377fde5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a6308279b4483b98755abc6a4e85fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f270a4a31b434339bcb212b71e3673f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132aa53ded5f4f3bb1670e7b0b43c178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf14d3b428c442ceb400c1f1c6261de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b916d1b987549478518ffc301a41c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc0eb44e92a49a1a1102dec100d41da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7316e6d618c7469796f3894c1baa890a",
              "IPY_MODEL_90a4f400add04d2d9ad36232df1ded70",
              "IPY_MODEL_23d56efb0f1a46c3b1197370317e6595"
            ],
            "layout": "IPY_MODEL_190f6033f16549f19abf38d5d0a712ad"
          }
        },
        "7316e6d618c7469796f3894c1baa890a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166d650e199e492691a8075fec745b50",
            "placeholder": "​",
            "style": "IPY_MODEL_85015e5173b14ff9bb8b687016af4495",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "90a4f400add04d2d9ad36232df1ded70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775d1cec774749499a7d7f46d714b3c0",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c47fb2388f6c46e7b08c5afa44639117",
            "value": 112
          }
        },
        "23d56efb0f1a46c3b1197370317e6595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210baaf6a086463fb32c744df4cb5cf5",
            "placeholder": "​",
            "style": "IPY_MODEL_a42aa144d83642bbbc8d263a558309bc",
            "value": " 112/112 [00:00&lt;00:00, 4.92kB/s]"
          }
        },
        "190f6033f16549f19abf38d5d0a712ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166d650e199e492691a8075fec745b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85015e5173b14ff9bb8b687016af4495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "775d1cec774749499a7d7f46d714b3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c47fb2388f6c46e7b08c5afa44639117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "210baaf6a086463fb32c744df4cb5cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42aa144d83642bbbc8d263a558309bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b82c3627f6416ebe94b47d040a0d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c0070d748d4491187783a53b8bcb28e",
              "IPY_MODEL_fb31d8c3dbe343679714491622a979ce",
              "IPY_MODEL_e3f4efa87a2d4a609febc7a21719acf4"
            ],
            "layout": "IPY_MODEL_a62155c689e44d02a2f6febb8a85909f"
          }
        },
        "5c0070d748d4491187783a53b8bcb28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50c08868abf4dfbb96c417ac184896b",
            "placeholder": "​",
            "style": "IPY_MODEL_978aa48dd1654048b1a46c8d01559104",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "fb31d8c3dbe343679714491622a979ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9ce263d7034032a88d298f38641fea",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_529c12a8e30447debed3cb4bcba9d7a2",
            "value": 190
          }
        },
        "e3f4efa87a2d4a609febc7a21719acf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2971fa440a48ceb6236e8e67f65ba1",
            "placeholder": "​",
            "style": "IPY_MODEL_16bf60cc0d0d48f7bdf5e5d735d83998",
            "value": " 190/190 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "a62155c689e44d02a2f6febb8a85909f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50c08868abf4dfbb96c417ac184896b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978aa48dd1654048b1a46c8d01559104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9ce263d7034032a88d298f38641fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529c12a8e30447debed3cb4bcba9d7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb2971fa440a48ceb6236e8e67f65ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bf60cc0d0d48f7bdf5e5d735d83998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janali-17/RAG_Project/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_qLYghS0wHD",
        "outputId": "af893653-1cd0-45cf-e92d-fafb25addc3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.16.11-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pdfminer==20191125\n",
            "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfminer.six==20221105\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pillow_heif\n",
            "  Downloading pillow_heif-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting unstructured_inference\n",
            "  Downloading unstructured_inference-0.8.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Collecting pycryptodome (from pdfminer==20191125)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105) (43.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n",
            "  Downloading langchain_core-0.3.28-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.12.14)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.28.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.1)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.10/dist-packages (from pillow_heif) (11.0.0)\n",
            "Collecting layoutparser (from unstructured_inference)\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting python-multipart (from unstructured_inference)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (0.27.0)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (4.10.0.84)\n",
            "Collecting onnx (from unstructured_inference)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured_inference)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (2.5.1+cu121)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (1.0.12)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured_inference) (4.47.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured_inference) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured_inference) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured_inference) (24.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured_inference)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured_inference) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured_inference) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured_inference) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unstructured_inference) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured_inference) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured_inference) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured_inference) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured_inference) (0.4.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured_inference) (2.2.2)\n",
            "Collecting iopath (from layoutparser->unstructured_inference)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser->unstructured_inference)\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from layoutparser->unstructured_inference)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured_inference) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->unstructured_inference) (0.20.1+cu121)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.2.0)\n",
            "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured_inference)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting portalocker (from iopath->layoutparser->unstructured_inference)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unstructured_inference) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured_inference) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured_inference) (2024.2)\n",
            "INFO: pip is looking at multiple versions of pdfplumber to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pdfplumber (from layoutparser->unstructured_inference)\n",
            "  Downloading pdfplumber-0.11.3-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading pdfplumber-0.11.1-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading pdfplumber-0.10.4-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured_inference)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.13-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading unstructured-0.16.11-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_inference-0.8.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.28-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: pdfminer, langdetect, iopath\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140062 sha256=3cc7e4cc43894c4955b43c0638274eee7417e31d4d802b6520669517f6127a50\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/c1/68/f7bd0a8f514661f76b5cbe3b5f76e0033d79f1296012cbbf72\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=97291f44d3718c1c01f77acb8d9a0a984e0904b47c8c590ed1282decedbbebc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=4e52fb7053c63d0cae4341dee30738b97dd5f55d61d6e211b47bf439e1b6005c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built pdfminer langdetect iopath\n",
            "Installing collected packages: filetype, rapidfuzz, pytube, python-multipart, python-magic, python-iso639, python-dotenv, pypdfium2, pypdf, pydantic-core, pycryptodome, portalocker, pinecone-plugin-interface, pillow_heif, pdf2image, onnx, olefile, mypy-extensions, marshmallow, langdetect, jsonpath-python, humanfriendly, httpx-sse, emoji, backoff, aiofiles, youtube-transcript-api, typing-inspect, tiktoken, python-oxmsg, pydantic, pinecone-plugin-inference, pdfminer, iopath, coloredlogs, unstructured-client, pydantic-settings, pinecone-client, pdfminer.six, onnxruntime, dataclasses-json, aiohttp, unstructured, pdfplumber, langchain-core, layoutparser, langchain_pinecone, unstructured_inference, langchain, langchain-community\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.1\n",
            "    Uninstalling pydantic_core-2.27.1:\n",
            "      Successfully uninstalled pydantic_core-2.27.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.3\n",
            "    Uninstalling pydantic-2.10.3:\n",
            "      Successfully uninstalled pydantic-2.10.3\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.10\n",
            "    Uninstalling aiohttp-3.11.10:\n",
            "      Successfully uninstalled aiohttp-3.11.10\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed aiofiles-24.1.0 aiohttp-3.9.5 backoff-2.2.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 emoji-2.14.0 filetype-1.2.0 httpx-sse-0.4.0 humanfriendly-10.0 iopath-0.1.10 jsonpath-python-1.0.6 langchain-0.3.13 langchain-community-0.3.13 langchain-core-0.3.28 langchain_pinecone-0.2.0 langdetect-1.0.9 layoutparser-0.3.4 marshmallow-3.23.2 mypy-extensions-1.0.0 olefile-0.47 onnx-1.17.0 onnxruntime-1.20.1 pdf2image-1.17.0 pdfminer-20191125 pdfminer.six-20221105 pdfplumber-0.10.4 pillow_heif-0.21.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 portalocker-3.0.0 pycryptodome-3.21.0 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.7.0 pypdf-5.1.0 pypdfium2-4.30.1 python-dotenv-1.0.1 python-iso639-2024.10.22 python-magic-0.4.27 python-multipart-0.0.20 python-oxmsg-0.0.1 pytube-15.0.0 rapidfuzz-3.11.0 tiktoken-0.8.0 typing-inspect-0.9.0 unstructured-0.16.11 unstructured-client-0.28.1 unstructured_inference-0.8.1 youtube-transcript-api-0.6.3\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langchain-community openai tiktoken pinecone-client langchain_pinecone unstructured pdfminer==20191125 pdfminer.six==20221105 pillow_heif unstructured_inference youtube-transcript-api pytube sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, WebBaseLoader, YoutubeLoader, DirectoryLoader, TextLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "import os\n",
        "from langchain_community.document_loaders import YoutubeLoader"
      ],
      "metadata": {
        "id": "k0rTuoe80-O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671b24d7-e8f6-474c-f431-1b1c6373245a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key"
      ],
      "metadata": {
        "id": "5Yql0_U41Bxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openrouter_client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=userdata.get(\"OPENROUTER_API\")\n",
        ")"
      ],
      "metadata": {
        "id": "89CFAYC815f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jg4t4lu-e2Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = tiktoken.get_encoding('p50k_base')\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(\n",
        "        text,\n",
        "        disallowed_special=()\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2000,\n",
        "        chunk_overlap=100,\n",
        "        length_function=tiktoken_len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ],
      "metadata": {
        "id": "CugF5zaJ2ifV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def get_embedding(text):\n",
        "    return hf_embeddings.embed_query(text)\n",
        "\n",
        "def cosine_similarity_between_sentences(sentence1, sentence2):\n",
        "    embedding1 = np.array(get_embedding(sentence1))\n",
        "    embedding2 = np.array(get_embedding(sentence2))\n",
        "\n",
        "    if embedding1 is None or embedding2 is None:\n",
        "        return None\n",
        "\n",
        "    embedding1 = embedding1.reshape(1, -1)\n",
        "    embedding2 = embedding2.reshape(1, -1)\n",
        "\n",
        "    print(\"Sentence 1 Embedding: \", embedding1)\n",
        "    print(\"Sentence 2 Embedding: \", embedding2)\n",
        "\n",
        "    similarity = cosine_similarity(embedding1, embedding2)\n",
        "    return similarity[0][0]\n",
        "\n",
        "sentence1 = \"Great to finally meet!\"\n",
        "sentence2 = \"Nice to meet you\"\n",
        "\n",
        "similarity = cosine_similarity_between_sentences(sentence1, sentence2)\n",
        "if similarity is not None:\n",
        "    print(f\"Cosine similarity between sentences:\\n'{sentence1}' and '{sentence2}': {similarity:.4f}\")\n",
        "else:\n",
        "    print(\"Could not compute similarity due to an error.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4e34e6dc6d6c43fdb212185a70633f41",
            "91f351a68b944226879e5b02a1549b90",
            "51e355281ca648bf81d98f516301f894",
            "646756d67520440bab9b02f409196a83",
            "15d12ad0d1804143bcee3ccdf7941a1d",
            "3a7472072d6e4d08b545ef7dc9a4c042",
            "ae4988e99ff24f17811ebe49aa3a5b8e",
            "75dc50be29564b788ad92d67658f63ce",
            "c1c60a0648614cfab699d470c1811273",
            "d2eed6c12db543e095d0b035e3efce79",
            "adcae626857b4cd1a83aed965c33a5f4",
            "818c4c1f9c3146ea8a6e3c50ef3da441",
            "cce8a354bc5c4627a226c921d17aa15e",
            "240f04c172fe41fbba842b91221868eb",
            "8f0023440f984e56ace57c88160ed44b",
            "98dafb247c8a4f61b5e53e39377ed9d6",
            "c58fbe1d8a6241dab2b2b3e0952593a9",
            "5315ccc350f34fe982b69235ae5c3261",
            "f04258a729044295aa68632c4af0705e",
            "2b4ec2631aae44d0a3c69da847e7e89f",
            "eb419e52ed944fabad27682ff3258840",
            "0c5e587f0ccb43df8e030ed13d97595a",
            "75ac90b8b4a04a929a02500d8b4cc7e3",
            "6955a5f909014b68813b695a5cc7ccde",
            "4fa8f11da08e4b99a25ea2b0b9d5b71d",
            "9a14fb1ad8c44780921742c5fdda5f6d",
            "8ab5958284df424f88354f13f155d4aa",
            "73e630aa0179445f9396a3fb9ebdccea",
            "73ac8547444f44a5a6db217c9e4663f9",
            "ff9d6027fe784dbe8feb59785e1238b7",
            "c86a2669b097433db25bfb32e9444dd9",
            "defbff37dca94a0093d30d5f1b95603b",
            "14bf7340a5144738b1b126078d5c1802",
            "73ff832c933e4d4c90ae2f1d508f1e12",
            "c270415fe9d042249e110613e013a884",
            "47136c72318049dc9880f8823e9fb610",
            "3869528639c747d0b33d737bf19faa3f",
            "e0bdc67ac7ac488dbea0cb4b47cfb80e",
            "d6a8db6387fe4ba7bb66644b7e6cf852",
            "ef17724c8e3e4103942013cf6bb51ee4",
            "cd445ee6ccfb4716962ad62e70369aeb",
            "8707464250974b2d909793a8f6edf1b7",
            "3b4db1b0f1424da7b52efb60b5fe8489",
            "ca85ef360f0249518f0ea21ebc2874f1",
            "5b624fbb245949c59cd6a10fef4bce95",
            "b7f0ec4ba6bb4122a220b43fc2eb2d80",
            "ec3fff1b2b9f46b7a14bf0e71d470b0f",
            "e060765442634fcc942d3a0cff1ebd6e",
            "1b1faeb413494ca3b6ea40725d2707cd",
            "a2332bf9316349c5bd435c1783b3304e",
            "436ddf12ed7d40ac8e5a78bc1af3e378",
            "52cfca8fc08642be8aa4547a19f1a3d8",
            "022557768cc24e55a364c8d9174d07c7",
            "876316aa7428401c8e5b246d8a66e761",
            "0a750ab0ec5a40bc84510566dbc91bfa",
            "8d351b76040649f79e58d03c60a31c0d",
            "6ca7c0057dfb44c1aabe587ff33eae6a",
            "1be159d0246e4411931a9b5df45fd6d3",
            "a25026e10574414a85f1de087ff22d5e",
            "a40aec6a53c643fc88c6592398962710",
            "4dce5053944545c4aac9c81ef15f344f",
            "faf2a8f887334520b431098b79e268bf",
            "108ee39e417b4fd3927614d830446f24",
            "ea3e5a08c5b047728d98ac15d73c567f",
            "2148f1ea4a44483a8802fa838c2c6627",
            "8c2b22556906477882063f5e4af085f9",
            "73abca324aa24a37b6496538fd12e7ed",
            "a730c57ee1274e19a920a3f86c861494",
            "84ced0da0a9f415fb05ae07974cedf5d",
            "23834ad576584284b94366743845648c",
            "10839830da7645a189a3c1c080528fdc",
            "813f57bba264403c9e39ccd94b53cb84",
            "cf2232742b3f4ed99028436151ec19c4",
            "087b7202c8cf4f3ca296095eed851419",
            "125d6b1be7e24e8789b9f2a9de4f9dba",
            "4e631b1f978b4ee48291724efcdd5288",
            "e4498075497f49a4bf76bea372cf481b",
            "b6457e7301b545539d33ceeca0c18021",
            "09f6e497bcf44e9c8a697a7778dabeec",
            "711244e120964547a130ceb7ae5fab6f",
            "7a70f51fd6df4ca7a2cee4be87e2f3f0",
            "39e2702dc1c34c22a0497625d58962b1",
            "1d901de693e14cdb939c530d0377bda8",
            "c1b236ebaca749cfa91235c8aa6e8867",
            "9b92c1d6657c4e8ca873696a0ae3ac51",
            "87297bfd79a449d782081f33f22a0678",
            "da683948b3484038aa392570064a5818",
            "4b55ece2bc1546a1b012dc9f8f47630e",
            "4513e1f8119044a78aa5d67dea29166c",
            "167cf0e27f3b4c89bab78a95227c9838",
            "5fa5cb8ecafb4041bb37b5cf3fdbf2e4",
            "26adb5ffbbbb416987b313aa37892e80",
            "f45a329a2d0741e3b63b936196b24ea2",
            "f14f972ee9304161ba233edc377fde5c",
            "38a6308279b4483b98755abc6a4e85fd",
            "f270a4a31b434339bcb212b71e3673f2",
            "132aa53ded5f4f3bb1670e7b0b43c178",
            "cf14d3b428c442ceb400c1f1c6261de9",
            "5b916d1b987549478518ffc301a41c03",
            "ecc0eb44e92a49a1a1102dec100d41da",
            "7316e6d618c7469796f3894c1baa890a",
            "90a4f400add04d2d9ad36232df1ded70",
            "23d56efb0f1a46c3b1197370317e6595",
            "190f6033f16549f19abf38d5d0a712ad",
            "166d650e199e492691a8075fec745b50",
            "85015e5173b14ff9bb8b687016af4495",
            "775d1cec774749499a7d7f46d714b3c0",
            "c47fb2388f6c46e7b08c5afa44639117",
            "210baaf6a086463fb32c744df4cb5cf5",
            "a42aa144d83642bbbc8d263a558309bc",
            "49b82c3627f6416ebe94b47d040a0d58",
            "5c0070d748d4491187783a53b8bcb28e",
            "fb31d8c3dbe343679714491622a979ce",
            "e3f4efa87a2d4a609febc7a21719acf4",
            "a62155c689e44d02a2f6febb8a85909f",
            "c50c08868abf4dfbb96c417ac184896b",
            "978aa48dd1654048b1a46c8d01559104",
            "7b9ce263d7034032a88d298f38641fea",
            "529c12a8e30447debed3cb4bcba9d7a2",
            "cb2971fa440a48ceb6236e8e67f65ba1",
            "16bf60cc0d0d48f7bdf5e5d735d83998"
          ]
        },
        "collapsed": true,
        "id": "XxDN7taV2os2",
        "outputId": "33d9b2f5-f2af-4bf3-d680-be33b248a429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8fa2e95f6ca8>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e34e6dc6d6c43fdb212185a70633f41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "818c4c1f9c3146ea8a6e3c50ef3da441"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75ac90b8b4a04a929a02500d8b4cc7e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73ff832c933e4d4c90ae2f1d508f1e12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b624fbb245949c59cd6a10fef4bce95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d351b76040649f79e58d03c60a31c0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73abca324aa24a37b6496538fd12e7ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6457e7301b545539d33ceeca0c18021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4513e1f8119044a78aa5d67dea29166c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecc0eb44e92a49a1a1102dec100d41da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49b82c3627f6416ebe94b47d040a0d58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 Embedding:  [[-6.42226040e-02 -2.30498277e-02  4.12189811e-02  5.67926466e-02\n",
            "  -1.63038597e-02  4.15017158e-02  8.88479128e-03 -4.60831709e-02\n",
            "  -1.57466414e-03 -2.54955254e-02 -3.06746550e-03  9.07608494e-03\n",
            "   1.05423806e-02  3.58030386e-02  3.46321873e-02  9.65092238e-03\n",
            "  -2.56988853e-02 -3.51948030e-02  3.15498598e-02  3.47745456e-02\n",
            "  -5.27179986e-02 -2.66816318e-02  2.66268365e-02 -1.34273320e-02\n",
            "  -5.38467579e-02  3.75799456e-04 -2.99408399e-02  4.46607508e-02\n",
            "   4.49724793e-02  1.95614807e-02 -1.07248917e-01  1.15735307e-01\n",
            "  -4.73707877e-02  5.04956283e-02  4.24734168e-02  3.78863029e-02\n",
            "   3.02728396e-02 -3.62443663e-02  7.66253024e-02  1.54855186e-02\n",
            "  -3.44800763e-02  1.85779128e-02  5.72161041e-02  5.62272444e-02\n",
            "  -3.45480926e-02  4.13312130e-02  5.84770320e-03  4.52666581e-02\n",
            "   1.93616562e-02  2.63053197e-02  2.68412270e-02  1.28470203e-02\n",
            "   3.65549289e-02 -4.26418483e-02  2.21714508e-02  1.24915272e-01\n",
            "  -1.69741251e-02 -1.28599599e-01 -3.78995319e-03 -1.23820156e-02\n",
            "  -1.37036946e-02  2.92978194e-02 -9.93026569e-02  3.67058665e-02\n",
            "  -4.03593741e-02 -2.03459002e-02 -3.39515619e-02  6.86520152e-03\n",
            "  -1.29833678e-02  4.22235206e-02 -2.93361358e-02  4.44860496e-02\n",
            "  -6.48025274e-02 -5.65681746e-03 -5.28992200e-03  1.50736934e-02\n",
            "   1.46897584e-02 -5.25742956e-02  3.88295539e-02  9.30276234e-03\n",
            "   2.97261383e-02  1.85073409e-02 -2.64315866e-02 -1.74278058e-02\n",
            "   3.81178521e-02 -1.02411091e-01  2.83274986e-03  2.16274764e-02\n",
            "   5.34450868e-03 -3.05306688e-02  1.16348201e-02  8.62853453e-02\n",
            "  -1.02155432e-01  1.64235588e-02 -8.62869434e-03  1.64961051e-02\n",
            "   5.98804019e-02  8.00298825e-02 -2.77322568e-02  8.42324272e-02\n",
            "  -2.30015628e-02  1.00098491e-01 -4.07621749e-02  1.82525944e-02\n",
            "  -5.17911874e-02  3.15530114e-02 -1.99624512e-04  6.45773336e-02\n",
            "   1.34219332e-02 -4.62456159e-02  2.38428544e-02 -3.13486233e-02\n",
            "   2.59901248e-02  4.91599366e-02  4.17788923e-02  1.02843925e-01\n",
            "   3.84061523e-02  6.20888025e-02  3.77833401e-03  4.02218429e-03\n",
            "   7.35900830e-03  1.05642546e-02  1.45091908e-02 -5.96767850e-03\n",
            "  -1.94758978e-02 -1.82391983e-02  8.87656659e-02 -4.62935683e-33\n",
            "  -2.30989680e-02  1.83251370e-02  6.91477954e-02  8.22615027e-02\n",
            "   7.06474576e-03  2.83910185e-02 -4.59862761e-02  2.33577040e-04\n",
            "  -3.29390317e-02  2.78798677e-02  1.32314144e-02  8.43987763e-02\n",
            "   6.86162263e-02 -5.99235576e-03 -1.27380878e-01 -4.38284092e-02\n",
            "  -2.06286013e-02  3.39739993e-02 -8.64192918e-02  1.31204771e-02\n",
            "  -6.29363358e-02 -4.38187830e-02 -5.76115679e-03  6.88235983e-02\n",
            "  -1.36050098e-02  3.06978188e-02  4.36875001e-02 -7.46835780e-04\n",
            "   1.38283044e-01  1.01575712e-02 -4.77176979e-02  1.56100625e-02\n",
            "   1.42114442e-02  6.25208616e-02  4.95602889e-03  3.91234993e-04\n",
            "  -8.52342993e-02 -3.60275395e-02 -2.87217610e-02  6.70225322e-02\n",
            "   5.26934229e-02 -2.73676086e-02 -2.52818596e-02 -1.02681085e-01\n",
            "  -1.77904144e-02 -1.91138946e-02  8.26902315e-03  7.57661238e-02\n",
            "   7.94136822e-02 -4.79719415e-02 -1.68728009e-01 -2.19535902e-02\n",
            "  -4.86609377e-02  4.86230366e-02 -5.06183393e-02 -1.41496956e-03\n",
            "  -3.55932713e-02 -5.89707270e-02 -1.96696557e-02  1.76663939e-02\n",
            "   7.27829859e-02  2.48407554e-02 -1.22681027e-04 -4.93119471e-02\n",
            "  -1.27324769e-02 -1.42833600e-02  4.13103625e-02 -3.27057652e-02\n",
            "   1.44091612e-02 -4.75920551e-02  3.63372453e-02  4.96513732e-02\n",
            "  -1.56122204e-02  2.12402698e-02 -4.35497984e-02  2.08052360e-02\n",
            "   5.51926270e-02  1.00913895e-02 -6.01914898e-03  4.03440408e-02\n",
            "   5.91461994e-02  4.56936248e-02 -6.60578087e-02 -2.80798804e-02\n",
            "   7.13107525e-04  3.87827829e-02 -2.55099703e-02 -1.03675187e-01\n",
            "  -5.35968468e-02  5.52796982e-02 -7.17611760e-02 -2.14631632e-02\n",
            "   1.23390667e-01 -1.39540248e-02 -3.66609469e-02  3.00964390e-33\n",
            "   1.04707353e-01 -1.30605176e-02  2.35316753e-02 -9.49833915e-02\n",
            "   2.68475525e-02 -5.51710352e-02  3.63139063e-02  4.20623866e-04\n",
            "  -1.28477728e-02  5.50851226e-02  2.87414212e-02  3.96983996e-02\n",
            "   3.14161330e-02  1.41023879e-03 -1.68626830e-02  1.00590466e-02\n",
            "   1.37017876e-01 -3.44775878e-02  6.12158068e-02 -5.75645529e-02\n",
            "  -1.78554635e-02 -2.55881739e-03 -3.15821171e-02 -9.47083980e-02\n",
            "  -4.65619937e-02  2.94500217e-02  4.44775447e-02  4.95099090e-03\n",
            "  -5.46808504e-02 -1.04199713e-02 -7.77080841e-03  2.03417055e-02\n",
            "  -8.83187205e-02  5.67233283e-03  3.67271565e-02  7.41802827e-02\n",
            "   5.23128882e-02 -5.93599454e-02 -5.28508378e-03 -9.00437161e-02\n",
            "  -2.39572898e-02  3.30259055e-02 -5.70902824e-02  7.13287666e-02\n",
            "   8.23828802e-02  1.50654148e-02  4.18888219e-02 -4.21833545e-02\n",
            "  -1.26918048e-01 -4.26131859e-02 -8.96740556e-02 -4.47868742e-02\n",
            "  -2.50034686e-02 -1.71019480e-01  4.13342332e-03 -1.02778859e-02\n",
            "   3.43203694e-02 -1.52881071e-02 -1.58438161e-02 -4.13099267e-02\n",
            "  -1.30371228e-01 -1.34097028e-03  5.99074438e-02  8.39323029e-02\n",
            "   8.31516087e-02 -6.58085793e-02  3.77311334e-02  6.27571270e-02\n",
            "  -7.30860159e-02  2.64372621e-02 -6.25907332e-02  9.29294247e-03\n",
            "  -6.02289364e-02  5.01121022e-02  3.65423858e-02 -1.31453365e-01\n",
            "   5.33742271e-02 -5.95514663e-02  2.95271240e-02  4.61796485e-03\n",
            "  -1.03127072e-02  9.63522494e-02 -2.50646286e-02 -8.75922516e-02\n",
            "   9.55772549e-02  6.66492572e-03 -1.16265137e-02  5.23640029e-02\n",
            "   1.29797414e-03  2.05322094e-02 -3.40085365e-02 -5.41874953e-03\n",
            "   1.90975238e-02 -3.84742506e-02  2.58489139e-03 -1.74131092e-08\n",
            "   2.26862007e-03  6.26498684e-02 -1.00589953e-01  1.16997277e-02\n",
            "   6.59071505e-02  3.36221866e-02 -2.59980541e-02 -5.21326717e-03\n",
            "  -8.40255246e-02  3.21167819e-02  3.15936543e-02  5.37900403e-02\n",
            "  -1.84508283e-02  6.94431216e-02  1.02637157e-01 -1.86491739e-02\n",
            "   5.49655370e-02  2.84079881e-03 -5.54136522e-02 -9.63384472e-03\n",
            "  -5.39970957e-02  2.14650319e-03 -4.29607444e-02  4.35333923e-02\n",
            "   1.16909174e-02  8.96502379e-03  9.78875533e-02  2.23915195e-04\n",
            "   2.45680171e-03 -1.11320294e-01 -3.23610045e-02  9.23087448e-02\n",
            "  -8.54442939e-02  7.19826343e-03  7.75974337e-03 -3.70782651e-02\n",
            "  -1.25155345e-01 -1.72702521e-02  8.08847025e-02 -2.07690932e-02\n",
            "  -2.87189037e-02 -2.69354805e-02  1.02065261e-02  2.27441061e-02\n",
            "  -9.92841274e-02  7.61671364e-02  6.02979809e-02  2.09282972e-02\n",
            "  -3.21588702e-02 -2.34845188e-02 -1.05701834e-02  2.62698736e-02\n",
            "   6.27441704e-02 -3.01131271e-02 -1.16191506e-02  2.00894181e-04\n",
            "  -2.02886504e-03 -8.67634721e-04  4.07408513e-02  5.59934936e-02\n",
            "   3.94737422e-02 -1.58700030e-02 -9.19784009e-02  2.82899532e-02]]\n",
            "Sentence 2 Embedding:  [[-1.16453961e-01 -2.92127579e-03  3.83908302e-02  6.27462044e-02\n",
            "  -1.40758813e-03 -2.21835934e-02  8.67564306e-02  5.03959917e-02\n",
            "   3.39859352e-02 -5.91018312e-02 -4.12727445e-02 -4.19746898e-02\n",
            "   2.44072210e-02  2.17092596e-02  1.15176262e-02  2.22473629e-02\n",
            "   3.07963230e-02 -4.10713069e-02 -1.12784049e-02 -4.81454888e-03\n",
            "  -1.23517349e-01  4.49188538e-02  3.92199829e-02 -1.51306288e-02\n",
            "  -3.01322192e-02  7.54133239e-03  3.93885449e-02  1.04686528e-01\n",
            "   4.63969894e-02  4.21798863e-02 -7.83049315e-02  9.25174728e-02\n",
            "  -1.37902386e-02  1.56472828e-02  4.91475351e-02  1.13380728e-02\n",
            "  -2.01585498e-02 -5.86688928e-02 -3.62284807e-03  1.52611108e-02\n",
            "  -2.61287261e-02 -3.03400867e-03  3.95897701e-02  8.66246317e-03\n",
            "  -5.19446731e-02  4.27096291e-03 -2.85723042e-02  5.49017340e-02\n",
            "   5.88021725e-02  3.04737035e-02 -4.42490540e-02  2.10498720e-02\n",
            "  -1.15910778e-02 -4.95096743e-02  1.04225710e-01  1.32923752e-01\n",
            "  -4.68021445e-02 -9.47758108e-02  1.68597815e-03 -1.78268291e-02\n",
            "   2.63190940e-02 -1.36306630e-02 -7.19815791e-02  1.45303681e-02\n",
            "  -8.00229516e-03  1.12559991e-02 -4.70141508e-03 -4.86625917e-02\n",
            "   1.64162144e-02  7.16753444e-03 -6.59445301e-02  4.40674350e-02\n",
            "  -5.78154810e-02  7.43971020e-03 -6.34375308e-03  5.73437428e-03\n",
            "   4.11303937e-02 -6.99684843e-02  3.85790765e-02 -1.58948135e-02\n",
            "   6.59129471e-02  2.63587497e-02 -2.73076966e-02 -2.12433767e-02\n",
            "   1.46892918e-02 -7.49684125e-02  4.24511395e-02 -2.06356030e-02\n",
            "   3.14780101e-02 -1.40456147e-02 -5.73785454e-02  1.25840604e-01\n",
            "  -4.06443924e-02 -3.72165255e-02 -4.00918014e-02 -2.44186521e-02\n",
            "   1.08977713e-01  7.23351687e-02  2.91924905e-02  1.19257830e-01\n",
            "   3.81135419e-02  1.15232840e-01  1.66220162e-02  2.89957747e-02\n",
            "  -3.92660275e-02  4.53887917e-02 -6.17753193e-02  4.65461127e-02\n",
            "  -3.15921642e-02 -4.19571288e-02 -8.94722936e-04  3.14769782e-02\n",
            "  -6.75233901e-02  5.67337386e-02  2.51887590e-02  7.61917233e-02\n",
            "  -2.73314938e-02  8.41440558e-02  3.44232507e-02 -8.23529884e-02\n",
            "  -3.95162776e-03  1.32083157e-02 -1.40036866e-02  6.71662912e-02\n",
            "  -2.04496589e-02 -7.47722611e-02 -4.43085376e-03 -4.06870701e-33\n",
            "   1.21538471e-02 -1.37735000e-02 -7.98338035e-04  3.14905830e-02\n",
            "   3.84071507e-02  9.40233190e-03 -4.52554375e-02  2.22396338e-03\n",
            "  -3.19622755e-02  9.33023393e-02  4.92487997e-02  8.32003057e-02\n",
            "   3.42486016e-02 -1.49680837e-03 -5.88654317e-02 -6.04940318e-02\n",
            "   6.42913505e-02  9.74745080e-02 -8.07799473e-02  1.42826671e-02\n",
            "  -6.45506084e-02 -9.74870622e-02  1.69046912e-02  7.01410174e-02\n",
            "  -5.57352304e-02  3.81146930e-02  2.48017497e-02 -7.00597540e-02\n",
            "   9.84421968e-02  3.48058087e-03  4.54228856e-02 -1.07497964e-02\n",
            "   3.97560820e-02  2.64036115e-02 -4.20504715e-03 -6.89581037e-02\n",
            "  -1.18634235e-02  8.61665979e-03 -7.54674599e-02  6.74642846e-02\n",
            "   4.16183807e-02  8.19702726e-03  8.16927552e-02 -8.24550167e-02\n",
            "   9.86737479e-03  1.78411836e-03  2.67887600e-02  5.91698997e-02\n",
            "   2.75837705e-02 -6.85028434e-02 -9.60430652e-02  1.61139648e-02\n",
            "  -6.97775036e-02  3.99830267e-02 -1.81329716e-02 -2.31205914e-02\n",
            "  -2.26413570e-02  1.23530030e-02 -2.78643072e-02  2.15554759e-02\n",
            "   2.42058951e-02  1.10037141e-02  1.81219783e-02 -1.16808917e-02\n",
            "  -1.01544507e-01  5.27913275e-04  5.64734191e-02 -4.43596803e-02\n",
            "   5.51035553e-02 -4.33262885e-02 -4.64154087e-04  3.29051986e-02\n",
            "   1.74684487e-02  5.55364639e-02  4.67557507e-03  1.69599596e-02\n",
            "   7.47050866e-02 -1.28858781e-03 -3.34962942e-02  2.60403864e-02\n",
            "   5.57207502e-02  5.82317561e-02 -5.44517562e-02 -3.70655917e-02\n",
            "   2.09187344e-02  3.35246027e-02 -2.81055812e-02 -1.63042441e-01\n",
            "  -4.01618257e-02  2.08000075e-02 -6.12007901e-02 -3.73519398e-02\n",
            "   9.86997485e-02 -2.09095571e-02 -4.34037410e-02  2.57933932e-33\n",
            "   5.07275537e-02  6.14775298e-03  4.38639298e-02 -4.67665680e-02\n",
            "  -7.02104047e-02 -4.66595925e-02  4.89599146e-02  8.76545012e-02\n",
            "  -3.67165953e-02  1.10406309e-01 -5.84891485e-03  1.32545615e-02\n",
            "   3.83009464e-02 -1.94416996e-02  4.31172810e-02  1.52090443e-02\n",
            "   1.50696725e-01 -2.51170546e-02 -1.44853666e-02 -8.71512666e-02\n",
            "  -3.77265550e-02  4.14163508e-02 -6.46643266e-02 -9.59269851e-02\n",
            "   6.38876436e-03 -2.27919947e-02 -7.62827918e-02  3.23981419e-02\n",
            "  -2.28348356e-02 -1.48946019e-02  3.43969017e-02  5.22194169e-02\n",
            "  -7.05068260e-02 -3.54217291e-02  1.93730667e-02  1.51355937e-02\n",
            "   8.35507289e-02  4.79010940e-02  4.83094435e-03 -8.15715119e-02\n",
            "  -5.30847758e-02  6.16078526e-02 -4.84553277e-02  8.21677223e-03\n",
            "   1.01950929e-01 -1.94116589e-02  3.19465660e-02  1.93900859e-03\n",
            "  -7.83596411e-02 -7.19042197e-02 -4.60397527e-02 -5.64365499e-02\n",
            "   3.44880000e-02 -1.05285138e-01 -9.66846012e-03 -8.98630545e-02\n",
            "   1.96130555e-02 -1.46562895e-02  1.52730253e-02 -7.11100101e-02\n",
            "  -1.61154062e-01  4.20912029e-03  1.69390477e-02  6.55570924e-02\n",
            "   7.78813884e-02 -3.36599797e-02 -4.65667434e-02  8.24721754e-02\n",
            "  -3.20688784e-02 -1.34478435e-02 -3.51749547e-02 -1.15427207e-02\n",
            "  -6.55404702e-02  5.10310493e-02  4.27620970e-02 -1.58229277e-01\n",
            "   6.53023049e-02 -1.46722011e-02  1.39685431e-02 -7.25907311e-02\n",
            "  -1.65799428e-02  2.85619423e-02 -1.95595231e-02 -3.20337191e-02\n",
            "   7.32156709e-02 -8.03894848e-02  8.45490303e-03  4.05258462e-02\n",
            "   2.37620138e-02  5.88516472e-03 -8.39945767e-03  4.68033627e-02\n",
            "  -3.46951336e-02 -1.70185529e-02 -4.96730208e-02 -1.61833622e-08\n",
            "   3.69519256e-02  4.13731523e-02 -6.11952692e-02  3.40306163e-02\n",
            "   2.97121089e-02  5.85289448e-02 -4.48670285e-03  3.80318277e-02\n",
            "  -1.38128474e-02  6.28627241e-02  4.11210693e-02  4.89862636e-02\n",
            "  -2.50920858e-02  2.17534546e-02  4.78542820e-02 -1.78951584e-02\n",
            "  -4.44396138e-02  2.61065699e-02 -4.60289232e-02  1.10178608e-02\n",
            "  -1.29456995e-02  3.23779769e-02 -4.21551131e-02  4.46082316e-02\n",
            "   2.88796164e-02 -1.07450900e-03  3.18100862e-02 -1.85230921e-03\n",
            "   2.06784420e-02 -5.87127097e-02 -3.12911347e-02  1.54527694e-01\n",
            "  -1.57166813e-02 -1.30469706e-02  2.33398844e-02 -4.86664698e-02\n",
            "  -7.46036395e-02 -7.87342265e-02  2.73639690e-02 -6.43746555e-02\n",
            "  -1.60082200e-04 -2.10426543e-02  2.42376626e-02  9.31794196e-03\n",
            "  -1.09235972e-01 -9.00791399e-03  5.24655320e-02 -4.31316532e-02\n",
            "  -1.67269334e-02 -8.40723235e-03 -3.48236877e-03 -6.63483108e-04\n",
            "   3.78386453e-02  1.44931525e-02  2.50036716e-02 -1.38950162e-02\n",
            "  -3.19931693e-02  2.45495774e-02  2.91109383e-02 -1.27600506e-02\n",
            "   3.78702767e-02  6.31291717e-02 -7.63634443e-02 -4.11733845e-03]]\n",
            "Cosine similarity between sentences:\n",
            "'Great to finally meet!' and 'Nice to meet you': 0.7020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=OuZrhykVytg&t=334s\", add_video_info=False)\n",
        "data = loader.load()\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ33tRXa4v9v",
        "outputId": "14733906-3c4d-4f5d-be3d-ee15d4462223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'OuZrhykVytg'}, page_content=\"in this video we're going to go over what are events in c-sharp how they work and how they're used we're going to see the benefits of events and how they are essential to keeping our code nice and clean but Vienna [Music] hello and welcome I'm your code monkey and this channel is all about helping you learn how to make your own games with enough tutorials made by a professional indie game developer so if you find the video helpful consider subscribing okay so if you've seen a bunch of my videos you've probably heard me mention two things one I always highlight the importance of writing clean code and two I use events to d-cup on various systems and keep my code clean if you want to write good quality code you need to learn and use events the good thing is they're actually very easy so events aren't just a way of saying something happened without knowing or caring about who is listening if anyone you have publishers and subscribers the publisher has its event and these subscribers can subscribe to that event multiple subscribers can subscribe to the same event then when something happens the publisher fires off the event and all these subscribers get notified that the event was fired the key thing is that the publisher does not know who these subscribers are so there might be lots of them or there might be none they might process the event or completely ignore it the publisher doesn't know and doesn't care who is listening and what they did with that information so this allows you to write code in the publisher that is decoupled from whatever other code you also want to run that isn't essential this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get some perks and help keep the videos free for everyone one way you've seen me use events a lot is to keep the illogic and visual separate normally you don't want your logic code to be tightly coupled with the visual you want a logic to work on its own regardless of whether or not there's a visual component the visual should just display what is happening inside and logic so to keep those separate the logic class fires off events which may or may not be caught by a class at Hamill's the visuals for example I made the unlevel system quite a long time ago and as always implement the logic and events and connected that test visual to those events and recently I made a video on a skill tree and I use the exact same level system class the difference is only individual on the level system I had a dummy character some buttons and a bar and on the skill tree I have a moving player and the experience bar with a level counter since I used events I didn't have to modify any of the code inside the unlevel system because I use the same logic and only change the visuals so using events allowed me to very easily reuse that class in a completely different project all right let's look at some code so over here I have my basic script now the way you define an event is very simple first you define the accessor so in this case let's make it public and then you use the event keyword so this is how you define that this film is going to be an event then we need to know the type and now the center time for events as used in the.net standard is the event handler which is inside using system now if an handler as you can see it's just a simple delegate with two fields we have an object for the center and the event args which we'll cover in a bit so we define the type and then we just pass in the name so in this case um let's call it on space press normally you also name it starring with on and then whatever it represents so on space pressed on enemy killed on play win and so on so here we have defined our event now let's see how we can trigger and how to subtract first let's do the trigger so in here let's make our update function and let's test for the spacebar bring down and when we press the spacebar and let's fire off our event so to do that we call our event as if it were a function so on space pressed and we just count now for the similar let's just pass in this and for the event args since we don't have any extra information we can use the constant event our X dot empty and that's it so over here we are firing off our event whenever we press the spacebar so let's try it out okay here we are the game is running here is the console and press space and there we go we have an error we have a known reference exception now the reason is because right now we do not have any subscribers so the underlying structure for our event is set to no so when we fire an event we need to first test that the event is not know so if on space pressed if there is not now then we actually do fire off our event now I can press the spacebar and there you go we do not have an error and since C sharp 6 we can shorten this in order to use the null conditional operator so we just do question mark and then call invoke so this does the exact same thing it invokes event only if on space pressed is not no and again here I am and I'm pressing space and there we go no errors awesome so now that we have the event being fired let's do something with it now in order to subscribe to the event first we define a function that will receive that event now the function signature needs to be the same as event so in this case we're going to make a function that takes a object and the event args parameter so here we have our function which matches this signature and when we have different relatively simple debug log ok now in order to subscribe we access the event so on space pressed and we do plus equals and we add our function so this is how we add our function onto this event so when this event is invoked it won't call the functions attached to that event which in this case is this function so when we press space it's going to run this code and do a lock let's see so here we are and now I press space and there yo we have our log so our event is being fired when we press space and it's being captured by that function which then does a lock ok great now here we are triggering and listening to the event on the same class but the benefits are when we listen from somewhere else so let's do that in the editor and let's make another script and let's attach this script into the same game object ok and now in here first we need to get a reference to our other script so since they're on the same game object we just do get component of our testing event script and now with this reference we can access our event on space pressed and just like before we do pause equals and then we add our function and now if you're using Visual Studio you can use code completion to really speed this up so we're here as you can see I can press tab and there you go it automatically creates the function and now here let's do the same debug log ok so that's it now back into the publisher script and let's get rid of this one so this script is only responsible for firing off the event and then this script accesses now one end subscribes to that event let's see okay so here we are in our press space any of there you go we have our message and if in here we remove the subscriber script and I'll run again and I press space and there you go we do not have any errors and everything is still running exactly the same so the publisher class does not require the subscriber to exist alright so here we have our example we have this class which fires off this event and this class is absolutely no knowledge that this other class exists so this one just fires off the event whether someone is listening or not which again this is perfect for separating logic and visuals you need visuals to know about logic but you do not want the logic to know about the visuals you want a logic to be able to work with or without the visuals so you just have your logic fair enough events in your visuals if they exist listening to those events now here we are subscribing to the event but as you can imagine we can also unsubscribe so uncertain let's subscribe and then after receiving the event once let's unsubscribe so to unsubscribe instead of pause equals we do minus equals so that's it let's test ok here we are and let's press space and there you go we have the unlock function but now press space again and there you go no more messages so we unsubscribed so we stopped receiving the events now in here we're using the event handler which as you can see has two fields an object and an event args the event Rx is the standard way for passing more information through the event so the way we do that is first we make a class that derives from event args and now in here we define whatever fields we want so let's say we have an end for this place County and now up here when we define the event we can use the generic version and pass in our specific event args as the generic parameter so in this case on Swiss press event arts so now our event won't contain an object of this type on the second parameter so down here you can already see the error in here we need to pass in of type on space pressed event args so we do a new and we create our object so just like that so whenever we press space we are incrementing this local field then we're firing out the event and constructing a on space pressed event args and passing in a specific parameter and now we go back into our subscriber and here we modify our signature to receive our new time and now we can access that new type and we can get for example D space count so just like this we're passing extra data along with our event now let's see so here we are in press space and yep there it is we have our event being filed and passing along some extra than that awesome now another thing about events is you do not have to use event handler this is just the normal dotnet standard events work with delegates and if an handler is simply D standard delegate so here we can define our own delegate so here we the finally delegate it returns void and takes a parameter for a float now if you're not familiar with delegates they are essentially function signatures let me know in the comments if you'd like to see a video dedicated just to delegates now we can make an event of this time so again we passing the event keyword and then our specific delegate type and we can fire up very much in the same way so we can't invoke and in this case we take a fold parameter okay so we have our event being fired and now back in the subscriber and here let's subscribe to our new event so on float event plus equals press tab and there you go there's our automatic event which as you can see takes a full parameter and just like that alright so let's test okay so here we are on press space and there you go we have our vent being fired on with a fault parameter and again if we're working with delegates then we can also use the default delegate called action so you make a public event and we can use the time action so action as you can see as you see don't forget that returns void and action also has a generic version so you can define it with a bunch of different types so in this case and what's the final action that takes a boolean and an integer and then down here we fire off the event just like we do every time so there it is we have our event working with an action that takes a boolean and an int and then here we subscribe the same way and let's test and here we are and yep we have all of our events working so you can see how you're not forced to work event handler you can use whatever that'll get you want personally I like to stick with the standard so use event handler and then if I need extra info I create an event arts but you can use whatever time we get you want now another thing specific to unity our unity events these were pretty much the same way with difference being that they are shown in the editor so in here we make a public of time unity event and unity event is inside unity engine that events so here we have our unity event then we invoke it exactly the same way so we called out invoke in this case we have no parameters and also note how this does not have the event keyword and now if we go back into the editor with our object selected you can see over here in the inspector we have a field for our unity event so we can click the plus icon and in here some liked an object so let's select this same object and then we can select a function from that so let's make a function to call here in our subscriber script let's make it so here we have a function with no parameters returning void and it's public and now back into the editor over here we can select that function so click in here then we go into our script testing event subscriber and down here we have our testing unity event function so select it and now let's tests so here we are in press space and if there you go everything is working correctly here we have our testing unit event main trigger so the main benefit of unity events are that you can easily set them in the editor so if you're trying to make your game more fun to designers this may be a good tool alright so here we looked on how events work how they're used and what are the main benefits as you saw events are excellent for helping you keep your code nice and organized it allows objects to work with other objects without being tightly coupled this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get parks and help keep the videos free for everyone as always you can download the project files in Italy's room in tucumán calm subscribe to the channel for more unity tutorials post any questions I have in the comments and I'll see you next time [Music]\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(data)\n"
      ],
      "metadata": {
        "id": "_Xy8zj5s5XBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PQLbJnW5i2W",
        "outputId": "5af99ee1-79e6-4d3d-acf3-627c4de4df01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'OuZrhykVytg'}, page_content=\"in this video we're going to go over what are events in c-sharp how they work and how they're used we're going to see the benefits of events and how they are essential to keeping our code nice and clean but Vienna [Music] hello and welcome I'm your code monkey and this channel is all about helping you learn how to make your own games with enough tutorials made by a professional indie game developer so if you find the video helpful consider subscribing okay so if you've seen a bunch of my videos you've probably heard me mention two things one I always highlight the importance of writing clean code and two I use events to d-cup on various systems and keep my code clean if you want to write good quality code you need to learn and use events the good thing is they're actually very easy so events aren't just a way of saying something happened without knowing or caring about who is listening if anyone you have publishers and subscribers the publisher has its event and these subscribers can subscribe to that event multiple subscribers can subscribe to the same event then when something happens the publisher fires off the event and all these subscribers get notified that the event was fired the key thing is that the publisher does not know who these subscribers are so there might be lots of them or there might be none they might process the event or completely ignore it the publisher doesn't know and doesn't care who is listening and what they did with that information so this allows you to write code in the publisher that is decoupled from whatever other code you also want to run that isn't essential this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get some perks and help keep the videos free for everyone one way you've seen me use events a lot is to keep the illogic and visual separate normally you don't want your logic code to be tightly coupled with the visual you want a logic to work on its own regardless of whether or not there's a visual component the visual should just display what is happening inside and logic so to keep those separate the logic class fires off events which may or may not be caught by a class at Hamill's the visuals for example I made the unlevel system quite a long time ago and as always implement the logic and events and connected that test visual to those events and recently I made a video on a skill tree and I use the exact same level system class the difference is only individual on the level system I had a dummy character some buttons and a bar and on the skill tree I have a moving player and the experience bar with a level counter since I used events I didn't have to modify any of the code inside the unlevel system because I use the same logic and only change the visuals so using events allowed me to very easily reuse that class in a completely different project all right let's look at some code so over here I have my basic script now the way you define an event is very simple first you define the accessor so in this case let's make it public and then you use the event keyword so this is how you define that this film is going to be an event then we need to know the type and now the center time for events as used in the.net standard is the event handler which is inside using system now if an handler as you can see it's just a simple delegate with two fields we have an object for the center and the event args which we'll cover in a bit so we define the type and then we just pass in the name so in this case um let's call it on space press normally you also name it starring with on and then whatever it represents so on space pressed on enemy killed on play win and so on so here we have defined our event now let's see how we can trigger and how to subtract first let's do the trigger so in here let's make our update function and let's test for the spacebar bring down and when we press the spacebar and let's fire off our event so to do that we call our event as if it were a function so on space pressed and we just count now for the similar let's just pass in this and for the event args since we don't have any extra information we can use the constant event our X dot empty and that's it so over here we are firing off our event whenever we press the spacebar so let's try it out okay here we are the game is running here is the console and press space and there we go we have an error we have a known reference exception now the reason is because right now we do not have any subscribers so the underlying structure for our event is set to no so when we fire an event we need to first test that the event is not know so if on space pressed if there is not now then we actually do fire off our event now I can press the spacebar and there you go we do not have an error and since C sharp 6 we can shorten this in order to use the null conditional operator so we just do question mark and then call invoke so this does the exact same thing it invokes event only if on space pressed is not no and again here I am and I'm pressing space and there we go no errors awesome so now that we have the event being fired let's do something with it now in order to subscribe to the event first we define a function that will receive that event now the function signature needs to be the same as event so in this case we're going to make a function that takes a object and the event args parameter so here we have our function which matches this signature and when we have different relatively simple debug log ok now in order to subscribe we access the event so on space pressed and we do plus equals and we add our function so this is how we add our function onto this event so when this event is invoked it won't call the functions attached to that event which in this case is this function so when we press space it's going to run this code and do a lock let's see so here we are and now I press space and there yo we have our log so our event is being fired when we press space and it's being captured by that function which then does a lock ok great now here we are triggering and listening to the event on the same class but the benefits are when we listen from somewhere else so let's do that in the editor and let's make another script and let's attach this script into the same game object ok and now in here first we need to get a reference to our other script so since they're on the same game object we just do get component of our testing event script and now with this reference we can access our event on space pressed and just like before we do pause equals and then we add our function and now if you're using Visual Studio you can use code completion to really speed this up so we're here as you can see I can press tab and there you go it automatically creates the function and now here let's do the same debug log ok so that's it now back into the publisher script and let's get rid of this one so this script is only responsible for firing off the event and then this script accesses now one end subscribes to that event let's see okay so here we are in our press space any of there you go we have our message and if in here we remove the subscriber script and I'll run again and I press space and there you go we do not have any errors and everything is still running exactly the same so the publisher class does not require the subscriber to exist alright so here we have our example we have this class which fires off this event and this class is absolutely no knowledge that this other class exists so this one just fires off the event whether someone is listening or not which again this is perfect for separating logic and visuals you need visuals to know about logic but you do not want the logic to know about the visuals you want a logic to be able to work with or without the visuals so you just have your logic fair enough events in your visuals if they exist listening to those events now here we are subscribing to the event but as you can imagine we can also unsubscribe so uncertain let's subscribe and then after receiving the event once let's unsubscribe so to unsubscribe instead of pause equals we do minus equals so that's it let's test ok here we are and let's press space and there you go we have the unlock function but now press space again and there you go no more messages so we unsubscribed so we stopped receiving the events now in here we're using the event handler which as you can see has two fields an object and an event args the event Rx is the standard way for passing more information through the event so the way we do that is first we make a class that derives from event args and now in here we define whatever fields we want so let's say we have an end for this place County and now up here when we define the event we can use the generic version and pass in our specific event args as the generic parameter so in this case on Swiss press event arts so now our event won't contain an object of this type on the second parameter so down here you can already see the error in here we need to pass in of type on space pressed event args so we do a new and we create our object so just like that so whenever we press space we are incrementing this local field then we're firing out the event and constructing a on space pressed event args and passing in a specific parameter and now we go back into our subscriber and here we modify our signature to receive our new time and now we can access that new type and we can get for example D space count so just like this we're passing extra data along with our event now let's see so here we are in press space and yep there it is we have our event being filed and passing along some extra than\"),\n",
              " Document(metadata={'source': 'OuZrhykVytg'}, page_content=\"field then we're firing out the event and constructing a on space pressed event args and passing in a specific parameter and now we go back into our subscriber and here we modify our signature to receive our new time and now we can access that new type and we can get for example D space count so just like this we're passing extra data along with our event now let's see so here we are in press space and yep there it is we have our event being filed and passing along some extra than that awesome now another thing about events is you do not have to use event handler this is just the normal dotnet standard events work with delegates and if an handler is simply D standard delegate so here we can define our own delegate so here we the finally delegate it returns void and takes a parameter for a float now if you're not familiar with delegates they are essentially function signatures let me know in the comments if you'd like to see a video dedicated just to delegates now we can make an event of this time so again we passing the event keyword and then our specific delegate type and we can fire up very much in the same way so we can't invoke and in this case we take a fold parameter okay so we have our event being fired and now back in the subscriber and here let's subscribe to our new event so on float event plus equals press tab and there you go there's our automatic event which as you can see takes a full parameter and just like that alright so let's test okay so here we are on press space and there you go we have our vent being fired on with a fault parameter and again if we're working with delegates then we can also use the default delegate called action so you make a public event and we can use the time action so action as you can see as you see don't forget that returns void and action also has a generic version so you can define it with a bunch of different types so in this case and what's the final action that takes a boolean and an integer and then down here we fire off the event just like we do every time so there it is we have our event working with an action that takes a boolean and an int and then here we subscribe the same way and let's test and here we are and yep we have all of our events working so you can see how you're not forced to work event handler you can use whatever that'll get you want personally I like to stick with the standard so use event handler and then if I need extra info I create an event arts but you can use whatever time we get you want now another thing specific to unity our unity events these were pretty much the same way with difference being that they are shown in the editor so in here we make a public of time unity event and unity event is inside unity engine that events so here we have our unity event then we invoke it exactly the same way so we called out invoke in this case we have no parameters and also note how this does not have the event keyword and now if we go back into the editor with our object selected you can see over here in the inspector we have a field for our unity event so we can click the plus icon and in here some liked an object so let's select this same object and then we can select a function from that so let's make a function to call here in our subscriber script let's make it so here we have a function with no parameters returning void and it's public and now back into the editor over here we can select that function so click in here then we go into our script testing event subscriber and down here we have our testing unity event function so select it and now let's tests so here we are in press space and if there you go everything is working correctly here we have our testing unit event main trigger so the main benefit of unity events are that you can easily set them in the editor so if you're trying to make your game more fun to designers this may be a good tool alright so here we looked on how events work how they're used and what are the main benefits as you saw events are excellent for helping you keep your code nice and organized it allows objects to work with other objects without being tightly coupled this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get parks and help keep the videos free for everyone as always you can download the project files in Italy's room in tucumán calm subscribe to the channel for more unity tutorials post any questions I have in the comments and I'll see you next time [Music]\")]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "pc = Pinecone()\n",
        "pc.create_index(\n",
        "    name=\"projectrag\", dimension=384, metric=\"cosine\", spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "collapsed": true,
        "id": "tbioHwie5ncA",
        "outputId": "e2c41053-2a13-4cf9-bb1b-c78579f3b3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PineconeApiException",
          "evalue": "(409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '9dc6ab9cd7f70487db91788ca32c1a58', 'Date': 'Sat, 21 Dec 2024 13:57:19 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-611efc6bc8e8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PINECONE_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinecone_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPinecone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m pc.create_index(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"projectrag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mServerlessSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"aws\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"us-east-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/control/pinecone.py\u001b[0m in \u001b[0;36mcreate_index\u001b[0;34m(self, name, dimension, spec, metric, timeout, deletion_protection)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spec must be of type dict, ServerlessSpec, or PodSpec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         api_instance.create_index(\n\u001b[0m\u001b[1;32m    385\u001b[0m             create_index_request=CreateIndexRequest(\n\u001b[1;32m    386\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \"\"\"\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/control/api/manage_indexes_api.py\u001b[0m in \u001b[0;36m__create_index\u001b[0;34m(self, create_index_request, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_host_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_host_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"create_index_request\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_index_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         self.create_index = _Endpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"endpoint_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"http_method\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             return self.__call_api(\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mresource_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             return self.rest_client.POST(\n\u001b[0m\u001b[1;32m    461\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     ):\n\u001b[0;32m--> 345\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/openapi/shared/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPineconeApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPineconeApiException\u001b[0m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '9dc6ab9cd7f70487db91788ca32c1a58', 'Date': 'Sat, 21 Dec 2024 13:57:19 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore(index_name=\"projectrag\", embedding=hf_embeddings)\n",
        "\n",
        "index_name = \"projectrag\"\n",
        "\n",
        "namespace = \"youtube-video\""
      ],
      "metadata": {
        "id": "T6sq2iSY6sri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for document in texts:\n",
        "  print(\"-----------\")\n",
        "  print(document.metadata, document.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXcod13166KI",
        "outputId": "d2d6f15c-b350-4a53-bcfc-d310c478022d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------\n",
            "{'source': 'OuZrhykVytg'} in this video we're going to go over what are events in c-sharp how they work and how they're used we're going to see the benefits of events and how they are essential to keeping our code nice and clean but Vienna [Music] hello and welcome I'm your code monkey and this channel is all about helping you learn how to make your own games with enough tutorials made by a professional indie game developer so if you find the video helpful consider subscribing okay so if you've seen a bunch of my videos you've probably heard me mention two things one I always highlight the importance of writing clean code and two I use events to d-cup on various systems and keep my code clean if you want to write good quality code you need to learn and use events the good thing is they're actually very easy so events aren't just a way of saying something happened without knowing or caring about who is listening if anyone you have publishers and subscribers the publisher has its event and these subscribers can subscribe to that event multiple subscribers can subscribe to the same event then when something happens the publisher fires off the event and all these subscribers get notified that the event was fired the key thing is that the publisher does not know who these subscribers are so there might be lots of them or there might be none they might process the event or completely ignore it the publisher doesn't know and doesn't care who is listening and what they did with that information so this allows you to write code in the publisher that is decoupled from whatever other code you also want to run that isn't essential this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get some perks and help keep the videos free for everyone one way you've seen me use events a lot is to keep the illogic and visual separate normally you don't want your logic code to be tightly coupled with the visual you want a logic to work on its own regardless of whether or not there's a visual component the visual should just display what is happening inside and logic so to keep those separate the logic class fires off events which may or may not be caught by a class at Hamill's the visuals for example I made the unlevel system quite a long time ago and as always implement the logic and events and connected that test visual to those events and recently I made a video on a skill tree and I use the exact same level system class the difference is only individual on the level system I had a dummy character some buttons and a bar and on the skill tree I have a moving player and the experience bar with a level counter since I used events I didn't have to modify any of the code inside the unlevel system because I use the same logic and only change the visuals so using events allowed me to very easily reuse that class in a completely different project all right let's look at some code so over here I have my basic script now the way you define an event is very simple first you define the accessor so in this case let's make it public and then you use the event keyword so this is how you define that this film is going to be an event then we need to know the type and now the center time for events as used in the.net standard is the event handler which is inside using system now if an handler as you can see it's just a simple delegate with two fields we have an object for the center and the event args which we'll cover in a bit so we define the type and then we just pass in the name so in this case um let's call it on space press normally you also name it starring with on and then whatever it represents so on space pressed on enemy killed on play win and so on so here we have defined our event now let's see how we can trigger and how to subtract first let's do the trigger so in here let's make our update function and let's test for the spacebar bring down and when we press the spacebar and let's fire off our event so to do that we call our event as if it were a function so on space pressed and we just count now for the similar let's just pass in this and for the event args since we don't have any extra information we can use the constant event our X dot empty and that's it so over here we are firing off our event whenever we press the spacebar so let's try it out okay here we are the game is running here is the console and press space and there we go we have an error we have a known reference exception now the reason is because right now we do not have any subscribers so the underlying structure for our event is set to no so when we fire an event we need to first test that the event is not know so if on space pressed if there is not now then we actually do fire off our event now I can press the spacebar and there you go we do not have an error and since C sharp 6 we can shorten this in order to use the null conditional operator so we just do question mark and then call invoke so this does the exact same thing it invokes event only if on space pressed is not no and again here I am and I'm pressing space and there we go no errors awesome so now that we have the event being fired let's do something with it now in order to subscribe to the event first we define a function that will receive that event now the function signature needs to be the same as event so in this case we're going to make a function that takes a object and the event args parameter so here we have our function which matches this signature and when we have different relatively simple debug log ok now in order to subscribe we access the event so on space pressed and we do plus equals and we add our function so this is how we add our function onto this event so when this event is invoked it won't call the functions attached to that event which in this case is this function so when we press space it's going to run this code and do a lock let's see so here we are and now I press space and there yo we have our log so our event is being fired when we press space and it's being captured by that function which then does a lock ok great now here we are triggering and listening to the event on the same class but the benefits are when we listen from somewhere else so let's do that in the editor and let's make another script and let's attach this script into the same game object ok and now in here first we need to get a reference to our other script so since they're on the same game object we just do get component of our testing event script and now with this reference we can access our event on space pressed and just like before we do pause equals and then we add our function and now if you're using Visual Studio you can use code completion to really speed this up so we're here as you can see I can press tab and there you go it automatically creates the function and now here let's do the same debug log ok so that's it now back into the publisher script and let's get rid of this one so this script is only responsible for firing off the event and then this script accesses now one end subscribes to that event let's see okay so here we are in our press space any of there you go we have our message and if in here we remove the subscriber script and I'll run again and I press space and there you go we do not have any errors and everything is still running exactly the same so the publisher class does not require the subscriber to exist alright so here we have our example we have this class which fires off this event and this class is absolutely no knowledge that this other class exists so this one just fires off the event whether someone is listening or not which again this is perfect for separating logic and visuals you need visuals to know about logic but you do not want the logic to know about the visuals you want a logic to be able to work with or without the visuals so you just have your logic fair enough events in your visuals if they exist listening to those events now here we are subscribing to the event but as you can imagine we can also unsubscribe so uncertain let's subscribe and then after receiving the event once let's unsubscribe so to unsubscribe instead of pause equals we do minus equals so that's it let's test ok here we are and let's press space and there you go we have the unlock function but now press space again and there you go no more messages so we unsubscribed so we stopped receiving the events now in here we're using the event handler which as you can see has two fields an object and an event args the event Rx is the standard way for passing more information through the event so the way we do that is first we make a class that derives from event args and now in here we define whatever fields we want so let's say we have an end for this place County and now up here when we define the event we can use the generic version and pass in our specific event args as the generic parameter so in this case on Swiss press event arts so now our event won't contain an object of this type on the second parameter so down here you can already see the error in here we need to pass in of type on space pressed event args so we do a new and we create our object so just like that so whenever we press space we are incrementing this local field then we're firing out the event and constructing a on space pressed event args and passing in a specific parameter and now we go back into our subscriber and here we modify our signature to receive our new time and now we can access that new type and we can get for example D space count so just like this we're passing extra data along with our event now let's see so here we are in press space and yep there it is we have our event being filed and passing along some extra than\n",
            "-----------\n",
            "{'source': 'OuZrhykVytg'} field then we're firing out the event and constructing a on space pressed event args and passing in a specific parameter and now we go back into our subscriber and here we modify our signature to receive our new time and now we can access that new type and we can get for example D space count so just like this we're passing extra data along with our event now let's see so here we are in press space and yep there it is we have our event being filed and passing along some extra than that awesome now another thing about events is you do not have to use event handler this is just the normal dotnet standard events work with delegates and if an handler is simply D standard delegate so here we can define our own delegate so here we the finally delegate it returns void and takes a parameter for a float now if you're not familiar with delegates they are essentially function signatures let me know in the comments if you'd like to see a video dedicated just to delegates now we can make an event of this time so again we passing the event keyword and then our specific delegate type and we can fire up very much in the same way so we can't invoke and in this case we take a fold parameter okay so we have our event being fired and now back in the subscriber and here let's subscribe to our new event so on float event plus equals press tab and there you go there's our automatic event which as you can see takes a full parameter and just like that alright so let's test okay so here we are on press space and there you go we have our vent being fired on with a fault parameter and again if we're working with delegates then we can also use the default delegate called action so you make a public event and we can use the time action so action as you can see as you see don't forget that returns void and action also has a generic version so you can define it with a bunch of different types so in this case and what's the final action that takes a boolean and an integer and then down here we fire off the event just like we do every time so there it is we have our event working with an action that takes a boolean and an int and then here we subscribe the same way and let's test and here we are and yep we have all of our events working so you can see how you're not forced to work event handler you can use whatever that'll get you want personally I like to stick with the standard so use event handler and then if I need extra info I create an event arts but you can use whatever time we get you want now another thing specific to unity our unity events these were pretty much the same way with difference being that they are shown in the editor so in here we make a public of time unity event and unity event is inside unity engine that events so here we have our unity event then we invoke it exactly the same way so we called out invoke in this case we have no parameters and also note how this does not have the event keyword and now if we go back into the editor with our object selected you can see over here in the inspector we have a field for our unity event so we can click the plus icon and in here some liked an object so let's select this same object and then we can select a function from that so let's make a function to call here in our subscriber script let's make it so here we have a function with no parameters returning void and it's public and now back into the editor over here we can select that function so click in here then we go into our script testing event subscriber and down here we have our testing unity event function so select it and now let's tests so here we are in press space and if there you go everything is working correctly here we have our testing unit event main trigger so the main benefit of unity events are that you can easily set them in the editor so if you're trying to make your game more fun to designers this may be a good tool alright so here we looked on how events work how they're used and what are the main benefits as you saw events are excellent for helping you keep your code nice and organized it allows objects to work with other objects without being tightly coupled this video is made possible thanks to these awesome supporters go to patreon.com/scishow to code monkey to get parks and help keep the videos free for everyone as always you can download the project files in Italy's room in tucumán calm subscribe to the channel for more unity tutorials post any questions I have in the comments and I'll see you next time [Music]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore(index_name=index_name, embedding=hf_embeddings)"
      ],
      "metadata": {
        "id": "UJO-G0uU6-WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precomputed_embeddings = [\n",
        "    hf_embeddings.embed_query(\n",
        "        f\"Source: {t.metadata.get('source', 'Unknown Source')}, \"\n",
        "        f\"Title: {t.metadata.get('title', 'Untitled')} \\n\\n\"\n",
        "        f\"Content: {t.page_content}\"\n",
        "    )\n",
        "    for t in texts\n",
        "]"
      ],
      "metadata": {
        "id": "viIYv5qN7B1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, document in enumerate(texts):\n",
        "    embedding = precomputed_embeddings[i]\n",
        "    vectorstore.add_texts(\n",
        "        texts=[document.page_content],\n",
        "        metadatas=[document.metadata],\n",
        "        embeddings=[embedding],\n",
        "        namespace=\"youtube-video\"\n",
        "    )"
      ],
      "metadata": {
        "id": "_4CPQiSd7bb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone(api_key=userdata.get(\"PINECONE_API_KEY\"))\n",
        "pinecone_index = pc.Index(\"projectrag\")"
      ],
      "metadata": {
        "id": "dWVBjvqW7wp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_youtube_rag(query):\n",
        "    query_embedding = hf_embeddings.embed_query(query)\n",
        "\n",
        "    top_matches = pinecone_index.query(vector=query_embedding, top_k=10, include_metadata=True, namespace=namespace)\n",
        "\n",
        "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
        "\n",
        "    augmented_query = \"\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
        "\n",
        "    system_prompt = f\"\"\"You are an expert personal assistant. Answer any questions I have about the Youtube Video provided. You always answer questions based only on the context that you have been provided.\n",
        "    \"\"\"\n",
        "\n",
        "    res = openrouter_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": augmented_query}\n",
        "    ]\n",
        "    )\n",
        "\n",
        "    return res.choices[0].message.content"
      ],
      "metadata": {
        "id": "h0c6Rl7n7wrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_youtube_rag(\"How to Create Events in Unity\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1IFOvUHF8Yg5",
        "outputId": "def7b5c0-5d8e-4719-e481-730936a3a905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To create events in Unity, you can follow these general steps based on the provided context from the video:\\n\\n1. Define an Event: Start by defining an event within your script. You can create an event by using the `event` keyword, specifying the access modifier (such as public), and assigning a delegate type. The delegate type commonly used for events in C# is `EventHandler`.\\n\\n2. Trigger the Event: To trigger the event, you can call the event as if it were a function. This is typically done when a specific action or condition occurs in your game.\\n\\n3. Subscribe to the Event: Define a function that will receive the event when it is triggered. The function signature should match the delegate type of the event. Subscribe to the event by using the `+=` operator and adding your function to the list of event subscribers.\\n\\n4. Unsubscribe from the Event: If needed, you can unsubscribe from the event by using the `-=` operator, removing your function from the list of event subscribers.\\n\\n5. Pass Additional Data (Optional): If you need to pass additional information along with the event, you can create a custom class that derives from `EventArgs` and define the necessary fields. Modify the event delegate type to include this custom event args type for passing extra data along with the event.\\n\\n6. Working with Unity Events: In Unity, you can also use Unity Events for setting up event triggers in the Inspector. To work with Unity Events, create a public UnityEvent variable in your script and invoke it when needed. You can set up the Unity Event in the Inspector by selecting a function to call when the event is triggered.\\n\\nRemember, creating events in Unity allows for decoupling different components of your game and can help in organizing and managing interactions within your game code.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"Statistics-book.pdf\")\n",
        "data = loader.load()\n",
        "\n",
        "print(data)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2000,\n",
        "        chunk_overlap=100,\n",
        "        length_function=tiktoken_len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "texts = text_splitter.split_documents(data)\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)\n",
        "\n",
        "vectorstore_from_texts = PineconeVectorStore.from_texts(\n",
        "    [f\"Source: {t.metadata.get('source', 'Unknown')}, Title: {t.metadata.get('title', 'Unknown')} \\n\\nContent: {t.page_content}\" for t in texts],\n",
        "    embeddings,\n",
        "    index_name=index_name,\n",
        "    namespace=namespace\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grfnEgR_9dYw",
        "outputId": "21742ab8-0d92-4f79-8a29-d981aa4260fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'Statistics-book.pdf', 'page': 0}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       i                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nVirtual University of Pakistan \\n \\nStatistics and Probability \\n \\nSTA301 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 1}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       ii                                                                                                                                           \\nTABLE OF CONTENTS \\n \\n \\nTITLE                                                           PAGE NO \\nLECTURE NO. 1                      1 \\nDefinition of Statistics \\nObservation and Variable \\nTypes of Variables \\nMeasurement Sales \\nError of Measurement \\nLECTURE NO. 2                                      6 \\nData collection \\nSampling \\nLECTURE NO. 3                                   16 \\nTypes of Data \\nTabulation and Presentation of Data \\nFrequency distribution of Discrete variable \\nLECTURE NO. 4                                   23 \\nFrequency distribution of continuous variable \\nLECTURE NO. 5                                    32 \\nTypes o frequency Curves \\nCumulative frequency Distribution \\nLECTURE NO.  6                     42 \\nStem and Leaf  \\nIntroduction to Measures of Central Tendency \\nMode \\nLECTURE NO. 7                                     53 \\nArithmetic Mean \\nWeighted Mean \\nMedian in case of ungroup Data \\nLECTURE NO.  8                                                         62 \\nMedian in case of group Data \\nMedian in case of an open-ended frequency distribution \\nEmpirical relation between the mean, median and the mode \\nQuantiles (quartiles, deciles & percentiles) \\nGraphic location of Quantiles \\nLECTURE NO.  9                                    70 \\nGeometric mean \\nHarmonic mean \\nRelation between the arithmetic, geometric and harmonic means \\nSome other measures of central tendency \\nLECTURE NO. 10                       76 \\nConcept of dispersion \\nAbsolute and relative measures of dispersion \\nRange  \\nCoefficient of dispersion \\nQuartile deviation \\nCoefficient of quartile deviation \\nLECTURE NO. 11                                          82 \\nMean Deviation \\nStandard Deviation and Variance \\nCoefficient of variation \\nLECTURE NO.  12                    89 \\nChebychev’s Inequality \\nThe Empirical Rule  \\nThe Five-Number Summary \\n \\nLECTURE NO. 13                                     95 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 2}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       iii                                                                                                                                           \\nBox and Whisker Plot \\nPearson’s Coefficient of Skewness \\nLECTURE NO. 14                                  106 \\nBowley’s coefficient of Skewness \\nThe Concept of Kurtosis \\nPercentile Coefficient of Kurtosis \\nMoments & Moment Ratios \\nSheppard’s Corrections \\nThe Role of Moments in Describing Frequency Distributions \\nLECTURE NO. 15                    115 \\nSimple Linear Regression  \\nStandard Error of Estimate \\nCorrelation  \\nLECTURE NO. 16                                 128 \\nBasic Probability Theory \\nSet Theory \\nCounting Rules: \\nThe Rule of Multiplication  \\nLECTURE NO. 17                                  136 \\nPermutations \\nCombinations \\nRandom Experiment \\nSample Space  \\nEvents \\nMutually Exclusive Events \\nExhaustive Events \\nEqually Likely Events \\nLECTURE NO. 18                  143 \\nDefinitions of Probability \\nRelative Frequency Definition of Probability \\nLECTURE NO. 19                  147 \\nRelative Frequency Definition of Probability \\nAxiomatic Definition of Probability \\nLaws of Probability \\nRule of Complementation \\nAddition Theorem  \\nLECTURE NO. 20                  152 \\nApplication of Addition Theorem \\nConditional Probability \\nMultiplication Theorem \\nLECTURE NO. 21                  156 \\nIndependent and Dependent Events \\nMultiplication Theorem of Probability for Independent Events \\nMarginal Probability \\nLECTURE NO. 22                  161 \\nBayes’ Theorem \\nDiscrete Random Variable \\nDiscrete Probability Distribution \\nGraphical Representation of a Discrete Probability Distribution \\nMean, Standard Deviation and Coefficient of Variation of a Discrete Probability Distribution  \\nDistribution Function of a Discrete Random Variable \\nLECTURE NO. 23                  169 \\nGraphical Representation of the Distribution Function of a Discrete Random Variable  \\nMathematical Expectation   \\nMean, Variance and Moments of a Discrete Probability Distribution  \\nProperties of Expected Values \\n \\n \\nLECTURE NO. 24                  177 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 3}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       iv                                                                                                                                           \\nChebychev’s Inequality  \\nConcept of Continuous Probability Distribution  \\nMathematical Expectation, Variance & Moments of a Continuous Probability Distribution   \\nLECTURE NO. 25                  185 \\nMathematical Expectation, Variance & Moments of a Continuous Probability Distribution  \\nBIVARIATE Probability Distribution \\nLECTURE NO. 26                  192 \\nBIVARIATE Probability Distributions (Discrete and Continuous) \\nProperties of Expected Values in the case of Bivariate Probability Distributions \\nLECTURE NO. 27                  199 \\nProperties of Expected Values in the case of Bivariate Probability Distributions \\nCovariance & Correlation  \\nSome Well-known Discrete Probability Distributions: \\nDiscrete Uniform Distribution \\nAn Introduction to the Binomial Distribution \\nLECTURE NO. 28                  207 \\nBinomial Distribution \\nFitting a Binomial Distribution to Real Data \\nAn Introduction to the Hyper geometric Distribution  \\nLECTURE NO. 29                  215 \\nHyper geometric Distribution   \\nPoisson distribution and limiting approximation to Binomial  \\nPoisson Process \\nContinuous Uniform Distribution  \\nLECTURE NO. 30                  221 \\nNormal Distribution \\nThe Standard Normal Distribution  \\nNormal Approximation to the Binomial Distribution \\nLECTURE NO. 31                    232 \\nSampling Distribution of \\nX  \\nMean and Standard Deviation of the Sampling Distribution of \\nX  \\nCentral Limit Theorem \\nLECTURE NO. 32                  239 \\nSampling Distribution of \\npˆ   \\nSampling Distribution of  \\n21 XX \\uf02d    \\nLECTURE NO. 33                  249 \\nPoint Estimation \\nDesirable Qualities of a Good Point Estimator \\nLECTURE NO. 34                  256 \\nMethods of Point Estimation  \\nInterval Estimation \\nLECTURE NO. 35                  263 \\nConfidence Interval for \\uf06d   \\nConfidence Interval for \\uf06d1-\\uf06d2 \\nLECTURE NO. 36                  268 \\nLarge Sample Confidence Intervals for p and p1-p2  \\nDetermination of Sample Size (with reference to Interval Estimation) \\nHypothesis-Testing (An Introduction) \\nLECTURE NO. 37                  274 \\nHypothesis-Testing (continuation of basic concepts) \\nHypothesis-Testing regarding \\uf06d (based on Z-statistic \\nLECTURE NO. 38                   280 \\nHypothesis-Testing regarding \\uf06d1 - \\uf06d2    (based on Z-statistic) \\nHypothesis Testing regarding p      (based on Z-statistic) \\n \\nLECTURE NO. 39                  285 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 4}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       v                                                                                                                                           \\nHypothesis Testing regarding p1-p2 (based on Z-statistic) \\nThe Student’s t-distribution  \\nConfidence Interval for \\uf06d based on the t-distribution \\nLECTURE NO.  40                  292 \\nTests and Confidence Intervals based on the t-distribution  \\nt-distribution in case of paired observations \\nLECTURE NO. 41                  298 \\nHypothesis-Testing regarding Two Population Means in the Case of Paired Observations (t -distribution)  \\nThe Chi-square Distribution \\nHypothesis Testing and Interval Estimation Regarding a Population Variance (based on Chi -square \\nDistribution) \\nLECTURE NO. 42                  306 \\nThe F-Distribution \\nHypothesis Testing and Interval Estimation in order to compare the Variances of Two Normal  \\nPopulations (based on F-Distribution)  \\nLECTURE NO. 43                  315 \\nAnalysis of Variance   \\nExperimental Design  \\nLECTURE NO. 44                  323 \\nRandomized Complete Block Design    \\nThe Least Significant Difference (LSD) Test  \\nChi-Square Test of Goodness of Fit \\nLECTURE NO. 45                  331 \\nChi-Square Test of Independence \\nThe Concept of Degrees of Freedom \\nP-value \\nRelationship between Confidence Interval and Tests of Hypothesis \\nAn Overview of the Science of Statistics in Today’s World (including Latest'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 5}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       1                                                                                                                                           \\n \\n               \\nLECTURE NO. 1 \\n \\nWHAT IS STATISTICS? \\n \\n\\uf0b7 That science which enables us to draw conclusions about various phenomena on the basis of real data \\ncollected on sample-basis \\n\\uf0b7 A tool for data-based research \\n\\uf0b7 Also known as Quantitative Analysis \\n\\uf0b7 A lot of application in a wide variety of disciplines Agriculture, Anthropology, Astronomy, Biology, \\nEconomic, Engineering, Environment, Geology, Genetics, Medicine, Physics, Psychology, Sociology, \\nZoology …. Virtually every single subject from Anthropology to Zoology …. A to Z!  \\n\\uf0b7 Any scientific enquiry in which you would like to base your conclusions and decisions on real-life data, you \\nneed to employ statistical techniques! \\n\\uf0b7 Now a day, in the developed countries of the world, there is an active movement for of Statistical Literacy. \\n \\n                   THE NATURE OF THIS DISCIPLINE \\n \\n                                             DESCRIPTIVE STATISTICS  \\n                                                               \\n \\n                                                        PROBABILITY   \\n \\n \\n                                             INFERENTIAL STATISTICS \\n \\n                            \\n \\n \\nMEANINGS OF ‘STATISTICS’ \\n \\n \\nThe word “Statistics” which comes from the Latin words status, meaning a political state, originally meant information \\nuseful to the state, for example, information about the sizes of population sand armed forces. But this word has now \\nacquired different meanings. \\n \\n\\uf0b7 In the first place , the word statistics refers to “numerical facts systematically arranged”. In this sense, th e \\nword statistics is always used in plural. We have, for instance, statistics of prices, statistics of road accidents, \\nstatistics of crimes, statistics of births, statistics of educational institutions, etc. In all these examples, the \\nword statistics denot es a set of numerical data in the respective fields. This is the meaning the man in the \\nstreet gives to the word Statistics and most people usually use the word data instead. \\n \\n\\uf0b7 In the second place, the word statistics is defined as a discipline that includes procedures and techniques used \\nto collect process and analyze numerical data to make inferences and to research decisions in the face of '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 6}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       2                                                                                                                                           \\nuncertainty. It should of course be borne in mind that uncertainty does not imply ignorance but it refers to the \\nincompleteness and the instability of data available. In this sense, the word statistics is used in the singular. \\nAs it embodies more of less all stages of the general process of learning, sometimes called scientific method, \\nstatistics is characterized as a sc ience. Thus the word statistics used in the plural refers to a set of numerical \\ninformation and in the singular, denotes the science of basing decision on numerical data. It should be noted \\nthat statistics as a subject is mathematical in character. \\n \\n\\uf0b7 Thirdly, the word statistics are numerical quantities calculated from sample observations; a single quantity \\nthat has been so collected is called a statistic. The mean of a sample for instance is a statistic. The word \\nstatistics is plural when used in this sense. \\n \\nCHARACTERISTICS OF THE SCIENCE OF STATISTICS \\n \\nStatistics is a discipline in its own right. It would therefore be desirable to know the characteristic features of statistic s \\nin order to appreciate and understand its general nature. Some of its important characteristics are given below: \\n \\n\\uf0b7 Statistics deals with the behaviour of aggregates or large groups of data. It has nothing to do with what is \\nhappening to a particular individual or object of the aggregate.  \\n\\uf0b7 Statistics deals with aggregates of observations of the same kind rather than isolated figures. \\n\\uf0b7 Statistics deals with variability that obscures underlying patterns. No two objects in this universe are exactly \\nalike. If they were, there would have been no statistical problem. \\n\\uf0b7 Statistics deals with uncertainties as every process of getting observations whether controlled or uncontrolled, \\ninvolves deficiencies or chance variation. That is why we have to talk in terms of probability. \\n\\uf0b7 Statistics deals with those characteristics or aspects of things which can  be described numerically either by \\ncounts or by measurements.  \\n\\uf0b7 Statistics deals with those aggregates which are subject to a number of random causes, e.g. the heights of \\npersons are subject to a number of causes such as race, ancestry, age, diet, habits, climate and so forth. \\n\\uf0b7 Statistical laws are valid on the average or in the long run. There is n guarantee that a certain law will hold in \\nall cases. Statistical inference is therefore made in the face of uncertainty. \\n\\uf0b7 Statistical results might be misleading the incorrect if sufficient care in collecting, processing and interpreting \\nthe data is not exercised or if the statistical data are handled by a person who is not well versed in the subject \\nmater of statistics. \\nTHE WAY IN WHICH STATISTICS WORKS \\n \\nAs it is such an important area of knowledge, it is definitely useful to have a fairly good idea about the way in which it \\nworks, and this is exactly the purpose of this introductory course.  \\nThe following points indicate some of the main functions of this science: \\n \\n\\uf0b7 Statistics assists in summarizing the larger set of data in a form that is easily understandable. \\n\\uf0b7 Statistics assists in the efficient design of laboratory and field experiments as well as surveys. \\n\\uf0b7 Statistics assists in a sound and effective planning in any field of inquiry.  \\n\\uf0b7 Statistics assists in drawing general conclusions and in making predictions of how much of a thing will \\nhappen under given conditions. \\nIMPORTANCE OF STATISTICS IN VARIOUS FIELDS \\n \\nAs stated earlier, Statistics is a discipline that has finds application in the most diverse fields of activity. It is perhaps a \\nsubject that should be used by everybody. Statistical techniques being powerful tools for analyzing numerical data are \\nused in almost every branch of learning. In all areas, statisti cal techniques are being increasingly used, and are \\ndeveloping very rapidly. '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 7}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       3                                                                                                                                           \\n\\uf0b7 A modern administrator whether in public or private sector leans on statistical data to provide a factual basis \\nfor decision. \\n\\uf0b7 A politician uses statistics advantageously to lend support and credence to his arguments while elucidating the \\nproblems he handles. \\n\\uf0b7 A businessman, an industrial and a research worker all employ statistical methods in their work. Banks, \\nInsurance companies and Government all have their statistics departments.  \\n\\uf0b7 A social scientist uses statistical methods in various areas of socio-economic life a nation. It is sometimes said \\nthat “a social scientist without an adequate understanding of statistics, is often like the blind man groping in a \\ndark room for a black cat that is not there”. \\nTHE MEANING OF DATA \\n \\nThe word “data” appears in many contexts and frequently is used in ordinary conversation. Although the word carries \\nsomething of an aura of scientific mystique, its meaning is quite simple and mundane. It is Lati n for “those that are \\ngiven” (the singular form is “datum”). Data may therefore be thought of as the results of observation.  \\n \\nEXAMPLES OF DATA \\n \\n\\uf0b7 Data are collected in many aspects of everyday life.  \\n\\uf0b7 Statements given to a police officer or physician or psychologist during an interview are data.  \\n\\uf0b7 So are the correct and incorrect answers given by a student on a final examination.  \\n\\uf0b7 Almost any athletic event produces data.  \\n\\uf0b7 The time required by a runner to complete a marathon,  \\n\\uf0b7 The number of errors committed by a baseball team in nine innings of play.  \\n \\n\\uf0b7 And, of course, data are obtained in the course of scientific inquiry:  \\n\\uf0b7 the positions of artifacts and fossils in an archaeological site,  \\n\\uf0b7 The number of interactions between two members of an animal colony during a period of observation,  \\n\\uf0b7 The spectral composition of light emitted by a star. \\n \\nOBSERVATIONS AND VARIABLES \\n \\nIn statistics, an observation often means any sort of numerical recording of information, whether it is a physical \\nmeasurement such as height or wei ght; a classification such as heads or tails, or an answer to a question such as yes or \\nno. \\n \\nVARIABLES \\n \\nA characteristic that varies with an individual or an object is called a variable. For example, age is a variable as it varies \\nfrom person to person. A variable can assume a number of values. The given set of all possible values from which the \\nvariable takes on a value is called its Domain. If for a given problem, the domain of a variable contains only one value, \\nthen the variable is referred to as a constant. \\n \\nQUANTITATIVE AND QUALITATIVE VARIABLES \\n \\nVariables may be classified into quantitative and qualitative according to the form of the characteristic of interest. A \\nvariable is called a quantitative variable  when a characteristic can be expressed numeri cally such as age, weight, \\nincome or number of children. On the other hand, if the characteristic is non -numerical such as education, sex, eye -\\ncolour, quality, intelligence, poverty, satisfaction, etc. the variable is referred to as a qualitative variable. A qualitative \\ncharacteristic is also called an attribute. An individual or an object with such a characteristic can be counted or \\nenumerated after having been assigned to one of the several mutually exclusive classes or categories. \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 8}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       4                                                                                                                                           \\nDISCRETE AND CONTINUOUS VARIABLES \\n \\nA quantitative variable may be classified as discrete or continuous. A discrete  variable is one that can take only a \\ndiscrete set of integers or whole numbers, which is the values, are taken by jumps or breaks. A discrete variable \\nrepresents count data such as the number of persons in a family, the number of rooms in a house, the number of deaths \\nin an accident, the income of an individual, etc. \\n          A variable is called a continuous variable if it can take on any value -fractional or inte gral––within a given \\ninterval, i.e. its domain is an interval with all possible values without gaps. A continuous variable represents \\nmeasurement data such as the age of a person, the height of a plant, the weight of a commodity, the temperature at a \\nplace, etc. \\n         A variable whether countable or measurable, is generally denoted by some symbol such as X or Y and X i or Xj \\nrepresents the ith or jth value of the variable. The subscript i or j is replaced by a number such as 1,2,3, … when referred \\nto a particular value. \\n \\nMEASUREMENT SCALES \\n \\nBy measurement, we usually mean the assigning of number to observations or objects and scaling is a process of \\nmeasuring. The four scales of measurements are briefly mentioned below: \\n \\nNOMINAL SCALE \\n \\nThe classification o r grouping of the observations into mutually exclusive qualitative categories or classes is said to \\nconstitute a nominal scale. For example, students are classified as male and female. Number 1 and 2 may also be used \\nto identify these two categories. Simil arly, rainfall may be classified as heavy moderate and light. We may use number \\n1, 2 and 3 to denote the three classes of rainfall. The numbers when they are used only to identify the categories of the \\ngiven scale carry no numerical significance and there is no particular order for the grouping.  \\n \\nORDINAL OR RANKING SCALE \\n \\nIt includes the characteristic of a nominal scale and in addition has the property of ordering or ranking of \\nmeasurements. For example, the performance of students (or players) is rated a s excellent, good fair or poor, etc. \\nNumber 1, 2, 3, 4 etc. are also used to indicate ranks. The only relation that holds between any pair of categories is that \\nof “greater than” (or more preferred). \\n  \\nINTERVAL SCALE \\n \\nA measurement scale possessing a const ant interval size (distance) but not a true zero point, is called an interval scale. \\nTemperature measured on either the Celsius or the Fahrenheit scale is an outstanding example of interval scale because \\nthe same difference exists between 20o C (68o F) and 30o C (86o F) as between 5o C (41o F) and 15o C (59o F). It cannot \\nbe said that a temperature of 40 degrees is twice as hot as a temperature of 20 degree, i.e. the ratio 40/20 has no \\nmeaning. The arithmetic operation of addition, subtraction, etc. is meaningful. \\n \\nRATIO SCALE \\n \\nIt is a special kind of an interval scale where the sale of measurement has a true zero point as its origin. The ratio scale \\nis used to measure weight, volume, distance, money, etc. The, key to differentiating interval and ratio scale  is that the \\nzero point is meaningful for ratio scale. \\n \\nERRORS OF MEASUREMENT \\n \\nExperience has shown that a continuous variable can never be measured with perfect fineness because of certain habits \\nand practices, methods of measurements, instruments used, e tc. the measurements are thus always recorded correct to \\nthe nearest units and hence are of limited accuracy. The actual or true values are, however, assumed to exist. For \\nexample, if a student’s weight is recorded as 60 kg (correct to the nearest kilogram ), his true weight in fact lies between \\n59.5 kg and 60.5 kg, whereas a weight recorded as 60.00 kg means the true weight is known to lie between 59.995 and \\n60.005 kg.  Thus there is a difference, however small it may be between the measured value and the t rue value. This \\nsort of departure from the true value is technically known as the error of measurement.  In other words, if the observed \\nvalue and the true value of a variable are denoted by x and x + \\uf065 respectively, then the difference (x + \\uf065) – x, i.e. \\uf065 is the \\nerror. This error involves the unit of measurement of x and is therefore called an absolute error . An absolute error \\ndivided by the true value is called the relative error. Thus the relative error\\n\\uf065\\uf02b\\n\\uf065\\uf03d x , which when multiplied by 100, \\nis percentage error. These errors are independent of the units of measurement of x. It ought to be noted that an error has \\nboth magnitude and direction and that the word error in statistics does not mean mistake which is a chance inaccuracy. '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 9}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       5                                                                                                                                           \\n \\nBIASED AND RANDOM ERRORS \\n \\nAn error is said to be biased when the observed value is consistently and constantly higher or lower than the true value. \\nBiased errors arise from the personal limitations of the observer, the imperfection in the instruments used or some other  \\nconditions which control the measurements. These errors are not revealed by repeating the measurements. They are \\ncumulative in nature, that is, the greater the number of measurements, the greater would be the magnitude of error. \\nThey are thus more troublesome. These errors are also called cumulative or systematic errors. \\nAn error, on the other hand, is said to be unbiased when the deviations, i.e. the excesses and defects, from the true value \\ntend to occur equally often. Unbiased errors and revealed when m easurements are repeated and they tend to cancel out \\nin the long run. These errors are therefore compensating and are also known as random errors or accidental errors.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 10}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       6                                                                                                                                           \\nLECTURE NO. 2  \\n \\n \\nSteps involved in a Statistical   Research-Project \\n\\uf0b7 Collection of Data: \\n\\uf0d8 Primary Data \\n\\uf0d8 Secondary Data \\n\\uf0b7 Sampling: \\n\\uf0d8 Concept of Sampling \\n\\uf0d8 Non-Random Versus Random Sampling \\n\\uf0d8 Simple Random Sampling \\n\\uf0d8 Other Types of Random Sampling \\n \\nSTEPS INVOLVED IN ANY STATISTICAL RESEARCH \\n \\n\\uf0b7 Topic and significance of the study \\n\\uf0b7 Objective of your study \\n\\uf0b7 Methodology for data-collection \\n\\uf0d8 Source of your data \\n\\uf0d8 Sampling methodology \\n\\uf0d8 Instrument for collecting data \\n \\nAs far as the objectives of your research are concerned, they should be stated in such a way that you are absolutely clear \\nabout the goal of your study --- EXACTLY WHAT IT IS THAT YOU ARE TRYING TO FIND OUT? \\nAs far as the methodology for DATA-COLLECTION is concerned, you need to consider: \\n \\n\\uf0b7 Source of your data   (the statistical population)  \\n\\uf0b7 Sampling Methodology  \\n\\uf0b7 Instrument for collecting data \\n \\nCOLLECTION OF DATA \\n \\nThe most important part of statistical work is perhaps the collection of data.  Statistical data are collected either by a \\nCOMPLETE enumeration of the whole field, called CENSUS, which in many cases would be too costly and too time \\nconsuming as it requires large number of enumerators and supervisory staff, or by a PARTIAL enumeration associated \\nwith a SAMPLE which saves much time and money. \\n \\nPRIMARY AND SECONDARY DATA \\n \\nData that have been originally collect ed (raw data) and have not undergone any sort of statistical treatment, are called \\nPRIMARY data. Data that have undergone any sort of treatment by statistical methods at least ONCE, i.e. the data that \\nhave been collected, classified, tabulated or presented in some form for a certain purpose, are called SECONDARY data. \\n \\nCOLLECTION OF PRIMARY DATA  \\nOne or more of the following methods are employed to collect primary data: \\n\\uf0b7 Direct Personal Investigation    \\n\\uf0b7 Indirect Investigation \\n\\uf0b7 Collection through Questionnaires  \\n\\uf0b7 Collection through Enumerators  \\n\\uf0b7 Collection through Local Sources   \\n \\nDIRECT PERSONAL INVESTIGATION \\n \\nIn this method, an investigator collects the information personally from the individuals concerned. Since he interviews \\nthe informants himself, the information collected is generally considered quite accurate and complete. This method may \\nprove very costly and time -consuming when the area to be covered is vast. However, it is useful for laboratory \\nexperiments or localized inquiries. Errors are likely to enter the results due to personal bias of the investigator.  \\n \\nINDIRECT INVESTIGATION \\n \\nSometimes the direct sources do not exist or the informants hesitate to respond for some reason or other. In such a case, \\nthird parties or witnesses having information are i nterviewed. Moreover, due allowance is to be made for the personal \\nbias. This method is useful when the information desired is complex or there is reluctance or indifference on the part of \\nthe informants. It can be adopted for extensive inquiries. '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 11}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       7                                                                                                                                           \\nCOLLECTION THROUGH QUESTIONNAIRES \\n \\nA questionnaire is an inquiry form comprising of a number of pertinent questions with space for entering information \\nasked. The questionnaires are usually sent by mail, and the informants are requested to return the questionnaire s to the \\ninvestigator after doing the needful within a certain period. This method is cheap, fairly expeditious and good for \\nextensive inquiries. But the difficulty is that the majority of the respondents (i.e. persons who are required to answer the \\nquestions) do not care to fill the questionnaires in, and to return them to the investigators. Sometimes, the \\nquestionnaires are returned incomplete and full of errors. Students, in spite of these drawbacks, this method is \\nconsidered as the STANDARD method for routine business and administrative inquiries.  \\n It is important to note that the questions should be few, brief, very simple, and easy  for all respondents \\nanswer, clearly worded and not offensive to certain respondents. \\n \\nCOLLECTION THROUGH ENUMERATORS \\n \\nUnder this method, the information is gathered by employing  trained enumerators who assist the informants in making \\nthe entries in the schedules or questionnaires correctly. This method gives the most reliable information if the \\nenumerator is well -trained, ex perienced and tactful. Students, it is considered the BEST method when a large -scale \\ngovernmental inquiry is to be conducted. This method can generally not be adopted by a private individual or institution \\nas its cost would be prohibitive to them. \\n \\nCOLLECTION THROUGH LOCAL SOURCES \\n \\n In this method, there is no formal collection of data but the agents or local  correspondents are directed to collect and \\nsend the required information, using their own judgment as to the best way of obtaining it. This method is cheap and \\nexpeditious, but gives only the estimates.  \\n \\nCOLLECTION OF SECONDARY DATA \\n      \\nThe secondary data may be obtained from the following sources: \\n\\uf0b7 Official, e.g. the publications of the Statistical Division, Ministry of Finance, the Federal and Provincial \\nBureaus of Statistics, Ministries of Food, Agriculture, Industry, Labour, etc. \\n\\uf0b7 Semi-Official, e.g., State Bank of Pakistan, Railway Board, Central Cotton Committee, Boards of Economic \\nInquiry, District Councils, Municipalities, etc. \\n\\uf0b7 Publications of Trade Associations, Chambers of Commerce, etc \\n\\uf0b7 Technical and Trade Journals and Newspapers \\n\\uf0b7 Research Organizations such as universities, and other institutions \\n \\nLet us now consider the POPULATION from which we will be collecting our data . In this context, the  first important \\nquestion is: Why do we have to resort to Sampling? \\nThe answer is that: If we have available to us every value of the variable under study, then that would be an ideal and a \\nperfect situation. But, the problem is that this ideal situation i s very rarely available --- very rarely do we have access to \\nthe entire population.  \\nThe census is an exercise in which an attempt is made to cover the entire population.  But, as you might know, even the \\nmost developed countries of the world cannot afford to conduct such a huge exercise on an annual basis! \\nMore often than not, we have to conduct our research study on a sample basis.  In fact, the goal of the science of \\nStatistics is to draw conclusions about large populations on the basis of information contained in small samples.  \\n \\n‘POPULATION’ \\n \\nA statistical population is the collection of every member of a group possessing the same basic and defined \\ncharacteristic, but varying in amount or quality from one member to another. \\n \\nEXAMPLES \\n \\n\\uf0b7 Finite population: \\n\\uf0d8 IQ’s of all children in a school.                  \\n\\uf0b7 Infinite population: \\n\\uf0d8 Barometric pressure:  \\n(There are an indefinitely large number of points on the surface of the earth). \\n\\uf0d8 A flight of migrating ducks in Canada  \\n (Many finite pops are so large that they can be treated as effectively infinite). The examples that we have just \\nconsidered are those of existent populations. \\nA hypothetical population can be defined as the aggregate of all the conceivable ways in which a specified event can \\nhappen.  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 12}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       8                                                                                                                                           \\nFor Example: \\n\\uf0b7 1)All the possible outcomes from the throw of a die – however long we throw the die and record the results, \\nwe could always continue to do so far a still longer period in a theoretical concept – one which has no \\nexistence in reality. \\n\\uf0b7 2) The No. of ways in which a football team of 11 players can be selected from the 16 possible members \\nnamed by the Club Manager. \\nWe also need to differentiate between the sampled population and the target population. Sampled population is that \\nfrom which a sample is chosen whereas the population about which information is sought is called the target population \\nthus our population will consist of the total no. of students in all the colleges in the Punjab. \\n Suppose on account of shortage of resources or of time, we are able to c onduct such a survey on only 5 \\ncolleges scattered throughout the province. In this case, the students of all the colleges will constitute the target pop \\nwhereas the students of those 5 colleges from which the sample of students will be selected will consti tute the sampled \\npopulation. The above discussion regarding the population, you must have realized how important it is to have a very \\nwell-defined population. \\nThe next question is: How will we draw a sample from our population?  \\nThe answer is that:  In ord er to draw a random sample from a finite population, the first thing that we need is the \\ncomplete list of all the elements in our population. \\nThis list is technically called the FRAME. \\n \\nSAMPLING FRAME \\n \\nA sampling frame is a complete list of all the elements in the population. For example:  \\n\\uf0b7 The complete list of the BCS students of Virtual University of Pakistan on February 15, 2003  \\n\\uf0b7 Speaking of the sampling frame, it must be kept in mind that, as far as possible, our frame should be free from \\nvarious types of defects: \\n\\uf0b7 does not contain inaccurate elements \\n\\uf0b7 is not incomplete \\n\\uf0b7 is free from duplication, and \\n\\uf0b7 Is not out of date. \\nNext, let’s talk about the sample that we are going to draw from this population. \\nAs you all know, a sample is only a part of a statistical population, and hence it can represent the population to only to \\nsome extent. Of course, it is intuitively logical that the larger the sample, the more likely it is to represent the \\npopulation. Obviously, the limiting case is that: when the sample size ten ds to the population size, the sample will tend \\nto be identical to the population. But, of course, in general, the sample is much smaller than the population.  \\nThe point is that, in general, statistical sampling seeks to determine how accurate a descriptio n of the population the \\nsample and its properties will provide. We may have to compromise on accuracy, but there are certain such advantages \\nof sampling because of which it has an extremely important place in data-based research studies.  \\n \\nADVANTAGES OF SAMPLING  \\n \\n1.  Savings in time and money. \\n\\uf0b7 Although cost per unit in a sample is greater than in a complete investigation, the total cost will \\nbe less (because the sample will be so much smaller than the statistical population from which \\nit has been drawn). \\n\\uf0b7 A sample survey can be completed faster than a full investigation so that variations from \\nsample unit to sample unit over time will largely be eliminated. \\n\\uf0b7 Also, the results can be processed and analyzed with increased speed and precision because \\nthere are fewer of them. \\n2. More detailed information may be obtained from each sample unit. \\n3. Possibility of follow-up:  \\n(After detailed checking, queries and omissions can be followed up --- a procedure which might prove impossible in a \\ncomplete survey). \\n4. Sampling is the only feasible possibility where tests to destruction are undertaken or where the population is \\neffectively infinite. \\nThe next two important concepts that need to be considered are those of sampling and non-sampling errors. \\n \\nSAMPLING & NON-SAMPLING ERRORS \\n \\n1. SAMPLING ERROR \\n \\nThe difference between the estimate derived from the sample (i.e. the statistic) and the true population value (i.e. the \\nparameter) is technically called the sampling error. For example, \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 13}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       9                                                                                                                                           \\nSampling error arises due to the fact that a sample cannot exactly represent the pop, even if it is drawn in a correct \\nmanner \\n2. NON-SAMPLING ERROR \\n \\nBesides sampling errors, there are certain errors which are not attributable to sampling but arise in the process of data \\ncollection, even if a complete count is carried out. \\nMain sources of non sampling errors are: \\n\\uf0b7 The defect in the sampling frame. \\n\\uf0b7 Faulty reporting of facts due to personal preferences. \\n\\uf0b7 Negligence or indifference of the investigators \\n\\uf0b7 Non-response to mail questionnaires. \\nThese (non-sampling) errors can be avoided through  \\n\\uf0b7 Following up the non-response, \\n\\uf0b7 Proper training of the investigators. \\n\\uf0b7 Correct manipulation of the collected information,  \\n \\nLet us now consider exactly what is meant by ‘sampling error’:  We can say that there are two types of non -response --- \\npartial non-response and total non-response. ‘Partial non-response’ implies that the respondent refuses to answer some \\nof the questions. On the other hand, ‘ total non -response’ implies that the respondent refu ses to answer any of the \\nquestions. Of course, the problem of late returns and non -response of the kind that I have just mentioned occurs in the \\ncase of HUMAN populations.  Although refusal of sample units to cooperate is encountered in interview surveys, i t is \\nfar more of a problem in mail surveys. It is not uncommon to find the response rate to mail questionnaires as low as 15 \\nor 20%.The provision of INFORMATION ABOUT THE PURPOSE OF THE SURVEY helps in stimulating interest, \\nthus increasing the chances of g reater response.  Particularly if it can be shown that the work will be to the \\nADVANTAGE of the respondent IN THE LONG RUN. \\nSimilarly, the respondent will be encouraged to reply if a pre -paid and addressed ENVELOPE is sent out with the \\nquestionnaire. But in spite of these ways of reducing non-response, we are bound to have some amount of non-response. \\nHence, a decision has to be taken about how many RECALLS should be made. \\nThe term ‘recall’ implies that we approach the respondent more than once in order to persuade him to respond to our \\nqueries.  \\nAnother point worth considering is:  \\nHow long the process of data collection should be continued?  Obviously, no such process can be carried out for an \\nindefinite period of time! In fact, the longer the time period o ver which the survey is conducted, the greater will be the \\npotential VARIATIONS in attitudes and opinions of the respondents. Hence, a well -defined cut -off date generally \\nneeds to be established. Let us now look at the various ways in which we can select a  sample from our population. We \\nbegin by looking at the difference between non-random and RANDOM sampling. First of all, what do we mean by non-\\nrandom sampling? \\n \\nNONRANDOM SAMPLING \\n \\n‘Nonrandom sampling’ implies that kind of sampling in which the population  units are drawn into the sample by using \\none’s personal judgment.  This type of sampling is also known as purposive sampling. Within this category, one very \\nimportant type of sampling is known as Quota Sampling. \\n \\nQUOTA SAMPLING \\n \\nIn this type of sampling, t he selection of the sampling unit from the population is no longer dictated by chance. A \\nsampling frame is not used at all, and the choice of the actual sample units to be interviewed is left to the discretion of \\nthe interviewer. However, the interviewer i s restricted by quota controls.  For example, one particular interviewer may \\nbe told to interview ten married women between thirty and forty years of age living in town X, whose husbands are \\nprofessional workers, and five unmarried professional women of the same age living in the same town.  Quota sampling \\nis often used in commercial surveys such as consumer market-research. Also, it is often used in public opinion polls. \\n \\nADVANTAGES OF QUOTA SAMPLING \\n \\n\\uf0b7 There is no need to construct a frame. \\n\\uf0b7 It is a very quick form of investigation. \\n\\uf0b7 Cost reduction. \\n\\uf06d\\uf02dX\\nSampling error = '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 14}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       10                                                                                                                                           \\n \\nDISADVANTAGES \\n \\n\\uf0b7 It is a subjective method. One has to choose between objectivity and convenience. \\n\\uf0b7 If random sampling is not employed, it is no longer theoretically possible to evaluate the sampling error.   \\n\\uf0b7 (Since the selection of the elements is not based on probability theory but on the personal judgment of the \\ninterviewer, hence the precision and the reliability of the estimates can not be determined objectively i.e. in \\nterms of probability.) \\n\\uf0b7 Although the purpose of implementing quota controls is to reduce bias, bias creeps in due to the fact that the \\ninterviewer is FREE to select particular individuals within the quotas. (Interviewers usually look for persons \\nwho either agree with their points of view or are personally known to them or can easily be contacted.) \\n\\uf0b7 Even if the above is not the case, the interviewer may still be making unsuitable selection of sample units.  \\n\\uf0b7 (Although he may put some qualifying questions to a potential respondent in order to determine whether he or \\nshe is of the type prescribed by the quota controls, some features must necessarily be decided arbitrarily by \\nthe interviewer, the most difficult of these being social class.) \\n \\nIf mistakes are being made, it is almost impossible for the organiz ers to detect these, because follow -ups are not \\npossible unless a detailed record of the respondents’ names, addresses etc. has been kept.  \\nFalsification of returns is therefore more of a danger in quota sampling than in random sampling. In spite of the ab ove \\nlimitations, it has been shown by F. Edwards that a well -organized quota survey with well -trained interviewers can \\nproduce quite adequate results. \\nNext, let us consider the concept of random sampling. \\n \\nRANDOM SAMPLING \\n \\nThe theory of statistical sampling rests on the assumption that the selection of the sample units has been carried out in a \\nrandom manner. \\nBy random sampling we mean sampling that has been done by adopting the lottery method. \\n \\nTYPES OF RANDOM SAMPLING \\n \\n\\uf0b7 Simple Random Sampling \\n\\uf0b7 Stratified Random Sampling \\n\\uf0b7 Systematic Sampling \\n\\uf0b7 Cluster Sampling \\n\\uf0b7 Multi-stage Sampling, etc. \\n \\n In this course, I will discuss with you the simplest type of random sampling i.e. simple random sampling. \\n \\nSIMPLE RANDOM SAMPLING \\n \\n In this type of sampling, the chance of any one element of the parent pop being included in the sample is the same as \\nfor any other element. By extension, it follows that, in simple random sampling, the chance of any one sample \\nappearing is the same as for any other. There exists quite a lot of misconception regarding the concept of random \\nsampling. Many a time, haphazard selection is considered to be equivalent to simple random sampling.   \\nFor example, a market research interviewer may select women shoppers to find their attitude to brand X of a product by \\nstopping one and then another as they pass along a busy shopping area --- and he may think that he has accomplished \\nsimple random sampling! \\n Actually, there is a strong possibility of bias as the interviewer may tend to ask his questions of young \\nattractive women rather than older housewives, or he may stop women who have packets of brand X prominently on \\nshow in their shopping bags!. \\nIn this example, there is no suggestion of INTENTIONAL bias! From experience, it is known that the human being is a \\npoor random selector --- one who is very subject to bias. \\nFundamental psychological traits prevent complete objectivity, and no amount of training or conscious effort can \\neradicate them. As stated earlier, random sampling is that in which population units are selected by the lottery method. \\n As you know, the traditional method of writing people’s names on small pieces of paper, folding these pieces \\nof paper and shuffling them is very cumbersome!  \\nA much more convenient alternative is the use of RANDOM NUMBERS TABLES. \\nA random number table is a page full of digits from zero to 9.  These digits are printed on the page in a TOTALLY \\nrandom manner i.e. there is no systematic pattern of printing these digits on the page.  \\n                           \\n    \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 15}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       11                                                                                                                                           \\n ONE THOUSAND RANDOM DIGITS  \\n \\n2 3 1 5 7 5 4 8 5 9 0 1 8 3 7 2 5 9 9 3 7 6 2 4 9 7 0 8 8 6 9 5 2 3 0 3 6 7 4 4 \\n0 5 5 4 5 5 5 0 4 3 1 0 5 3 7 4 3 5 0 8 9 0 6 1 1 8 3 7 4 4 1 0 9 6 2 2 1 3 4 3 \\n1 4 8 7 1 6 0 3 5 0 3 2 4 0 4 3 6 2 2 3 5 0 0 5 1 0 0 3 2 2 1 1 5 4 3 8 0 8 3 4 \\n3 8 9 7 6 7 4 9 5 1 9 4 0 5 1 7 5 8 5 3 7 8 8 0 5 9 0 1 9 4 3 2 4 2 8 7 1 6 9 5 \\n9 7 3 1 2 6 1 7 1 8 9 9 7 5 5 3 0 8 7 0 9 4 2 5 1 2 5 8 4 1 5 4 8 8 2 1 0 5 1 3 \\n1 1 7 4 2 6 9 3 8 1 4 4 3 3 9 3 0 8 7 2 3 2 7 9 7 3 3 1 1 8 2 2 6 4 7 0 6 8 5 0 \\n4 3 3 6 1 2 8 8 5 9 1 1 0 1 6 4 5 6 2 3 9 3 0 0 9 0 0 4 9 9 4 3 6 4 0 7 4 0 3 6 \\n9 3 8 0 6 2 0 4 7 8 3 8 2 6 8 0 4 4 9 1 5 5 7 5 1 1 8 9 3 2 5 8 4 7 5 5 2 5 7 1 \\n4 9 5 4 0 1 3 1 8 1 0 8 4 2 9 8 4 1 8 7 6 9 5 3 8 2 9 6 6 1 7 7 7 3 8 0 9 5 2 7 \\n3 6 7 6 8 7 2 6 3 3 3 7 9 4 8 2 1 5 6 9 4 1 9 5 9 6 8 6 7 0 4 5 2 7 4 8 3 8 8 0 \\n0 7 0 9 2 5 2 3 9 2 2 4 6 2 7 1 2 6 0 7 0 6 5 5 8 4 5 3 4 4 6 7 3 3 8 4 5 3 2 0 \\n4 3 3 1 0 0 1 0 8 1 4 4 8 6 3 8 0 3 0 7 5 2 5 5 5 1 6 1 4 8 8 9 7 4 2 9 4 6 4 7 \\n6 1 5 7 0 0 6 3 6 0 0 6 1 7 3 6 3 7 7 5 6 3 1 4 8 9 5 1 2 3 3 5 0 1 7 4 6 9 9 3 \\n3 1 3 5 2 8 3 7 9 9 1 0 7 7 9 1 8 9 4 1 3 1 5 7 9 7 6 4 4 8 6 2 5 8 4 8 6 9 1 9 \\n5 7 0 4 8 8 6 5 2 6 2 7 7 9 5 9 3 6 8 2 9 0 5 2 9 5 6 5 4 6 3 5 0 6 5 3 2 2 5 4 \\n0 9 2 4 3 4 4 2 0 0 6 8 7 2 1 0 7 1 3 7 3 0 7 2 9 7 5 7 3 6 0 9 2 9 8 2 7 6 5 0 \\n9 7 9 5 5 3 5 0 1 8 4 0 8 9 4 8 8 3 2 9 5 2 2 3 0 8 2 5 2 1 2 2 5 3 2 6 1 5 8 7 \\n9 3 7 3 2 5 9 5 7 0 4 3 7 8 1 9 8 8 8 5 5 6 6 7 1 6 6 8 2 6 9 5 9 9 6 4 4 5 6 9 \\n7 2 6 2 1 1 1 2 2 5 0 0 9 2 2 6 8 2 6 4 3 5 6 6 6 5 9 4 3 4 7 1 6 8 7 5 1 8 6 7 \\n6 1 0 2 0 7 4 4 1 8 4 5 3 7 1 2 0 7 9 4 9 5 9 1 7 3 7 8 6 6 9 9 5 3 6 1 9 3 7 8 \\n9 7 8 3 9 8 5 4 7 4 3 3 0 5 5 9 1 7 1 8 4 5 4 7 3 5 4 1 4 4 2 2 0 3 4 2 3 0 0 0 \\n8 9 1 6 0 9 7 1 9 2 2 2 2 3 2 9 0 6 3 7 3 5 0 5 5 4 5 4 8 9 8 8 4 3 8 1 6 3 6 1 \\n2 5 9 6 6 8 8 2 2 0 6 2 8 7 1 7 9 2 6 5 0 2 8 2 3 5 2 8 6 2 8 4 9 1 9 5 4 8 8 3 \\n8 1 4 4 3 3 1 7 1 9 0 5 0 4 9 5 4 8 0 6 7 4 6 9 0 0 7 5 6 7 6 5 0 1 7 1 6 5 4 5 \\n1 1 3 2 2 5 4 9 3 1 4 2 3 6 2 3 4 3 8 6 0 8 6 2 4 9 7 6 6 7 4 2 2 4 5 2 3 2 4 5 \\n \\n \\nActually, Random Number Tables are constructed according to certain mathematical principles so that each digit has \\nthe same chance of selection. Of course, nowadays randomness may be achieved electronically. Computers have all \\nthose programmes by which we can generate random numbers.  \\n \\nEXAMPLE \\n \\nThe following frequency table of distribution gives the ages of a population of 1000 teen-age college students in a \\nparticular country.  \\nSelect a sample of 10 students using the random numbers table. Find the sample mean age and compare with the \\npopulation mean age. \\n \\nHow will we proceed to select our sample of size 10 from this population of size 1000? \\nAge  \\n(X) \\nNo. of Students \\n(f) \\n13 6 \\n14 61 \\n15 270 \\n16 491 \\n17 153 \\n18 15 \\n19 4 \\n 1000 \\n \\nStudent-Population of a College '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 16}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       12                                                                                                                                           \\nThe first step is to allocate to each student in this population a sampling number. For this purpose, we will begin by \\nconstructing a column of cumulative frequencies. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow that we have the cumulative frequency of each class, we are in a position to allocate the sampling numbers to all \\nthe values in a class. As the frequency as well as the cumulative frequency of the first class is 6, we allocate numbers \\n000 to 005 to the six students who belong to this class. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs the cumulative frequency of the second class is 67 while that of the first class was 6, therefore we allocate sampling \\nnumbers 006 to 066 to the 61 students who belong to this class. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAGE \\nX \\nNo. of  \\nStudents \\nf \\ncf Sampling  \\nNumbers \\n13 6 6 000 – 005 \\n14 61 67  \\n15 270 337  \\n16 491 828  \\n17 153 981  \\n18 15 996  \\n19 4 1000  \\n 1000   \\n \\nAGE \\nX \\nNo. of Students \\nf \\nCumulative Frequency \\ncf \\n13 6 6 \\n14 61 67 \\n15 270 337 \\n16 491 828 \\n17 153 981 \\n18 15 996 \\n19 4 1000 \\n 1000  \\n \\nAGE \\nX \\nNo. of  \\nStudents \\nf \\ncf Sampling  \\nNumbers \\n13 6 6 000 – 005 \\n14 61 67 006 – 066 \\n15 270 337  \\n16 491 828  \\n17 153 981  \\n18 15 996  \\n19 4 1000  \\n 1000   \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 17}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       13                                                                                                                                           \\n \\n \\nAs the cumulative frequency of the third class is 337 while that of the second class was 67, therefore we allocate \\nsampling numbers 067 to 336 to the 270 students who belong to this class. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nProceeding in this manner, we obtain the column of sampling numbers. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe column implies that the first student of the first class has been allocated the sampling number  000, the second \\nstudent has been allocated the sampling 001, and, proceeding in this fashion, the last student i.e. the 1000th student has \\nbeen allocated the sampling number 999. \\n \\nThe question is: Why did we not allot the number 0001 to the first student and the number 1000 to the 1000th student?  \\nThe answer is that we could do that but that would have meant that every student would have been allocated a four-digit \\nnumber, whereas by shifting the number backward by 1, we are able to allocate to every student a three-digit number --- \\nwhich is obviously simpler.  \\nThe next step is to SELECT 10 RANDOM NUMBERS from the random number table. This is accomplished by closing \\none’s eyes and letting one’s finger land anywhere on the random number table.  In this exampl e, since all our sampling \\nnumbers are three -digit numbers, hence we will read three digits that are adjacent to each other at that position where \\nour finger landed. Suppose that we adopt this procedure and our random numbers come out to be 041, 103, 374, 1 71, \\n508, 652, 880, 066, 715, 471 \\nSelected Random Numbers: \\n041, 103, 374, 171, 508, 652, 880, 066, 715, 471 \\nThus the corresponding ages are:  \\n14, 15, 16, 15, 16, 16, 17,  15, 16, 16  \\n \\nEXPLANATION \\n \\nOur first selected random number is 041 which mean that we have to pick up the 42nd student. The cumulative \\nfrequency of the first class is 6 whereas the cumulative frequency of the second class is 67. This means that definitely \\nthe 42nd student does not belong to the first class but does belong to the second class. \\nAGE \\nX \\nNo. of  \\nStudents \\nf \\ncf Sampling  \\nNumbers \\n13 6 6 000 – 005 \\n14 61 67 006 – 066 \\n15 270 337 067 – 336 \\n16 491 828  \\n17 153 981  \\n18 15 996  \\n19 4 1000  \\n 1000   \\n \\nAGE \\nX \\nNo. of  \\nStudents \\nf \\ncf Sampling  \\nNumbers \\n13 6 6 000 – 005 \\n14 61 67 006 – 066 \\n15 270 337 067 – 336 \\n16 491 828 337 – 827 \\n17 153 981 828 – 980 \\n18 15 996 981 – 995 \\n19 4 1000 996 - 999 \\n 1000   \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 18}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       14                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe age of each student in this class is 14 years; hence, obviously, the age of the 42nd student is also 14 years. This is \\nhow we are able to ascertain the ages of all the students who have been selected in our sampling. You will recall that in \\nthis example, our aim was to draw a sample from the population of college students, and to compare the sample’s mean \\nage with the population mean age. The population mean age comes out to be 15.785 years. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe population mean age is : \\n \\n \\n  \\n \\n \\n \\nThe above formula is a slightly modified form of the basic formula that you have done ever-since school-days i.e. the \\nmean is equal to the sum of all the observations divided by the total number of observations.  \\nNext, we compute the sample mean age.  \\nAdding the 10 values and dividing by 10, we obtain: \\nAges of students selected in the sample (in years): \\n14, 15, 16, 15, 16, 16, 17, 15, 16, 16 \\nHence the sample mean age is: 15.6, comparing the sample mean age of 15.6 years with the population mean age of \\n15.785 years, we note that the difference is really quite slight, and hence the sampling error is equal to  \\n \\n \\nyears185.0\\n785.156.15X\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf06d\\uf02d\\nAGE \\nX \\nNo. of Students \\nf fX \\n13 6 78 \\n14 61 854 \\n15 270 4050 \\n16 491 7856 \\n17 153 2601 \\n18 15 270 \\n19 4 76 \\n 1000 15785 \\n \\nyears\\nf\\nfx\\n785.15\\n1000\\n15785\\n\\uf03d\\n\\uf03d\\uf03d\\n\\uf0e5\\n\\uf0e5\\uf06d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf03d\\n\\uf03d\\uf03d \\uf0e5\\nyears\\nn\\nX\\nX\\n6.15\\n10\\n156\\nAGE \\nX \\nNo. of  \\nStudents \\nf \\ncf \\n13 6 6 \\n14 61 67 \\n15 270 337 \\n16 491 828 \\n17 153 981 \\n18 15 996 \\n19 4 1000 \\n 1000  \\n \\nSampling Error \\n \\n    \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 19}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       15                                                                                                                                           \\nAnd the reason for such a small error is that we have adopted the RANDOM sampling method. The basic advantage of \\nrandom sampling is that the probability is very high that the sample will be a good representative of the population from \\nwhich it has been drawn, and any quantity computed from the sample will be a good estimate of the corresponding \\nquantity computed from the population! Actually, a sample is supposed to be a MINIATURE REPLICA of the \\npopulation. As stated earlier, there are various other types of random sampling.  \\n \\nOTHER TYPES OF RANDOM SAMPLING \\n \\n\\uf0b7 ·Stratified sampling (if the population  is heterogeneous) \\n\\uf0b7 Systematic sampling (practically, more convenient than simple random sampling)  \\n\\uf0b7 Cluster sampling (sometimes the sampling units exist in natural clusters) \\n\\uf0b7 Multi-stage sampling   \\nAll these designs rest upon random or quasi-random sampling. They are various forms of PROBABILITY sampling --- \\nthat in which each sampling unit has a known (but not necessarily equal) probability of being selected. \\nBecause of this knowledge, there exist methods by which the precision and the reliability of the estimates can be \\ncalculated OBJECTIVELY.  \\nIt should be realized that in practice, several sampling techniques are incorporated into each survey design, and only \\nrarely will simple random sample be used, or a multi-stage design be employed, without stratification. \\nThe point to remember is that whatever method be adopted, care should be exercised at every step so as to make the \\nresults as reliable as possible.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 20}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       16                                                                                                                                           \\n \\nLECTURE NO. 3 \\n \\n\\uf0b7 Tabulation \\n\\uf0b7 Simple bar chart \\n\\uf0b7 Component bar chart \\n\\uf0b7 Multiple bar chart \\n\\uf0b7 Pie chart \\n \\nAs indicated in the last lecture, there are two broad categories of data … qualitative data and quantitative data. A variety \\nof methods exist for summarizing and describing these two types of data. The tree-diagram below presents an outline of \\nthe various techniques \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTYPES OF DATA \\nQuantitative Qualitative \\nUnivariate \\nFrequency \\nTable \\nPercentages \\nPie Chart \\nBar Chart \\nBivariate \\nFrequency  \\nTable \\nMultiple \\nBar \\nChart \\nDiscrete \\nFrequency \\nDistribution \\nLine \\nChart \\nContinuous \\nFrequency \\nDistribution \\nHistogram \\nFrequency \\nPolygon \\n \\nFrequency \\nCurve \\n \\nComponent  \\nBar Chart '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 21}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       17                                                                                                                                           \\n \\nIn today’s lecture, we will be dealing with various techniques for summarizing and describing qualitative data.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWe will begin with the univariate situation, and will proceed to the bivariate situation. \\n \\nEXAMPLE \\n \\nSuppose that we are carrying out a survey of the students of first year studying in a co -educational college of Lahore. \\nSuppose that in all there are 1200 students of fi rst year in this large college. We wish to determine what proportion of \\nthese students have come from Urdu medium schools and what proportion has come from English medium schools.  So \\nwe will interview the students and we will inquire from each one of them about their schooling. As a result, we will \\nobtain a set of data as you can now see on the screen.   \\nWe will have an array of observations as follows: \\n \\n U, U, E, U, E, E, E, U, …… \\n \\n(U : URDU MEDIUM) \\n(E : ENGLISH MEDIUM) \\n \\nNow, the question is what should we do with this data? \\nObviously, the first thing that comes to mind is to count the number of students who said “Urdu medium” as well as the \\nnumber of students who said “English medium”. This will result in the following table: \\n \\nMedium of \\nInstitution \\nNo. of Students \\n(f) \\nUrdu 719 \\nEnglish 481 \\n 1200 \\n \\nThe technical term for the numbers given in the second column of this table is “frequency”.  It means “how frequently \\nsomething happens?” Out of the 1200 students, 719 stated that they had come from Urdu medium schools.  So in this \\nexample, the frequency of the first category of responses is 719 whereas the frequency of the second category of \\nresponses is 481. \\n \\nQualitative \\nUnivariate \\nFrequency \\nTable \\nPercentages \\nPie Chart \\nBar Chart \\nBivariate \\nFrequency  \\nTable \\nMultiple \\nBar Chart \\nComponent  \\nBar Chart '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 22}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       18                                                                                                                                           \\nIt is evident that this information is not as useful as if we compute the proportion or percentage of students falling in \\neach category. Dividing the cell frequencies by the total frequency and multiplying by 100 we obtain the following: \\n \\nMedium of \\nInstitution f % \\nUrdu 719 59.9 = 60% \\nEnglish 481 40.1 = 40% \\n 1200  \\n \\n \\nWhat we have just accomplished is an example of a univariate frequency table pertaining to qualitative data.  \\nLet us now see how we can represent this information in the form of a diagram.  \\nOne good way of representing the above information is in the form of a pie chart. \\nA pie chart consists of a circle which is divi ded into two or more parts in accordance with the number of distinct \\ncategories that we have in our data. \\nFor the example that we have just considered, the circle is divided into two sectors, the larger sector pertaining to \\nstudents coming from Urdu medium schools and the smaller sector pertaining to students coming from English medium \\nschools. \\nHow do we decide where to cut the circle? \\nThe answer is very simple! All we have to do is to divide the cell frequency by the total frequency and multiply by 360.  \\nThis process will give us the exact value of the angle at which we should cut the circle. \\n \\nPIE CHART    \\n \\n \\n \\nMedium of \\nInstitution f Angle \\nUrdu 719 215.70 \\nEnglish 481 144.30 \\n 1200  \\n                                                                  \\n \\n    \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUrdu\\n215.70\\nEnglish\\n144.30'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 23}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       19                                                                                                                                           \\nSIMPLE BAR CHART: \\n \\n The next diagram to be considered is the simple bar chart. \\n \\n A simple bar chart consists of horizontal or vertical bars of equal width and lengths proportional to values \\nthey represent.  \\n \\n As the basis of comparison is one -dimensional, the widths of these bars have no mathematical significance \\nbut are taken in order to make the chart look attractive.  \\nLet us consider an example. \\n \\n Suppose we have available to us information regarding the turnover of a company for 5 years as  given in the \\ntable below: \\n \\nYears 1965 1966 1967 1968 1969 \\nTurnover (Rupees) 35,000 42,000 43,500 48,000 48,500 \\n \\nIn order to represent the above information in the form of a bar chart, all we have to do is to take the year along the x-\\naxis and construct a scale for turnover along the y-axis. \\n \\n Next, against each year, we will draw vertical bars of equal width and different heights in accordance with the \\nturn-over figures that we have in our table. \\n \\nAs a result we obtain a simple and attractive diagram as shown below. \\nWhen our values do not relate to time, they should be arranged in ascending or descending order before-charting. \\n  \\n BIVARIATE FREQUENCY TABLE \\nWhat we have just considered was the univariate situation.  In each of the two examples, we were dea ling with one \\nsingle variable. In  the example of the first year students of a college, our lone variable of interest was ‘medium of \\nschooling’. And in the second example, our one single variable of interest was turnover. Now  let us expand the \\ndiscussion a little, and consider the bivariate situation.  \\n0\\n10,000\\n20,000\\n30,000\\n40,000\\n50,000\\n1965 1966 1967 1968 1969\\n0 \\n10,000 \\n20,000 \\n30,000 \\n40,000 \\n50,000 \\n1965 1966 1967 1968 1969 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 24}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       20                                                                                                                                           \\nGoing back to the example of the first year students, suppose that alongwith the enquiry about the Medium of \\nInstitution, you are also recording the sex of the student. \\nSuppose that our survey results in the following information: \\n \\nStudent No. Medium Gender \\n1 U F \\n2 U M \\n3 E M \\n4 U F \\n5 E M \\n6 E F \\n7 U M \\n8 E M \\n: : : \\n: : : \\n \\nNow this is a bivariate situation; we have two variables, medium of schooling and sex of the student. \\nIn order to summarize the above information, we will construct a table containing a box head and a stub as shown \\nbelow: \\n \\nSex \\nMed. \\nM\\nA\\nL\\nE \\nFemale Total \\nUrdu    \\nEnglish    \\nTotal    \\n \\n  \\nThe top row of this kind of a table is known as the boxhead and the first column of the table is known as stub.  \\nNext, we will count the number of students falling in each of the following four categories: \\n \\n1. Male student coming from an Urdu medium school. \\n2. Female student coming from an Urdu medium school. \\n3. Male student coming from an English medium school. \\n4. Female student coming from an English medium school. \\n \\nAs a result, suppose we obtain the following figures:  \\n \\nSex \\nMed. \\nM\\nA\\nL\\nE \\nFemale Total \\nUrdu 202 517 719 \\nEnglish 350 131 481 \\nTotal 552 648 1200 \\n \\n \\nWhat we have just accomplished is an example of a bivariate frequency table pertaining to two qualitative variables.  \\n                                      \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 25}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       21                                                                                                                                           \\nCOMPONENT BAR CHAR: \\n \\nLet us now consider how we will depict the above information diagrammatically.  \\nThis can be accomplished by constructing the component bar chart (also known as the subdivided bar chart) as shown \\nbelow:   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn the above figure, each bar has been divided into two parts.  The first bar represents the total number of male students \\nwhereas the second bar represents the total number of female students. \\n \\n As far as the medium of schooling is concerned, the lower part of each bar represents the students coming \\nfrom English medium schools. Whereas the upper part of each bar represents the students coming from the Urdu \\nmedium schools. The advantage of this kind of a diagram is that we are able to ascertain the situation of both the \\nvariables at a glance. \\n            We can compare the number of male students in the college with the number of female students, and at the same \\ntime we can compare the number of English medium students among the males with the number of English medium \\nstudents among the females. \\n \\nMULTIPLE BAR CHARTS \\n \\nThe next diagram to be considered is the multiple bar charts. Let us consider an example.  \\nSuppose we have information regarding the imports and exports of Pakistan for the years 1970 -71 to 1974-75 as shown \\nin the table below: \\n \\nYears Imports \\n(Crores of Rs.) \\nExports \\n(Crores of Rs.) \\n1970-71 370 200 \\n1971-72 350 337 \\n1972-73 840 855 \\n1973-74 1438 1016 \\n1974-75 2092 1029 \\nSource: State Bank of Pakistan \\n \\n \\nA multiple bar chart is a very useful and effective way of presenting this kind of information. \\n \\nThis kind of a chart consists of a set of grouped bars, the lengths of which are proportionate to the values of ou r \\nvariables, and each of which is shaded or colored differently in order to aid identification.  With reference to the above \\nexample, we obtain the multiple bar chart shown below: \\n \\n \\n \\n \\n \\n \\n \\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700\\n800\\nMale Female\\nUrdu\\nEnglish'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 26}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       22                                                                                                                                           \\nMultiple Bar Chart Showing  \\nImports & Exports  \\nof Pakistan 1970-71 to 1974-75 \\n \\n This is a very good device for the comparison of two different kinds of information. \\nIf, in addition to information regarding imports and exports, we also had information regarding production, we could \\nhave compared them from year to year by grouping the three bars together.  \\nThe question is, what is the basic difference between a component bar chart and a multiple bar chart? \\nThe component bar chart should be used when we have available to us information regarding totals and their \\ncomponents.  \\n \\n For example, the total number of male students out of which some are Urdu medium and some are English \\nmedium. The number of Urdu medium male students and the number of English medium male students add up to give \\nus the total number of male students.  \\nOn the contrary, in the example of exports and imports, the imports and exports do not add up to give us the totality of \\nsome one thing! \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 27}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       23                                                                                                                                           \\nLECTURE NO. 4 \\n \\nIn THIS Lecture, we will discuss the frequency distribution of a   continuous variable & the graphical ways of \\nrepresenting data pertaining to a continuous variable i.e. histogram, frequency polygon and frequency curve.       \\n You will recall that in Lecture No. 1, it was mentioned that a continuous variable takes values over a continuous \\ninterval (e.g. a normal Pakistani adult male’s height may lie anywhere between 5.25 feet and 6.5 feet). \\nHence, in such a situation, the method of constructing a frequency distribution is somewhat different from the one that \\nwas discussed in the last lecture. \\n \\nEXAMPLE: \\n \\n               Suppose that the Environmental Protection Agency of a developed country performs extensive tests on all new \\ncar models in order to determine their mileage rating. Suppose that the following 30 measurements are obtained by \\nconducting such tests on a particular new car model. \\n \\n \\n \\nThere are a few steps in the construction of a frequency distribution for this type of a variable. \\n \\nCONSTRUCTION OF A FREQUENCY DISTRIBUTION \\n \\nStep-1 \\n \\nIdentify the smallest and the largest measurements in the data set. \\nIn our example: \\n           Smallest value (X0) = 30.1, \\n           Largest Value (Xm) = 44.9, \\nStep-2 \\n \\nFind the range which is defined as the difference between the largest value and the smallest value \\nIn our example: \\n         Range = Xm – X0  \\n                        = 44.9 – 30.1  \\n                        = 14.8 \\nLet us now look at the graphical picture of what we have just computed.  \\n \\n \\nEPA MILEAGE RATINGS ON 30 CARS \\n(MILES PER GALLON) \\n36.3 42.1 44.9 \\n30.1 37.5 32.9 \\n40.5 40.0 40.2 \\n36.2 35.6 35.9 \\n38.5 38.8 38.6 \\n36.3 38.4 40.5 \\n41.0 39.0 37.0 \\n37.0 36.7 37.1 \\n37.1 34.8 33.9 \\n39.9 38.1 39.8 \\n \\nEPA: Environmental Protection Agency '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 28}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       24                                                                                                                                           \\n \\nStep-3 \\n Decide on the number of classes into which the data are to be grouped.  \\n(By classes, we mean small sub -intervals of the total interval which, in this example, is 14.8 units long.)There are no \\nhard and fast rules for this purpose. The decision will depend on the size of the data. When the data are suffi ciently \\nlarge, the number of classes is usually taken between 10 and 20.In this example, suppose that we decide to form 5 \\nclasses (as there are only 30 observations). \\n \\n Step-4 \\n Divide the range by the chosen number of classes in order to obtain the approxi mate value of the class \\ninterval i.e. the width of our classes. \\nClass interval is usually denoted by h.  Hence, in this example  \\nClass interval = h   = 14.8 / 5  = 2.96  \\nRounding the number 2.96, we obtain 3, and hence we take h = 3.  \\nThis means that our big interval will be divided into small sub-intervals, each of which will be 3 units long.  \\n  \\nStep-5 \\n \\nDecide the lower class limit of the lowest class. Where should we start from? \\nThe answer is that we should start constructing our classes from a number equ al to or slightly less than the smallest \\nvalue in the data. \\nIn this example,  smallest value = 30.1 \\nSo we may choose the lower class limit of the lowest class to be 30.0. \\n \\n Step-6 \\n \\nDetermine the lower class limits of the successive classes by adding h = 3 successively. Hence, we obtain the following \\ntable: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep-7 \\n \\nDetermine the upper class limit of every class. The upper class limit of the highest class should cover the largest value \\nin the data. It should be noted that the upper class limits wi ll also have a difference of h between them. Hence, we \\nobtain the upper class limits that are visible in the third column of the following table. \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n30 35 40 45 \\n14.8 \\n(Range) \\n30.1 44.9 \\nR \\nClass  \\nNumber Lower Class Limit \\n1 30.0 \\n2 30.0 + 3  = 33.0 \\n3 33.0 + 3 = 36.0 \\n4 36.0 + 3 = 39.0 \\n5 39.0 + 3 = 42.0 \\n \\nClass  \\nNumber \\nLower Class \\nLimit \\nUpper Class \\nLimit \\n1 30.0 32.9 \\n2 30.0 + 3  = 33.0 32.9 + 3 = 35.9 \\n3 33.0 + 3 = 36.0 35.9 + 3 = 38.9 \\n4 36.0 + 3 = 39.0 38.9 + 3 = 41.9 \\n5 39.0 + 3 = 42.0 41.9 + 3 = 44.9 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 29}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       25                                                                                                                                           \\nHence we obtain the following classes: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe question arises: why did we not write 33 instead of 32.9? Why did we not write 36 instead of 35.9? and so on. \\n                 The reason is that if we wrote 30 to 33 and then 33 to 36, we would have trouble when tallying our data into \\nthese classes. Where should I put the value 33? Should I put it in the first class, or should I put it in the second class? By \\nwriting 30.0 to 32.9 and 33.0 to 35.9, we avoid this problem. And the point to be noted is that the class interval is still 3, \\nand not 2.9 as it appears to be. This point will be better und erstood when we discuss the concept of class boundaries … \\nwhich will come a little later in today’s lecture.  \\n \\nStep-8 \\n \\nAfter forming the classes, distribute the data into the appropriate classes and find the frequency of each class, in this \\nexample: \\n \\nThis is a simple example of the frequency distribution of a continuous or, in other words, measurable variable. \\n \\nCLASS BOUNDARIES: \\n \\n  The true class limits of a class are known as its class boundaries. In this example: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\nClass Tally Frequency \\n30.0 – 32.9 || 2 \\n33.0 – 35.9 |||| 4 \\n36.0 – 38.9 ||||   ||||   |||| 14 \\n39.0 – 41.9 ||||   ||| 8 \\n42.0 – 44.9 || 2 \\n Total 30 \\n \\n \\nClasses \\n30.0 – 32.9 \\n33.0 – 35.9 \\n36.0 – 38.9 \\n39.0 – 41.9 \\n42.0 – 44.9 \\n \\nClass Limit Class Boundaries Frequency \\n30.0 – 32.9 29.95 – 32.95 2 \\n33.0 – 35.9 32.95 – 35.95 4 \\n36.0 – 38.9 35.95 – 38.95 14 \\n39.0 – 41.9 38.95 – 41.95 8 \\n42.0 – 44.9 41.95 – 44.95 2 \\n Total 30 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 30}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       26                                                                                                                                           \\nIt should be noted that the difference between the upper class boundary and the lower class boundary of any class is \\nequal to the class interval h = 3. \\n32.95 minus 29.95 is equal to 3, 35.95 minus 32.95 is equal to 3, and so on. \\nA key point in this entire discussion is that the class boundaries should be taken up to one decimal place more than the \\ngiven data. In this way, the possibility of an observation falling exactly on the boundary is avoided. (The observed value \\nwill either be greater than or less  than a particular boundary and hence will conveniently fall in its appropriate \\nclass).Next, we consider the concept of the relative frequency distribution and the percentage frequency distribution. \\nNext, we consider the concept of the relative frequency distribution and the percentage frequency distribution. \\nThis concept has already been discussed when we considered the frequency distribution of a discrete variable. \\nDividing each frequency of a frequency distribution by the total number of observations, we  obtain the relative \\nfrequency distribution.  \\nMultiplying each relative frequency by 100, we obtain the percentage of frequency distribution. \\nIn this way, we obtain the relative frequencies and the percentage frequencies shown below \\n \\n \\nClass  \\nLimit Frequency Relative \\nFrequency \\n%age  \\nFrequency \\n30.0 – 32.9 2 2/30 = 0.067 6.7 \\n33.0 – 35.9 4 4/30 = 0.133 13.3 \\n36.0 – 38.9 14 14/30 = 0.467 4.67 \\n39.0 – 41.9 8 8/30 = 0.267 26.7 \\n42.0 – 44.9 2 2/30 = 0.067 6.7 \\n 30   \\n \\n \\nThe term ‘relative frequencies’ simply means that we are considering the frequencies of the various classes relative to \\nthe total number of observations. \\nThe advantage of constructing a relative frequency distribution is that  comparison is possible  between two sets of data \\nhaving similar classes. \\nFor example, suppose that the Environment Protection Agency perform tests on two car models A and B, and obtains \\nthe frequency distributions shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to be able to compare the pe rformance of the two car models, we construct the relative frequency distributions \\nin the percentage form: \\n \\n \\n \\n \\nFREQUENCY MILEAGE Model A Model B \\n30.0 – 32.9 2 7 \\n33.0 – 35.9 4 10 \\n36.0 – 38.9 14 16 \\n39.0 – 41.9 8 9 \\n42.0 – 44.9 2 8 \\n 30 50 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 31}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       27                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFrom the table it is clear that whereas 6.7% of the cars of model A fall in the mileage group 42.0 to 44.9, as many as \\n16% of the cars of model B fall in this group. Other comparisons can similarly be made. \\nLet us now turn to the visual representation of a continuous frequency distribution.  In this context, we will discuss three \\ndifferent types of graphs i.e. the histogram, the frequency polygon, and the frequency curve. \\n \\nHISTOGRAM: \\n \\nA histogram consists of a set of adjacent rectangles whose bases are marked off by class boundaries along the X -axis, \\nand whose heights are proportional to the frequencies associated with the respective classes.  \\nIt will be recalled that, in the last lecture, we were considering the mileage ratings of the cars that had been inspected by \\nthe Environment Protection Agency. Our frequency table came out as shown below: \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn accordance with the procedure that I just mentioned, we need to take the class boundaries along the X axis  \\nWe obtain \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMILEAGE Model A Model B \\n30.0-32.9 2/30 x 100 = 6.7 7/50 x 100 = 14 \\n33.0-35.9 4/30 x 100 = 13.3 10/50 x 100 = 20 \\n36.0-38.9 14/30 x 100 = 46.7 16/50 x 100 = 32 \\n39.0-41.9 8/30 x 100 = 26.7 9/50 x 100 = 18 \\n42.0-44.9 2/30 x 100 = 6.7 8/50 x 100 = 16 \\n \\nClass  \\nLimit \\nClass  \\nBoundaries Frequency \\n30.0 – 32.9 29.95 – 32.95 2 \\n33.0 – 35.9 32.95 – 35.95 4 \\n36.0 – 38.9 35.95 – 38.95 14 \\n39.0 – 41.9 38.95 – 41.95 8 \\n42.0 – 44.9 41.95 – 44.95 2 \\n Total 30 \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n29.95 32.95 35.95 38.95 41.95 44.95\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 32}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       28                                                                                                                                           \\nNow, as seen in the frequency table, the frequency of the first class is 2. As such, we will draw a rectangle of height \\nequal to 2 units and obtain the following figure: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe frequency of the second class is 4. Hence we draw a rectangle of height equal to 4 units against the second class, \\nand thus obtain the following situation: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe frequency of the third class is 14. Hence we draw a rectangle of height equal to 14 units against the third class, and \\nthus obtain the following picture: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n29.95 32.95 35.95 38.95 41.95 44.95Miles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n29.95 32.95 35.95 38.95 41.95 44.95\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n29.95 32.95 35.95 38.95 41.95 44.95\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 33}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       29                                                                                                                                           \\nContinuing in this fashion, we obtain the following attractive diagram: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis diagram is known as the histogram, and it gives an indication of the overall pattern of our frequency distribution. \\n \\n  FREQUENCY POLYGON: \\n \\nA frequency polygon is obtained by plotting the class frequencies against the mid -points of the classes, and connect ing \\nthe points so obtained by straight line segments.  In our example of the EPA mileage ratings, the classes are  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThese mid-points are denoted by X. \\n Now let us add two classes to my frequency table, one class in the very beginning, and one class at the very end.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe frequency of each of these two classes is 0, as in our data set, no value falls in these classes.  \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n29.95 32.95 35.95 38.95 41.95 44.95\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\nClass Boundaries \\n29.95 – 32.95 \\n32.95 – 35.95 \\n35.95 – 38.95 \\n38.95 – 41.95 \\n41.95 – 44.95 \\n \\nClass  \\nBoundaries \\nMid-Point \\n(X) \\nFrequency \\n(f) \\n26.95 – 29.95 28.45  \\n29.95 – 32.95 31.45 2 \\n32.95 – 35.95 34.45 4 \\n35.95 – 38.95 37.45 14 \\n38.95 – 41.95 40.45 8 \\n41.95 – 44.95 43.45 2 \\n44.95 – 47.95 46.45  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 34}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       30                                                                                                                                           \\n \\nNow, in order to construct the frequency polygon, the mid -points of the clas ses are taken along the X -axis and the \\nfrequencies along the Y-axis, as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, we plot points on our graph paper according to the frequencies of the various classes, and join the points so \\nobtained by straight line segments. In this way, we obtain the following frequency polygon: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIt is well-known that the term ‘polygon’ implies a many -sided closed figure. As such, we want our frequency polygon \\nto be a closed figure. This is exactly the reason why we added two c lasses to our table, each having zero frequency. \\nBecause of the frequency being zero, the line segment touches the X -axis both at the beginning and at the end, and our \\nfigure becomes a closed figure.  \\n                 \\n \\n \\n \\nClass  \\nBoundaries \\nMid-Point \\n(X) \\nFrequency \\n(f) \\n26.95 – 29.95 28.45 0 \\n29.95 – 32.95 31.45 2 \\n32.95 – 35.95 34.45 4 \\n35.95 – 38.95 37.45 14 \\n38.95 – 41.95 40.45 8 \\n41.95 – 44.95 43.45 2 \\n44.95 – 47.95 46.45 0 \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n31.45 34.45 37.45 40.45 43.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 35}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       31                                                                                                                                           \\n  Had we not carried out this step, our graph would have been as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAnd since this graph is touching the X -axis, hence it cannot be called a frequency polygon (because it is not a closed \\nfigure)! \\n \\nFREQUENCY CURVE: \\n \\nWhen the frequency polygon is smoothed, we obtain what may be called the frequency curve. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn our example: \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n31.45 34.45 37.45 40.45 43.45Miles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 36}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       32                                                                                                                                           \\nLECTURE NO. 5 \\n  \\n \\nToday’s lecture is in continuation with the last lecture, and today we will begin with various types of frequency curves \\nthat are encountered in practice.  Also, we will discuss the cumulative frequency distribution and cumulative frequency \\npolygon for a continuous variable.  \\n \\nFREQUENCY POLYGON: \\n \\nA frequency polygon is obtained by plotting the class frequencies against the mid -points of the classes, and con necting \\nthe points so obtained by straight line segments. In our example of the EPA mileage ratings, the classes were: \\n \\n \\n                             \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAnd our frequency polygon came out to be: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAlso, it was mentioned that, when the frequency polygon is smoothed, we obtain what may be called the  \\n \\nFREQUENCY CURVE \\n \\nIn our example: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nClass  \\nBoundaries \\nMid-Point \\n(X) \\nFrequency \\n(f) \\n26.95 – 29.95 28.45  \\n29.95 – 32.95 31.45 2 \\n32.95 – 35.95 34.45 4 \\n35.95 – 38.95 37.45 14 \\n38.95 – 41.95 40.45 8 \\n41.95 – 44.95 43.45 2 \\n44.95 – 47.95 46.45  \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 37}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       33                                                                                                                                           \\n \\nIn the above figure, the dotted line represents the frequency curve. It should be noted that it is not necessary that our \\nfrequency curve must touch all the points. The purpose of the frequency curve is simply to display the overall pattern of \\nthe distribution. Hence we draw the curve by the free -hand method, and hence it does not have to touch all the plotted \\npoints. It should be realized that the frequency curve is actually a theoretical concept.  \\nIf the class interval of a histogram is made very small, and the number of classes is very large, the rectangles of the \\nhistogram will be narrow as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe smaller the class interval and the larger the number of classes, the narrower the rectangles will be. In this way, the \\nhistogram approaches a smooth curve as shown below: \\n \\n \\n \\nIn spite of the fact that the frequency curve is a theoretical conc ept, it is useful in analyzing real -world problems. The \\nreason is that very close approximations to theoretical curves are often generated in the real world so close that it is \\nquite valid to utilize the properties of various types of mathematical curves i n order to aid analysis of the real -world \\nproblem at hand. \\n \\nVARIOUS TYPES OF  FREQUENCY CURVES \\n \\n\\uf0b7 the symmetrical frequency curve \\n\\uf0b7 the moderately skewed frequency curve \\n\\uf0b7 the extremely skewed frequency curve \\n\\uf0b7 the U-shaped frequency curve \\n \\nLet us discuss them one by one. First of all, the symmetrical frequency curve is of the following shape: \\n \\n \\n \\nTHE SYMMETRIC CURVE \\nX \\nf '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 38}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       34                                                                                                                                           \\nIf we place a vertical mirror in the centre of this graph, the left hand side will be the mirror image of the right hand side. \\n \\n \\n  x \\n \\nNext, we consider the moderately skewed frequency curve. We have the positively skewed curve and the negatively \\nskewed curve. The positively skewed curve is that one whose right tail is longer than its left tail, as shown below \\n \\n    \\n  \\nOn the other hand, the negatively skewed frequency curve is the one for which the left tail is longer than the right tail.  \\n \\n   \\n  \\n \\nBoth of these that we have just considered are moderately positively and negatively skewed.  \\nSometimes, we have the extrem e case when we obtain the EXTREMELY skewed frequency curve. An extremely \\nnegatively skewed curve is of the type shown below: \\n \\n \\n \\n \\n \\n \\n \\nX \\nf '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 39}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       35                                                                                                                                           \\n  \\n \\n  \\nThis is the case when the maximum frequency occurs at the end of the frequency table. \\nFor example, if we think of the death rates of adult males of various age groups starting from age 20 and going up to \\nage 79 years, we might obtain something like this: \\n \\n \\n \\nThis will result in a J-shaped distribution similar to the one shown above. \\nSimilarly, the extremely positively skewed distribution is known as the REVERSE J-shaped distribution. \\n \\n \\n    \\n  \\n \\n \\n \\n \\n \\n \\nAge Group No. of deaths \\nper thousand \\n20 – 29 2.1 \\n30 – 39 4.3 \\n40 – 49 5.7 \\n50 – 59 8.9 \\n60 – 69 12.4 \\n70 – 79 16.7 \\n \\n                 DEATH RATES BY AGE GROUP '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 40}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       36                                                                                                                                           \\nA relatively LESS frequently encountered frequency distribution is the U-shaped distribution. \\n \\n \\n     \\n  \\nIf we consider the example of the death rates not for only the adult population but for the population of ALL the age \\ngroups, we will obtain the U-shaped distribution.  \\nOut of all these curves, the MOST frequently encountered frequency distribution is the moderately skewed frequency \\ndistribution. There are th ousands of natural and social phenomena which yield  the moderately skewed frequency \\ndistribution. Suppose that we walk into a school and collect data of the weights, heights, marks, shoulder -lengths, \\nfinger-lengths or any other such variable pertaining to the children of any one class. \\nIf we construct a frequency distribution of this data, and draw its histogram and its frequency curve, we will find that \\nour data will generate a moderately skewed distribution. Until now, we have discussed the various possi ble shapes of \\nthe frequency distribution of a continuous variable.  Similar shapes are possible for the frequency distribution of a \\ndiscrete variable. \\n \\nVARIOUS TYPES OF DISCRETE FREQUENCY DISTRIBUTION \\n \\n \\n \\n \\n  \\n  \\n \\n \\nI.  Positively Skewed Distribution \\n0 1 2 3 4 5 6 7 8 9 10 \\nX \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 41}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       37                                                                                                                                           \\n  \\n  \\nLet us now consider another aspect of the frequency distribution i.e.  \\n \\nCUMULATIVE FREQUENCY DISTRIBUTION \\n \\nAs in the case of the frequency distribution of a discrete variable, if we start adding the frequencies of our frequency \\ntable column-wise, we obtain the column of cumulative frequencies. \\n In our example, we obtain the cumulative frequencies shown below: \\n \\n \\n \\nIn the above table, 2+4 gives 6, 6+14 gives 20, and so on.  \\nThe question arises: “What is the purpose of making this column?”  \\nYou wi ll recall that, when we were discussing the frequency distribution of a discrete variable, any particular \\ncumulative frequency meant that we were counting the number of observations starting from the very first value of X \\nand going up to THAT particular value of X against which that particular cumulative frequency was falling. \\n In case of a the distribution of a continuous variable, each of these cumulative frequencies represents the \\ntotal frequency of a frequency distribution from the lower class boundary of the lowest class to the UPPER class \\nboundary of THAT class whose cumulative frequency we are considering.  \\n In the above table, the total number of cars showing mileage less than 35.95 miles per gallon is 6, the \\ntotal number of car showing mileage less than 41.95 miles per gallon is 28, etc. \\n \\n \\nSuch a cumulative frequency distribution is called a “ less than” type of a cumulative frequency distribution. The graph \\nof a cumulative frequency distribution is called a   \\n \\nClass  \\nBoundaries Frequency Cumulative \\nFrequency \\n29.95 – 32.95 2 2 \\n32.95 – 35.95 4 2+4 = 6 \\n35.95 – 38.95 14 6+14 = 20 \\n38.95 – 41.95 8 20+8 = 28 \\n41.95 – 44.95 2 28+2 = 30 \\n 30  \\n \\nCUMULATIVE FREQUENCY DISTRIBUTION \\nClass  \\nBoundaries Frequency Cumulative \\nFrequency \\n29.95 – 32.95 2 2 \\n32.95 – 35.95 4 2+4 = 6 \\n35.95 – 38.95 14 6+14 = 20 \\n38.95 – 41.95 8 20+8 = 28 \\n41.95 – 44.95 2 28+2 = 30 \\n 30  \\n \\nCUMULATIVE FREQUENCY \\nDISTRIBUTION '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 42}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       38                                                                                                                                           \\nCUMULATIVE FREQUENCY POLYGON or OGIVE \\n \\n A “less than” type ogive is obtained by marking off the upper class boundaries of the various \\nclasses along the X-axis and the cumulative frequencies along the y-axis, as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe cumulative frequencies  are plotted on the graph paper against the upper class boundaries, and the points so \\nobtained are joined by means of straight line segments. \\nHence we obtain the cumulative frequency polygon shown below: \\n \\n \\n  \\nIt should be noted t hat this graph is touching the X -Axis on the left -hand side. This is achieved by ADDING a class \\nhaving zero frequency in the beginning of our frequency distribution, as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSince the frequency of the first class is zero, hence the  cumulative frequency of the first class will also be zero, and \\nhence, automatically, the cumulative frequency polygon will touch the X -Axis from the left hand side. If we want our \\ncumulative frequency polygon to be closed from the right -hand side also, we can achieve this by connecting the last \\npoint on our graph paper with the X-axis by means of a vertical line, as shown below: \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n29.95 32.95 35.95 38.95 41.95 44.95\\n   Cumulative Frequency Polygon or OGIVE \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n29.95 32.95 35.95 38.95 41.95 44.95\\nUpper Class Boundaries\\ncf\\nClass  \\nBoundaries Frequency Cumulative \\nFrequency \\n26.95 – 29.95 0 0 \\n29.95 – 32.95 2 0+2 = 2 \\n32.95 – 35.95 4 2+4 = 6 \\n35.95 – 38.95 14 6+14 = 20 \\n38.95 – 41.95 8 20+8 = 28 \\n41.95 – 44.95 2 28+2 = 30 \\n 30  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 43}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       39                                                                                                                                           \\n \\nIn the example of EPA mileage ratings, all the data -values were correct to one decimal place.   Let us now consider \\nanother example: \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n29.95 32.95 35.95 38.95 41.95 44.95\\nOGIVE \\nEXAMPLE:  \\nFor a sample of 40 pizza products, the following data represent cost \\nof a slice in dollars (S Cost). \\nPRODUCT S cost \\nPizza Hut Hand Tossed 1.51 \\nDomino’s Deep Dish 1.53 \\nPizza Hut Pan Pizza 1.51 \\nDomino’s Hand Tossed 1.90 \\nLittle Caesars Pan! Pizza! 1.23 \\n \\n \\nPRODUCT S Cost \\nEllio’s 9-slice 0.52 \\nKroger 0.72 \\nHealthy Choice French Bread 1.50 \\nLean Cuisine French Bread 1.49 \\nDiGiorno Rising Crust 0.87 \\nTombstone Special Order 0.81 \\nPappalo’s 0.73 \\nJack’s New More Cheese! 0.64 \\nTombstone Original 0.77 \\nRed Baron Premium 0.80 \\n \\nPRODUCT S Cost \\nBoboli crust with Boboli sauce 1.00 \\nJack’s Super Cheese 0.69 \\nPappalo’s Three Cheese 0.75 \\nTombstone Original Extra Cheese 0.81 \\nMaster Choice Gourmet Four Cheese 0.90 \\nCeleste Pizza For One 0.92 \\nTotino’s Party 0.64 \\nThe New Weight Watchers Extra Cheese 1.54 \\nJeno’s Crisp’N Tasty 0.72 \\nStouffer’s French Bread 2-Cheese 1.15 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 44}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       40                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSource: “Pizza,” Copyright 1997 by Consumers Union of United States, Inc., Yonkers, N.Y. 10703. \\n \\n \\n \\n \\n   \\n \\n \\nIn order to c onstruct the frequency distribution of the above data, the first thing to note is that, in this example, all our \\ndata values are correct to two decimal places. As such, we should construct the class limits correct to TWO decimal \\nplaces, and the class boundaries correct to three decimal places. \\n As in the last example, first of all, let us find the maximum and the minimum values in our \\ndata, and compute the RANGE.  \\nMinimum value X0 = 0.52 \\nMaximum value Xm = 1.90 \\nHence:  \\n Range  = 1.90 - 0.52 = 1.38  \\n \\n \\n \\nLower limit of the first class = 0.51 \\nDesired number of classes = 8 \\nHence: \\nClass interval h =         RANGE/No. of classes             \\n        = 1.38 / 8 = 0.1725 ~ 0.20 \\nPRODUCT Scost \\nTony’s Italian Style Pastry Cruse 0.83 \\nRed Baron Deep Dish Singles 1.13 \\nTotino’s Party 0.62 \\nThe New Weight Watchers 1.52 \\nJeno’s Crisp’N Tasty 0.71 \\nStouffer’s French Bread 1.14 \\nCeleste Pizza For One 1.11 \\nTombstone For One French Bread 1.11 \\nHealthy Choice French Bread 1.46 \\nLean Cuisine French Bread 1.71 \\n \\nPRODUCT Scost \\nLittle Caesars Pizza! Pizza! 1.28 \\nPizza Hut Stuffed Crust 1.23 \\nDiGiorno Rising Crust Four Cheese 0.90 \\nTombstone Speical Order Four Cheese 0.85 \\nRed Baron Premium 4-Cheese 0.80 \\n \\nExample taken from  \\n“Business Statistics – A First Course” by Mark L. Berenson & David M. \\nLevine (International Edition), Prentice -Hall International, Inc., \\nCopyright © 1998. \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 45}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       41                                                                                                                                           \\nHence, our successive class limits come out to be:  \\n \\nClass Limits \\n0.51 – 0.70 \\n0.71 – 0.90 \\n0.91 – 1.10 \\n1.11 – 1.30 \\n1.31 – 1.50 \\n1.51 – 1.70 \\n1.71 – 1.90 \\n \\n \\n Stretching the class limits to the left and to the right, we obtain class boundaries as shown below: \\n \\nClass Limits Class Boundaries \\n0.51 – 0.70 0.505 – 0.705 \\n0.71 – 0.90 0.705 – 0.905 \\n0.91 – 1.10 0.905 – 1.105 \\n1.11 – 1.30 1.105 – 1.305 \\n1.31 – 1.50 1.305 – 1.505 \\n1.51 – 1.70 1.505 – 1.705 \\n1.71 – 1.90 1.705 – 1.905 \\n \\n \\n \\nBy tallying the data-values in the appropriate classes, we will obtain a frequency distribution similar to the one that we \\nobtained in the examples of the EPA mileage ratings.   \\nBy constructing the histogram of this data -set, we will  be able to decide whether our distribution is symmetric, \\npositively skewed or negatively skewed. This may please be attempted as an exercise.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 46}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       42                                                                                                                                           \\nLECTURE NO. 6 \\n \\n \\nThis plot was introduced by the famous statistician John Tukey in 1977.  A frequency table has the disadvantage that the \\nidentity of individual observations is lost in grouping process. To overcome this drawback, John Tukey (1977) \\nintroduced this particular technique (known as the Stem-and-Leaf Display). \\n This technique offers a quick and novel way for simultaneously sorting and displaying data sets where each \\nnumber in the data set is divided into two parts, a Stem and a Leaf.  \\nA stem is the leading digit(s) of each number and is used in sorting, while a leaf is the rest of the number or t he trailing \\ndigit(s) and shown in display. A vertical line separates the leaf (or leaves) from the stem.  \\n \\nHow do we construct a stem and leaf display when we have a whole set of values?  This is explained by way of the \\nfollowing example: \\n \\nEXAMPLE: \\n \\nThe ages of 30 patients admitted to a certain hospital during a particular week were as follows: \\n           48, 31, 54, 37, 18, 64, 61, 43, 40, 71, 51, 12, 52, 65, 53, 42,  39, 62, 74, 48, 29, 67, 30, 49,  68, 35, 57, 26, 27, 58. \\nConstruct a stem-and-leaf display from the data and list the data in an array. \\nA scan of the data indicates that the observations range (in age) from 12 to 74. We use the first (or leading) \\ndigit as the stem and the second (or trailing) digit as the leaf. The f irst observation is 48, which has a stem of 4 and a \\nleaf of 8, the second a stem of 3 and a leaf of 1, etc. Placing the leaves in the order in which they APPEAR in the data, \\nwe get the stem-and-leaf display as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBut it is a c ommon practice to ARRANGE the trailing digits in each row from smallest to highest. In this example, in \\norder to obtain an array, we associate the leaves in order of size with the stems as shown below: \\n \\nDATA IN THE FORM OF AN ARRAY (in ascending order): \\n \\n12, 18, 26, 27, 29, 30, 31, 35,  37, 39, 40, 42, 43, 48, 48, 49,  51, 52, 53, 54, 57, 58, 61, 62,  64, 65, 67, 68, 71, 74. \\nHence we obtain the stem and leaf plot shown below: \\n \\n \\n \\n \\n \\nFor example, the number 243 could be split in two ways: \\nLeading \\nDigit \\nTrailing \\nDigits \\nOR Leading \\nDigit \\nTrailing \\nDigit \\n2 43  24 3 \\nStem Leaf  Stem Leaf \\n \\nStem  \\n(Leading Digit) \\nLeaf  \\n(Trailing Digit) \\n1 8 2 \\n2 9 6 7 \\n3 1 7 9 0 5 \\n4 8 3 0 2 8 9 \\n5 4 1 2 3 7 8 \\n6 4 1 5 2 7 8 \\n7 1 4 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 47}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       43                                                                                                                                           \\n \\n \\n \\nSTEM AND LEAF DISPLAY \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe stem-and-leaf table provides a useful description of the data set and, if we so desire, can easily be converted to a \\nfrequency table.  In this example, th e frequency of the class 10 -19 is 2, the frequency of the class 20 -29 is 3, and the \\nfrequency of the class 30-39 is 5, and so on. \\n \\nSTEM AND LEAF DISPLAY \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, this stem and leaf plot conveniently converts into the frequency distribution shown below: \\n \\nFREQUENCY DISTRIBUTION \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStem \\n(Leading Digit) \\nLeaf \\n(Trailing Digit) \\n1 2   8 \\n2 6   7   9 \\n3 0   1   5   7   9 \\n4 0   2   3   8   8   9 \\n5 1   2   3   4   7   8 \\n6 1   2   4   5   7   8 \\n7 1   4 \\n \\nStem \\n(Leading Digit) \\nLeaf \\n(Trailing Digit) \\n1 2 8 \\n2 6 7 9 \\n3 0 1 5 7 9 \\n4 0 2 3 8 8 9 \\n5 1 2 3 4 7 8 \\n6 1 2 4 5 7 8 \\n7 1 4 \\n \\nClass  \\nLimits \\nClass  \\nBoundaries \\nTally  \\nMarks Frequency \\n10 – 19 9.5 – 19.5 // 2 \\n20 – 29 19.5 – 29.5 /// 3 \\n30 – 39 29.5 – 39.5 //// 5 \\n40 – 49  39.5 – 49.5 //// / 6 \\n50 – 59 49.5 – 59.5 //// / 6 \\n60 – 69 59.5 – 69.5 //// / 6 \\n70 - 79 69.5 – 79.5 // 2 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 48}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       44                                                                                                                                           \\n \\n \\n \\n \\nConverting this frequency distribution into a histogram, we obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we rotate this histogram by 90 degrees, we will obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us re-consider the stem and leaf plot that we obtained a short while ago. \\n \\nSTEM AND LEAF DISPLAY \\n \\n \\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n9.5 19.5 29.5 39.5 49.5 59.5 69.5 79.5Age\\nNumber of Patients\\nX\\nY\\n0 2 4 6 8\\n9.5\\n19.5\\n29.5\\n39.5\\n49.5\\n59.5\\n69.5\\n79.5\\nX\\nY\\nNumber of Patients\\nAge'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 49}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       45                                                                                                                                           \\n \\n \\n \\nIt is noteworthy that the shape of the stem an d leaf display is exactly like the shape of our histogram. Let us now \\nconsider another example. \\n \\n \\nEXAMPLE \\n \\n Construct a stem-and-leaf display for the data of mean annual death rates per thousand at ages 20-65 given below: \\n7.5, 8.2, 7.2, 8.9, 7.8, 5.4, 9.4, 9.9, 10.9, 10.8, 7.4, 9.7, 11.6, 12.6, 5.0, 10.2, 9.2, 12.0, 9.9, 7.3, 7.3, 8.4, 10.3, 10.1, 10.0, \\n11.1, 6.5, 12.5, 7.8, 6.5, 8.7, 9.3, 12.4, 10.6, 9.1, 9.7, 9.3, 6.2, 10.3, 6.6, 7.4, 8.6, 7.7, 9.4, 7.7, 12.8, 8.7, 5.5, 8.6,  9.6, \\n11.9, 10.4, 7.8, 7.6, 12. 1, 4.6, 14.0, 8.1, 11.4, 10.6, 11.6, 10.4, 8.1, 4.6, 6.6, 12.8, 6.8, 7.1, 6.6, 8.8, 8.8, 10.7, 10.8, 6.0, \\n7.9, 7.3, 9.3, 9.3, 8.9, 10.1, 3.9, 6.0, 6.9, 9.0, 8.8, 9.4, 11.4, 10.9  \\nUsing the decimal part in each number as the leaf and the rest of the digits as the stem, we get the ordered \\nstem-and-leaf display shown below: \\n \\nSTEM AND LEAF DISPLAY \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nEXERCISE \\n \\n\\uf0b7 The above data may be converted into a stem and leaf plot (so as to verify that the one shown above is \\ncorrect).  \\n\\uf0b7 Various variations of the stem and leaf display may be studied on your own. \\nThe next concept that we are going to consider is the concept of the central tendency of a data -set. In this context, the \\nfirst thing to note is that in any data -based study, our data is always go ing to be variable, and hence, first of all, we will \\nneed to describe the data that is available to us. \\nStem Leaf \\n3 9 \\n4 6 6 \\n5 0 4 5 \\n6 0 0 2 2 5 5 6 6 6 8 9 \\n7 1 3 3 3 4 4 5 6 7 7 8 8 8 9 \\n8 1 1 2 4 6 6 7 7 8 8 8 9 9 \\n9 0 1 2 3 3 3 3 4 4 4 6 7 7 9 9 \\n10 0 1 1 2 3 3 4 4 6 6 7 8 8 9 9 \\n11 1 4 4 6 6 9 \\n12 0 1 4 5 6 8 8 \\n14 0 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 50}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       46                                                                                                                                           \\n \\nDESCRIPTION OF VARIABLE DATA: \\n \\n                             Regarding any statistical enquiry, primarily we need some means of describing the situation  with \\nwhich we are confronted. A concise numerical description is often preferable to a lengthy tabulation, and if this form of \\ndescription also enables us to form a mental image of the data and interpret its significance, so much the better.  \\n \\n                                          \\nAVERAGES   (I.E. MEASURES OF CENTRAL TENDENCY) \\n \\nAn average is a single value which is intended to represent a set of data or a distribution as a whole. It is more or less \\nCENTRAL value ROUND which the observations in the set of data or distribution usually tend to cluster. \\nAs a measure of central tendency (i.e. an average) indicates the location or general position of the distribution on the X -\\naxis, it is also known as a measure of location or position.  \\nLet us consider an example: Suppose that we have the following two frequency distributions: \\n \\nEXAMPLE: \\n \\nLooking at these two frequency distributions, we should ask ourselves what exactly is the distinguishing feature? \\nIf we draw the frequency polygon of the two frequency distributions, we obtain \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nInspection of these frequency polygons shows that they have exactly the same shape. It is their position relative to the \\nhorizontal axis (X-axis) which distinguishes them.  \\nIf we compute th e mean number of rooms per house for each of the two suburbs, we will find that the average number \\nof rooms per house in A is 6.67 while in B it is 7.67. \\nThis difference of 1 is equivalent to the difference in position of the two frequency polygons. \\n          Our interpretation of the above situation would be that there are LARGER houses in suburb B than in suburb A, \\nto the extent that there are on the average.  \\n \\nVARIOUS TYPES OF AVERAGES: \\n \\nThere are several types of averages each of which has a use in specifically defined circumstances. \\nThe most common types of averages are: \\n\\uf0b7 The arithmetic mean, \\n\\uf0b7 The geometric mean, \\n\\uf0b7 Averages enable us to measure the central tendency of \\nvariable data \\n \\n\\uf0b7 Measures o f dispersion enable us to measure its \\nvariability. \\nMEASURES OF CENTRAL TENDENCY \\nAND \\nMEASURES OF DISPERSION \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n4 5 6 7 8 9 10\\nSuburb A\\nSuburb B'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 51}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       47                                                                                                                                           \\n\\uf0b7 The harmonic mean  \\n\\uf0b7 The median, and  \\n\\uf0b7 The mode \\n \\nThe Arithmetic, Geometric and Harmonic means  are averages that are mathematical in character, and give an \\nindication of the magnitude of the observed values.  \\nThe Median indicates the middle position while the mode provides information about the most frequent value in the \\ndistribution or the set of data. THE MODE: \\nThe Mode is defined as that value which occurs most frequently in a set of data i.e. it indicates the most common result. \\n \\nEXAMPLE: \\n \\nSuppose that the marks of eight students in a particular test are as follows: \\n                               2, 7, 9, 5, 8, 9, 10, 9  \\nObviously, the most common mark is 9. In other words, Mode = 9. \\n  \\nMODE IN CASE OF RAW DATA  PERTAINING TO A CONTINUOUS VARIABLE \\n \\nIn case of a set of values (pertaining to a continuous variable) that have not been grouped into a frequency distribution \\n(i.e. in case of raw data pertaining to a continuous variable), the mode is obtained by counting the number of times each \\nvalue occurs. \\n \\nEXAMPLE: \\n \\nSuppose that the government of a country collected data regarding the percentages of revenues spent on Research and \\nDevelopment by 49 different companies, and obtained the following figures: \\n \\n                           Percentage of Revenues Spent on Research and Development \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCompan\\ny Percentage Compan\\ny Percentage \\n1 13.5 14 9.5 \\n2 8.4 15 8.1 \\n3 10.5 16 13.5 \\n4 9.0 17 9.9 \\n5 9.2 18 6.9 \\n6 9.7 19 7.5 \\n7 6.6 20 11.1 \\n8 10.6 21 8.2 \\n9 10.1 22 8.0 \\n10 7.1 23 7.7 \\n11 8.0 24 7.4 \\n12 7.9 25 6.5 \\n13 6.8 26 9.5 \\n \\nCompan\\ny Percentage Compan\\ny Percentage \\n27 8.2 39 6.5 \\n28 6.9 40 7.5 \\n29 7.2 41 7.1 \\n30 8.2 42 13.2 \\n31 9.6 43 7.7 \\n32 7.2 44 5.9 \\n33 8.8 45 5.2 \\n34 11.3 46 5.6 \\n35 8.5 47 11.7 \\n36 9.4 48 6.0 \\n37 10.5 49 7.8 \\n38 6.9   \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 52}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       48                                                                                                                                           \\n \\n \\n \\n \\n \\n \\nWe can represent this data by means of a plot that is called dot plot. \\n \\nDOT PLOT: \\n \\n               The horizontal axis of a dot plot contains a scale for the quantitative variable that we want to represent. The \\nnumerical value of each measurement in the data set is located on the horizontal scale by a dot. When data values \\nrepeat, the dots are placed above one another, forming a pile at that particular numerical location.  \\nIn this example \\n \\n \\n \\n \\n \\nAs is obvious from the above diagram, the value 6.9 occurs 3 times whereas all the other values are occurring either \\nonce or twice.  \\nHence the modal value is 6.9.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n                                                          Dot plot: \\n \\n \\nDot Plot \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n4.5 6 7.5 9 10.5 12 13.5\\nR&D\\nXˆ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 53}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       49                                                                                                                                           \\n                               = 6.9 \\n \\n \\n \\n \\n \\nAlso, this dot plot shows that  \\n•  almost all of the R&D percentages are falling between 6% and 12%,  \\n•  most of the percentages are  falling between 7% and 9%.  \\n \\nTHE MODE IN CASE OF A DISCRETE FREQUENCY DISTRIBUTION: \\n \\nIn case of a discrete frequency distribution, identification of the mode is immediate; one simply finds that value which \\nhas the highest frequency. \\n \\nEXAMPLE: \\n \\n An airline found the following numbers of passengers in fifty flights of a forty-seated plane \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHighest Frequency fm = 13  \\nOccurs against the X value 39  \\nHence: Mode = x= 39  \\nThe mode is obviously 39 passen gers and the company should be quite satisfied that a 40 seater is the correct -size \\naircraft for this particular route. \\n \\nTHE MODE IN CASE OF THE FREQUENCY DISTRIBUTION OF A CONTINUOUS VARIABLE \\n \\nIn case of grouped data, the modal group is easily recognizable (the one that has the highest frequency).  \\nAt what point within the modal group does the mode lie? \\nThe answer is contained in the following formula: \\n \\nMode: \\n \\n \\n \\n \\n \\nWhere \\n \\n \\nl = lower class boundary of the modal class, \\nfm = frequency of the modal class, \\nf1 = frequency of the class preceding the  \\n    modal class \\nf2 = frequency of the class following modal \\nNo. of Passengers \\nX \\nNo. of Flights \\nf \\n28 1 \\n33 1 \\n34 2 \\n35 3 \\n36 5 \\n37 7 \\n38 10 \\n39 13 \\n40 8 \\nTotal 50 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 hxffff\\nff1Xˆ\\n2m1m\\n1m\\n\\uf02d\\uf02b\\uf02d\\n\\uf02d\\uf02b\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 54}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       50                                                                                                                                           \\n    class  \\nh = length of class interval of the modal class \\n \\n \\n \\nGoing back to the example of EPA mileage ratings, we have: \\n \\n \\n \\nIt is evident that the third class is the modal class. The mode lies somewhere between 35.95 and 38.95.  \\nIn order to apply the formula for the mode, we note that fm = 14, f1 = 4 and f2 = 8. \\nHence we obtain:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  Let us now perceive the mode by conside ring the graphical representation of our frequency distribution. You will \\nrecall that, for the example of EPA Mileage Ratings, the histogram was as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMileage \\nRating \\nClass  \\nBoundaries \\nNo. of \\nCars \\n30.0 – 32.9 29.95 – 32.95 2 \\n33.0 – 35.9 32.95 – 35.95 4 = f1 \\n36.0 – 38.9 35.95 – 38.95 14 = fm \\n39.0 – 41.9 38.95 – 41.95 8 = f2 \\n42.0 – 44.9 41.95 – 44.95 2 \\n \\nEPA MILEAGE RATINGS \\n\\uf028 \\uf029 \\uf028 \\uf029\\n825.37\\n875.195.35\\n3610\\n1095.35\\n3814414\\n41495.35Xˆ\\n\\uf03d\\n\\uf02b\\uf03d\\n\\uf0b4\\uf02b\\uf02b\\uf03d\\n\\uf0b4\\uf02d\\uf02b\\uf02d\\n\\uf02d\\uf02b\\uf03d\\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n29.95 32.95 35.95 38.95 41.95 44.95\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 55}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       51                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\nThe frequency polygon of the same distribution was: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAnd the frequency curve was as indicated by the dotted line in the following figure: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 56}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       52                                                                                                                                           \\n \\n \\n \\n \\n \\n \\nIn this example, the mode is 37.825, and if we locate this value on the X-axis, we obtain the following picture: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n                                                     \\n        = 37.825 \\n \\n \\n \\nSince, in most of the situations the mode exists somewhere in the middle of our data -values, hence it is thought of as a \\nmeasure of central tendency. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\n28.45 31.45 34.45 37.45 40.45 43.45 46.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\nXˆ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 57}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       53                                                                                                                                           \\n \\n \\nLECTURE NO. 7 \\n \\nIn general, it was noted that, for most of the frequency distributions, the mode lies somewhere in the middle of our \\nfrequency distribution, and hence is eligible to be called a measure of central tendency. \\nThe mode has some very desirable properties.  \\n \\n DESIRABLE PROPERTIES OF THE MODE: \\n \\n\\uf0b7 The mode is easily understood and easily ascertained in case of a discrete frequency distribution. \\n\\uf0b7 It is not affected by a few very high or low values.  \\nThe question arises, “When s hould we use the mode?” The  answer to this question is that the mode is a valuable \\nconcept in certain situations such as the one described below: \\nSuppose the manager of a men’s clothing store is asked about the average size of hats sold. He will probably \\nthink not of the arithmetic or geometric mean size, or indeed the median size. Instead, he will in all likelihood quote that \\nparticular size which is sold most often. This average is of far more use to him as a businessman than the arithmetic \\nmean, geometric mean or the median. The modal size of all clothing is the size which the businessman must stock in the \\ngreatest quantity and variety in comparison with other sizes. Indeed, in most inventory (stock level) problems, one \\nneeds the mode more often than any other measure of central tendency. It should be noted that in some situations there \\nmay be no mode in a simple series where no value occurs more than once. \\n On the other hand, sometimes a frequency distribution contains two modes in which case it is called  \\na bi-modal distribution as shown below: \\n \\n \\n \\n \\n \\nThe next measure of central tendency to be discussed is the arithmetic mean. \\n                                            \\nTHE ARITHMETIC MEAN \\n \\nThe arithmetic mean is the statistician’ s term for what the layman knows as the average. It can be thought of as that \\nvalue of the variable series which is numerically MOST representative of the whole series. Certainly, this is the most \\nwidely used average in statistics. Easiest In addition, it is probably the to calculate. \\nIts formal definition is:  \\n“The arithmetic mean or simply the mean is a value obtained by dividing the sum of all the observations by their \\nnumber.” \\n \\nf \\n0 X \\nTHE BI-MODAL FREQUENCY DISTRIBUTION '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 58}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       54                                                                                                                                           \\n \\nWhere n represents the number of observations in the sample that has been the ith observation in the sample (i = 1, 2, 3, \\n…, n), and  represents the mean of the sample. \\nFor simplicity, the above formula can be written as \\n \\n \\n \\n \\n \\nIn other words, it is not necessary to insert the subscript ‘i’.)  \\n \\nEXAMPLE: \\n \\nInformation regarding the receipts of a news agent for seven days of a particular week are given below \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMean sales per day in this week:  \\n       = £ 259.85/7 = £ 37.12 (To the nearest penny). \\n \\nINTERPRETATION: \\n \\nThe mean, £ 37.12, represe nts the amount (in pounds sterling) that would have been obtained on each day if the same \\namount were to be obtained on each day. The above example pertained to the computation of the arithmetic mean in \\ncase of ungrouped data i.e. raw data. \\n         Let us now consider the case of data that has been grouped into a frequency distribution. When data pertaining to \\na continuous variable has been grouped into a frequency distribution, the frequency distribution is used to calculate the \\napproximate values of descriptive measures --- as the identity of the observations is lost.  \\nTo calculate the approximate value of the mean, the observations in each class are assumed to be identical with the class \\nmidpoint Xi.  \\nThe mid-point of every class is known as its class -mark. In other words, the midpoint of a class ‘marks’ th at class. As \\nwas just mentioned,  the observations in each class are assumed to be identical with the midpoint i.e. the class -mark. \\n(This is based on the assumption that the observations in the group are evenly scattered between the two extremes of the \\nclass interval). \\n As was just mentioned, the observations in each class are assumed to be identical with the midpoint i.e. the class -mark. \\n(This is based on the assumption that the observations in the group are evenly scattered between the two extremes of the \\nclass interval).  \\n \\n \\nSum of all the observations \\nX\\n = Number of the observations \\n \\n \\nn\\nX\\nX\\nn\\ni\\ni\\uf0e5\\n\\uf03d\\uf03d 1\\nn\\nXX \\uf0e5\\uf03d\\nDay Receipt of News Agent \\nMonday £ 9.90 \\nTuesday £ 7.75 \\nWednesday £ 19.50 \\nThursday £ 32.75 \\nFriday £ 63.75 \\nSaturday £ 75.50 \\nSunday £ 50.70 \\nWeek Total £ 259.85 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 59}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       55                                                                                                                                           \\n \\n \\n \\nIn case of a frequency distribution, the arithmetic mean is defined as: \\nARITHMETIC MEAN \\n \\n \\n \\n \\n \\n \\n \\n \\nFor simplicity, the above formula can be written as \\n \\n \\n (The subscript ‘i’ can be dropped.) \\n \\n \\n \\nLet us understand this point with the help of an example: \\nGoing back to the example of EPA mileage ratings, that we dealt with when discussing the formation of a frequency \\ndistribution. The frequency distribution that we obtained was: \\n \\nEPA MILEAGE RATINGS OF 30 CARS OF A CERTAIN MODEL \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe first step is to compute the mid-point of every class.  \\n(You will recall that the concept of the mid-point has already been discussed in an earlier lecture.) \\n \\nCLASS-MARK (MID-POINT): \\n \\nThe mid-point of each class is obtained by adding the sum of the two limits of the class and dividing by 2.  \\nHence, in this example, our mid-points are computed in this manner: \\n 30.0 plus 32.9 divided by 2 is equal to 31.45,  \\n 33.0 plus 35.9 divided by 2 is equal to 34.45, \\n \\n \\nAnd so on. \\n \\n \\n \\nMid Point \\nX \\nFrequency \\nf \\nX1 f1 \\nX2 f2 \\nX3 f3 \\n: \\n: \\n: \\n: \\n: \\n: \\nXk fk \\n \\n           FREQUENCY DISTRIBUTION \\nn\\nXf\\nf\\nXf\\nX\\nk\\ni\\nii\\nk\\ni\\ni\\nk\\ni\\nii \\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf03d\\n\\uf03d\\n\\uf03d \\uf03d\\uf03d 1\\n1\\n1\\nn\\nfX\\nf\\nfXX \\uf0e5\\n\\uf0e5\\n\\uf0e5 \\uf03d\\uf03d\\nClass  \\n(Mileage Rating) \\nFrequency  \\n(No. of Cars) \\n30.0 – 32.9 2 \\n33.0 – 35.9 4 \\n36.0 – 38.9 14 \\n39.0 – 41.9 8 \\n42.0 – 44.9 2 \\nTotal 30 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 60}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       56                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to compute the arithmetic mean, we first need to construct the column of fX, as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nApplying the formula  \\n \\n \\n \\n \\nWe obtain \\n \\n \\n \\n \\nINTERPRETATION: \\n \\nThe average mi leage rating of the 30 cars tested by the Environmental Protection Agency is 37.85 – on the average, \\nthese cars run 37.85 miles per gallon. An important concept to be discussed at this point is the concept of grouping \\nerror. \\n \\nGROUPING ERROR: \\n \\n“Grouping error” refers to the error that is introduced by the assumption that all the values falling in a class are equal to \\nthe mid-point of the class interval. In reality, it is highly improbable to have a class for which all the values lying in that \\nclass are equal to the mid-point of that class. This is why the mean that we calculate from a frequency distribution does \\nnot give exactly the same answer as what we would get by computing the mean of our raw data. \\nAs indicated earlier, a frequency distribution is used t o calculate the approximate values of various descriptive \\nmeasures.(The word ‘approximate’ is being used because of the grouping error that was just discussed.) This grouping \\nerror arises in the computation of many descriptive measures such as the geometri c mean, harmonic mean, mean \\ndeviation and standard deviation. But, experience has shown that in the calculation of the arithmetic mean, this error is \\nusually small and never serious. Only a slight difference occurs between the true answer that we would get from the raw \\ndata, and the answer that we get from the data that has been grouped in the form of a frequency distribution. \\nIn this example, if we calculate the arithmetic mean directly from the 30 EPA mileage ratings, we obtain:  \\nArithmetic mean computed from raw data of the EPA mileage ratings: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nClass-mark \\n(Midpoint) \\nX \\nFrequency  \\nf fX \\n31.45 2 62.9 \\n34.45 4 137.8 \\n37.45 14 524.3 \\n40.45 8 323.6 \\n43.45 2 86.9 \\n 30 1135.5 \\n \\n,\\n\\uf0e5\\n\\uf0e5\\uf03d f\\nfXX\\n85.3730\\n5.1135 \\uf03d\\uf03dX\\n82.3730\\n7.1134 \\uf03d\\uf03d\\n30\\n8.399.33.....1.303.36 \\uf02b\\uf02b\\uf02b\\uf02b\\uf03dX\\nClass \\n(Mileage Rating) \\nClass-mark \\n(Midpoint) \\nX \\n30.0 – 32.9 31.45 \\n33.0 – 35.9 34.45 \\n36.0 – 38.9 37.45 \\n39.0 – 41.9 40.45 \\n42.0 – 44.9 43.45 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 61}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       57                                                                                                                                           \\n The difference between the true value of i.e. 37.82 and the value obtained from the frequency distribution i.e. 37.85 is \\nindeed very slight. The arithmetic mean is predominantly used as a measure of central tendency.  \\nThe question is, “Why is it that the arithmetic mean is known as a measure of central tendency?” \\nThe answer to this question is that we have just obtained i.e. 37.85 falls more or less in the centre of our frequency \\ndistribution. \\n \\n \\n \\n \\n \\nAs indicated earlier, the arithmetic mean is predominantly used as a measure of central tendency. \\nIt has many desirable properties: \\n \\nDESIRABLE PROPERTIES OF THE ARITHMETIC MEAN \\n \\n\\uf0b7 Best understood average in statistics.   \\n\\uf0b7 Relatively easy to calculate  \\n\\uf0b7 Takes into account every value in the series.  \\n \\nBut there is one limitation to the use of the arithmetic mean:  \\nAs we are aware, every value in a data -set is included in the calculation of the mean, whether the value be high or low. \\nWhere there are a few very high or very low values in the series, their effect can be to drag the arithmetic mean towards \\nthem. This may make the mean unrepresentative. \\n \\n EXAMPLE: \\n \\n Example of the Case Where the Arithmetic Mean Is Not a Proper Representative of the Data: \\nSuppose one walks down the main street of a large city centre and counts the number of floors in each building.  \\nSuppose, the following answers are obtained: \\n5, 4, 3, 4, 5, 4, 3, 4, 5, 20, 5, 6, 32, 8, 27 \\nThe mean number of floors is 9 even though 12 out of 15 of the buildings have 6 floors or less.  \\nThe three skyscraper blocks are having a disproportionat e effect on the arithmetic mean  (Some other average in this \\ncase would be more representative). The concept that we just considered was the concept of the simple arithmetic mean. \\nLet us now discuss the concept of the weighted arithmetic mean. \\nConsider the following example: \\n \\nEXAMPLE: \\n \\n Suppose that in a particular high school, there are:-  \\n 100 – freshmen \\n 80 – sophomores  \\n 70 – juniors \\n 50 – seniors \\nAnd suppose that on a given day, 15% of freshmen, 5% of sophomores, 10% of juniors, 2% of seniors are absent.  \\nThe problem is that: What percentage of students is absent for the school as a whole on that particular day?   \\nNow a student is likely to attempt to find the answer by adding the percentages and dividing by 4  \\ni.e. \\n \\n \\n \\nMean = 37.85 \\n0\\n5\\n10\\n15\\n28.4531.45 34.4537.45 40.4543.4546.45\\nMiles per gallon\\nNumber of Cars\\nX\\nY\\n84\\n32\\n4\\n210515 \\uf03d\\uf03d\\uf02b\\uf02b\\uf02b'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 62}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       58                                                                                                                                           \\n \\n \\nBut the fact of the matter is that the above calculation gives a wrong answer. In order to figure out why this is a wrong \\ncalculation, consider the following: As we have already  noted, 15% of the freshmen are absent on this particular day. \\nSince, in all, there are 100 freshmen in the school, hence the total number of freshmen who are absent is also 15.  \\n But as far as the sophomores are concerned, the total number of them in the school is 80, and if 5% of \\nthem are absent on this particular day, this means that the total number of sophomores who are absent is only 4. \\nProceeding in this manner, we obtain the following table. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nDividing the total number of students who are absent by the total number of students enrolled in the school, and \\nmultiplying by 100, we obtain: \\n \\n \\n \\n \\n \\n \\nThus its very clear that previous result was not correct.  This situation leads us to a very important observation, i.e. here \\nour figures pertaining to absenteeism in various categories of students cannot be regarded as having equal weightage. \\n \\nWhen we have such a situation, the concept of “weighing” applies i.e. every data value in the data set is assigned a \\ncertain weight according to a suitable cri terion. In this way, we will have a weighted series of data instead of an un -\\nweighted one. In this example, the number of students enrolled in each category acts as the weight for the number of \\nabsences pertaining to that category i.e. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe formula for the weighted arithmetic mean is:  \\n \\nWEIGHTED MEAN \\n \\n \\n \\n \\n \\n \\n \\nAnd, in this example, the weighted mean is equal to:  \\n \\n \\n \\nCategory of Student \\nPercentage of \\nStudents who are \\nabsent \\nXi \\nNumber of students \\nenrolled in the \\nschool \\n(Weights) \\nWi \\nWiXi \\n(Weighted Xi) \\nFreshman 15 100 100 \\uf0b4 15 = 1500 \\nSophomore 5 80 80 \\uf0b4 5 = 400 \\nJunior 10 70 70 \\uf0b4 10 = 700 \\nSenior 2 50 50 \\uf0b4 2 = 100 \\n Total \\uf053Wi = 300 \\uf053WiXi = 2700 \\n \\nCategory of Student Number of Students in the \\nschool \\nNumber of Students who are \\nabsent \\nFreshman 100 15 \\nSophomore 80 4 \\nJunior 70 7 \\nSenior 50 1 \\nTOTAL 300 27 \\n \\n9100300\\n27 \\uf03d\\uf0b4\\n\\uf0e5\\n\\uf0e5\\uf03d\\ni\\nii\\nw W\\nXWX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 63}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       59                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\nThus we note that, in this example, the weighted mean yields exactly the same as the answer that we obtained earlier. \\n As obvious, the weighing process leads us to a correct answer under the situation where we have data that \\ncannot be regarded as being such that each value should be given equal weightage.  \\nAn important point to note here is the criterion for assigning weigh ts. Weights can be assigned in a number of ways \\ndepending on the situation and the problem domain. \\nThe next measure of central tendency that we will discuss is the median. \\nLet us understand this concept with the help of an example. \\nLet us return to the pro blem of the ‘average’ number of floors in the buildings at the centre of a city. We saw that the \\narithmetic mean was distorted towards the few extremely high values in this series and became unrepresentative.   \\n We could more appropriately and easily employ the median as the ‘average’ in these circumstances.  \\n \\n MEDIAN \\n \\nThe median is the middle value of the series when the variable values are placed in order of magnitude.  \\n \\nThe median is defined as a “value which divides a set of data into two halves, one ha lf comprising of observations \\ngreater than and the other half smaller than it. More precisely, the median is a value at or below which 50% of the data \\nlie.” \\nThe median value can be ascertained by inspection in many series. For instance, in this very exampl e, the data that we \\nobtained was: \\n \\nEXAMPLE-1 \\n \\nThe average number of floors in the buildings at the centre of a city: \\n5, 4, 3, 4, 5, 4, 3, 4, 5, 20, 5, 6, 32, 8, 27 \\n Arranging these values in ascending order, we obtain \\n3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 8, 20, 27, 32 \\nPicking up the middle value, we obtain the median equal to 5. \\n \\nINTERPRETATION \\n \\nThe median number of floors is 5. Out of those 15 buildings, 7 have unto 5 floors and 7 have 5 floors or more. We \\nnoticed earlier that the arithmetic mean was distorted  toward the few extremely high values in the series and hence \\nbecame unrepresentative. The median = 5 is much more representative of this series. \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf0e5\\n\\uf0e5\\uf03d\\ni\\nii\\nw W\\nXWX\\n9\\n300\\n2700\\n\\uf03d\\n\\uf03d\\nHeight of buildings (number of floors) \\n3 \\n3 \\n4 \\n4   7 lower \\n4 \\n5 \\n5 \\n5 = median height \\n5  \\n5 \\n6 \\n8 7 higher \\n20 \\n27 \\n32 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 64}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       60                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\nEXAMPLE 2 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nA slight complication arises when there are even numbers of observations in the series, for now there are two  middle \\nvalues. \\nThe expedient of taking the arithmetic mean of the two is adopted as explained below: \\n \\nEXAMPLE-3 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nEXAMPLE -4: \\n \\nThe number of passengers traveling on a bus at six different times during a day is as follows: \\n5, 14, 47, 34, 18, 23 \\nFind the median. \\n \\nSolution: \\nArranging the values in ascending order, we obtain \\n5, 14, 18, 23, 34, 47 \\nAs before, a slight complication has arisen because of the fact that there are even numbers of observations in the series \\nand, as such, there are two middle values. As before, we take the arithmetic mean of the two middle values. \\nHence we obtain: \\n \\nMedian: \\n \\n \\n \\nA very important point to be noted here is that we must arrange the data in ascending order before searching for the two \\nmiddle values. All the above examples pertained to raw data. Let us now consider the case of grouped data.  \\nWe begin by discussing the case of discrete data grouped into a frequency table. \\nAs stated earlier, a discrete frequency distribution is no more than a concise representation of a simple series pertaining \\nto a discrete variable, so that the same approach as the one discussed just now would seem relevant. \\n \\nRetail price of motor-car (£) \\n(several makes and sizes) \\n415 \\n480 \\n525 4 above \\n608 \\n719               = median price \\n1,090 \\n2,059 \\n4,000 4 above \\n6,000 \\n \\nNumber of passengers travelling on a  \\nbus at six Different times during the day \\n4 \\n9 \\n14 \\n18 = median value \\n23 \\n47 \\nMedian = \\n2\\n1814 \\uf02b = 16 passengers \\n \\n5.202\\n2318X~ \\uf03d\\uf02b\\uf03d\\nPassengers '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 65}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       61                                                                                                                                           \\n \\n \\n \\n \\n \\n \\nEXAMPLE OF A DISCRETE FREQUENCY DISTRIBUTION \\n \\nComprehensive School \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to locate the middle value, the best thing is to first of all construct a column of cumulative frequencies: \\n   \\n  Comprehensive School \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn this school, there are 45 classes in all, so that we require as the media n that class -size below which there are 22 \\nclasses and above which also there are 22 classes.  \\nIn other words, we must find the 23rd class in an ordered list. We could simply count down noticing that there is 1 class \\nof 23 children, 2 classes with up to 25 children, 5 classes with up to 26 children. Proceeding in this manner, we find that \\n20 classes contain up to 28 children whereas  28 classes contain up to 29 children. This means that the 23rd class --- the \\none that we are looking for --- is the one which contains exactly 29 children. \\n \\nComprehensive School \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMedian number of pupils per class: \\n \\n \\n \\n \\nThis means that 29 is the middle size of the class. In other words, 22 classes are such which contain 29 or less than 29 \\nchildren, and 22 classes are such which contain 29 or more than 29 children. \\n \\nNumber of pupils per class Number of Classes \\n23 1 \\n24 0 \\n25 1 \\n26 3 \\n27 6 \\n28 9 \\n29 8 \\n30 10 \\n31 7 \\n 45 \\n \\nNumber of \\npupils per class \\nX \\nNumber of \\nClasses \\nf \\nCumulative \\nFrequency \\ncf \\n23 1 1 \\n24 0 1 \\n25 1 2 \\n26 3 5 \\n27 6 11 \\n28 9 20 \\n29 8 28 \\n30 10 38 \\n31 7 45 \\n 45  \\n \\nNumber of \\npupils per class \\nX \\nNumber of \\nClasses \\nf \\nCumulative \\nFrequency \\ncf \\n23 1 1 \\n24 0 1 \\n25 1 2 \\n26 3 5 \\n27 6 11 \\n28 9 20 \\n29 8 28 \\n30 10 38 \\n31 7 45 \\n 45  \\n \\n29X~ \\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 66}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       62                                                                                                                                           \\n \\n \\n \\nLECTURE NO. 8 \\n \\n\\uf0b7 Median in case of a frequency distribution of a continuous variable \\n\\uf0b7 Median in case of an open-ended frequency distribution \\n\\uf0b7 Empirical relation between the mean, median and the mode \\n\\uf0b7 Quantiles (quartiles, deciles & percentiles) \\n\\uf0b7 Graphic location of quantiles. \\n \\nMEDIAN IN CASE OF A FREQUENCY DISTRIBUTION OF A CONTINUOUS VARIABLE: \\n \\nIn case of a frequency distribution, the median is given by the formula  \\n \\n \\n \\n \\n \\nWhere \\nl =lower class boundary of the median class (i.e. that class for which the cumulative frequency is just in excess of n/2). \\nh=class interval size of the median class  \\nf =frequency of the median class  \\nn=\\uf053f (the total number of observations) \\nc =cumulative frequency of the class preceding the median class \\n \\nNote: \\nThis formula is based on the assumption that the observations in each class are evenly distributed between the two class \\nlimits. \\n \\nEXAMPLE: \\n \\nGoing back to the example of the EPA mileage ratings, we have \\n \\n \\n \\n \\n \\n \\n   \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn this example, n = 30 and n/2 = 15. \\nThus the third class is the median class. The median lies somewhere between 35.95 and 38.95. Applying the above \\nformula, we obtain \\n \\n \\n \\n \\n \\n \\n \\n \\nINTERPRETATION \\n \\nThis result implies that half of the cars have mileage less than or up to 37.88 miles per gallon whereas the other half of \\nthe cars has mileage greater than 37.88 miles per gallon. As discussed earlier, the median is preferable to the arithmetic \\n\\uf028 \\uf029\\n9.37~\\n88.37\\n93.195.35\\n61514\\n395.35X~\\n\\uf02d\\n\\uf03d\\n\\uf02b\\uf03d\\n\\uf02d\\uf02b\\uf03d\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d cn\\nf\\nhlX 2\\n~\\nMileage \\nRating \\nNo. \\nof  \\nCars \\nClass  \\nBoundaries \\nCumulative  \\nFrequency \\n30.0 – 32.9 2 29.95 – 32.95 2 \\n33.0 – 35.9 4 32.95 – 35.95 6 \\n36.0 – 38.9 14 35.95 – 38.95 20 \\n39.0 – 41.9 8 38.95 – 41.95 28 \\n42.0 – 44.9 2 41.95 – 44.95 30 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 67}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       63                                                                                                                                           \\nmean when there are a few very high or low figures in a series. It is also exceeding ly valuable when one encounters a \\nfrequency distribution having open-ended class intervals. \\nThe concept of open-ended frequency distribution can be understood with the help of the following example. \\n \\n \\n Example: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nIn this example, both the fir st class and the last class are open -ended classes. This is so because of the fact that we do \\nnot have exact figures to begin the first class or to end the last class. The advantage of computing the median in the case \\nof an  open-ended frequency distribution is that, except in the unlikely event of the median falling within an open-ended \\ngroup occurring in the beginning of our frequency distribution, there is no need to estimate the upper or lower \\nboundary. This is so because of the fact that, if the median  is falling in an intermediate class, then, obviously, the first \\nclass is not being involved in its computation. The next concept that we will discuss is the empirical relation between \\nthe mean, median and the mode. This is a concept which is not based on a rigid mathematical formula; rather, it is based \\non observation. In fact, the word ‘empirical’ implies ‘based on observation’. \\n This concept relates to the relative positions of the mean, median and the mode in case of a hump -\\nshaped distribution. In a sin gle-peaked frequency distribution, the values of the mean, median and mode coincide if the \\nfrequency distribution is absolutely symmetrical. \\n  \\n  \\n \\nBut in the case of a skewed distribution, the mean, median and mode do not all lie on the same point. They are  pulled \\napart from each other, and the empirical relation explains the way in which this happens. Experience tells us that in a \\nunimodal curve of moderate skewness, the median is usually sandwiched between the mean and the mode. \\n The second point is that,  in the case of many real -life data -sets, it has been observed that the distance \\nbetween the mode and the median is approximately double of the distance between the median and the mean, as shown \\nbelow: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMode \\nMedian \\nMean X \\nf \\nWAGES OF WORKERS  \\nIN A FACTORY \\nMonthly Income \\n(in Rupees) \\nNo. of \\nWorkers \\nLess than 2000/- 100 \\n2000/- to 2999/- 300 \\n3000/- to 3999/- 500 \\n4000/- to 4999/- 250 \\n5000/- and above 50 \\nTotal 1200 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 68}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       64                                                                                                                                           \\n \\nThis diagrammatic picture is equivalent to the following algebraic expression: \\nMedian - Mode      2 (Mean - Median) ---- (1) \\nThe above-mentioned point can also be expressed in the following way:  \\n \\nMean – Mode   =    3 (Mean – Median) ---- (2)   \\nEquation (1) as well as equation (2) yields the approximate relation given below: \\n \\nEMPIRICAL RELATION BETWEEN THE MEAN, MEDIAN AND THE MODE  \\n \\nMode   =    3 Median – 2 Mean \\nAn exactly similar situation holds in case of a moderately negatively skewed distribution.  \\nAn important point to note is that this empirical relation does not hold in case of a J-shaped or an extremely skewed \\ndistribution. \\n Let us now extend the concept of partitioning of the frequency distribution by taking up the concept of \\nquantiles (i.e. quartiles, deciles and percentiles). \\nWe have already seen that the median divides the area under the frequency polygon into two equal halves: \\n \\n \\nA further split to produce quarters, tenths or hundredths of the total area under the frequency polygon is equally \\npossible, and may be extremely useful for analysis. (We are often interested in the highest 10% of some group of va lues \\nor the middle 50% another. \\n \\nQUARTILES \\n \\nThe quartiles, together with the median, achieve the division of the total area into four equal parts.  \\nThe first, second and third quartiles are given by the formulae: \\n \\n1. FIRST QUARTILE \\n \\n \\n \\n \\n \\n2. SECOND QUARTILE (I.E. MEDIAN) \\n \\n \\n \\n \\n50% 50% \\nX \\nf \\nMedian \\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d cn\\nf\\nhlQ 4\\n1\\n\\uf028 \\uf029cnf\\nhlcn\\nf\\nhlQ \\uf02d\\uf02b\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d 24\\n2\\n2'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 69}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       65                                                                                                                                           \\n \\n3. THIRD QUARTILE \\n \\n \\n \\n \\nIt is clear from the formula of the second quartile that the second quartile is the same as the median.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n      \\n \\nDECILES & PERCENTILES \\n \\nThe deciles and the percentiles give the division of the total area into 10 and 100 equal parts respectively. \\n The formula for the first decile is  \\n \\n \\n \\n \\n \\n \\n \\n \\nThe formulae for the subsequent deciles are  \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\nand so on. \\n \\nIt is easily seen that the 5th decile is the same quantity as the median.  \\nThe formula for the first percentile is  \\n \\n \\n \\n \\n \\nThe formulae for the subsequent percentiles are  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nand so on. \\nAgain, it is easily seen that the 50th percentile is the  same as the median, the 25th percentile is the same as the 1st \\nquartile, the 75th percentile is the same as the 3rd quartile, the 40th percentile is the same as the 4th decile, and so on. \\n \\n \\n 25% \\nX \\nf \\nQ1  Q2 =\\nX~  Q3 \\n25% 25% 25% \\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d cn\\nf\\nhlQ 4\\n3\\n3\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c10\\nn\\nf\\nhlD1\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c10\\nn3\\nf\\nhlD3\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c10\\nn2\\nf\\nhlD2\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c100\\nn\\nf\\nhlP1\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c100\\nn2\\nf\\nhlP2\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf03d c100\\nn3\\nf\\nhlP3'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 70}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       66                                                                                                                                           \\nAll these measures i.e. the median, quartiles, deciles and percentiles are collectively called quantiles.  The \\nquestion is, “What is the significance of this concept of partitioning? Why is it that we wish to divide our frequency \\ndistribution into two, four, ten or hundred parts?”  \\nThe answer to the above questions is: In  certain situations, we may be interested in describing the relative quantitative \\nlocation of a particular measurement within a data set. Quantiles provide us with an easy way of achieving this. Out of \\nthese various quantiles, one of the most frequently used is percentile ranking.  \\nLet us understand this point with the help of an example. \\n \\nEXAMPLE \\n \\nIf oil company ‘A’ reports that its yearly sales are at the 90th percentile of all companies in the industry, the implication  \\nis that 90% of all oil companies ha ve yearly sales less than company A’s, and only 10% have year ly sales exceeding \\ncompany A’s,this is demonstrated in the following figure: \\n \\nRelative Frequency \\n  \\n \\n  \\n \\nIt is evident from the above example that the concept of percentile ranking is quite a usefu l concept, but it should be \\nkept in mind that percentile rankings are of practical value only for large data sets. \\nIt is evident from the above example that the concept of percentile ranking is quite a useful concept, but it should be \\nkept in mind that per centile rankings are of practical value only for large data sets.  The next concept that we will \\ndiscuss is the graphic location of quantiles.  \\nLet us go back to the example of the EPA mileage ratings of 30 cars that was discussed in an earlier lecture.  \\nEXAMPLE \\n \\nSuppose that the Environmental Protection Agency of a developed country performs extensive tests on all new car \\nmodels in order to determine their mileage rating. Suppose that the following 30 measurements are obtained by \\nconducting such tests on a particular new car model. \\n \\n  \\n  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 71}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       67                                                                                                                                           \\n \\nWhen the above data was converted to a frequency distribution, we obtained: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\nAlso, we considered the graphical representation of this distribution. \\nThe cumulative frequency polygon of this distribution came out to be as shown in the following figure: \\n \\n \\n \\n \\n \\nThis ogive enables us to find the median and any other quantile that we may be interested in very conveniently. And \\nthis process is known as the graphic location of quantiles. \\nLet us begin with the graphical location of the median: \\n Because of the fact that the median is that value before which half of the data lies, the first step is to \\ndivide the total number of observations n by 2. \\nIn this example: \\n \\n \\n \\nThe next step is to locate this number 15 on the y-axis of the cumulative frequency polygon. \\n \\n \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n29.95 32.95 35.95 38.95 41.95 44.95\\nCumulative Frequency Polygon or OGIVE \\nClass Limit Frequency \\n30.0 – 32.9 2 \\n33.0 – 35.9 4 \\n36.0 – 38.9 14 \\n39.0 – 41.9 8 \\n42.0 – 44.9 2 \\n 30 \\n \\n152\\n30\\n2 \\uf03d\\uf03dn'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 72}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       68                                                                                                                                           \\n \\n  \\nLastly, we drop a vertical line from the cumulative frequency polygon down to the x-axis.  \\n \\n \\nNow, if we read the x-value where our perpendicular touches the x-axis, students, we find that this value is \\napproximately the same as what we obtained from our formula. \\n \\n \\n \\n \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n29.95 32.95 35.95 38.95 41.95 44.95\\nCumulative Frequency Polygon or OGIVE \\n2\\nn'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 73}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       69                                                                                                                                           \\nIt is evident from the above example that the cumulative frequency polygon is a very useful device to find the value of \\nthe median very quickly. In  a similar way, we can locate the quartiles, deciles and percentiles. To  obtain the first \\nquartile, the horizontal line will be drawn against the value n/4, and for the third quartile, the horizontal line will be \\ndrawn against the value 3n/4. \\n \\n \\nFor the deciles, the horizontal lines will be against the values n/10, 2n/10, 3n/10, and so on. And for the percentiles, the \\nhorizontal lines will be against the values n/100, 2n/100, 3n/100, and so on. \\n The graphic location of the qua rtiles as well as of a few deciles and percentiles for the data -set of the \\nEPA mileage ratings may be taken up as an exercise: \\nThis brings us to the end of our discussion regarding quantiles which are sometimes also known as fractiles --- this \\nterminology because of the fact that they divide the frequency distribution into various parts or fractions.  \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n35\\n29.95 32.95 35.95 38.95 41.95 44.95\\nCumulative Frequency Polygon or OGIVE \\n4\\nn\\nQ1 Q3 \\n4\\nn3'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 74}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       70                                                                                                                                           \\nLECTURE NO. 9 \\n \\n\\uf0b7 Geometric mean \\n\\uf0b7 Harmonic mean \\n\\uf0b7 Relation between the arithmetic, geometric and harmonic means \\n\\uf0b7 Some other measures of central tendency \\n \\nGEOMETRIC MEAN \\n   \\nThe geometric mean, G, of a set of n positive values X1, X2,…,Xn is defined as the positive nth root of their product. \\n \\n \\n \\n (Where Xi > 0) \\nWhen n is large, the computation of the geometric mean becomes laborious as we have to extract the nth root of the \\nproduct of all the values. \\nThe arithmetic is simplified by the use of logarithms. \\n \\nTaking logarithms to the base 10, we get \\n \\n \\n \\n \\n \\nHence \\n \\n \\n \\n \\nEXAMPLE \\n \\nFind the geometric mean of numbers: \\n \\n45, 32, 37, 46, 39, 36, 41, 48, 36 \\n \\nSolution: \\nWe need to compute the numerical value of \\n \\n \\n= \\n \\nBut, obviously, it is a bit cumbersome to find the ninth root of a quantity. So we make use of logarithms, as shown \\nbelow: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above example pertained to the computation of the geometric mean in case of raw data. \\nNext, we consider the computation of the geometric mean in the case of grouped data. \\n \\nX log X \\n45 1.6532 \\n32 1.5052 \\n37 1.5682 \\n46 1.6628 \\n39 1.5911 \\n36 1.5563 \\n41 1.6128 \\n48 1.6812 \\n36 1.5563 \\n 14.3870 \\nn\\nXlogGlog \\uf0e5\\uf03d\\n \\n \\n5986.19\\n3870.14 \\uf03d\\uf03d\\n \\n \\n68.39\\n5986.1logantiGHence\\n\\uf03d\\n\\uf03d\\n \\n \\nn\\nnXXXG ...21\\uf03d\\n\\uf05b \\uf05dnXXXnG log....loglog1log 21 \\uf02b\\uf02b\\uf02b\\uf03d\\nn\\nX\\uf0e5\\uf03d log\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf03d \\uf0e5\\nn\\nXloglogantiG\\n9\\n364841363946373245 \\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 75}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       71                                                                                                                                           \\n \\n \\nGEOMETRICMEAN FOR GROUPED DATA \\n \\n In case of  a frequency distribution having k classes with midpoints X1, X2, …,Xk and the \\ncorresponding frequencies f1, f2, …, fk (such that \\uf0e5fi = n), the geometric mean is given by \\n \\n \\n \\n \\nEach value of X thus has to be multiplied by itself f times, and the whole procedure becomes quite a formidable task!  \\nIn terms of logarithms, the formula becomes \\n \\n \\n \\n \\n \\nHence \\n \\n \\n \\n \\n \\nObviously, the above formula is much easier to handle. Let us now apply it to an example. \\nGoing back to the example of the EPA mileage ratings, we have:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nG = antilog \\n \\n \\n  = antilog 1.5768 = 37.74 \\nThis means that, if we use the geometric mean to measures the central tendency of this data set, then the central value of \\nthe mileage of those 30 cars comes out to be 37.74 miles per gallon. \\nThe question is, “When should we use the geometric mean?”  \\nThe answer to this question is that when relative changes in some variable quantity are averaged, we prefer the \\ngeometric mean. \\n \\nEXAMPLE \\n \\nSuppose it is discovered that a firm’s turnover has increased during 4 years by the following amounts: \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nn k21 f\\nk\\nf\\n2\\nf\\n1 X....XXG \\uf03d\\n\\uf05b \\uf05dkk XfXfXfnG log...loglog1log 2211 \\uf02b\\uf02b\\uf02b\\uf03d\\nn\\nXf\\uf0e5\\uf03d log\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf03d \\uf0e5\\nn\\nXfantiG loglog\\nMileage \\nRating \\nNo. \\nof \\nCars \\nClass-mark \\n(midpoint) \\nX \\nlog X f log X \\n30.0 - 32.9 2 31.45 1.4976 2.9952 \\n33.0 - 35.9 4 34.45 1.5372 6.1488 \\n36.0 - 38.9 14 37.45 1.5735 22.0290 \\n39.0 - 41.9 8 40.45 1.6069 12.8552 \\n42.0 - 44.9 2 43.45 1.6380 3.2760 \\n 30   47.3042 \\n \\n30\\n3042.47\\nYear Turnover \\nPercentage \\nCompared  \\nWith Year \\nEarlier \\n1958 £ 2,000 – \\n1959 £ 2,500 125 \\n1960 £ 5,000 200 \\n1961 £ 7,500 150 \\n1962 £ 10,500 140 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 76}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       72                                                                                                                                           \\nThe yearly increase is shown in a percentage form in the rig ht-hand column i.e. the turnover of 1959 is 125 percent of \\nthe turnover of 1958, the turnover of 1960 is 200 percent of the turnover of 1959, and so on. The firm’s owner may be \\ninterested in knowing his average rate of turnover growth.  \\nIf the arithmetic mean is adopted he finds his answer to be: \\nArithmetic Mean: \\n \\n \\n \\n \\ni.e. we are concluding that the turnover for any year is 153.75% of the turnover for the previous year. In other words, \\nthe turnover in each of the years considered appears to be 53.75 per cent higher than in the previous year.  \\nIf this percentage is used to calculate the turnover from 1958 to 1962 inclusive, we obtain: \\n153.75% of £ 2,000 = £ 3,075 \\n153.75% of £ 3,075 = £ 4,728 \\n153.75% of £ 4,728 = £ 7,269 \\n153.75% of £ 7,269 = £ 11,176 \\nWhereas the actual turnover figures were  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIt seems that both the individual figures and, more important, the total at the end of the period, are incorrect. Using the \\narithmetic mean has exaggerated the ‘average’ annual rate of increase in the turnover o f this firm. Obviously, we would \\nlike to rectify this false impression. The geometric mean enables us to do so:  \\nGeometric mean of the turnover figures: \\n \\n \\n  \\n \\n \\n \\n \\n \\nNow, if we utilize this particular value to obtain the individual turnover figures, we find that: \\n151.37% of £2,000 = £3,027 \\n151.37% of £3,027 = £4,583 \\n151.37% of £4,583 = £6,937 \\n151.37% of £6,937 = £10,500 \\nSo that the turnover figure of 1962 is exactly the same as what we had in the original data. \\n \\nINTERPRETATION \\n \\nIf the turnover of this company were to increase annually at a constant rate, then the annual increase would have been \\n51.37 percent.(On the average, each year’s turnover is 51.37% higher than that in the previous year.)  The above \\nexample clearly indicates the significance of the geometr ic mean in a situation when relative changes in a variable \\nquantity are to be averaged. \\n But we should bear in mind that such situations are not encountered too often, and that the occasion to \\ncalculate the geometric mean arises less frequently than the ar ithmetic mean.(The most frequently used measure of \\ncentral tendency is the arithmetic mean.) \\nThe next measure of central tendency that we will discuss is the harmonic mean. \\n \\nHARMONIC MEAN \\n \\n The harmonic mean is defined as the reciprocal of the arithmetic mean of the reciprocals of the values.  \\nIn case of raw data: \\n \\n \\n \\n \\n \\n75.153\\n4\\n140150200125\\n\\uf03d\\n\\uf02b\\uf02b\\uf02b\\nYear Turnover \\n1958 £ 2,000 \\n1959 £ 2,500 \\n1960 £ 5,000 \\n1961 £ 7,500 \\n1962 £ 10,500 \\n \\n\\uf028 \\uf029\\n%37.151\\n525000000\\n140150200125\\n4\\n4\\n\\uf03d\\n\\uf03d\\n\\uf0b4\\uf0b4\\uf0b4\\n\\uf0e5 \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\nX\\nnMH 1..'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 77}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       73                                                                                                                                           \\nIn case of grouped data (data grouped into a frequency distribution): \\n \\n \\n \\n \\n \\n \\n(Where X represents the midpoints of the various classes) \\n \\nEXAMPLE \\n \\nSuppose a car travels 100 miles with 10 stops , each stop after an interval of 10 miles. Suppose that the speeds at which \\nthe car travels these 10 intervals are 30, 35, 40, 40, 45, 40, 50, 55, 55 and 30 miles per hours respectively.  \\nWhat is the average speed with which the car traveled the total distance of 100 miles? \\nIf we find the arithmetic mean of the 10 speeds, we obtain: \\nArithmetic mean of the 10 speeds: \\n \\n \\n \\n \\n \\n \\n \\n  \\nBut, if we study the problem carefully, we find that the above answer is incorrect. \\n By definition, the average speed is the speed w ith which the car would have traveled \\nthe 100 mile distance if it had maintained a constant speed throughout the 10 intervals of 10 miles each. \\n \\n \\n \\n \\n \\n \\nNow, total distance traveled = 100 miles. Total time taken will be computed as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence  \\nAverage speed = \\n \\n \\nwhich is not the same as 42 miles per hour. \\nLet us now try the harmonic mean to find the average speed of the car. \\n \\n \\n \\n \\n \\n \\n \\n\\uf0e5 \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\nXf\\nnMH 1..\\n10\\n30....3530 \\uf02b\\uf02b\\uf02b\\n420 42 miles per hour.10\\uf03d\\uf03d\\nTotal distance travelled Average speed = Total time taken \\n \\nDistance Distance Interval Distance Speed = Time Time = Speed \\n1 10 miles 30 mph 10/30 = 0.3333 hrs \\n2 10 miles 35 mph 10/35 = 0.2857 hrs \\n3 10 miles 40 mph 10/40 = 0.2500 hrs \\n4 10 miles 40 mph 10/40 = 0.2500 hrs \\n5 10 miles 45 mph 10/45 = 0.2222 hrs \\n6 10 miles 40 mph 10/40 = 0.2500 hrs \\n7 10 miles 50 mph 10/50 = 0.2000 hrs \\n8 10 miles 55 mph 10/55 = 0.1818 hrs \\n9 10 miles 55 mph 10/55 = 0.1818 hrs \\n10 10 miles 30 mph 10/30 = 0.333 hrs \\nTotal  =  100 miles Total Time = 2.4881  hrs \\n \\nmph2.404881.2\\n100 \\uf03d\\n\\uf0e5 \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\nX\\nnMH 1..'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 78}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       74                                                                                                                                           \\nwhere n is the no. of terms) \\nWe have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe key question is, “When should w e compute the harmonic mean of a data set?” The answer to this question will be \\neasy to understand if we consider the following rules: \\n \\nRULES \\n \\n\\uf0b7 When values are given as x per y where x is constant and y is variable, the Harmonic Mean is the appropriate \\naverage to use. \\n\\uf0b7 When values are given as x per y where y is constant and x is variable, the Arithmetic Mean is the appropriate \\naverage to use. \\n\\uf0b7 When relative changes in some variable quantity are to be averaged, the geometric mean is the appropriate \\naverage to use. \\nWe have already discussed the geometric and the harmonic means. Let us now try to understand Rule No. 1 with the \\nhelp of an example: \\n \\nEXAMPLE \\n \\nIf 10 students have obtained the following marks (in a test) out of 20: \\n13, 11, 9, 9, 6, 5, 19, 17, 12, 9 \\nThen the average marks (by the formula of the arithmetic mean) are: \\n \\n   \\n \\n \\n \\n \\n  \\n \\nThis is equivalent to  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nX 1/X \\n30 1/30 = 0.0333 \\n35 1/35 = 0.0286 \\n40 1/40 = 0.0250 \\n40 1/40 = 0.0250 \\n45 1/45 = 0.0222 \\n40 1/40 = 0.0250 \\n50 1/50 = 0.0200 \\n55 1/55 = 0.0182 \\n55 1/55 = 0.0182 \\n30 1/30 = 0.0333 \\n \\n\\uf0e5 \\uf03d 2488.0X\\n1  \\n\\uf0e5\\n\\uf03d\\nX\\n1\\nn.M.H\\n  \\n2488.0\\n10\\uf03d\\n \\n \\n= 40.2 mph \\n \\nHence it is clear that the harmonic mean \\ngives the totally correct result. \\n \\n10\\n912171956991113 \\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\n1110\\n110 \\uf03d\\uf03d\\n10\\n20\\n9\\n20\\n12\\n20\\n17\\n20\\n19\\n20\\n5\\n20\\n6\\n20\\n9\\n20\\n9\\n20\\n11\\n20\\n13 \\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\n20\\n11\\n2010\\n110\\n10\\n20\\n110\\n\\uf03d\\uf0b4\\uf03d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 79}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       75                                                                                                                                           \\n(i.e. the average marks of this group of students are 11 out of 20).In the above example, the point to be noted was that \\nall the marks were expressible as x per y where the denominator y was constant i.e. equal to 20, and hence, it was \\nappropriate to compute the arithmetic mean. \\nLet us now consider a mathematical relationship exists between these three measures of central tendency. \\n \\nRELATION BETWEEN ARITHMETIC, GEOMETRIC AND HARMONIC MEANS \\n \\nArithmetic Mean > Geometric Mean >Harmonic Mean \\nWe have considered the five most well -known measures of central tendency i.e. arithmetic mean, median, mode, \\ngeometric mean and harmonic mean. It is interestin g to note that there are some other measures of central tendency as \\nwell. Two of these are the mid range, and the mid quartile range.   \\nLet us consider these one by one: \\n \\nMID-RANGE \\n \\nIf there are n observations with x0 and xm as their smallest and largest o bservations respectively, then their mid -range \\nis defined as \\n \\n \\n \\n \\n \\nIt is obvious that if we add the smallest value with the largest, and divide by 2, we will get a value which is more or less \\nin the middle of the data-set. \\n \\nMID-QUARTILE RANGE \\n \\n If x1, x2… xn are n observations with Q1 and Q3 as their first and third quartiles \\nrespectively, then their mid-quartile range is defined as \\n \\n \\n \\n \\n \\nSimilar to the case of the mid -range, if we take the arithmetic mean of the upper and lower quartiles, we will obtain a \\nvalue that is somewhere in the middle of the data-set. The mid-quartile range is also known as the mid-hinge. \\nLet us now revise briefly the core concept of central tendency: Masses of data are usually expressed in the form of \\nfrequency tables so that it be comes easy to comprehend the data.  Usually, a statistician would like to go a step ahead \\nand to compute a number that will represent the data in some definite way. \\nAny such single number that represents a whole set of data is called ‘Average’. \\nTechnically speaking, there are many kinds of averages (i.e. there are several ways to compute them). These quantities \\nthat represent the data-set are called “measures of central tendency”.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n2\\nxxrangemid m0 \\uf02b\\uf03d\\uf02d\\n2\\nQQrangequartilemid 31 \\uf02b\\uf03d\\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 80}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       76                                                                                                                                           \\n \\nLECTURE NO. 10 \\n\\uf0b7 Concept of dispersion \\n\\uf0b7 Absolute and relative measures of dispersion \\n\\uf0b7 Range  \\n\\uf0b7 Coefficient of dispersion \\n\\uf0b7 Quartile deviation \\n\\uf0b7 Coefficient of quartile deviation \\n \\nLet us begin the concept of DISPERSION. \\nJust as variable series differ with respect to their location on the horizontal axis (having different ‘ average’ values); \\nsimilarly, they differ in terms of the amount of variability which they exhibit.  Let us understand this point with the \\nhelp of an example:  \\n \\nEXAMPLE \\n \\nIn a technical college, it may well be the case that the ages of a group of first -year students are quite consistent, e.g. 17, \\n18, 18, 19, 18, 19, 19, 18, 17, 18 and 18 years.  \\nA class of evening students undertaking a course of study in their spare time may show just the opposite situation, e.g. \\n35, 23, 19, 48, 32, 24, 29, 37, 58, 18, 21 and 30. \\nIt is very clear from this example that the variation that exists between the various values of a data -set is of substantial \\nimportance. We obviously need to be aware of the amount of variability present in a data-set if we are to come to useful \\nconclusions about the situation under review. This is perhaps best seen from studying the two freq uency distributions \\ngiven below. \\n \\nEXAMPLE \\n \\n The sizes of the classes in two comprehensive schools in different areas are as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf the arithmetic mean size of class is calculated, we discover that the answer is identical: 27.33 pupils in both areas.  \\nAverage class-size of each school \\n \\n \\nEven though these two distributions share a common average, it can readily be seen that they are entirely DIFFERENT. \\nAnd the graphs of the two distributions (given below) clearly indicate this fact.  \\nNumber of Classes Number \\nof Pupils Area A Area B \\n10 – 14 0 5 \\n15 – 19 3 8 \\n20 – 24 13 10 \\n25 – 29 24 12 \\n30 – 34 17 14 \\n35 – 39 3 5 \\n40 – 44 0 3 \\n45 - 49 0 3 \\n 60 60 \\n \\n33.27\\uf03dX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 81}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       77                                                                                                                                           \\n \\nThe question which must be posed and answered is ‘In what way can these two situations be distinguished?’  We need \\na measure of variability or DISPERSION to accompany the relevant measure of position or ‘average’ used.  \\nThe word ‘relevant’ is important here for we shall find one measure of dispersion which expresses the scatter of values \\nround the arithmetic mean, another the scatter o f values round the median, and so forth. Each measure of dispersion is \\nassociated with a particular ‘average’. \\n \\nABSOLUTE VERSUS RELATIVE MEASURES OF DISPERSION \\n \\nThere are two types of measurements of dispersion: absolute and relative.  \\nAn absolute measure of dispersion  is one that measures the dispersion in terms of the same units or in the square of \\nunits, as the units of the data.  \\nFor example, if the units of the data are rupees, meters, kilograms, etc., the units of the measures of dispersion will also \\nbe rupees, meters, kilograms, etc.  \\nOn the other hand, relative measure of dispersion  is one that is expressed in the form of a ratio, co -efficient of \\npercentage and is independent of the units of measurement.  \\nA relative measure of dispersion is useful fo r comparison of data of different nature. A measure of central tendency \\ntogether with a measure of dispersion gives an adequate description of data. We will be discussing FOUR measures of \\ndispersion i.e. the range, the quartile deviation, the mean deviation, and the standard deviation. \\n \\nRANGE \\n \\nThe range is defined as the difference between the two extreme values of a data -set, i.e. R = Xm – X0 where \\nXm represents the highest value and X0 the lowest.   \\nEvidently, the calculation of the range is a simple question of MENTAL arithmetic.  \\n \\nThe simplicity of the concept does not necessarily invalidate it, but in general it gives no idea of the DISTRIBUTION \\nof the observations between the two ends of the series. For this reason it is used principally as a supplemen tary aid in \\nthe description of variable data, in conjunction with other measures of dispersion. When the data are grouped into a \\nfrequency distribution, the range is estimated by finding the difference between the upper boundary of the highest class \\nand the lower boundary of the lowest class.  \\nWe now consider the graphical representation of the range: \\n \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n4 – 910 – 1415 – 1920 – 2425 – 2930 – 3435 – 3940 – 4444 - 4950 – 54\\nNumber of Pupils\\nNumber of Classes\\nArea A \\nArea B '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 82}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       78                                                                                                                                           \\n \\n \\n \\nObviously, the greater the difference between the largest and the smallest values, the greater will be the range. As stated \\nearlier, the range is a simple concept and is easy to compute. However, because of the fact that it is computed from only \\nthe two extreme values in a data-set, it has two serious disadvantages.  \\n \\n\\uf0b7 It ignores all the INFORMATION available from the intermediate observations. \\n\\uf0b7 It might give a MISLEADING picture of the spread in the data. \\n \\nFrom THIS point of view, it is an unsatisfactory measure of dispersion. However, it is APPROPRIATELY used in \\nstatistical quality control charts of manufactured products, daily t emperatures, stock prices, etc.  It is interesting to note \\nthat the range can also be viewed in the following way.  \\nIt is twice of the arithmetic mean of the deviations of the smallest and largest values round the mid-range i.e.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBecause of wh at has been just explained, the range can be regarded as that measure of dispersion which is associated \\nwith the mid-range. As such, the range may be employed to indicate dispersion when the mid-range has been adopted as \\nthe most appropriate average.  \\nThe range is an absolute measure of dispersion. Its relative measure is known as the CO -EFFICIENT OF \\nDISPERSION, and is defined by the relation given below: \\n\\\\ \\nCOEFFICIENT OF DISPERSION \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nThis is a pure (i.e. dimensionless) number and is used for the purposes of COMPARISON. (This is so because a pure \\nnumber can be compared with another pure number.) \\nX \\nf \\nXm X0 \\nRange \\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\nMidrangeXXMidrange\\n2\\nMidrangeXXMidrange\\nm0\\nm0\\n\\uf02d\\uf02b\\uf02d\\uf03d\\n\\uf02d\\uf02b\\uf02d\\n \\n2\\nXX 0m \\uf02d\\uf03d\\n \\n\\uf028 \\uf029\\n0m\\n0m\\n0m\\n0m\\n2\\n1\\nXX\\nXX\\n2\\nXX\\n2\\nXX\\nRangeMid\\nRange\\n\\uf02b\\n\\uf02d\\uf03d\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 83}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       79                                                                                                                                           \\nFor example, if the coefficient of dispersion for one data -set comes out to be 0.6 whereas the coefficient of dispersion \\nfor another data-set comes out to be 0.4, then it is obvious that there is greater amount of dispersion in the first data -set \\nas compared with the second. \\n \\nQUARTILE DEVIATION \\n \\nThe quartile deviation is defined as half of the difference between the third and first quartiles i.e.  \\n \\n \\n \\n \\nIt is also known as semi-interquartile range. Let us now consider the graphical representation of the quartile deviation: \\n \\n \\nAlthough simple to compute, it is NOT an extremely satisfactory measure of dispersion because it takes into a ccount \\nthe spread of only two values of the variable round the median, and this gives no idea of the rest of the dispersion within \\nthe distribution. \\nThe quartile deviation has an attractive feature that the range “Median + Q.D.” contains approximately 50% \\nof the data. This is illustrated in the figure given below: \\n \\n \\n \\n \\nLet us now apply the concept of quartile deviation to the following example: \\n \\n \\n \\n \\nX \\nf \\nMedian Median+Q.D. Median-Q.D. \\n50% \\nX \\nf \\nQ3 Q1 Inter-quartile Range \\nQuartile Deviation  \\n(Semi Inter-quartile Range) \\n2.. 13 QQDQ \\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 84}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       80                                                                                                                                           \\nEXAMPLE \\n \\n The shareholding structure of two companies is given below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe quartile deviation for company X is  \\n \\n \\n \\n                                                               Shares \\n \\nFor company Y, it is  \\n \\n                                                                 Shares \\n \\n \\nA comparison of the above two results indicate that there is a considerable concentration of shareholders about the \\nMEDIAN number of shares in company Y, whereas in company X, there does not exist this kind of a concentration \\naround the median. (In company X, there is approximately the SAME numbers of small, medium and large \\nshareholders.)  \\nFrom the above example, it is obvious that the larger the quartile deviation, the greater is the scatter of values within the \\nseries. The quartile deviation is superior to range as it is not affected by extremely large or small observations. It is \\nsimple to understand and easy to calculate.  \\nThe mean deviation can also be viewed in another way: It is the arithmetic mean of the deviations of the first and third \\nquartiles round the median i.e.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBecause o f what has been just explained, the quartile deviation is regarded as that measure of dispersion which is \\nassociated with the median.  As such, the quartile deviation should always be employed to indicate dispersion when \\nthe median has been adopted as the most appropriate average.  \\n \\nThe quartile deviation is also an absolute measure of dispersion. Its relative measure called the CO -EFFICIENT OF \\nQUARTILE DEVIATION or of Semi-Inter-quartile Range, is defined by the relation: \\n \\nCOEFFICIENT OF QUARTILE DEVIATION \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe Coefficient of Quartile Deviation is a pure number and is used for COMPARING the variation in two or more sets \\nof data. \\n1052\\n60270 \\uf03d\\uf02d\\n222\\n165210 \\uf03d\\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\nMQQM\\n2\\nMQQM\\n31\\n31\\n\\uf02d\\uf02b\\uf02d\\uf03d\\n\\uf02d\\uf02b\\uf02d\\n \\n2\\nQQ 13 \\uf02d\\uf03d\\n \\n,\\n2\\n2\\n13\\n13\\n13\\n13\\nQQ\\nQQ\\nQQ\\nQQ\\nRangeQuartileMid\\nDeviationQuartile\\n\\uf02b\\n\\uf02d\\uf03d\\uf02b\\n\\uf02d\\n\\uf03d\\n\\uf02d\\uf03d\\n Company \\nX \\nCompany \\nY \\n1st quartile 60 shares 165 shares \\nMedian 185 shares 185 shares \\n3rd quartile 270 shares 210 shares \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 85}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       81                                                                                                                                           \\nThe next two measures of dispersion to be discussed are the Mean Deviation and the Standard Deviation. In this regard,  \\nthe first thing to note is that, whereas the range as well as the quartile deviation are two such measures of dispersion \\nwhich are NOT based on all the values, the mean deviation and the standard deviation are two such measures of \\ndispersion that involve each and every data-value in their computation. \\n The range measures the dispersion of the data -set around the mid-range, whereas the quartile deviation \\nmeasures the dispersion of the data-set around the median. \\nHow are we to decide upon the amount of dispersion round the arithmetic mean?  \\nIt would seem reasonable to compute the DISTANCE of each observed value in the series from the arithmetic mean  of \\nthe series.  \\n But the problem is that the sum of the deviations of the values from the mean is ZERO! (No mat ter what the \\namount of dispersion in a data -set is, this quantity will always be zero, and hence it cannot be used to measure the \\ndispersion in the data-set.) \\nThen, the question arises, ‘HOW will we be able to measure the dispersion present in our data-set?’ In an attempt to \\nanswer this question, we might look at the numerical differences between the mean and the data values WITHOUT \\nconsidering whether these are positive or negative. By ignoring the sign of the deviations we will achieve  a NON -\\nZERO sum, and  averaging these absolute differences, again, we obtain a non -zero quantity which can be used as a \\nmeasure of dispersion. (The larger this quantity, the greater is the dispersion in the data-set). \\nThis quantity is known as the MEAN DEVIATION. \\nLet us denote these absolute differences  \\nby ‘modulus of d’ \\nor ‘mod d’. Then, the mean deviation is given by \\n \\nMEAN DEVIATION \\n \\n \\n \\n \\n \\n \\nAs the absolute deviations of the observations from their mean are being averaged, therefore the complete name of this \\nmeasure is Mean Ab solute Deviation --- but generally, it is simply called “Mean Deviation”. In the next lecture, this \\nconcept will be discussed in detail. (The case of raw data as well as the case of grouped data will be considered.)Next, \\nwe will discuss the most important and the most widely used measure of dispersion i.e. the Standard Deviation. \\nn\\n|d|.D.M \\uf0e5\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 86}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       82                                                                                                                                           \\n \\nLECTURE NO. 11 \\n \\n• Mean Deviation \\n• Standard Deviation and Variance \\n• Coefficient of variation \\n \\n First, we will discuss it for the case of raw data, and then we will go on to the case o f a frequency distribution. The first \\nthing to note is that, whereas the range as well as the quartile deviation are two such measures of dispersion which are \\nNOT based on all the values, the mean deviation and the standard deviation are two such measures of dispersion that \\ninvolve each and every data-value in their computation. \\n You must have noted that the range was measuring the dispersion of the data -set around the mid -range, \\nwhereas the quartile deviation was measuring the dispersion of the data-set around the median. \\n How are we to decide upon the amount of dispersion round the arithmetic mean? It would seem reasonable to \\ncompute the DISTANCE of each observed value in the series from the arithmetic mean of the series.  \\nLet us do this for a simple data-set shown below: \\nTHE NUMBER OF FATALITIES IN MOTORWAY ACCIDENTS IN ONE WEEK \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us do this for a simple data-set shown below: \\nTHE NUMBER OF FATALITIES IN MOTORWAY ACCIDENTS IN ONE WEEK \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe arithmetic mean number of fatalities per day is       \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to determine the distances of the data -values from the mean, we subtract our value of the arithmetic mean from \\neach daily figure, and this gives us the deviations that occur in the third column of the table below \\n \\nDay Number of fatalities \\nX \\nSunday 4 \\nMonday 6 \\nTuesday 2 \\nWednesday 0 \\nThursday 3 \\nFriday 5 \\nSaturday 8 \\nTotal 28 \\n \\nDay Number of fatalities \\nX \\nSunday 4 \\nMonday 6 \\nTuesday 2 \\nWednesday 0 \\nThursday 3 \\nFriday 5 \\nSaturday 8 \\nTotal 28 \\n \\n47\\n28\\nn\\nXX \\uf03d\\uf03d\\uf03d \\uf0e5'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 87}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       83                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe deviations are negative when the daily figure is less than the mean (4 accidents) and positive when the figure is \\nhigher than the mean. It does seem, however, that our efforts for computing the dispersion of this data set have been in \\nvain, for we find that the  total amount of dispersion obtained by summing the  (x – \\uf060x) column comes out to be zero! In \\nfact, this should be no surprise, for it is a basic property of the arithmetic means that: The sum of the deviations of the \\nvalues from the mean is zero. The question arises: \\n How will we measure the dispersion that is actually present in our data-set? \\nOur problem might at first sight seem irresolvable, for by this criterion it appears that no series has any dispersion. Yet \\nwe know that this is absolutely incorrect, and we must think of some other way of handling this situation. Surely, we \\nmight look at the numerical difference between the mean and the daily fatality figures without considering whether \\nthese are positive or negative.  Let us denote these absolute differences by ‘modulus of d’ or ‘mod d’. \\nThis is evident from the third column of the table below \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBy ignoring the sign of the deviations we have achieved a non -zero sum in our second column. Averaging these \\nabsolute differences, we obtain a measure of dispersion known as the mean deviation. \\nIn other words, the mean deviation is given by the formula: \\n \\nMEAN DEVIATION \\n \\n \\n \\n \\n \\n \\nAs we are averaging the absolute deviations of the observations from their mean, therefore the complete name of this \\nmeasure is mean absolute deviation --- but generally we just say “mean deviation”. Applying this formu la in our \\nexample, we find that, the mean deviation of the number of fatalities is \\n \\n \\n \\n \\n \\nThe formula that we have just considered is  valid in the case of raw data. In case of grouped data i.e. a frequency \\ndistribution, the formula becomes \\n \\n \\n \\n \\nDay Number of fatalities \\nX \\nXX \\uf02d  \\nSunday 4 0 \\nMonday 6 + 2 \\nTuesday 2 – 2 \\nWednesday 0 – 4 \\nThursday 3 – 1 \\nFriday 5 + 1 \\nSaturday 8 + 4 \\nTOTAL 28 0 \\n \\nX X –\\uf060X = d | d | \\n4 0 0 \\n6 2 2 \\n2 –2 2 \\n0 –4 4 \\n3 –1 1 \\n5 1 1 \\n8 4 4 \\nTotal 14 \\n \\nn\\n|d|.D.M i\\uf0e5\\uf03d\\n.27\\n14.D.M \\uf03d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 88}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       84                                                                                                                                           \\n \\n \\nMEAN DEVIATION FOR GROUPED DATA \\n \\n \\n \\n \\n \\n \\nAs far as the graphical representation of the mean deviation is concerned, it can be depicted by a horizontal line \\nsegment drawn below the X-axis on the graph of the frequency distribution, as shown below \\n \\n \\n \\nThe approach which we have adopted in the concept of the mean deviation is both quick and simple. But the problem is \\nthat we introduce a kind of artificiality in its calculation by ignoring the algebraic signs of the deviations.   \\nIn problems involving descriptions and comparisons alone, the mean deviation can validly be applied; but because the \\nnegative signs have been discarded, further theoretical development or application of the concept is impossible. \\n Mean deviation is an absolute measure of dispersion. Its relative measure, known as the co -efficient of mean \\ndeviation, is obtained by dividing the mean deviation by the aver age used in the calculation of deviations i.e. the \\narithmetic mean. Thus \\n \\nCO-EFFICIENT OF M.D \\n \\nSometimes, the mean deviation is computed by averaging the absolute deviations of the data -values from the median \\ni.e.  \\n \\n \\n \\n \\n \\nAnd when will we have a situation w hen we will be using the median instead of the mean?  As discussed earlier, the \\nmedian will be more appropriate than the mean in those cases where our data -set contains a few very high or very low \\nvalues. In such a situation, the coefficient of mean deviation is given by: \\n \\nCo-efficient of M.D: \\n \\n \\n \\nLet us now consider the standard deviation  --- that statistic which is the most important and the most widely used \\nmeasure of dispersion.  \\nThe point that made earlier that from the mathematical point of view, it is not very preferable to take the absolute values \\nof the deviations, This problem is overcome by computing the standard deviation. \\nIn order to compute the standard deviation, rather than taking the absolute values of the deviations, we square the \\ndeviations. \\n Averaging these squared deviations, we obtain a statistic that is known as the variance. \\n \\n \\n \\nX \\nf \\nMean Deviation \\nX\\nn\\ndf\\nn\\nxxf.D.M iiii \\uf0e5\\uf0e5 \\uf03d\\uf02d\\uf03d\\nMean\\n.D.M\\uf03d\\nn\\nx~xdeviationMean \\uf0e5 \\uf02d\\uf03d\\nMedian\\n.D.M\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 89}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       85                                                                                                                                           \\n \\n \\nVARIANCE \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us compute this quantity for the data of the above example. \\nOur X-values were: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTaking the deviations of the X-values from their mean, and then squaring these deviations, we obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nObviously, both (– 2)2 and (2)2 equal 4, both (– 4)2 and (4)2 equal 16, and both (– 1)2 and (1)2 = 1 \\nHence \\uf0e5(x – \\uf060x)2 = 42 is now positive, and this positive value has been achiev ed without ‘bending’ the rules of \\nmathematics. Averaging these squared deviations, the variance is given by: \\n \\nVariance: \\n \\n                =     \\n \\n \\n \\n \\n \\n \\nThe variance is frequently employed in statistical work, but it should be noted that the figure achieved is in ‘squared’ \\nunits of measurement.  \\nIn the example that we have just considered, the variance has come out to be “6 squared fatalities”, which does not \\nseem to make much sense! In order to obtain an answer which is in the original unit of measurement, w e take the \\npositive square root of the variance. The result is known as the standard deviation. \\n \\n \\n \\n \\n \\n\\uf028 \\uf029\\nn\\nxx 2\\uf0e5 \\uf02d\\uf03d\\nX \\n4 \\n6 \\n2 \\n0 \\n3 \\n5 \\n8 \\n \\nX (\\nxx \\uf02d ) (\\nxx \\uf02d )2 \\n4 0 0 \\n6 + 2 4 \\n2 – 2 4 \\n0 – 4 16 \\n3 – 1 1 \\n5 + 1 1 \\n8 + 4 16 \\n  42 \\n \\n\\uf028 \\uf029\\nn\\nxx\\uf0e5 \\uf02d\\n2\\n67\\n42 \\uf03d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 90}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       86                                                                                                                                           \\n \\n \\nSTANDARD DEVIATION \\n \\n \\n \\n \\n \\n \\nHence, in this example, our standard deviation has come out to be 2.45 fatalities. \\n In computing the standard deviation (or var iance) it can be tedious to first ascertain the arithmetic mean of a \\nseries, then subtract it from each value of the variable in the series, and finally to square each deviation and then sum.  \\nIt is very much more straight-forward to use the short cut formula given below: \\n \\nSHORT CUT FORMULA FOR THE STANDARD DEVIATION \\n \\n \\n \\n \\n \\n \\n \\nIn order to apply the short cut formula, we require only the aggregate of the series (\\uf0e5x) and the aggregate of the squares \\nof the individual values in the series (\\uf0e5x2).  \\nIn other words,  only two columns of figures are called for. The number of individual calculations is also considerably \\nreduced, as seen below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTherefore  \\n \\n \\n \\n  \\n \\n \\n \\nThe formulae that we have just discussed are valid in case of raw data. In case of grouped data i.e. a frequency \\ndistribution, each squared deviation round the mean must be multiplied by the appropriate frequency figure i.e. \\n  \\n \\nSTANDARD DEVIATION IN CASE OF GROUPED DATA \\n \\n \\n \\n \\n \\nAnd the short cut formula in case of a frequency distribution is: \\n \\nSHORT CUT FORMULA OF THE STANDARD DEVIATION IN CASE OF GROUPED DATA \\n \\n \\n \\n \\n\\uf028 \\uf029\\nn\\nxxS\\n2\\uf0e5 \\uf02d\\uf03d\\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf0ef\\uf0ee\\n\\uf0ef\\uf0ed\\n\\uf0ec\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d \\uf0e5\\uf0e5\\n22\\nn\\nx\\nn\\nxS\\n X X2 \\n 4 16 \\n 6 36 \\n 2 4 \\n 0 0 \\n 3 9 \\n 5 25 \\n 8 64 \\nTotal 28 154 \\n \\n\\uf028 \\uf029\\nfatalities45.26\\n16227\\n28\\n7\\n154S\\n2\\n\\uf03d\\uf03d\\n\\uf02d\\uf03d\\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf0ef\\uf0ee\\n\\uf0ef\\uf0ed\\n\\uf0ec\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf028 \\uf029\\nn\\nxxfS\\n2\\uf0e5 \\uf02d\\uf03d\\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf0ef\\uf0ee\\n\\uf0ef\\uf0ed\\n\\uf0ec\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d \\uf0e5\\uf0e5\\n22\\nn\\nfx\\nn\\nfxS'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 91}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       87                                                                                                                                           \\n \\nWhich is again preferred from the computational standpoint \\nFor example, the standard deviation life of a batch of electric light bulbs would be calculated as follows: \\n \\nEXAMPLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTherefore, standard deviation: \\n \\n \\n \\n \\n \\n \\n \\n \\n =13.9hundredhours \\n = 1390 hours  \\nAs far as the graphical representation of the standard deviation is concerned, a horizontal line segment is drawn below \\nthe X-axis on the graph of the frequency distribution --- just as in the case of the mean deviation. \\n \\n \\n \\n \\nThe standard deviation is an absolute measure of dispersion. Its relative measure called coefficient of standard deviation \\nis defined as: \\n \\nCOEFFICIENT OF S.D \\n \\n \\n \\n \\nAnd, multiplying this quantity by 100, we obtain a very important and well -known measure called the coefficient of \\nvariation. \\nX \\nf \\nStandard deviation \\nX\\nLife (in \\nHundreds of \\nHours) \\nNo. of  \\nBulbs \\nf \\nMid-\\npoint \\nx \\nfx fx2 \\n0 – 5 4 2.5 10.0 25.0 \\n5 – 10 9 7.5 67.5 506.25 \\n10 – 20 38 15.0 570.0 8550.0 \\n20 – 40 33 30.0 990.0 29700.0 \\n40 and over 16 50.0 800.0 40000.0 \\n 100  2437.5 78781.25 \\n \\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf0ef\\uf0ee\\n\\uf0ef\\uf0ed\\n\\uf0ec\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n2\\n100\\n5.2437\\n100\\n25.78781S\\nMean\\nDeviationdardtanS\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 92}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       88                                                                                                                                           \\n \\n \\nCOEFFICIENT OF VARIATION \\n \\n \\n \\n \\n \\nAs mentioned earlier, the standard deviation is expressed in absolute terms and is given in the same unit of \\nmeasurement as the variable itself.  \\nThere are occasions, however, when this absolute measure of dispersion is inadequate and a relative form becomes \\npreferable. For example, if a comparison between the variability of distributions with different variables i s required, or \\nwhen we need to compare the dispersion of distributions with the same variable but with very different arithmetic \\nmeans. To illustrate the usefulness of the coefficient of variation, let us  consider the following two examples. \\n \\nEXAMPLE-1 \\n \\nSuppose that, in a particular year, the mean weekly earnings of skilled factory workers in one particular country were $ \\n19.50 with a standard deviation of $ 4, while for its neighboring country the figures were Rs. 75 and Rs. 28 \\nrespectively.  \\n From these figures, it is not immediately apparent which country has the GREATER VARIABILITY in \\nearnings.  The coefficient of variation quickly provides the answer:  \\n \\n \\nFor country No. 1: \\n \\n \\n \\n \\n \\nAnd for country No. 2: \\n \\n \\n \\n \\n \\nFrom these calculations, it is immediately ob vious that the spread of earnings in country No. 2 is greater than that in \\ncountry No. 1, and the reasons for this could then be sought. \\n \\nEXAMPLE-2: \\n \\nThe crop yield from 20 acre plots of wheat -land cultivated by ordinary methods averages 35 bushels with a standard \\ndeviation of 10 bushels. The yield from similar land treated with a new fertilizer averages 58 bushels, also with a \\nstandard deviation of 10 bushels. At first glance, the yield variability may seem to be the same, but in fact it has \\nimproved (i.e. decreased) in view of the higher average to which it relates.  \\nAgain, the coefficient of variation shows this very clearly: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe coefficient of variation for the untreated land has come out to be 28.57 percent, whereas the coefficient of vari ation \\nfor the treated land is only 17.24 percent. \\n \\n \\n \\n \\n100X\\nS.V.C \\uf0b4\\uf03d\\n5.201005.19\\n4 \\uf03d\\uf0b4\\n per cent, \\n3.3710075\\n28 \\uf03d\\uf0b4\\n per cent.  \\nUntreated land: \\n    \\n57.2810035\\n10 \\uf03d\\uf0b4  per cent \\nTreated land: \\n    \\n24.1710058\\n10 \\uf03d\\uf0b4  per cent '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 93}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       89                                                                                                                                           \\n \\nLECTURE NO. 12 \\n \\n \\n• Chebychev’s Inequality \\n• The Empirical Rule  \\n• The Five-Number Summary \\nIn the last lecture, we discussed the concept of standard deviation in quite a lot of detail. \\nIt is an extremely impo rtant concept, and it is very important that we appreciate and understand its role in statistical \\nanalysis. We’ve seen that if we are comparing the variability of two samples selected from a population, the sample \\nwith the larger standard deviation is the more variable of the two.  \\nThus, we know how to interpret the standard deviation on a relative or comparative basis, but we haven’t considered \\nhow it provides a measure of variability for a single sample. \\nTo understand how the standard deviation provides a  measure of variability of a data set, consider a specific data set \\nand answer the following questions: \\n \\nQuestion-1 \\n \\n‘How many measurements are within 1 standard deviation of the mean?’ \\n \\nQuestion-2 \\n \\n‘How many measurements are within 2 standard deviations?’  \\nand so on. \\nFor any specific data set, we can answer these questions by counting the number of measurements in each of the \\nintervals.  However, if we are interested in obtaining a general answer to these questions the problem is a bit more \\ndifficult. We will discuss to you two sets of answers to the questions of how many measurements fall within 1, 2, and 3 \\nstandard deviations of the mean. General answer to these questions the problem is a bit more difficult.  The first, which \\napplies to any set of data, is  derived from a theorem proved by Russian mathematician, P.L. Chebychev (1821 -\\n1894).The second, which applies to mound -shaped, symmetric distributions of data, is based upon empirical evidence \\nthat has accumulated over the years. And this set of answers is  valid and applicable even if our distribution is slightly \\nskewed, Let us begin with the Chebychev’s theorem.  \\nChebychev’s Rule applies to any data set, regardless of the shape of the frequency distribution of the data. \\n \\nCHEBYCHEV’S THEOREM \\n \\n For any numbe r k greater than 1, at least 1 – 1/k2 of the data -values fall within k standard deviations of the \\nmean, i.e., within the interval (\\uf060X – kS,\\uf060X + kS) \\nThis means that:  \\na) At least 1 -1/22 = 3/4 will fall within 2 standard deviations of the mean, i.e. within t he interval  \\n(\\uf060X – 2S,\\uf060X + 2S). \\nb) At least 1-1/32=8/9 of the data-values will fall within 3 standard deviations of the mean, i.e. within the interval (\\uf060X – \\n3S,\\uf060X + 3S) \\nBecause of the fact that Chebychev’s theorem requires k to be greater than 1, therefore  no useful information is \\nprovided by this theorem on the fraction of measurements that fall within 1 standard deviation of the mean, i.e. within \\nthe interval (X–S,\\uf060X+S). \\n            Next, let us consider the Empirical Rule mentioned above. \\nThis is a rule of thumb that applies to data sets with frequency distributions that are mound -shaped and symmetric, as \\nfollows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRelative Frequency \\nMeasurements '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 94}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       90                                                                                                                                           \\nAccording to this empirical rule: \\n \\n\\uf0b7 Approximately 68% of the measurements will fall within 1 standard deviation of the mean, i .e. within the \\ninterval (\\uf060X – S,\\uf060X + S) \\n\\uf0b7 Approximately 95% of the measurements will fall within 2 standard deviations of the mean, i.e. within the \\ninterval (\\uf060X – 2S,\\uf060X + 2S). \\n\\uf0b7 Approximately 100% (practically all) of the measurements will fall within 3 standa rd deviations of the mean, \\ni.e. within the interval (\\uf060X – 3S,\\uf060X + 3S). \\nLet us understand this point with the help of an example: \\n \\nEXAMPLE \\n \\nThe 50 companies’ percentages of revenues spent on R&D (i.e. Research and Development) are: \\n \\n \\n \\n \\n \\n \\n \\n \\nCalculate the pr oportions of these measurements that lie within the intervals \\uf060X \\uf0b1 S,\\uf060X \\uf0b1 2S, and \\uf060X \\uf0b1 3S, and \\ncompare the results with the theoretical values. The mean and standard deviation of these data come out to be 8.49 and \\n1.98, respectively.  \\nMean: \\n\\uf060X = 8.49 \\nStandard deviation: \\n S = 1.98 \\nHence \\n \\n(\\uf060X – S,\\uf060X + S)  \\n  = (8.49 – 1.98, 8.49 + 1.98)  \\n  = (6.51, 10.47) \\n \\n A check of the measurement reveals that 34 of the 50 measurements, or 68%, fall between 6.51and 10.47. \\nSimilarly, the interval \\n \\n(\\uf060X – 2S,\\uf060X + 2S)     \\n= (8.49 – 3.96, 8.49 + 3.96) \\n= (4.53, 12.45) \\nContains 47 of the 50 measurements, i.e. 94% of the data-values \\nFinally, the 3-standard deviation interval around \\uf060X, i.e. (\\uf060X – 3S,\\uf060X + 3S)  \\n      = (8.49 – 5.94, 8.49 + 5.94)  \\n      = (2.55, 14.43) contains all, or 100%, of the measurements. \\n \\nIn spite of the fact that the distribution of these data is skewed to the right, the percentages of data -values falling within \\n1, 2, and 3 standard deviations of the mean are remarkably close to the theoretical values (68%, 95% , and 100%) given \\nby the Empirical Rule. \\nThe fact of the matter is that, unless the distribution is extremely skewed, the mound -shaped approximations will be \\nreasonably accurate. Of course, no matter what the shape of the distribution, Chebychev’s Rule, as sures that at least \\n75% and at least 89% (8/9) of the measurements will lie within 2 and 3 standard deviations of the mean, respectively. \\nIn this example, 94% of the values are lying inside the interval \\uf060X + 2S, and this percentage IS greater than 75%.  \\n Similarly,100% of the values are lying inside the interval \\uf060X + 3S, and this percentage IS greater than 89%. \\nBut, before we discuss all these new concepts, let us revise the concept of the Chebychev’s Inequality. In the last \\nlecture, we noted that when all the values in a set of data are located near their mean, they exhibit a small amount of \\nvariation or dispersion. \\nAnd those sets of data in which some values are located far from their mean have a large amount of dispersion. \\nExpressing these relationships in terms of the standard deviation, which measures dispersion, we can say that when the \\nvalues of a set of data are concentrated near their mean, the standard deviation is small. And when the values of a set of \\ndata are scattered widely about the mean, the standard deviation is large. In exactly the same way, if the standard \\ndeviation computed from a set of data is large, the values from which it is computed are dispersed widely about their \\nmean. A useful rule that illustrates the relationship between disper sion and standard deviation is given by Chebychev’s \\ntheorem, named after the Russian mathematician P.L. Chebychev (1821 -1894). This theorem enables us to calculate for \\nany set of data the minimum proportion of values that can be expected to lie within a sp ecified number of standard \\ndeviations of the mean. \\n13.5 9.5 8.2 6.5 8.4 8.1 6.9 7.5 10.5 13.5 \\n7.2 7.1 9.0 9.9 8.2 13.2 9.2 6.9 9.6 7.7 \\n9.7 7.5 7.2 5.9 6.6 11.1 8.8 5.2 10.6 8.2 \\n11.3 5.6 10.1 8.0 8.5 11.7 7.1 7.7 9.4 6.0 \\n8.0 7.4 10.5 7.8 7.9 6.5 6.9 6.5 6.8 9.5 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 95}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       91                                                                                                                                           \\nThe theorem tells us that at least 75% of the values in a set of data can be expected to fall within two standard \\ndeviations of the mean, at least 89% (8/9) within three standard deviations of the mean, an d at least 94% (15/16) within \\nfour standard deviations of the mean. \\nIn general, Chebychev’s theorem may be stated as follows: \\n \\nCHEBYCHEV’S THEOREM \\n \\nGiven a set of n observations x1, x2, x3… xn on the variable X, the probability is at least  \\n(1 – 1/k2) that X will take on a value within k standard deviations of the mean of the set of observations (where k > 1). \\nChebychev’s theorem is applicable to any set of observations, so we can use it for either samples or populations. Let us \\nnow see how we can suppose t hat a set of data has a mean of 150 and a standard deviation of 25. Putting k = 2 in the \\nChebychev’s theorem, at least  \\n1 – 1/ (2)2 = 75% of the data-values will take on a value within two standard deviations of the mean. \\nApply it in practice.  \\nSince the standard deviation is 25, hence 2(25) = 50, and at least 75% of the data -values will take on a value between \\n150 – 50 = 100 and 150 + 50 = 200. Consequently, we can say that we can expect at least 75% of the values to be \\nbetween 100 and 200.By similar calcu lations we find that we can expect at least 89% to be between 75 and 225, and at \\nleast 96% to be between 25 and 275. \\n(The last statement has been made by putting k = 5 in the formula 1 - 1/k2) \\nSuppose that another set of data has the same mean as before, i .e. 150, but a standard deviation of 10. Applying \\nChebychev’s theorem, for this set of data we can expect at least 75% of the values to be between 130 and 170, at least \\n89% to be between 120 and 180, and at least 96% to be between 100 and 200. \\nThe above results are summarized in the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThus the intervals computed for the latter set of data are all narrower than those for the former.  \\nFor two symmetric, hump-shaped distributions having the same mean, this point is depicted in the following diagram:  \\n \\nTHE SYMMETRIC CURVE \\n \\n \\n \\nTherefore, we see that for a set of data with a small standard deviation, a larger proportion of the values will be \\nconcentrated near the mean than for a set of data with a large standard deviation.  \\nA limitation of the Chebychev’s theorem is that  it gives no information at all about the probability of observing a value \\nwithin one standard deviation of the mean, since 1 – 1/k2 = 0 when k = 1. Also, it should be noted that the Chebyche v’s \\ntheorem provides weak information for our variable of interest. For many random variables, the probability of \\nobserving a value within 2 standard deviations of the mean is far greater than 1 – 1/22 = 0.75. \\nIn this way, the Chebychev’s theorem and the E mpirical Rule play an important role in understanding the nature and \\nimportance of the standard deviation as a measure of dispersion. \\nf \\n150 200 100 130 170 \\nPERCENTAGE  \\nOF DATA \\nFOR DATA-SET  \\nNO. 1 \\nFOR DATA-SET  \\nNO. 2 \\nAt least  \\n75 %  \\nLies Between  \\n100 & 200 \\nLies Between  \\n130 & 170 \\nAt least  \\n89 %  \\nLies Between  \\n75 & 225 \\nLies Between  \\n120 & 180 \\nAt least  \\n96 %  \\nLies Between  \\n25 & 275 \\nLies Between  \\n100 & 200 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 96}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       92                                                                                                                                           \\nThe next topic of today’s lecture is the five -number summary. (Now that we have studied the three major properties of \\nnumerical data (i.e. central tendency, variation, and shape), it is important that we identify and describe the major \\nfeatures of the data in a summarized format.)  \\nOne approach to this “exploratory data analysis” is to develop a five-number summary. \\n \\nFIVE-NUMBER SUMMARY \\n \\nA five-number summary consists of  X0,Q1, Median, Q3, and Xm  ; It provides us quite a good idea about the shape of \\nthe distribution. If the data were perfectly symmetrical, the following would be true: \\n \\n1. The distance from Q1 to the median would be equal to the distance from the median to Q3: \\n \\nTHE SYMMETRIC CURVE   \\n \\n \\n \\n3. The distance from X0 to Q1 would be equal to the distance from Q3 to Xm.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nf \\nX~\\nQ3 Q1 \\nX \\nf \\n \\nTHE SYMMETRIC CURVE  \\nQ3 Q1 Xm X0 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 97}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       93                                                                                                                                           \\n \\n \\n3. The median, the mid-quartile range, and the midrange would all be equal. All these measures would also be equal to \\nthe arithmetic mean of the data: \\n \\n \\n \\nOn the other hand, for non-symmetrical distributions, the following would be true: \\n1. In right-skewed distributions the distance from Q3 to Xm greatly exceeds the distance from X0 to Q1. \\n \\n \\n \\n2. in right-skewed distributions,  \\nmedian < mid-quartile range < midrange: \\n \\n \\nTHE POSITIVELY SKEWED CURVE \\nX \\n f \\nX~\\nMid-quartile Range \\nMid-Range \\nTHE SYMMETRIC CURVE \\nrangequartileMid\\nRangeMidX~X\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf03d\\nX \\nf \\nTHE POSITIVELY SKEWED CURVE \\nX \\n f \\nX0 Xm Q1 Q3 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 98}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       94                                                                                                                                           \\n \\nSimilarly, in left-skewed distributions, the distance from X0 to Q1 greatly exceeds the distance from Q3 to Xm.Also, in \\nleft-skewed distributions, midrange < mid-quartile range < median. \\nLet us try to understand this concept with the help of an example \\n \\nEXAMPLE \\n \\nSuppose that a study is being co nducted regarding the annual costs incurred by students attending public versus private \\ncolleges and universities in the United States of America. In particular, suppose, for exploratory purposes, our sample \\nconsists of 10 Universities whose athletic progr ams are members of the ‘Big Ten’ Conference. The annual costs \\nincurred for tuition fees, room, and board at 10 schools belonging to Big Ten Conference are given as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we wish to state the five -number summary for these data, th e first step will be to arrange our data -set in ascending \\norder: \\nOrdered Array: \\n \\n \\n \\nAnd if we carry out the relevant computations, we find that:  \\n \\n\\uf0b7 The median for this data comes out to be 15.30 thousand dollars.  \\n\\uf0b7 The first quartile comes out to be 14.90 thousand dollars, and  \\n\\uf0b7 The third quartile comes out to be 16.40 thousand dollars.  \\n \\nTherefore, the five-number summary for this data-set is:  \\nThe Five-Number Summary: \\n \\n \\n \\n \\n \\n \\n \\nIf we apply the rules that I am conveyed to you a short while ago, it is clear that  the annual cost data for our sample are \\nright-skewed. We come to this conclusion because of two reasons: \\n \\n\\uf0b7 The distance from Q3 to Xm (i.e., 6.7) greatly exceeds the distance from X0 to Q1 (i.e., 1.9).  \\n\\uf0b7 If we compare the median (which is 15.3), the mid-quartile range (which is 15.65), and the midrange (which \\nis 18.05), we observe that the median < the mid-quartile range < the midrange. \\n \\nBoth these points clearly indicate that our distribution is positively skewed. \\nThe gist of the above discussion is that the five-number summary is a simple yet effective way of determining the shape \\nof our frequency distribution --- without actually drawing the graph of the frequency distribution. \\nName of University Annual Costs \\n(in $000) \\nIndiana University 15.6 \\nMichigan State University 17.0 \\nOhio State University 15.2 \\nPennsylvania State University 16.4 \\nPurdue University 15.2 \\nUniversity of Illinois 15.4 \\nUniversity of Iowa 13.0 \\nUniversity of Michigan 23.1 \\nUniversity of Minnesota 14.3 \\nUniversity of Wisconsin 14.9 \\n \\nX0 = 13.0 14.3 14.9 15.2 15.2 15.4 15.6 16.4 17.0 Xm = 23.1 \\n \\nX0 Q1 \\nX~  Q3 Xm \\n13.0 14.9 15.3 16.4 23.1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 99}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       95                                                                                                                                           \\n \\nLECTURE NO. 13 \\n \\n \\n\\uf0b7 Box and Whisker Plot \\n\\uf0b7 Pearson’s Coefficient of Skewness  \\nPrior to discussing the THE BOX -AND-WHISKER PLOT, let us review the concept of THE FIVE -NUMBER \\nSUMMARY. As indicated in the last lecture, once we have studied the three major properties of numerical data (i.e. \\ncentral tendency, variation, and shape), it is imp ortant that we identify and describe the major features of the data in a \\nSUMMARIZED format. One way of doing this is to develop a five-number summary. \\n \\n \\nFIVE-NUMBER SUMMARY \\n \\nA five-number summary consists of X0, Q1, Median, Q3; Xm.It  provides us a better i dea as to the SHAPE of the \\ndistribution, as explained below: \\nIf the data were perfectly symmetrical, the following would be true: \\n1. The distance from Q1 to the median would be equal to the distance from the median to Q3, as shown \\nbelow: \\n \\n \\n \\n2. The distance from X0 to Q1 would be equal to the distance from Q3 to Xm, as shown below: \\n \\n                                THE SYMMETRIC CURVE \\n \\n \\n \\n \\n \\n \\nX \\nTHE SYMMETRIC CURVE \\nf \\nX~\\nQ3 Q1 \\nX \\nf \\n \\nQ3 Q1 Xm X0 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 100}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       96                                                                                                                                           \\n \\n \\n \\n3. The median, the mid-quartile range, and the midrange would ALL be equal.  \\nThese measures would also be equal to the arithmetic mean of the data, as shown below: \\n \\nOn the other hand, for non-symmetrical distributions, the following would be true: \\n \\n1. In right -skewed (positively-skewed) distributions the distance from Q3 to Xm greatly EXCEEDS the distance from \\nX0 to Q1, as shown below: \\n \\n \\n \\n \\n2. In right-skewed distributions,   \\n \\nmedian < mid-quartile range < midrange \\n \\nThis is indicated in the following figure: \\n \\nTHE SYMMETRIC CURVE \\nrangequartileMid\\nRangeMidX~X\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf03d\\nX \\nf \\nTHE POSITIVELY SKEWED CURVE \\nX \\n f \\nX0 Xm Q1 Q3 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 101}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       97                                                                                                                                           \\n \\nSimilarly, in left-skewed distributions, the distance from X0 to Q1 greatly exceeds the distance from Q3 to Xm.Also, in \\nleft-skewed distributions, midrange < mid-quartile range < median.  \\nLet us try to understand this concept with the help of an example: \\n \\nEXAMPLE \\n  \\n Suppose that a study is being conducted regarding the annual costs incurred by students attending public \\nversus private colleges and universities in the United States of America. In particular, suppose, for exploratory \\npurposes, our sample consists of 10 Universities whose athletic programs are members of the ‘Big Ten’ Conference? \\nThe annual costs incurred for tuition fees, room, and board at 10 schools belonging to Big Ten Conference are given in \\nthe following table; state the five-number summary for these data. \\n \\nAnnual Costs Incurred on Tuition Fees, etc. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSOLUTION: \\nFor our sample, the ordered array is \\n \\n \\n \\n \\n \\nTHE POSITIVELY SKEWED CURVE \\nX \\n f \\nX~\\nMid-quartile Range \\nMid-Range \\nName of University Annual Costs \\n(in $000) \\nIndiana University 15.6 \\nMichigan State University 17.0 \\nOhio State University 15.2 \\nPennsylvania State University 16.4 \\nPurdue University 15.2 \\nUniversity of Illinois 15.4 \\nUniversity of Iowa 13.0 \\nUniversity of Michigan 23.1 \\nUniversity of Minnesota 14.3 \\nUniversity of Wisconsin 14.9 \\n \\nX0 = 13.0 14.3 14.9 15.2 15.2 15.4 15.6 16.4 17.0 Xm = 23.1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 102}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       98                                                                                                                                           \\nThe median for this data comes out to be 15.30 thousand dollars. The first quartile comes out to be 14.90 thousand \\ndollars, and the third quartile comes out to be 16.40 thousand dollars.  \\nTherefore, the five-number summary is: \\n \\n \\n \\n \\n \\n \\n \\nWe may now use the five-number summary to study the shape of this distribution: \\nWe notice that \\n1. The distance from Q3 to Xm (i.e., 6.7) greatly exceeds the distance from X0 to Q1 (i.e., 1.9).  \\n2. If we compare the median (which is 15.3), the mid-quartile range (which is 15.65), and the midrange (which is \\n18.05), we observe that the median < the mid-quartile range < the midrange. \\nHence, from the preceding rules, it is clear that the annual cost data for our sample are right-skewed. The gist of the \\nabove discussion is that the five -number summary is a SIMPLE yet effective way of determining the shape of our \\nfrequency distribution --- WITHOUT actually drawing the graph of the frequency distribution. The concept of the five \\nnumber summary is directly linked with the concept of the box and whisker plot: \\n \\nBOX AND WHISKER PLOT \\n \\nIn its simplest form, a box -and-whisker plot provide s a graphical representation of the data through its five -number \\nsummary.  \\nBox and Whisker Plot \\n \\n \\nTo construct a box-and-whisker plot, we proceed as follows: \\nSteps involved in the construction of the Box and Whisker Plot: \\n \\n1. The variable of interest in represented on the horizontal axis. \\n \\n \\n \\n \\n  \\nX0 \\nVariable  \\nof Interest \\nQ3 \\nX~Q1 Xm \\nVariable of Interest \\n0  2  4  6  8  10  12   \\nX0 Q1 \\nX~  Q3 Xm \\n13.0 14.9 15.3 16.4 23.1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 103}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       99                                                                                                                                           \\n2. A BOX is drawn in the space above the horizontal axis in such a way that the left end of the box aligns with the first \\nquartile Q1 and the right end of the box is aligned with the third quartile Q3.  \\n \\n \\n \\n3. The box is divided into two parts by a VERTICAL line that aligns with the MEDIAN. \\n \\n \\n \\n4. A line, called a whisker, is extended from the LEFT end of the bo x to a point that aligns with X0, the smallest \\nmeasurement in the data set. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0  2  4  6  8  10  12   \\nQ1 \\nVariable  \\nof Interest \\nQ3 \\n0  2  4  6  8  10  12   \\nQ1 \\nVariable  \\nof Interest \\nQ3 \\nX~\\n0  2  4  6  8  10  12   \\nX0 \\nVariable  \\nof Interest \\nQ3 \\nX~Q1 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 104}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       100                                                                                                                                           \\n \\n5. Another line, or whisker, is extended from the RIGHT end of the box to a point that aligns with the LARGEST \\nmeasurement in the data set. \\n \\n \\n \\n \\n \\nLet us understand the construction of the box-and-whisker plot with reference to an example: \\n \\nEXAMPLE \\n \\nThe following table shows the downtime, in hours, recorded for 30 machines owned by a large manufacturing company. \\nThe period of time covered was the same for all machines. \\n \\nDOWNTIME IN HOURS OF 30 MACHINES \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to construct a box-and-whisker plot for these data, we proceed as follows: \\nFirst of all, we determine the two extreme values in our data-set:  \\nThe smallest and largest values are X0 = 1 and Xm = 13, respectively. \\nAs far as the computation of the quartiles is concerned, we note that, in this example, we are dealing with raw data. \\n \\nThe first quartile is the (30 + 1)/4 = 7.75th ordered measurement and is equal to 4. \\nThe median is the (30 + 1)/2 = 15.5th measurement, or 5,and  \\nThe third quartile is the 3(30 + 1)/4 = 23.25th ordered measurement, which is 8.25.  \\nAs a result, we obtain the following box and whisker plot: \\nBox and Whisker Plot \\n \\n \\n \\n \\n0  2  4  6  8  10  12   \\nX0 \\nVariable  \\nof Interest \\nQ3 \\nX~Q1 Xm \\nDowntime (hours) \\n0  2  4  6  8  10  12  14 \\n4 4 1 4 1 4 \\n6 10 5 5 8 2 \\n1 6 10 1 13 5 \\n8 4 3 9 4 9 \\n1 4 4 11 8 9 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 105}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       101                                                                                                                                           \\n \\nINTERPRETATION OF THE BOX AND WHISKER PLOT \\n \\nWith regard to the interpretation of the Box and Whisker Plot, it should be noted that, by looking at a box -and-whisker \\nplot, one can quickly form an impression regarding the amount of SPREAD, loc ation of CONCENTRATION, and \\nSYMMETRY of our data set.  \\nA glance at the box and whisker plot of the example that we just considered reveals that: \\n\\uf0b7 50% of the measurements are between 4 and 8.25.  \\n\\uf0b7 The median is 5, and the range is 12. and, most importantly: \\n\\uf0b7 Since the median line is closer to the left end of the box, hence the data are SKEWED to the RIGHT.(The \\nfundamental point is that in a perfectly symmetrical data set, the median line will be EXACTLY HALFWAY \\nbetween the two ends of the box, and in a data set that is skewed to the LEFT, the median line will be \\nCLOSER TO THE RIGHT END of the box.) \\nLet us consolidate all the above ideas by going back to the example of the Big Ten Universities in which the annual \\ncosts incurred for tuition fees, room, and board at 10 schools belonging to Big Ten Conference were given as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs stated earlier, the Five-Number Summary of this data-set is : \\nFor this data, the Box and Whisker Plot is of the form given below: \\n \\nBox and Whisker Plot \\n \\n \\nAs indicated earlier, the vertical line drawn within the box represents the location of the median value in the data; the \\nvertical line at the LEFT side of the box represents the location of Q1, and the vertical line at the RIGHT side of the box \\nrepresents the location of Q3. Therefore, the BOX contains the middle 50% of the observations in the distribution. The \\nlower 25% of the data are represented by the whisker that connects the left side of the box to the location of the smallest \\nvalue, X0, and the upper 25% of the data are represented by the whisker connecting the right side of the box to Xm. \\n \\n \\n5 10 15 20 25 \\nThousands of dollars \\nName of University Annual Costs \\n(in $000) \\nIndiana University 15.6 \\nMichigan State University 17.0 \\nOhio State University 15.2 \\nPennsylvania State University 16.4 \\nPurdue University 15.2 \\nUniversity of Illinois 15.4 \\nUniversity of Iowa 13.0 \\nUniversity of Michigan 23.1 \\nUniversity of Minnesota 14.3 \\nUniversity of Wisconsin 14.9 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 106}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       102                                                                                                                                           \\n \\n \\nINTERPRETATION OF THE BOX AND WHISKER PLOT \\n \\n                          We note that (1) the vertical median line is CLOSER to the left side of  the box, and (2) the left side \\nwhisker length is clearly SMALLER than the right side whisker length .Because of these observations, we The gist of \\nthe above discussion is that if the median line is at a greater distance from the left side of the box as co mpared with its \\ndistance from the right side of the box, our distribution will be skewed to the left. \\n In this situation, the whisker appearing on the left side of the box and whisker plot will be longer \\nthan the whisker of the right side. Conclude that the data-set of the annual costs is RIGHT-skewed.  \\nThe gist of the above discussion is that if the median line is at a greater distance from the left side of the box as \\ncompared with its distance from the right side of the box, our distribution will be skewed to the left. In this situation, the \\nwhisker appearing on the left side of the box and whisker plot will be longer than the whisker of the right side. The Box \\nand Whisker Plot comes under the realm of “exploratory data analysis” (EDA) which is a relativel y new area of \\nstatistics. The following figures provide a comparison between the Box and Whisker Plot and the traditional procedures \\nsuch as the frequency polygon and the frequency curve with reference to the SKEWNESS present in the data-set. \\nFour differen t types of hypothetical distributions are depicted through their box -and-whisker plots and \\ncorresponding frequency curves. \\n1) When a data set is perfectly symmetrical, as is the case in the following two figures, the mean, median, midrange, \\nand mid-quartile range will be the SAME: \\n \\n \\n \\nIn ADDITION, the length of the left whisker will be equal to the length of the right whisker, and the median line will \\ndivide the box in HALF. (In practice, it is unlikely that we will observe a data  set that is perfectly symmetrical. \\nHowever, we should be able to state that our data set is approximately symmetrical if the lengths of the two whiskers \\nare almost equal and the median line almost divides the box in HALF.) \\n2) When our data set is LEFT -skewed as in the following figure, the few small observations pull the midrange and \\nmean toward the LEFT tail: \\n(a) Bell-shaped distribution \\n(b) Rectangular distribution '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 107}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       103                                                                                                                                           \\n \\n \\nFor this LEFT-skewed distribution, we observe that the skewed nature of the data set indicates that there is a HEAVY \\nCLUSTERING of observations at the HIGH END of the scale (i.e., the RIGHT side). \\n75% of all data values are found between the left edge of the box (Q1) and the end of the right whisker (Xm). \\nTherefore, the LONG left whisker contains the distribution of only the smallest 25% of the observations, demonstrating \\nthe distortion from symmetry in this data set. \\n3) If the data set is RIGHT -skewed as shown in the following figure, the few large observations PULL the midrange \\nand mean toward the right tail.  \\n \\n \\nFor the right-skewed data set, the concentration of data points is on the LOW end of the scale (i.e., the left side of the \\nbox-and-whisker plot). Here, 75% of all data values are found between the beginning of the left whisker (X0) and the \\nRIGHT edge of the box (Q3), and the remaining 25% of the observations are DISPERSED ALONG the LONG right \\nwhisker at the upper end of the scale. This brings us to the end of the discussion of the five number summary and the \\nbox and whisker plot. \\n  Next, we discuss another way of determining the skewness of the data-set and that is the PEARSON’S  \\n \\nCOEFFICIENT OF SKEWNESS \\nIn this connection, the first thing to note is that, by providing information about the location of a series and \\nthe dispersion within t hat series it might appear that we have achieved a PERFECTLY adequate overall description of \\nthe data. But, the fact of the matter is that, it is quite possible that two series are decidedly dissimilar and yet have \\nexactly the same arithmetic mean AND standard deviation: Let us understand this point with the help of an example: \\n \\nEXAMPLE: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLeft-skewed distribution \\nRight-skewed distribution \\nAge of Onset of  \\nNervous Asthma  \\nin Children  \\n(to Nearest Year) \\nChildren  \\nof \\nManual \\nWorkers \\nChildren of  \\nNon-Manual \\nWorkers \\n0 – 2 3 3 \\n3 – 5 9 12 \\n6 – 8 18 9 \\n9 – 11 18  27 \\n12 – 14 9 6 \\n15 – 17 3 3 \\n 60 60 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 108}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       104                                                                                                                                           \\nIn order to compute the mean and standard deviation for each distribution, we carry out the following calculations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWe find that, for each of the two distributions, the mean is 8.5 years and the standard deviation is 3.61 years.  \\nThe frequency polygons of the two distributions are as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nBy inspecting these, it can be seen that one distribution is symmetrical while the other is quite different. The \\ndistinguishing feature here is the degree of asymmetry or SKEWNESS in the two polygons. In order to measure the \\nskewness in our distribution, we compute the PEARSON’s COEFFICIENT OF SKEWNESS which is defined as: \\nPearson’s Coefficient of Skewness: \\n \\n \\n \\n \\n \\nApplying the empirical relation  between the mean, median and the mode, the Pearson’s Coefficient of Skewness is \\ngiven by: \\n \\n \\n \\nPearson’s Coefficient of Skewness \\n \\n \\n \\n \\n \\nFor a symmetrical distribution the coefficient will always be ZE RO, for a distribution skewed to the RIGHT the answer \\nwill always be positive, and for one skewed to the LEFT the answer will always be negative.  \\nLet us now calculate this coefficient for the example of the children of the manual and non-manual workers. \\nSample statistics pertaining to the ages of these children are as follows: \\n \\n \\n \\n \\n \\n \\n \\nAge of Onset of  \\nNervous Asthma  \\nin Children  \\n(to Nearest Year) \\nChildren  \\nof Manual  \\nWorkers \\nChildren of  \\nNon-Manual  \\nWorkers \\nAge Group X f1 f1X f1X2 f2 f2X f2X2 \\n0 – 2 1 3 3 3 3 3 3 \\n3 – 5 4 9 36 144 12 48 192 \\n6 – 8 7 18 126 882 9 63 441 \\n9 – 11 10 18  180 1800 27 270 2700 \\n12 – 14 13 9 117 1521 6 78 1014 \\n15 – 17 16 3 48 768 3 48 768 \\n 51 60 510 5118 60 510 5118 \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n-2 1 4 7 10 13 16 19\\nage to nearest year \\nnumber of children\\nnon-manual\\nmanual\\ndeviationdards\\nemean\\ntan\\nmod\\uf02d\\n\\uf028 \\uf029\\ndeviationdardtans\\nmedianmean3 \\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 109}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       105                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe Pearson’s Coefficient of Skewness is calculated for each of the two categories of children, as shown below: \\nPearson’s Coefficient of Skewness (Modified): \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFor the data pertaining to children of manual workers, the coefficient is zero, whereas, for the children of non -manual \\nworkers, the coefficient has turned out to be a negative number. This indicates that the distribution of the ages of the \\nchildren of the manual workers is symmetric whereas the distribution of the ages of the children of the non -manual \\nworkers is negatively skewed. \\nThe students are encouraged to draw the frequency polygon and the frequency curve for each of the two distributions , \\nand to compare the results that have just been obtained with the shapes of the two distributions. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nChildren of \\nManual \\nWorkers \\nChildren of \\nNon-Manual \\nWorkers \\nMean 8.50 years 8.50 years \\nStandard deviation 3.61 years 3.61 years \\nMedian 8.50 years 9.16 years \\nQ1 6.00 years 5.50 years \\nQ3 11.00 years 10.83 years \\nQuartile deviation 2.50 years 2.66 years \\n \\nAges of Children  \\nof Manual Workers \\nAges of Children  \\nof Non-Manual Workers \\n\\uf028 \\uf029\\n61.3\\n50.850.83 \\uf02d\\n \\n\\uf028 \\uf029\\n61.3\\n16.950.83 \\uf02d  \\n              = 0           = – 0.55 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 110}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       106                                                                                                                                           \\nLECTURE NO. 14 \\n \\n• Bowley’s coefficient of skewness \\n• The Concept of Kurtosis \\n• Percentile Coefficient of Kurtosis \\n• Moments & Moment Ratios \\n• Sheppard’s Corrections \\n• The Role of Moments in Describing Frequency Distributions \\nYou will recall that the Pearson’s coefficient of skewness is defined as (mean - mode)/standard deviation, and if we \\napply the empirical relation between the mean, median and the mode, then the coefficient is given by: \\n \\nPEARSON’S COEFFICIENT OF SKEWNESS: \\n \\n \\n \\n \\nAs you can see, this coefficient involves the calculation of the mean as well as the standard deviation. Actually, the \\nnumerator is divided by the standard deviation in  order to obtain a pure number. If the analysis of a data -set is being \\nundertaken using the median and quartiles alone, then we use a measure called Bowley’s coefficient of skewness. \\nThe advantage of this particular formula is that it requires NO KNOWLEDGE  of the MEAN or STANDARD \\nDEVIATION. In an asymmetrical distribution, the quartiles will NOT be equidistant from the median, and the \\nAMOUNT by which each one deviates will give an indication of skewness. Where the distribution is positively skewed, \\nQ1 will be closer to the median than Q3.In other words, the distance between Q3 and the median will be greater than \\nthe distance between the median and Q1. \\n \\nPOSITIVE SKEWNESS \\n \\n \\n \\nAnd hence,  if we subtract the distance median - Q1 from the distance Q3 - median, we will obtain a positive answer. \\nIn case of a positively skewed distribution: \\n(Q3 - median) - (Median - Q1) > 0 \\ni.e. Q1 + Q3 - 2 median > 0 \\nThe opposite is true for skewness to the left \\n \\n \\n \\nQ3 Q1 \\nX~\\n\\uf028 \\uf029\\ndeviationdardtans\\nmedianmean3 \\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 111}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       107                                                                                                                                           \\n \\n \\nIn this case: \\n                    (Q3 - median) - (Median - Q1) < 0   i.e. \\n Q1 + Q3 - 2 median < 0 \\nThe gist of the above discussion is that in case of a positively skewed distribution, the quantity \\n \\n                                              Q1 + Q3 -            \\n \\nwill be positive, whereas in case of a negatively distribution, this quantity will be negative. \\nA RELATIVE measure of skewness is obtained by dividing \\n \\nQ1 + Q3 –                                             \\n \\nby the inter-quartile range i.e. Q3 - Q1, so that Bowley’s coefficient of skewness is given by: \\nBowley’s coefficient of Skewness \\n \\n \\n \\n \\nIt is a pure (unit less) number, and its value lies between 0 and \\uf0b1 1.  \\nFor a positively skewed distribution, this coefficient will turn out to be positive, and for a ne gatively skewed \\ndistribution this coefficient will come out to be negative. Let us apply this concept to the example regarding the ages of \\nchildren of the manual and non-manual workers that we considered in the last lecture. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNEGATIVE SKEWNESS \\n \\nQ1 Q3 \\nX~\\n\\uf028 \\uf029\\n13\\n31\\nQQ\\nX~2QQ\\n\\uf02d\\n\\uf02d\\uf02b\\uf03d\\nAge of Onset of  \\nNervous Asthma  \\nin Children  \\n(to Nearest Year) \\nChildren  \\nof Manual \\nWorkers \\nChildren of  \\nNon-Manual \\nWorkers \\n0 – 2 3 3 \\n3 – 5 9 12 \\n6 – 8 18 9 \\n9 – 11 18  27 \\n12 – 14 9 6 \\n15 – 17 3 3 \\n 60 60 \\n \\nX~2\\nX~2'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 112}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       108                                                                                                                                           \\n \\n \\nEXAMPLE: \\nSample statistics pertaining to ages of children of manual and non-manual workers: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe statistics pertaining to children of manual workers yield the following PICTURE:   \\n \\n \\nOn the other hand, the statistics pertaining to children of non-manual workers yield the following PICTURE: \\n \\n \\n \\n \\n \\nThe diagram pertaining to children of non-manual workers clearly shows that the distance between    \\nX \\nf \\nAges of Children of Manual Workers \\n5.8~ \\uf03dX\\nQ1 = \\n6.0 \\nQ3 = \\n11.0 \\nX \\n f \\nAges of Children of Non-Manual Workers \\n2.9X~ \\uf03d\\nQ1 = \\n5.5 \\nQ3 = 10.8 \\n \\nChildren of \\nManual \\nWorkers \\nChildren of \\nNon-Manual \\nWorkers \\nMean 8.50 years 8.50 years \\nStandard deviation 3.61 years 3.61 years \\nMedian 8.50 years 9.16 years \\nQ1 6.00 years 5.50 years \\nQ3 11.00 years 10.83 years \\nQuartile deviation 2.50 years 2.66 years \\n \\nX~andQ1\\n3QandX~'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 113}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       109                                                                                                                                           \\nis much greater than the distance between  \\nwhich happens whenever we are dealing with a negatively skewed distribution. If we compute the  Bowley’s coefficient \\nof skewness for each of these two data-sets, we obtain: \\nBowley’s Coefficient of Skewness \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs you have noticed, for the children of the manual workers, the Bowley’s coefficient has come out to be zero, whereas \\nfor the children of the non -manual workers, the coefficient has come out to be negative. This indicates that the \\ndistribution of the ages of the children of manual workers is symmetrica l whereas the distribution of the ages of the \\nchildren of the non -manual workers IS negatively skewed --- EXACTLY the same conclusion that we obtained when \\nwe computed the Pearson’s coefficient of skewness. \\n \\nKURTOSIS \\n \\n The term kurtosis was introduced by K arl Pearson. This word literally means ‘the amount of hump’, and is \\nused to represent the degree of PEAKEDNESS or flatness of a unimodal frequency curve.  \\nWhen the values of a variable are closely BUNCHED round the mode in such a way that the peak of the c urve becomes \\nrelatively high, we say that the curve is LEPTOKURTIC.  \\n \\n \\n \\n \\nOn the other hand, if the curve is flat-topped, we say that the curve is PLATYKURTIC: \\n \\n \\n \\n \\nThe NORMAL curve is a curve which is neither very peaked nor very flat, and hence it is taken as A BASIS FOR \\nCOMPARISON. The normal curve itself is called MESOKURTIC. \\nI will discuss with you the normal in detail when we discuss continuous probability distributions. \\nAt the moment, just think of the symmetric hump shaped curve shown below: \\n \\nMode \\nLeptokurtic \\nMode \\nPlatykurtic \\nAges of Children  \\nof Manual Workers \\n Ages of Children  \\nof Non-Manual Workers \\n50.2\\n50.8200.600.11 \\uf0b4\\uf02d\\uf02b\\uf03d\\n \\n \\n50.583.10\\n16.9250.583.10\\n\\uf02d\\n\\uf0b4\\uf02d\\uf02b\\n \\n= 0 = – 0.37 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 114}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       110                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n  \\nSuper-imposing the three curves on the same graph, we obtain the following picture: \\n \\n \\n \\nThe tallest one is called leptokurtic, the intermediate one is called mesokurtic, and the flat one is called platykurtic. \\nThe question arises, “How will we MEASURE the degree of peakedness or kurtosis of a data-set?” \\nA MEASURE of kurtosis based on quartiles and percentiles is  \\n \\n \\n \\n \\nThis is known as the PERCENTILE COEFFICIENT OF KURTOSIS.  \\nIt has been shown that K for a normal distribution is 0.263 and that it lies between 0 and 0.50. \\nIn case of a leptokurtic distribution, the percentile coefficient of kurtosis comes out to be LESS THAN 0.263, and in the \\ncase of a  platykurtic distribution, the percentile coefficient of kurtosis comes out to be GREATER THAN 0.263.The \\nnext concept that I am going to discuss with you is the concept of moments --- a MATHEMATICAL concept, and a \\nvery important concept in statistics. \\n. \\nMOMENTS \\n \\n            A moment designates the power to which deviations are raised before averaging them. \\nFor example, the quantity  \\n \\n \\n \\n \\nis called the first sample moment about the mean, and is denoted by m1.  \\nSimilarly, the quantity   \\n \\n \\n \\n \\n \\nMode \\nMesokurtic \\nMode \\nMesokurtic \\nPlatykurtic \\nLeptokurtic \\n,..\\n1090 PP\\nDQK \\uf02d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5 \\uf02d\\uf03d\\uf02d xxn\\n1xxn\\n1\\ni\\n1\\ni\\n\\uf028 \\uf0292\\ni xxn\\n1 \\uf0e5 \\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 115}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       111                                                                                                                                           \\nis called the se cond sample moment about the mean, and is denoted by m2.In general, the rth moment about the mean \\nis: the arithmetic mean of the rth power of the deviations of the observations from the mean. In symbols, this means that \\n \\n    for sample data.  \\n \\n \\nMoments about the mean are also called the central moments or the mean moments. \\nIn a similar way, moments about an arbitrary origin, say \\uf061, are defined by the relation \\n     \\n \\n \\n                                             ,                            for sample data \\n \\nFor r = 1, we have \\n \\n \\n \\n \\nand \\n \\n \\n \\n \\n \\nPutting r = 2 in the relation for mean moments, we see that   \\n \\n \\n \\nwhich is exactly the same as the sample variance.  \\nIf we take the positive square root of this quantity, we obtain the standard deviation. \\nIn the formula, \\n \\n \\nif we put \\uf061 = 0, we obtain \\n \\n \\n \\nand this is called the rth moment about zero, or the rth moment about the origin. \\nLet us now consolidate the idea of moments by considering an example. \\n \\nEXAMPLE \\n \\nCalculate the first four moments about the mean for the foll owing set of examination marks: 45, 32, 37, 46, 39, 36, 41, \\n48 & 36. \\nFor convenience, the observed values are written in an increasing sequence. The necessary calculations appear in the \\ntable below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow       marks. \\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d r\\nir xxn\\n1m\\n\\uf028 \\uf029\\uf0e5 \\uf061\\uf02d\\uf03d\\uf0a2 r\\nir xn\\n1m\\n\\uf028 \\uf029\\uf0e5 \\uf0e5 \\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d ,0xxxn\\nxxxn\\n1m i\\ni1\\n\\uf028 \\uf029\\uf0e5 \\uf0e5 \\uf061\\uf02d\\uf03d\\uf061\\uf02d\\uf03d\\uf061\\uf02d\\uf03d .xn\\nxxn\\n1'm i\\ni1\\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d 2\\ni2 xxn\\n1m\\n\\uf028 \\uf029\\uf0e5 \\uf061\\uf02d\\uf03d\\uf0a2 r\\nir xn\\n1m\\n\\uf0e5\\uf03d\\uf0a2 r\\nir xnm 1\\nxi xi –\\uf060x (xi –\\uf060x)2 (xi –\\uf060x)3 (xi –\\uf060x)4 \\n32 – 8 64 – 512 4096 \\n36 – 4 16 – 64 256 \\n36 – 4 16 – 64 256 \\n37 – 3 9 – 27 81 \\n39 – 1 1 – 1 1 \\n41 1 1 1 1 \\n45 5 25 125 625 \\n46 6 36 216 1296 \\n48 8 64 512 4096 \\n360 0 232 186 10708 \\n \\n409\\n360 \\uf03d\\uf03d\\uf03d \\uf0e5\\nn\\nxx\\ni\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 116}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       112                                                                                                                                           \\n \\nTherefore  \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\nAll the formulae that I have discussed until now pertain to the case of raw data. \\nHow will we compute the various moments in the case of grouped data? \\n \\nMOMENTS IN THE CASE OF GROUPED DATA \\n \\nWhen the sample data are grouped into a frequency distribution having k classes with midpoints x1, x2, …, xk and the \\ncorresponding frequencies f1, f2, …,fk , (\\uf0e5fi = n), the rth sample moments are given by \\n \\n \\n \\n \\n \\n \\n \\n  \\nIn the calculation of moments from a grouped frequency distribution, an error is introduced by th e assumption that the \\nfrequencies associated with a class are located at the MIDPOINT of the class interval. You remember the concept of \\ngrouping error that I discussed with you in an earlier lecture? Our moments therefore need corrections.  \\nThese corrections were introduced by W.F. Sheppard, and hence they are known as SHEPPARD’S CORRECTIONS: \\nSheppard’s Corrections for Grouping Error: \\nIt has been shown by W.F. Sheppard that, if the frequency distribution (i) is continuous and (ii) tails off to zero at each  \\nend, the corrected moments are as given below: \\nm2 (corrected) = m2 (uncorrected) –\\n12\\nh2 ; \\nm3 (corrected) = m3 (uncorrected); \\nm4 (corrected) = m4 (uncorrected) –\\n2\\nh2 . m2 (uncorrected) +\\n240\\n7 . h4; \\nwhere h denotes the uniform class-interval. \\nThe important point to note here is that these corrections are NOT applicable to highly skewed distributions and \\ndistributions having unequal class -intervals. I am now going to discuss with you certain mathematical \\nRELATIONSHIPS that exist between the moments about the mean and the moments about an arbitrary origin. \\nThe reason for doing so is that, in many situations, it is easier to calculate the moments in the first instance, about an \\narbitrary origin. They are then transformed to the mean-moments using the relationships that I am now going to convey \\nto you. \\nThe equations are: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 0n\\nxxm i\\n1 \\uf03d\\uf02d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029 \\uf028 \\uf0292\\n2\\ni\\n2 marks78.259\\n232\\nn\\nxxm \\uf03d\\uf03d\\uf02d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029 \\uf028 \\uf0293\\n3\\ni\\n3 marks67.209\\n186\\nn\\nxxm \\uf03d\\uf03d\\uf02d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029 \\uf028 \\uf0294\\n4\\ni\\n4 marks78.11899\\n10708\\nn\\nxxm \\uf03d\\uf03d\\uf02d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d r\\niir xxfn\\n1m\\n, and \\n\\uf028 \\uf029\\uf0e5 \\uf061\\uf02d\\uf03d .xfn\\n1'm r\\niir\\n \\nm1 = 0 \\nm2 \\n\\uf028 \\uf029 ;'m'm 2\\n12 \\uf02d\\uf03d  \\n\\uf028 \\uf029 ,'m2'm'm3'mm 3\\n11233 \\uf02b\\uf02d\\uf03d\\n and \\n\\uf028 \\uf029 \\uf028 \\uf0294\\n1\\n2\\n121344 'm3'm'm6'm'm4'mm \\uf02d\\uf02b\\uf02d\\uf03d\\n \"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 117}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       113                                                                                                                                           \\nIn this course, I will not be discussing the mathematical derivation of these relationships. You are welcome to study the \\nmathematics behind these formulae if you are interested. (The derivation is available in your own text book.)But I \\nwould like to give you two tips for remembering these formulae:   \\n\\uf0b7 In each of these relations, the sum of the coefficients of various terms on the right hand side equals zero and  \\n\\uf0b7 Each term on the right is of the same dimension as the term on the left. \\nLet us now apply these concepts to an example: \\n \\nEXAMPLE \\n \\nCompute the first four moments for the following distribution of marks after applying Sheppard’s corrections: \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we wish to compute the first four moments about the mean by the direct method, first of all, we will have to compute \\nmean itself. The mean of this particular data-set comes out to be 10.06. \\nBut, 10.06 is not a very convenient number to work with! \\nThis is so because when we construct the columns of        etc., \\n  \\nwe will have a lot many decimals. An alternative way of computing the moments is to take a convenient number as the \\narbitrary origin and to compute the moments about this num ber. Later, we utilize the relationships between the \\nmoments about the mean and the moments about the arbitrary origin in order to find the moments about the mean. \\nIn this example, we may select 10 as the arbitrary origin, which is the X -value corresponding to the highest frequency \\n51, and construct the column of D which is the same as X -10. Next, we compute the columns of fD, fD2, fD3, and so \\non. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMoments about the mean are: \\n \\nm1 = 0 \\nm2 = m´2 – (m ´1)2 = 2.64 – (0.06)2 = 2.64 \\n \\nm3 = m ´3 – 3m ´2m´1 + 2 (m ´1)3 \\n  = 0.56 – 3(2.64) (0.06) + 2(0.06)3  \\n  = 0.08 \\n \\nm4 = m ´4 – 4m ´3m ´1 + 6m ´2 (m ´1)2  – 3(m ´1)4 \\n  = 28.38 – 4.(0.56) (0.06) + 6(2.64) (0.06)2 – 3(0.06)4 \\nMarks out of 20 5 6 7 8 9 10 11 12 13 14 15 \\nNo. of Students 1 2 5 10 20 51 22 11 5 3 1 \\n \\n\\uf028 \\uf029\\n2\\nXX,XX \\uf02d\\uf02d\\nEarnings \\nin \\nRs.(xi) \\nNo. of \\nMen \\nfi \\nDi \\n(xi – 10) fiDi fiDi\\n2 fiDi\\n3 fiDi\\n4 \\n5 1 – 5 – 5 25 – 125 625 \\n6 2 – 4 – 8 32 – 128 512 \\n7 5 – 3 – 15 45 – 135 405 \\n8 10 – 2 – 20 40 – 80 160 \\n9 20 – 1 – 20 20 – 20 20 \\n10 51 0 0 0 0 0 \\n11 22 1 22 22 22 22 \\n12 11 2 22 44 88 176 \\n13 5 3 15 45 135 405 \\n14 3 4 12 48 192 768 \\n15 1 5 5 25 125 625 \\nSum 131 .. 8 346 74 3718 \\nSum \\uf0b8 n 1 .. 0.06 \\n=m\\uf0a21 \\n2.64 \\n=m\\uf0a22 \\n0.56 \\n=m\\uf0a23 \\n28.38 \\n=m\\uf0a24 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 118}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       114                                                                                                                                           \\n  = 28.30 \\n \\nApplying Sheppard’s corrections, we have \\n \\nm2 (corrected)  = m2 (uncorrected) –   = 2.64 – 0.08 = 2.56, \\n \\nm3 (corrected) = m3 (uncorrected) = 0.08, \\n \\nm4 (corrected) = m4 (uncorrected)  \\n  –        . m2 (uncorrected) +  \\n \\n = 28.30 – 1.32 + 0.03 = 27.01 \\nI have discussed with you in quite a lot of detail the concept of moments. \\nThe question arises, “Why is it that we are going through all these lengthy calculations? What is the significance of \\ncomputing moments? “You will obtain the answer to this question when I discuss with you the concept of moment \\nratios. There are cert ain ratios in which both the numerators and the denominators are moments. The most common of \\nthese moment-ratios are denoted by b1 and b2, and defined by the relations:  \\n \\nMOMENT RATIOS: \\n \\n \\n \\n \\n(in the case of sample data) \\nThey are independent of origin and units of measurement, i.e. they are pure numbers.  \\nb1 is used to measure the skewness of our distribution, and b2 is used to measure the kurtosis of the distribution. \\n \\nINTERPRETATION OF b1 \\n \\n For symmetrical distributions, b1 is equal to zero. Hence, for any  data-set, b1 comes out to be zero, we \\ncan conclude that our distribution is symmetric. It should be noted that the measure which will indicate the direction of \\nskewness is the third moment round the mean. \\n If our distribution is positively skewed, m3 wil l be positive, and if our distribution is negatively \\nskewed, m3 will be negative.b1 will turn out to be positive in both situations because it is given by  \\n \\n \\n \\n \\n \\n(Since m3 is being squared, b1 will be positive regardless of the sign of m3.)  \\n \\nINTERPRETATION OF b2 \\n \\n For the normal distribution, b2 = 3. \\nFor a leptokurtic distribution, b2 > 3, and for a platykurtic distribution, b2 < 3 \\nYou have noted that the third and fourth moments about the mean provide information about the skewness and the \\nkurtosis of our data-set. This is so because m3 occurs in the numerator of b1 and m4 occurs in the numerator of b2. \\nWhat about the dispersion and the centre of our data-set? Do you not remember that the second moment about the mean \\nis exactly the same thing as the varia nce, the positive square root of which is the standard deviation --- the most \\nimportant measure of dispersion? W hat about the centre of the distribution? You will be interested to note that the first \\nmoment about zero is NONE OTHER than the arithmetic mean! \\nThis is so because  \\n \\n     is equal to  \\n \\n--- none other than the arithmetic mean! In this way, the first four moments play a KEY role in describing frequency \\ndistributions. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n4\\n23\\n2\\n2\\n3\\n1\\nm\\nmband\\nm\\nmb \\uf03d\\uf03d\\n\\uf028 \\uf029\\n\\uf028 \\uf0293\\n2\\n2\\n3\\n1\\nm\\nmb \\uf03d\\n\\uf028 \\uf029\\uf0e5 \\uf02d 1\\ni 0xn\\n1\\n\\uf0e5 ixn\\n1'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 119}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       115                                                                                                                                           \\nLECTURE NO. 15 \\n \\nOn numerous occasions, our interest lies not in just one  single variable but in two, three, four or more variables. For \\nexample, if we talk about the yield of a crop, we realize that the yield of any crop depends on a variety of factors --- the \\nfertility of the soil, the type of fertilizer used, the amount of rainfall, and so on. \\n• Simple Linear Regression  \\n• Standard Error of Estimate \\n• Correlation \\nLet me begin the discussion of the bivariate situation by picking up an example. \\n \\nEXAMPLE: \\n \\nAn important concern for any pharmaceutical company producing drugs is to deter mine how a particular drug will \\naffect one’s perception or general awareness. Suppose one such company wants to establish a relationship between the \\nPERCENTAGE of a drug in the blood-stream and the LENGTH OF TIME it takes to respond to a stimulus.  \\nSuppose the company administers this drug on 5 subjects and obtains the following information: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn this example, the reaction time to the stimulus will DEPEND on the amount of drug in the blood -stream. As you \\nmust know, the dependent variable is deno ted by Y, and the independent variable is denoted by X.In this example, the \\nreaction time will be denoted by Y, and the percentage of drug in the blood stream by X. Going back to the example \\nthat we were just considering, it is obvious that we are interest ed in determining the nature of the relationship between \\nthe amount of drug in the blood stream and the time it takes to react to a stimulus. \\nIn order to ascertain the nature of the relationship between these two variables, the first step is to draw a SCATTER \\nDIAGRAM --- which is a simple graph of the X-values against the Y-values depicted on the graph paper in the form of \\npoints. \\nIn this example, the scatter diagram is as follows: \\n \\n \\n \\nAs you can see, there is an upward trend in t he scatter diagram i.e. it is clear that as X increases, Y also increases. Of \\ncourse, the points are not all falling on a straight line, but if we look carefully, we find an overall linear pattern as \\nshown below:  \\n \\n \\n \\n \\nScatter Diagram: \\n0\\n1\\n2\\n3\\n4\\n5\\n0 1 2 3 4 5 6\\nX\\nY\\nPercentage  \\nof drug \\nReaction Time  \\n(milli-seconds) Subject \\nX Y \\nA 1 1 \\nB 2 1 \\nC 3 2 \\nD 4 2 \\nE 5 4 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 120}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       116                                                                                                                                           \\n \\nIt will be very RARE in the field of behavioral or social sciences to find two sets of data which are related perfectly by \\na straight line: it is more likely that only a general linear pattern or tendency will be apparent.  \\nWHY is it that we will not get an exact linear relationship? \\nLet me explain this to you with the help of an example: \\nSuppose one is studying the relationship between the research and development expenditure and the profit margin on \\nproducts of a number of firms. While it may be generally true to state that the two will increase together, it is \\nINEVITABLE that some firms’ profit margin will be higher than others with the SAME  \\nR and D expenditure, and vice versa. The reasons for this may be that the conditions under which the various firms are \\noperating may be very different. The goods being produced, the firm’s share of the market, the efficiency of the firm \\netc. will ALL play a part in determining the individual results. \\n                     A linear relationship between two variables is a SURPRIS INGLY common occurrence, and even where a \\nrefined non-linear curve might prove slightly superior, the SIMPLER form will often be quite adequate in the context of \\nthe problem under consideration. Having plotted the n pairs of values in the form of a scatter  diagram, IF an overall \\nlinear pattern emerges, then the object of regression is to superimpose on this pattern the general relationship between y \\nand x in the linear form which will REMOVE the effect of outside factors. I am sure that you are aware of the  equation \\nof a straight line.  \\nDo you not remember the equation Y = mX + c,  where Y represents the slope of the line, and c represent the Y -\\nintercept? \\nThis equation can also be stated as Y = c + mX, and if we rename c and m as ‘a’ and ‘b’, the equation bec omes Y = a + \\nbX. \\n \\nEQUATION OF A STRAIGHT LINE \\n \\n Y = a + bX  \\nWhere  \\n• Y represents the dependent variable \\n• X represents the independent variable \\n• a represents the Y-intercept \\n(i.e. the value of Y when X is equal to zero) \\n• b represents the slope of the line  \\n(i.e. the value of the tan \\uf071, where \\uf071 represents the angle between the line and the horizontal axis)  \\nScatter Diagram: \\n0\\n1\\n2\\n3\\n4\\n5\\n0 1 2 3 4 5 6\\nX\\nY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 121}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       117                                                                                                                                           \\n \\n \\nA very important point to note is that MANY lines can be drawn through the same scatter diagram.  \\n  \\n \\nEven with the greatest care and skill, a line drawn between the points with a ruler will be highly SUBJECTIVE, and \\ndifferent individuals will arrive at different lines. \\nThe real objective is to find the line of BEST fit.  For this, we use a method known as  THE METHOD OF LEAST \\nSQUARES. The line of best fit obtained by the method of least squares is called the REGRESSION LINE of Y on X.  \\nAnd, this whole process is known as simple linear regression. A very important point to note here is that, from the \\nMATHEMATICAL standpoint, simple linear regression requires that X is a NON -RANDOM variable, whereas Y is a \\nRANDOM variable. For example, consider the case of agricultural experiments. If we conduct an experiment to \\ndetermine the optimal amount of a particular fer tilizer to obtain the maximum yield of a certain crop, then the amount \\nof fertilizer is a non -random variable whereas the yield is a random variable. This is so because the amount of fertilizer \\nis in our OWN control. But, the yield is a random variable bec ause it is NOT in our control. In connection with \\ndetermining the line of BEST fit, the first point is that. \\nIf we use the ‘FREE -hand’ method of curve-fitting in order to represent the relationship between X and Y as portrayed \\nby the scatter diagram, one t ends, consciously or subconsciously, to draw the straight line such that there is EQUAL \\nnumbers of points located on either side of the line. \\nWhat is more, the eye will automatically try to judge and EQUATE the total distances between the points above and \\nbelow the line. \\nThis is a recognition of the fact that the line of best fit must be an ‘AVERAGE’ line in the true sense.  \\nYou will recall that the sum of the deviations round the ARITHMETIC MEAN of a data -set is always equal to zero i.e. \\nthe positive and negative deviations CANCEL each other. \\nSimilarly, POSITIVE and NEGATIVE deviations round a line of BEST fit must CANCEL out.  \\nInterpretation of ‘a’ and ‘b’: \\nNL\\nMN\\uf03d\\uf03d \\uf071 tan  b\\nL \\na \\nN \\nX \\nM \\nY \\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n0 5 10 15 20 25 30\\nDays in stock\\nEvaporation loss (pints)\\nTHE LINEAR PATTERN: '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 122}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       118                                                                                                                                           \\nThis is the first of the conditions or requirements for an optimal line. \\nBut, the point to understand is that there are an INFINIT ELY large number of straight lines which will satisfy this \\ncondition.  \\nAny line that passes through the point   will satisfy this condition, and as shown in the following figure, \\nnumerous lines can pass through the point   \\n \\n \\n     . \\nFor each of the three lines that you see, the SUM of the VERTICAL deviations between the data -points and the line is \\nZERO. These deviations are depicted by the following diagram: \\n \\n \\n \\n \\n \\n \\n \\nHow will we calculate these vertical deviations? \\nThe values of Y obtained from the line are denoted by    . \\nAnd the deviations of the actual Y -values from the corresponding Y -values obtained from the line are obtained by \\nsubtracting     from Y. \\nIn all the cases --- as long as our line passes through the point                 ---  , we find that the sum of the deviations of \\nthe actual Y-values from the corresponding Y-values obtained from the line is zero. \\nHence, it appears that we need some SECOND criterion for establishing a unique position for the BEST-fitting line.  \\nOur interest is NOT simply in achieving a non-zero sum: it is the MAGNITUDE of the sum which is our main concern. \\nIn the two figures that follow, the DIFFERENCES in the sums of squared deviations for two different lines passing \\nthrough the SAME scatter diagram are clearly portrayed.  In position 1, the shaded areas are relatively large, but AS the \\nline is rotated around the point        in a clockwise direction to position 2, the areas become smaller.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n70 \\n60 \\n50 \\n40 \\n30 \\n20 \\n10 \\n20 30 10 \\n\\uf028 \\uf029Y,X\\n \\nY \\nX \\nY=15.80+1.54X \\nY=8.99+2.14X Y= –5.42+3.37X \\nDays in stock \\nEvaporation loss (pints) \\nX\\n \\nY \\nThree equations where \\n\\uf028 \\uf029 :0YˆY \\uf03d\\uf02d\\uf0e5\\nY \\nX 0 \\n\\uf0ad \\na \\n\\uf0af \\n \\n\\uf028 \\uf029YX ,\\n\\uf028 \\uf029YX ,\\n\\uf028 \\uf029y,x\\n\\uf028 \\uf029YX ,'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 123}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       119                                                                                                                                           \\n \\n \\n \\n \\n \\n \\nThere would seem to be some UNIQUE position at which the sum of the square deviations is at a MINIMUM. This is \\nthe position of least squares.  \\nIf we can ascertain the location of THIS particular straight line in terms of the constants a and b of the linear equation Y \\n= a + bX,   then we have found the line of BEST fit.  \\nThe rationale is that the SMALLER the sum of the squared deviations round the mean, the LESS dispersed are the data \\npoints around the fitted line.  \\n \\nTHE PRINCIPAL OF LEAST SQUARES \\n \\n According to the principal of least squares, the best -fitting line to a set of points is the one for which the sum \\nof the squares of the vertical distances between the points and the line is minimum. \\nThe line Y = a + bX is the one that best fits the given set of points according to the principal of least squares. \\nAnd, this best fitting line is obtained by solving simultaneously two equations which are known as the normal \\nequations. \\n \\n \\nNORMAL EQUATIONS \\n \\n \\n \\n \\n \\nIn connection with these two equations, two points should be noted: \\n1) I will not be discussing the mathematical derivation of these equations. \\n2)  The word “normal” here has nothing to do with the well-known normal distribution. \\nFor any bivariate data-set, obviously we will have available to us two columns, a column of X and a column of Y.  \\nHence, obviously, we will be in a position to compute sums like \\uf0e5X, \\uf0e5Y, \\uf0e5XY, and so on. \\ny \\n\\uf060y \\n\\uf060x \\nx \\nPosition 1 \\nA \\nB \\nC \\nD \\ny \\n\\uf060y \\n\\uf060x \\nx \\nPosition 2 \\nA \\nB \\nC \\nD \\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf02b\\uf03d\\n\\uf02b\\uf03d\\n\\uf0e5\\uf0e5\\uf0e5\\n\\uf0e5\\uf0e5\\n2XbXaXY\\nXbnaY'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 124}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       120                                                                                                                                           \\nHence, the only unknown quantities in the two normal equations are a and b, as shown below: \\n \\nNORMAL EQUATIONS \\n \\n \\n \\n \\n \\nHence, when we solve the two normal equations simultaneously, we will obtain the values of a and b, and these are \\nEXACTLY the two quantities that we need in order to obtain the BEST-fitting line.  \\nLet me explain this whole concept to you with the help of the same example that I picked up in the beginning of today’s \\nlecture: \\n \\nEXAMPLE \\n \\nAn important concern for any pharmaceutical company producing drugs is to determine how a particular drug will \\naffect one’s perception or general awareness. Suppo se one such company wants to establish a relationship between the \\nPERCENTAGE of a drug in the blood -stream and the LENGTH OF TIME it takes to respond to a stimulus. Suppose \\nthe company administers this drug on 5 subjects and obtains the following information: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nIn order to find a and b, we need to solve the two normal equations, and for this purpose, we will carry out \\ncomputations as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nScatter Diagram: \\n0\\n1\\n2\\n3\\n4\\n5\\n0 1 2 3 4 5 6\\nX\\nY\\n\\uf0ef\\uf0fe\\n\\uf0ef\\uf0fd\\n\\uf0fc\\n\\uf02b\\uf03d\\n\\uf02b\\uf03d\\n\\uf0e5\\uf0e5\\uf0e5\\n\\uf0e5\\uf0e5\\n2XbXaXY\\nXbnaY\\nPercentage  \\nof drug \\nReaction Time  \\n(milli-seconds) Subject \\nX Y \\nA 1 1 \\nB 2 1 \\nC 3 2 \\nD 4 2 \\nE 5 4 \\n \\nX Y X2 XY \\n1 1 1 1 \\n2 1 4 2 \\n3 2 9 6 \\n4 2 16 8 \\n5 4 25 20 \\n15 10 55 37 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 125}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       121                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence our straight line is given by \\n Y = -0.1 + 0.7 X \\n \\nA hat is placed on top of the Y so as to differentiate the Y values obtained from the line from the ones that pertain to the \\nactual data-points. \\nThe question is, “What is the advantage of fitting this line?”  \\nThe answer to this ques tion is that this line can be used to ESTIMATE the value of the dependent variable \\ncorresponding to  some particular value of the independent variable.  In this example, suppose that we are interested in \\nfinding out what will be the reaction time of a perso n who has 4.33% of the drug in his blood stream?  The answer will \\nbe obtained by putting X=4.33 in the equation that we just obtained. \\nOur regression line is  \\n = -0.1 + 0.7 X \\nPutting X = 4.33, we obtain \\n  = -0.1 + 0.7 (4.33)  \\n = -0.1 + 3.031 = 2.931 \\n \\nHence we conclude that it can be expected that a person having 4.33% of the drug in his blood stream will take 2.9 \\nmilli-seconds to react to the stimulus. A point to be noted here is that this procedure of estimating the value of the \\ndependent variable should no t be used for extrapolation. Extrapolation means the making of estimates or predictions \\noutside the range of the experimental data, and in some situations, this can be very unwise.  \\nLet me explain this point with the help of the following diagram: \\n \\n \\n \\nWhile a set of observations may show a good linear relationship between the variables, there is NEVER any guarantee \\nthat the SAME linear form is present over THOSE ranges of the variable NOT under consideration. I would now like to \\nconvey to you another point: All the discussion that I have done until now assumes that Y is the dependent variable and \\nX is the independent variable, and therefore, we are regressing Y on X. But, in some situations, we may be interested in \\njust the OPPOSITE --- i.e. we may wish to regress X on Y. In this situation, all we have to do is to interchange the roles \\nof X and Y. I would like to encourage you to work on this on your own, and to establish the normal equations that will \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n A = region of interpolation \\n B = regions of extrapolation \\n C = true relationship in regions of \\nextrapolation \\ny \\n0 \\nB \\nB \\nC \\nC \\nA \\nThe extrapolation trap \\n10 = 5a + 15 b   –– 1 \\n37 = 15a + 55b  –– 2 \\n–7 = –10b \\nb = \\n10\\n7\\n\\uf02d\\n\\uf02d  = 0.7 \\n10 = 5a + 15b \\n\\uf05c 10 – 15b = 5a \\n\\uf05c 10 – 15(0.7) = 5a \\n\\uf05c 10 – 10.5 = 5a \\n\\uf05c – 0.5 = 5a \\uf05c a = \\n5\\n5.0\\uf02d  =-0.1 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 126}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       122                                                                                                                                           \\nbe required in this situation.  You may be thinking, “Why should we go through this hassle? Can’t we use the equation \\nthat we have just fitted i.e. Y = a + bX to estimate X from Y?”  \\nIt is important to note that this is not the case. If we are confronted with a situation where we requir e to predict Y from \\nX AND X from Y, then two DISTINCT equations need to be found. The regressions of Y on X and X on Y for the \\nsame bivariate data are NOT identical. \\nThe next concept that I am going to discuss with you is the STANDARD ERROR OF ESTIMATE. \\n \\nSTANDARD ERROR OF ESTIMATE \\n \\nThe observed values of (X, Y) do not all fall on the regression line but they scatter away from it. The degree of scatter \\nof the observed values about the regression line is measured by what is called the standard deviation of regression or the \\nstandard error of estimate of Y on X. \\nFor sample data, the standard error of estimate is obtained from the formula \\n \\n \\n \\n \\nwhere Y denotes an observed values, denotes the corresponding values obtained from the least -squares line and n \\ndenotes the sample size. \\nThe formula that I just conveyed to you is a bit cumbersome to apply because, in order to apply it, we first need to \\ncompute  corresponding to all our X-values. \\nAlternative formula for Sy.x \\nThe standard error of estimate can be more conveniently computed from the alternative formula \\n \\n \\n \\n \\n \\nINTERPRETATION OF Sy.x \\n \\nThe range within which sy.x lies is given by 0 < sy.x < sy (where sy denotes the standard deviation of the y values). \\nsy.x will be zero when all the observed points fall on the regr ession line (denoting perfect relationship between the two \\nvariables). sy.x will be equal to sy when there is no relationship between the two variables. Hence the closer sy.x is to \\nzero (the further away it is from sy), the closer the points are to the lin e, and the more RELIABLE is our line for \\npurposes of prediction. \\nLet us apply this concept to the example of the amount of drug in the blood stream and the time taken to react to a \\nstimulus: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n\\uf028 \\uf029\\n2n\\nYˆYs\\n2\\nx.y \\uf02d\\n\\uf02d\\uf03d \\uf0e5\\n2n\\nXYbYaYs\\n2\\nx.y \\uf02d\\n\\uf02d\\uf02d\\uf03d \\uf0e5\\uf0e5\\uf0e5\\nX Y X2 Y2 XY \\n1 1 1 1 1 \\n \\n2 1 4 1 2 \\n3 2 9 4 6 \\n4 2 16 4 8 \\na = -0.1 \\nb = 0.7 \\n5 4 25 16 20 \\n15 10 55 26 37  \\n \\nSy.x \\n2n\\nXYbYaY2\\n\\uf02d\\n\\uf02d\\uf02d\\uf03d \\uf0e5\\uf0e5\\uf0e5  \\n \\n\\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n25\\n377.0101.026\\n\\uf02d\\n\\uf02d\\uf02d\\uf02d\\uf03d  \\n \\n3\\n9.25126 \\uf02d\\uf02b\\uf03d  \\n \\n61.03667.03\\n1.1 \\uf03d\\uf03d\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 127}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       123                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nINTERPRETATION \\n \\nSy.x is NOT very small compared with sy, hence our least-squares line. \\n       \\n \\nis probably NOT very reliable for purposes of prediction.  As it explained a short while ago, the smaller our Standard \\nError of Estimate, the closer the data -points will be to the l ine --- i.e. the more REPRESENTATIVE our line will be of \\nthe data-points --- and, hence, the more RELIABLE our line will be for estimation purposes.  \\nThe next concept that I am going to discuss with you is the concept of CORRELATION. \\nIt is a concept that is very closely linked with the concept of linear regression. \\n \\nCORRELATION  \\n \\nis a measure of the strength or the degree of relationship between two RANDOM variables. \\n \\n A numerical measure of the strength of the linear relationship between two random variabl es X and Y is \\nknown as Pearson’s Product-Moment Coefficient of Correlation. \\n \\nPEARSON’S COEFFICIENT OF CORRELATION \\n \\n \\nwhere, covariance of X and Y is defined as \\n \\n \\n \\n \\n \\n \\n \\n \\nThis formula is a bit cumbersome to apply. Therefore, we may use the following short cut formula: \\n \\nSHORT CUT FORMULA FOR THE PEARSON’S COEFFICIENT OF CORRELATION \\n \\n \\n \\n \\n \\n \\nIt should be noted that \\nr is a pure number that lies between –1 and 1 i.e.   \\n -1 < r < 1 \\nActually, the mathematical expressions that you have just seen is a combination of th ree different mathematical \\nexpressions: \\n \\nCase 1: \\n \\nPositive correlation: 0 < r < 1 \\n \\nCase 2: \\n \\nNo correlation:  r = 0  \\n \\nCase 3: \\n \\nNegative correlation: -1 < r < 0  \\nXY 7.01.0ˆ \\uf02b\\uf02d\\uf03d\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029YVarXVar\\nYXCovr ,\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\nn\\nYYXXYXCov \\uf0e5 \\uf02d\\uf02d\\uf03d,\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf05b \\uf05d \\uf028 \\uf029\\uf05b \\uf05dnYYnXX\\nnYXXYr\\n2222\\n\\uf0e5\\uf0e5\\uf0e5\\uf0e5\\n\\uf0e5\\uf0e5\\uf0e5\\n\\uf02d\\uf02d\\n\\uf02d\\uf03d\\nAlso, sy \\n22\\nn\\nY\\nn\\nY \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf02d\\uf03d \\uf0e5\\uf0e5  \\n \\n42.55\\n10\\n5\\n26 2\\n\\uf02d\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d  \\n \\n10.12.1 \\uf03d\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 128}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       124                                                                                                                                           \\n \\nCase 1:  \\nIn case of a positive linear relationship, r lies between 0 and 1. \\n \\n \\n \\nIn this case, the closer the points are to the UPWARD -going line, the STRONGER is the positive linear relationship, \\nand the closer r is to 1. \\n \\nIn this case, the closer the points are to the DOWNWARD -going line, the s tronger is the linear relationship, and the \\ncloser r is to –1. \\nY \\nX 0 \\nPerfect Positive Linear Correlation (r = 1):  \\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n0 1 2 3 4 5 6 7 8 9 10\\ny\\nx'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 129}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       125                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n0 1 2 3 4 5 6 7 8 9 10\\ny\\nx\\nCase 3:  \\nIn a situation where neither an upward linear trend nor a downward \\nlinear trend can be visualized, r ~ 0 \\nHere, the bivariate data seem to be completely random. \\nY \\nX 0 \\nIn such a situation, X and Y are said to be uncorrelated. \\nThe extreme of dissociation (zero correlation (r = 0)): '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 130}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       126                                                                                                                                           \\nEXAMPLE \\n \\nSuppose that the principal of a college wants to know if there exists any correlation between grades in Mathematics and \\ngrades in Statistics. Suppose that he selects a random sample of 9 students out of all those who take this combination of \\nsubjects. The following information is obtained: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to compute the correlation coefficient, we carry out the following computations, \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n0 5 10 15 20 25 30\\nMarks in Mathematics\\nMarks in Statistics\\nY\\nX\\nSCATTER DIAGRAM \\nMarks in  \\nMathematics  \\n(Total Marks: 25) \\nMarks in  \\nStatistics  \\n(Total Marks: 25) Student \\nX Y \\nA 5 11 \\nB 12 16 \\nC 14 15 \\nD 16 20 \\nE 18 17 \\nF 21 19 \\nG 22 25 \\nH 23 24 \\nI 25 21 \\n \\nX Y X2 Y2 XY \\n5 11 25 121 55 \\n12 16 144 256 192 \\n14 15 196 225 210 \\n16 20 256 400 320 \\n18 17 324 289 306 \\n21 19 441 361 399 \\n22 25 484 625 550 \\n23 24 529 576 552 \\n25 21 625 441 525 \\n156 168 3024 3294 3109 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 131}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       127                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nINTERPRETATION \\n \\nThere exists a strong positive linear correlation between marks in Mathematics and marks in Statistics for these 9 \\nstudents who have been taken into consideration. \\nThe conclusion that we have just drawn i.e. strong positive linear correlation --- this conclusion is supported by the \\nscatter diagram. \\n \\n \\n \\n \\n \\n \\n \\n \\nAs you can see in the scatter diagram, the data-points appear to follow a linear pattern quite strongly.  \\nIn today’s lecture, I have discussed with you the concept of regression and correlation. Although I have conveyed to \\nyou a number of interesting concepts, believe me, this is only the BEGINNING of a very vast and important area of \\nStatistics. You can s tudy this concept further, and, if possible, to study a little bit about MULTIPLE regression and \\ncorrelation as well --- the situation when we try to study the relationship between three or more variables.  \\nThis brings us to the end of the FIRST part of this course i.e. Descriptive Statistics. \\nThis brings us to the end of the FIRST part of this course i.e. Descriptive Statistics. \\n \\n0\\n5\\n10\\n15\\n20\\n25\\n30\\n0 5 10 15 20 25 30\\nMarks in Mathematics\\nMarks in Statistics\\nY\\nX\\nSCATTER DIAGRAM \\nr \\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf05b \\uf05d \\uf028 \\uf029\\uf05b \\uf05dnYYnXX\\nnYXXY\\n2222 \\uf0e5\\uf0e5\\uf0e5\\uf0e5\\n\\uf0e5\\uf0e5\\uf0e5\\n\\uf02d\\uf02d\\n\\uf02d\\uf03d  \\n \\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf05b \\uf05d \\uf028 \\uf029\\uf05b \\uf05d9168329491563024\\n91681563109\\n22 \\uf02d\\uf02d\\n\\uf02d\\uf03d  \\n \\n\\uf05b \\uf05d\\uf05b \\uf05d3136329427043024\\n29123109\\n\\uf02d\\uf02d\\n\\uf02d\\uf03d  \\n \\n88.086.224\\n197\\n158320\\n197 \\uf03d\\uf03d\\n\\uf0b4\\n\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 132}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       128                                                                                                                                           \\nLECTURE NO. 16 \\n \\n\\uf0b7 Set Theory \\n\\uf0b7 Counting Rules: \\n\\uf0b7 The Rule of Multiplication \\n \\n“SET” \\n         A set is any well -defined collection or list of distinct objects, e.g. a group of students, the books in a library, the \\nintegers between 1 and 100, all human beings on the earth, etc. The term well -defined here means that any object must \\nbe classified as either belonging or not belonging to the set under consideration, and the term distinct implies that each \\nobject must appear only once. The objects that are in a set, are called members or elements of that set. Sets are usually \\ndenoted by capital letters such as A, B, C, Y, etc., while their elements are represented by small letters such as, a, b, c, \\ny, etc.  \\nElements are enclosed by parentheses to represent a set.  \\nFor example: \\n \\nEXAMPLES OF SETS: \\n \\n A = {a, b, c, d} or  \\n B = {1, 2, 3, 7} \\nThe Number of a set A, written as n(A), is defined as the number of elements in A. \\nIf x is an element of a set A, we write x \\uf0ce A which is read as “x belongs to A” or x is in A. If x does not belong to A, \\ni.e. x is not an element of A, we write x \\uf0cf A. \\nA set that has no elements is called an empty or a null set and is denoted by the symbol\\uf066. (It must be noted that {0} is \\nnot an empty set as it contains an element 0.)  \\nIf a set contains only one element, it is called a unit set or a singleton set.  \\nIt is also important to note the difference between an element “x” and a unit set {x}.  \\nA set may be specified in two ways: \\n1. We may give a list of all the elements of a set (the “Roster” method),  \\ne.g. \\n A = {1, 3, 5, 7, 9, 11} ;  \\n B = {a book, a city, a clock,  a teacher};  \\n2. We may state a rule that enables us to determine whether or not a given object is a member of the set(the “Rule” \\nmethod or the “Set Builder” method),  \\ne.g. \\n A = {x | x is an odd number and x < 12} meaning that A is a set of all elements x such that x is an odd number and x is \\nless than 12. (The vertical line is read as “such that”.). An important point to note is that: The repetition or the order in \\nwhich the elements of a set occur, does not change the nature of the set. The size of a set is given by the number of \\nelements present in it. This number may be finite or infinite. Thus a set is finite when it contains a finite number of \\nelements; otherwise it is an infinite set.  \\nThe Empty set is regarded as a Finite set.  \\n \\nEXAMPLES OF FINITE SETS \\n \\ni) A = {1, 2, 3……., 99, 100}; \\n \\nii) B = {x | x is a month of  \\n the year}; \\n \\niii) C = {x | x is a printing \\n mistake in a book}; \\n \\niv) D = {x | x is a living citizen \\n of Pakistan};  \\n Examples of infinite sets: \\ni) A = {x | x is an even \\n integer}; \\nii) B = {x | x is a real number \\n between 0 and 1 inclusive}, \\n  i.e. B = (x | x 0 < x < 1} \\niii) C = {x | x is a point on a line}; \\niv) D = {x | x is a sentence in a  \\n English language}; etc \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 133}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       129                                                                                                                                           \\nSUBSETS \\n \\n           A set that consists of some elements of another set, is called a subset of that set.  \\nFor example, if B is a subset of A, then every member of set B is also a member of set A. \\n If B is a subset of A, we write: \\nB \\uf0cc A or equivalently: \\nA \\uf0c9 B \\n‘B is a subset of A’ is also read as  ‘B is contained in A’,  \\nor ‘A contains B’. \\n \\nEXAMPLE \\n \\nIf  A = {1, 2, 3, 4, 5, 10}  \\nand  B {1, 3, 5}  \\nthen B \\uf0cc A,  \\ni.e. B is contained in A.  \\nIt should be noted that any set is always regarded a subset of itself. \\nand an empty set \\uf066 is considered to be a subset of every set.  \\nTwo sets A and B are Equal or Identical, if and only if they contain exactly the same elements. \\nIn other words, A = B if and only if A \\uf0cc B and B \\uf0cc A.  \\n \\nPROPER SUBSET \\n \\nIf a set B contains some but not all of the elements of another set A, while A contains each element of B, i.e. if \\n B \\uf0cc A and B \\uf0b9 A \\nthen the set B is defined to be a proper subset of A.  \\nUniversal Set: \\n         The original set of which all the sets we talk about, are subsets, is called the universal set (or the space) and is \\ngenerally denoted by S or \\uf057. \\nThe universal set thus contains all possible elements under consideration.  \\nA set S with n elements will produce 2n subsets, including S and \\uf066. \\nEXAMPLE; \\nConsider the set A = {1, 2, 3}. \\nAll possible subsets of this set are: \\n\\uf066, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3} and {1, 2, 3} \\nHence, there are 23 = 8 subsets of the set A. \\n \\nVENN DIAGRAM \\n \\n                         A diagram that is understood to represent sets by circular regions, parts of circular regions or their \\ncomplements with respect to a rectangle representing the space S is call ed a Venn diagram, named after the English \\nlogician John Venn (1834-1923). \\nThe Venn diagrams are used to represent sets and subsets in a pictorial way and to verify the relationship among sets \\nand subsets.  \\nA Simple Venn diagram: \\n \\nDisjoint Sets \\n \\n \\nA \\nB S '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 134}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       130                                                                                                                                           \\n \\n \\n \\n \\nOPERATIONS ON SETS \\n \\n                         Let the sets A and B be the subsets of some universal set S. Then these sets may be combined and \\noperated on in various ways to form new sets which are also subsets of S.  \\nThe basic operations are union, intersection, difference and complementation. \\n \\nUNION OF SETS \\n \\n The union or sum of two sets A and B, denoted by A \\uf0c8 B, and read as “A union B”, means the set of all \\nelements that belong to at least one of the sets A and B, that is  \\nA \\uf0c8 B = { x | x \\uf0ce A or x \\uf0ce B} \\nBy means of a Venn Diagram, A \\uf0c8 B is shown by the shaded area as below: \\n \\n \\n \\nEXAMPLE \\n \\n Let A = {1, 2, 3, 4} and B = {3, 4, 5, 6} \\nThen A \\uf0c8 B = {1, 2, 3, 4, 5, 6} \\n \\n \\n \\nA B \\nS \\n \\nA B \\nS \\nA \\uf0c8 B is shaded '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 135}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       131                                                                                                                                           \\nINTERSECTION OF SETS \\n \\n                     The intersection of two sets A and B, denoted by A \\uf0c7 B, and read as “A intersection B”, means that the set \\nof all elements that belong to both A and B; that is \\nA \\uf0c7 B = {x | x \\uf0ce and x \\uf0ce B}. \\nDiagrammatically, A \\uf0c7 B is shown by the shaded area as below: \\n \\n  \\n \\n \\nEXAMPLE \\n \\n Let A = {1, 2, 3, 4} and B = {3, 4, 5, 6} \\nThen A \\uf0c7 B = {3, 4} \\nThe operations of union and intersection that have been defined for two sets may conveniently be extended to any finite \\nnumber of sets. \\n \\nDISJOINT SETS \\n \\n Two sets A and B are defined to be disjoint or mutually exclusive or non -overlapping when they have no \\nelements in common, i.e. when their intersection is an empty set  \\ni.e. A \\uf0c7 B = \\uf066.  \\nOn the other hand, two sets A and B are said to be conjoint when the have at least one element in common. \\n \\nSET DIFFERENCE \\n \\n The difference of two sets A and B, denoted by A – B or by A – (A \\uf0c7 B), is the set of all elements of A which \\ndo not  belong to B.  \\nSymbolically, \\nA – B = {x | x \\uf0ce A and x \\uf0cf B} \\n \\nIt is to be pointed out that in general A – B \\uf0b9 B – A.  \\nThe shaded area of the following Venn diagram shows the difference A – B: \\n \\nA \\nB \\nS \\nA \\uf0c7 B is shaded '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 136}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       132                                                                                                                                           \\n \\nIt is to be noted that A – B and B are disjoint sets. If A and B are disjoint, then the difference A – B coincides with the \\nset A. \\n \\nCOMPLEMENTATION \\n \\n The particular difference S – A, that is, the set of all those elements of S which do not belong to A, \\nis  called the complement of A and is denoted by\\uf060A  or by Ac. \\nIn symbols: \\n \\uf060A = {x | x \\uf0ce S and s \\uf0cf A} \\nThe complement of S is the empty set \\uf066.  \\nThe complement of A is shown by the shaded portion in the following Venn diagram. \\n \\n \\nIt should be noted that A – B and A \\uf0c7 \\uf060B, where \\uf060B is the complement of set B, are the same set. Next, we consider the \\nAlgebra of Sets. The algebra of sets provides us with laws which can be used to solve many problems in probability \\ncalculations.  \\nLet A, B and C be any subsets of the universal set S. Then, we have: \\n1. Commutative laws: \\n A \\uf0c8 B = B \\uf0c8 A  \\n A \\uf0c7 B = B \\uf0c7 A \\n2. Associative laws: \\n (A \\uf0c8 B) \\uf0c8 C = A \\uf0c8 (B \\uf0c8 C) \\n   \\n (A \\uf0c7 B) \\uf0c7 C = A \\uf0c7 (B \\uf0c7 C) \\nA \\nB \\nS \\nDifference A – B is shaded \\nS \\n\\uf060A  is shaded \\nA B '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 137}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       133                                                                                                                                           \\n \\n3. Distributive laws \\n \\nA \\uf0c7 (B \\uf0c8 C) = (A \\uf0c7 B) \\uf0c8 (A \\uf0c7 C) \\nA \\uf0c8 (B \\uf0c7 C) = (A \\uf0c8 B) \\uf0c7 (A \\uf0c8 C) \\n \\n4. Idempotent laws \\n \\nA \\uf0c8 A = A   \\nA \\uf0c7 A = A \\n5. Identity laws \\n \\nA \\uf0c8 S = S,  \\nA \\uf0c7 S = A,  \\nA \\uf0c8 \\uf066 = A, and  \\nA \\uf0c7 \\uf066 = \\uf066. \\n6. Complementation laws \\n \\nA \\uf0c8 \\uf060A = S,  \\nA \\uf060\\uf0c7A = \\uf066,  \\n \\n(\\uf060A ) = A,  \\n \\n\\uf060S  = \\uf066, and \\n\\uf066\\uf060 = S \\n7. De Morgan’s laws: \\n \\n \\n  \\n    \\n \\nPARTITION OF SETS \\n \\n                                 A partition of a set S is a sub -division of the set int o non -empty subsets that are disjoint and \\nexhaustive, i.e. their union is the set S itself.  \\nThis implies that: \\n\\uf0b7 i)Ai \\uf0c7 Aj = \\uf066, where i \\uf0b9 j; \\n \\n\\uf0b7 ii)A1 \\uf0c7 A2 \\uf0c8 … \\uf0c8 An = S. \\nThe subsets in a partition are called cells.  \\n \\nEXAMPLE \\n \\nLet us consider a set S = {a, b, c, d, e}.  \\nThen {a, b}, and {c, d, e} is a partition of S as each element of S belongs to exactly one cell. \\n \\nCLASS OF SETS \\n \\nA set of sets is called a class. For example, in a set of lines, each line is a set of points.  \\n \\nPOWER SET \\n \\nThe class of ALL subsets of a set A is called the Power Set of A and is denoted by P(A).  \\nFor example, if A = {H, T}, then P(A) = {\\uf066, {H}, {T}, {H, T}}. \\n \\nCARTESIAN PRODUCT OF SETS \\n \\nThe Cartesian product of sets A and B, denoted by A \\uf0b4 B, (read as “A cross B”), is a set that contai ns all ordered pairs \\n(x, y), where x belongs to A and y belongs to B.  \\nSymbolically, we write \\nA \\uf0b4 B = {(x, y) | x \\uf0ce A and y \\uf0ce B} \\nThis set is also called the Cartesian set of A and B set of A and B, named after the French mathematician Rene’ \\nDescartes (1596-1605).  \\nThe product of a set A by itself is denoted by A2.  \\nThis concept of product may be extended to any finite number of sets. \\n \\n \\n\\uf028 \\uf029 ,BABA \\uf0c7\\uf03d\\uf0c8   \\nand  \\n\\uf028 \\uf029 BABA \\uf0c8\\uf03d\\uf0c7  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 138}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       134                                                                                                                                           \\n \\nEXAMPLE \\nLet A = {H, T} and B = {1, 2, 3, 4, 5, 6}. Then the Cartesian product set is the collection of the following twelve (2 \\uf0b4 \\n6) ordered pairs: \\nA\\uf0b4B = {(H, 1); (H, 2);(H, 3); (H, 4);(H, 6); (H, 6);(T, 1); (T, 2); (T, 3); (T, 4); (T, 5); (T, 6) } \\nClearly, these twelve elements together make up the universal set S when a COIN and a DIE are tossed together.  \\nA die is a cube of wood or ivory whose six faces are marked with dots are shown below: \\n \\n \\n \\nThe plural of the word ‘die’ is ‘dice’. \\nThe product A \\uf0b4 B may conveniently be found by means of the so -called   \\ntree diagram shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTREE DIAGRAM \\n \\n                          The “tree” is constructed from the left to the right. A “tree diagram” is a useful device for enumerating \\nall the possible outcomes of two or more sequential events.  \\nThe possible outcomes are represented by the individual paths or branches of the tree.  \\nIt is relevant to note that, in general  \\n \\n  A \\uf0b4 B \\uf0b9 B \\uf0b4 A. \\nHaving reviewed the basics of set theory, let us now review the COUNTING RULES that facilitate the computation of \\nprobabilities in a number of problems. \\n \\nRULE OF MULTIPLICATION \\n \\n If a compound experiment consists of two experiments which that the first experiment has exactly m distinct \\noutcomes and, if corresponding to each outcome of the first experiment there can be n distinct outcomes of th e second \\nexperiment, then the compound experiment has exactly mn outcomes. \\n \\nEXAMPLE \\n \\nB         A \\uf0b4 B \\n1 (H, 1) \\n1 (H, 2) \\n1 (H, 3) \\n1 (H,4 ) \\n1 (H, 5) \\n1 (H, 6) \\n1 (T, 1) \\n2 (T, 2) \\n3 (T, 3) \\n4 (T, 4) \\n5 (T, 5) \\n6 (T, 6) \\n \\nH \\n \\nT \\nA \\nTree Diagram '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 139}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       135                                                                                                                                           \\nThe compound experiment of tossing a coin and throwing a die together consists of two experiments. The coin-tossing \\nexperiment consists of two distinct outcomes (H, T), and the die-throwing experiment consists of six distinct outcomes \\n(1, 2, 3, 4, 5, 6). \\nThe total number of possible distinct outcomes of the compound experiment is therefore 2 \\uf0b4 6 = 12 as each of the two \\noutcomes of the coin-tossing experiment can occur with each of the six outcomes of die-throwing experiment. As stated \\nearlier, if A = {H, T} and B = {1, 2, 3, 4, 5, 6}, then the Cartesian product set is the collection of the following twelve \\n(2 \\uf0b4 6) ordered pairs: \\nA\\uf0b4B = { (H, 1); (H, 2);(H, 3); (H, 4); \\n        (H, 6); (H, 6);(T, 1); (T, 2);  \\n  (T, 3); (T, 4); (T, 5); (T, 6) }  \\n \\n \\nThe rule of multiplication can be readily extended to compound experiments consisting of any number of experiments \\nperformed in a given sequence. \\n \\nThis rule can also be called the Multiple Choice Rule, as illustrated by  the following example: \\n \\nEXAMPLE \\n \\n Suppose that a restaurant offers three types of soups, four types of sandwiches, and two types of desserts. \\nThen, a customer can order any one out of 3 \\uf0b4 4 \\uf0b4 2 = 24 different meals.  \\n \\nEXAMPLE \\n \\n Suppose that we have a combination lock on which there are eight rings.  \\nIn how many ways can the lock be adjusted? \\nSolution: \\nThe logical way to look at this problem is to see that there are eight rings on the lock, each of which can have any of the \\n10 figures 0 to 9: \\n \\n \\n \\n \\nring A  can have any of the digits 0 to 9 and ring B  can have any of the digits 0 to 9 and ring C  can have \\nany of the digits 0 to 9 and \\n  . \\n  . \\n  . \\nring H  can have any of the digits 0 to 9 \\nHence the total No. of ways in which these 8 rings can be filled is 8 \\n10 \\uf0b4 10 \\uf0b4 10 \\uf0b4 10 \\uf0b4 10 \\uf0b4 10 \\uf0b4 10 \\uf0b4 10  \\n= 10 \\ni.e.  100,000,000 –– one hundred million. \\nB         A \\uf0b4 B \\n1 (H, 1) \\n1 (H, 2) \\n1 (H, 3) \\n1 (H,4 ) \\n1 (H, 5) \\n1 (H, 6) \\n1 (T, 1) \\n2 (T, 2) \\n3 (T, 3) \\n4 (T, 4) \\n5 (T, 5) \\n6 (T, 6) \\n \\nH \\n \\nT \\nA \\nTree Diagram \\nHGFEDCBA'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 140}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       136                                                                                                                                           \\nLECTURE NO. 17 \\n\\uf0b7 Permutations \\n\\uf0b7 Combinations \\n\\uf0b7 Random Experiment \\n\\uf0b7 Sample Space  \\n\\uf0b7 Events \\n\\uf0d8 Mutually Exclusive Events \\n\\uf0d8 Exhaustive Events \\n\\uf0d8 Equally Likely Events \\nCOUNTING RULES \\n  \\n As discussed in the last lecture, there are certain rules that facilitate the calculations of probabilities in certain \\nsituations. They are known as counting rules and include concepts of;  \\n\\uf0b7 Multiple Choice \\n\\uf0b7 Permutations \\n\\uf0b7 Combinations \\nWe have already discussed the rule of multiplication in the last lecture. \\nLet us now consider the rule of permutations. \\n \\n \\nRULE OF PERMUTATION \\n \\nA permutation is any ordered subset from a set of n distinct objects.  \\nFor example, if we have the set {a, b}, then one permutation is ab, and the other permutation is ba.  The number of \\npermutations of r objects, selected in a definite order from n distinct objects is denoted by the symbol \\nn\\nrP  and is given \\nby  \\nn\\nrP\\n = n (n – 1) (n – 2) … (n – r + 1) \\n \\n \\n \\n \\n \\nFACTORIALS \\n \\n 7! = 7 \\uf0b4 6 \\uf0b4 5 \\uf0b4 4 \\uf0b4 3 \\uf0b4 2 \\uf0b4 1 \\n 6! = 6 \\uf0b4 5 \\uf0b4 4 \\uf0b4 3 \\uf0b4 2 \\uf0b4 1 \\n . \\n . \\n . \\n 1! = 1  \\nAlso, we define 0! = 1. \\n \\n \\nEXAMPLE \\n \\nA club consists of four members. How many ways are there of selec ting three officers: president, secretary and \\ntreasurer? It is evident that the order, in which 3 officers are to be chosen, is of significance. Thus there are 4 choices \\nfor the first office, 3 choices for the second office, and 2 choices for the third off ice. Hence the total number of ways in \\nwhich the three offices can be filled is 4 \\uf0b4 3 \\uf0b4 2 = 24. \\nThe same result is obtained by applying the rule of permutations: \\n \\n \\n \\n \\n \\n \\n \\n \\nLet the four members be, A, B, C and D. Then a tree diagram which provides an organiz ed way of listing the possible \\narrangements, for this example, is given below: \\n\\uf028 \\uf029 .!rn\\n!n\\n\\uf02d\\uf03d\\n\\uf028 \\uf029\\n24\\n234\\n!34\\n!4P3\\n4\\n\\uf03d\\n\\uf0b4\\uf0b4\\uf03d\\n\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 141}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       137                                                                                                                                           \\n \\n \\n \\nPERMUTATIONS \\n \\nIn the formula of\\nn\\nrP , if we put r = n, we obtain: \\nn\\nnP\\n = n (n – 1) (n – 2) … 3 \\uf0b4 2 \\uf0b4 1 \\n = n!  \\nI.e. the total number of permutations of n distinct objects, taking all n at a time, is equal to n! \\n \\nEXAMPLE \\n \\n Suppose that there are three persons A, B & D, and that they wish to have a photograph taken. \\n The total number of ways in which they can be seated on three chairs (placed side by side) is         \\n3P3 = 3! = 6  \\n  \\nThese are: \\nABD,  \\nADB, \\nBAD, \\nBDA, \\nDAB,  \\nDBA \\nThe above discussion pertained to the case when all the objects under consideration are distinct objects. If some of the \\nobjects are not distinct, the formula of permutations modifies as given below: \\nThe number of permutations of n objects, selected all at a time, when n objects consist of n1 of one kind, n2 of a second \\nkind, …, nk of a kth kind, \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTreasurer \\nC \\nSecretary Sample Space \\nABC \\nD ABD \\nB ACB \\nD ACD \\nB ADB \\nC ADC \\nC BAC \\nD BAD \\nA BCA \\nD BCD \\nA BDA \\nC BDC \\nB CAB \\nD CAD \\nA CBA \\nD CBD \\nA CDA \\nB CDB \\nB DAB \\nC DAC \\nA DBA \\nC DBC \\nA DCA \\nB DCB \\nPresident \\nB \\nC \\nD \\nA \\nC \\nD \\nA \\nB \\nD \\nA \\nB \\nC \\nA \\nB \\nC \\nD \\n\\uf028 \\uf029\\uf0e5 \\uf03d\\n\\uf03d\\nnnwhere\\n.!n.....!n!n\\n!nPis\\ni\\nk21'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 142}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       138                                                                                                                                           \\nEXAMPLE \\n \\nHow many different (meaningless) words can be formed from the word ‘committee’? \\nIn this example: \\nn = 9 (because the total number of letters in this word is 9) \\nn1 = 1 (because there is one c) \\nn2 = 1 (because there is one o) \\nn3 = 2 (because there are two m’s) \\nn4 = 1 (because there is one i) \\nn5 = 2 (because there are two t’s) \\nand \\nn6 = 2 (because there are two e’s) \\nHence, the total number of (meaningless) words  \\n(permutations) is: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, let us consider the rule of combinations. \\n \\nRULE OF COMBINATION \\n \\nA combination is any subset of r objects, selected without regard to their order, from a set of n distinct objects. The total \\nnumber of such combinations is denoted by the symbol \\n \\n \\nand is given by \\n \\n \\n \\n \\nwhere r < n. \\nIt should be noted that \\n \\n \\n \\n \\nIn other words, every combination of r objects (out of n objects) generates r! Permutations \\n \\nEXAMPLE \\n \\nSuppose we have a group of three persons, A, B, & C. If we wish to select a group of two persons out of these three, the \\nthree possible groups are {A, B}, {A, C} and {B, C}.In other words, the total number of combinations of size two out \\nof this set of size three is 3. \\n Now, suppose that our interest lies in forming a committee of two persons, one of whom is to be the president \\nand the other the secretary of a club. \\nThe six possible committees are: \\n   (A, B), (B, A),  \\n  (A, C), (C, A),  \\n  (B, C) & (C, B) \\nIn other words, the total number of permutations of two persons out of three is 6. \\nAnd the point to note is that each of three combinations mentioned earlier generates 2 = 2! Permutations, I.e. the \\ncombination {A, B} generates the permutations (A, B) and (B, A) and the combination {A, C} generates the \\npermutations (A, C) and (C, A); and the combination {B, C} generates the permutations (B, C) and (C, B). \\n \\nThe quantity   \\n \\n \\n \\n \\n45360\\n121211211\\n123456789\\n!2!2!1!2!1!1\\n!9\\n.!.....!!\\n!\\n21\\n\\uf03d\\n\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\n\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf03d\\n\\uf03d\\n\\uf03d\\nknnn\\nnP\\n,\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nr\\nnorCr\\nn\\n\\uf028 \\uf029!rn!r\\n!n\\nr\\nn\\n\\uf02d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d r\\nn!rPr\\nn\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nr\\nn'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 143}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       139                                                                                                                                           \\nor\\nn\\nrC   is also called a binomial co-efficient because of its appearance in the binomial expansion of \\n \\n \\n \\n \\n \\nThe binomial co-efficient has two important properties. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAlso, it should be noted that  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nEXAMPLE \\n \\nA three-person committee is to be formed out of a group of ten persons. In how many ways can this be done? \\nSince the order in which the three persons of the committee are chosen, is unimportant, it is therefore an example of a \\nproblem involving combinations. Thus the desired number of combinations is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn other words, there are one hundred and twenty different ways of forming a three -person committee out of a group of \\nonly ten persons! \\n \\nEXAMPLE \\n \\nIn how many ways can a person draw a hand of 5 cards from a well-shuffled ordinary deck of 52 cards? \\nThe total number of ways of doing so is given by \\n \\n \\n \\n \\n \\nHaving reviewed the counting rules that facilitate calculations of probabilities in a number of problems, let us now \\nbegin the discussion of concepts that lead to the formal de finitions of probability. The first concept in this regard is the \\nconcept of Random Experiment.  The term experiment means a planned activity or process whose results yield a set of \\ndata.  A single performance of an experiment is called a trial. The result obtained from an experiment or a trial is called \\nan outcome. \\n \\n \\nRANDOM EXPERIMENT \\n \\n An experiment which produces different results even though it is repeated a large number of times under \\nessentially similar conditions is called a Random Experiment.  \\n\\uf028 \\uf029 .\\n0\\nrrn\\nn\\nr\\nn\\nbar\\nnba \\uf02d\\n\\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\uf02b \\uf0e5\\ni) \\n,rn\\nn\\nr\\nn\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  and \\nii) \\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02b\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf02d r\\n1n\\nr\\nn\\nrn\\nn  \\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf03d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n11\\n10\\nn\\nnnn\\nand\\nn\\nnn\\n\\uf028 \\uf029\\n120\\n1234567123\\n12345678910\\n!7!3\\n!10\\n!310!3\\n!10\\n3\\n10\\nr\\nn\\n\\uf03d\\n\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\n\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf03d\\n\\uf03d\\uf02d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n960,598,212345\\n4849505152\\n5\\n52 \\uf03d\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\n\\uf0b4\\uf0b4\\uf0b4\\uf0b4\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nr\\nn'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 144}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       140                                                                                                                                           \\nThe tossing of a fair coin, the throwing of a balanced die, drawing of a card from a well -shuffled deck of 52 playing \\ncards, selecting a sample, etc. are examples of random experiments.  \\n \\nPROPERTIES OF A RANDOM EXPERIMENT \\n \\nA random experiment has three properties: \\n \\n\\uf0b7 The experiment can be repeated, practically or theoretically, any number of times. \\n\\uf0b7 The experiment always has two or more possible outcomes. An experiment that has only one possible \\noutcome is not a random experiment. \\n\\uf0b7 The outcome of each repetition is unpredictable, i.e. it has some degree of uncertainty. \\nConsidering a more realistic example, interviewing a person to find out whether or not he or she is a smoker is an \\nexample of a random experiment. This is so because this example fulfils all the three p roperties that have just been \\ndiscussed: \\n\\uf0b7 This process of interviewing can be repeated a large number of times. \\n\\uf0b7 To each interview, there are at least two possible replies: ‘I am a smoker’ and ‘I am not a smoker’. \\n\\uf0b7 For any interview, the answer is not known i n advance i.e. there is an element of uncertainty regarding the \\nperson’s reply. \\nA concept that is closely related with the concept of a random experiment is the concept of the Sample Space. \\n \\nSAMPLE SPACE \\n \\nA set consisting of all possible outcomes that can result from a random experiment (real or conceptual), can be defined \\nas the sample space for the experiment and is denoted by the letter S. Each possible outcome is a member of the sample \\nspace, and is called a sample point in that space. Let us consider a few examples: \\n \\nEXAMPLE-1 \\n \\nThe experiment of tossing a coin results in either of the two possible outcomes: a head (H) or a tail (T). (We assume \\nthat it is not possible for the coin to land on its edge or to roll away). The sample space for this experiment may be \\nexpressed in set notation as S = {H, T}. ‘H’ and ‘T’ are the two sample points. \\n \\nEXAMPLE-2 \\n \\nThe sample space for tossing two coins once (or tossing a coin twice) will contain four possible outcomes denoted by  \\n S = {HH, HT, TH, TT}.  \\nIn this example, clearly, S is the Cartesian product A \\uf0b4 A, where A = {H, T}. \\n \\nEXAMPLE-3 \\n \\nThe sample space S for the random experiment of throwing two six-sided dice can be described by the Cartesian  \\nproduct A \\uf0b4 A, where  A = {1, 2, 3, 4, 5,6}. In other words, S = A \\uf0b4 A   = {(x, y) | x \\uf0ce A and y \\uf0ce A}, Where x denotes \\nthe number of dots on the upper face of the first die, and y denotes the number of dots on the upper face of the second \\ndie. Hence, S contains 36 outcomes or sample points, as shown below:  \\n \\nS =    {(1, 1), (1, 2), (1, 3), (1, 5), (1, 6), \\n   (2, 1), (2, 2), (2, 3), (2, 5), (2, 6), \\n   (3, 1), (3, 2), (3, 3), (3, 5), (3, 6), \\n   (4, 1), (4, 2), (4, 3), (4, 5), (4, 6), \\n   (5, 1), (5, 2), (5, 3), (5, 5), (5, 6), \\n   (6, 1), (6, 2), (6, 3), (6, 5), (6, 6)} \\n \\nThe next concept is that of events. \\n \\nEVENTS \\n \\nAny subset of a sample space S of a random experiment, is called an event. In other words, an event is an individual \\noutcome or any number of outcomes (sample points) of a random experiment.  \\n \\nSIMPLE & COMPOUND EVENTS \\n \\nAn event that contains exactly one sample point is defined as a simple event. A compound event contains more than one \\nsample point, and is produced by the union of simple events. \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 145}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       141                                                                                                                                           \\nEXAMPLE  \\n \\nThe occurrence of a 6 when a die is thrown, is a simple event, while the occurrence of a sum of 10 with a pair of dice, is \\na compound event, as it can be decomposed into three simple events (4, 6), (5, 5) and (6, 4). \\n \\nOCCURRENCE OF AN EVENT \\n \\nAn event A is said to occur if and only if the outcome of the experiment corresponds to some element of A.  \\n \\nEXAMPLE \\n \\nSuppose we toss a die, and we are interested in the occurrence of an even number. \\nIf ANY of the three numbers ‘2’, ‘4’ or ‘6’ occurs, we say that the event of our interest has occurred. \\nIn this example, the event A is represented by the set {2, 4, 6}, and if the outcome ‘2’ occurs, then, since this outcome \\nis corresponding to the first element of the set A, therefore, we say that A has occurred. \\n \\nCOMPLEMENTARY EVENT \\n \\nThe event “not-A” is denoted by \\uf060A or Ac and called the negation (or complementary event) of A. \\n \\nEXAMPLE \\n \\nIf we toss a coin once, then the complement of “heads” is “tails”. If we toss a coin four times, then the complement of \\n“at least one head” is “no heads”. A sample space consisting of n sample points can produce 2n different subsets (or \\nsimple and compound events). \\n \\nEXAMPLE \\n \\nConsider a sample space S containing 3 sample points, i.e. S = {a, b, c}. \\nThen the 23 = 8 possible subsets are \\n \\uf066, {a}, {b}, {c}, {a, b},  \\n  {a, c}, {b, c}, {a, b, c} \\nEach of these subsets is an event. The subset {a, b, c} is the sample space itself and is also an event. It always occurs \\nand is known as the certain or sure event. The empty set \\uf066 is also an event, sometimes known as impossible event, \\nbecause it can never occur. \\n \\nMUTUALLY EXCLUSIVE EVENTS \\n \\nTwo events A and B of a single experiment are said to be mutually exclusive or disjoint if and only if they cannot both \\noccur at the same time i.e. they have no points in common.  \\n \\nEXAMPLE-1 \\n \\nWhen we toss a coin, we get either a head or a tail, but not both at the same time. The two events head and tail are \\ntherefore mutually exclusive.  \\n \\nEXAMPLE-2 \\n \\nWhen a die is rolled, the events ‘even number’ and ‘odd number’ are mutually exclusive as we can get either an even \\nnumber or an odd number in one throw, not both at the same time. Similarly, a student either qualifies or fails, a single \\nbirth must be either a boy or a girl, it cannot be both, etc., etc. Three or more events originating from the same \\nexperiment are mutually exclusive if pai r wise they are mutually exclusive. If the two events can occur at the same \\ntime, they are not mutually exclusive, e.g., if we draw a card from an ordinary deck of 52 playing cars, it can be both a \\nking and a diamond.  \\nTherefore, kings and diamonds are not mutually exclusive. Similarly, inflation and recession are not mutually exclusive \\nevents. Speaking of playing cards, it is to be remembered that an ordinary deck of playing cards contains 52 cards \\narranged in 4 suits of 13 each. The four suits are called diamonds, hearts, clubs and spades; the first two are red and the \\nlast two are black. The face values called denominations, of the 13 cards in each suit are ace, 2, 3, …, 10, jack, queen \\nand king.  The face cards are king, queen and jack. These cards are used for various games such as whist, bridge, poker, \\netc. We have discussed the concepts of mutually exclusive events.  Another important concept is that of exhaustive \\nevents. \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 146}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       142                                                                                                                                           \\nEXHAUSTIVE EVENTS \\n \\nEvents are said to be collectively exhaustive, when the u nion of mutually exclusive events is equal to the entire sample \\nspace S. \\n \\nEXAMPLES \\n \\n\\uf0b7 In the coin-tossing experiment, ‘head’ and ‘tail’ are collectively exhaustive events.  \\n\\uf0b7 In the die-tossing experiment, ‘even number’ and ‘odd number’ are collectively exhaustive events. \\nIn conformity with what was discussed in the last lecture:  \\n  \\nPARTITION OF THE SAMPLE SPACE \\n \\nA group of mutually exclusive and exhaustive events belonging to a sample space is called a partition of the sample \\nspace. With reference to any sampl e space S, events A and \\uf060A form a partition as they are mutually exclusive and their \\nunion is the entire sample space. The Venn Diagram below clearly indicates this point. \\n \\n \\nNext, we consider the concept of equally likely events: \\n \\nEQUALLY LIKELY EVENTS \\n \\nTwo events A and B are said to be equally likely, when one event is as likely to occur as the other.  In other words, each \\nevent should occur in equal number in repeated trials.  \\n \\nEXAMPLE \\n \\nWhen a fair coin is tossed, the head is as likely to appear as the tail, and the proportion of times each side is expected to \\nappear is 1/2.  \\n \\nEXAMPLE \\n \\nIf a card is drawn out of a deck of well -shuffled cards, each card is equally likely to be drawn, and the probability that \\nany card will be drawn is 1/52. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nS \\n\\uf060A is shaded \\nA '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 147}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       143                                                                                                                                           \\nLECTURE NO. 18 \\n \\nDEFINITIONS OF PROBABILITY \\n \\n\\uf0b7 Subjective Approach to Probability \\n\\uf0b7 Objective Approach: \\n\\uf0b7 Classical Definition of Probability \\n \\nRELATIVE FREQUENCY DEFINITION OF PROBABILITY \\n \\nBefore we begin the various definitions of probability, let us revise the concepts of: \\n\\uf0b7 Mutually Exclusive Events \\n\\uf0b7 Exhaustive Events \\n\\uf0b7 Equally Likely Events \\n \\nMUTUALLY EXCLUSIVE EVENTS \\n \\nTwo events A and B of a single experiment are said to be mutually exclusive or disjoint if and only if they cannot both \\noccur at the same time i.e. they have no points in common.  \\n \\nEXAMPLE-1 \\n \\nWhen we toss a coin, we get either a head or a tail, but not both at the same time.  The two events head and tail are \\ntherefore mutually exclusive.  \\n \\nEXAMPLE-2 \\n \\nWhen a die is rolled, the events ‘ even number’ and ‘odd number’ are mutually exclusive as we can get either an even \\nnumber or an odd number in one throw, not both at the same time. Similarly, a student either qualifies or fails, a person \\nis either a teenager or not a teenager, etc., etc. \\nThree or more events originating from the same experiment are mutually exclusive if pair wise they are mutually \\nexclusive. If the two events can occur at the same time, they are not mutually exclusive, e.g., if we draw a card from an \\nordinary deck of 52 playing cars, it can be both a king and a diamond.  \\nTherefore, kings and diamonds are not mutually exclusive. Speaking of playing cards, it is to be remembered that an \\nordinary deck of playing cards contains 52 cards arranged in 4 suits of 13 each. The four s uits are called diamonds, \\nhearts, clubs and spades; the first two are red and the last two are black. The face values called denominations, of the 13 \\ncards in each suit are ace, 2, 3, …, 10, jack, queen and king. The face values called denominations, of th e 13 cards in \\neach suit are ace, 2, 3, …, 10, jack, queen and king. We have discussed the concepts of mutually exclusive events. \\nAnother important concept is that of exhaustive events. \\n \\nEXHAUSTIVE EVENTS \\n Events are said to be collectively exhaustive, when the union of mutually exclusive events is equal to the entire sample \\nspace S. \\n \\nEXAMPLES \\n \\n\\uf0b7 In the coin-tossing experiment, ‘head’ and ‘tail’ are collectively exhaustive events.  \\n\\uf0b7 In the die-tossing experiment, ‘even number’ and ‘odd number’ are collectively exhaustive events. \\nIn conformity with what was discussed in the last lecture:  \\n \\nPARTITION OF THE SAMPLE SPACE \\n \\nA group of mutually exclusive and exhaustive events belonging to a sample space is called a partition of the sample \\nspace. With reference to any sample space S, events A and \\uf060A form a partition as they are mutually exclusive and their \\nunion is the entire sample space. The Venn Diagram below clearly indicates this point. '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 148}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       144                                                                                                                                           \\n \\n \\n \\nEQUALLY LIKELY EVENTS \\n \\nTwo events A and B are said to be equally likely, when one event is as likely to occur as the other.  In other words, \\neach event should occur in equal number in repeated trials.  \\n \\nEXAMPLE \\n \\nWhen a fair coin is tossed, the head is as likely to appear as the tail, and the proportion of times each side is expected to \\nappear is 1/2.  \\n \\nEXAMPLE \\n \\nIf a card is drawn out of a deck of well -shuffled cards, each card is equally likely to be drawn, and the proportion of \\ntimes each card can be expected to be drawn in a very large number of draws is 1/52.Having discussed basic concepts \\nrelated to probability theory, we now begin the discussion of THE CONCEPT AND DEFINITIONS OF \\nPROBABILITY. Probability can be discussed from two points of view: the subjective approach, and the objective \\napproach.  \\n \\nSUBJECTIVE OR PERSONALISTIC PROBABILITY \\n \\nAs its name suggests, the subjective or personality probability is a measure of the strength of a person’s belief regarding \\nthe occurrence of an event A. Probability in this sense is purely subjective, and is based o n whatever evidence is \\navailable to the individual. It has a disadvantage that two or more persons faced with the same evidence may arrive at \\ndifferent probabilities.  \\nFor example, suppose that a panel of three judges is hearing a trial. It is possible tha t, based on the evidence that is \\npresented, two of them arrive at the conclusion that the accused is guilty while one of them decides that the evidence is \\nNOT strong enough to draw this conclusion. On the other hand, objective probability relates to those situations where \\neveryone will arrive at the same conclusion.  \\nIt can be classified into two broad categories, each of which is briefly described as follows: \\n \\n1. THE CLASSICAL OR ‘A PRIORI’ DEFINITION OF PROBABILITY \\n \\nf a random experiment can produce n mut ually exclusive and equally likely outcomes, and if m out to these outcomes \\nare considered favorable to the occurrence of a certain event A, then the probability of the event A, denoted by P(A), is \\ndefined as the ratio m/n. \\nSymbolically, we write \\n \\n \\n \\n \\n \\n \\n \\nThis definition was formulated by the French mathematician P.S. Laplace (1949 -1827) and can be very conveniently \\nused in experiments where the total number of possible outcomes and the number of outcomes favorable to an event can \\nbe DETERMINED. \\nS \\n\\uf060A is shaded \\nA \\nVenn Diagram \\n\\uf028 \\uf029\\noutcomespossibleofnumberTotal\\noutcomesfavourableofNumber\\nn\\nmAP\\n\\uf03d\\n\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 149}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       145                                                                                                                                           \\nLet us now consider a few examples to illustrate the classical definition of probability: \\n \\nEXAMPLE-1 \\n \\nIf a card is drawn from an ordinary deck of 52 playing cards, find the probability that i) the card is a red card, ii) the \\ncard is a 10. \\n \\nSOLUTION: \\nThe total number o f possible outcomes is 13+13+13+13 = 52, and we assume that all possible outcomes are equally \\nlikely.(It is well -known that an ordinary deck of cards contains 13 cards of diamonds, 13 cards of hearts, 13 cards of \\nclubs, and 13 cards of spades.) \\n(i) Let A represent the event that the card drawn is a red card.  \\nThen the number of outcomes favorable to the event A is 26 (since the 13 cards of diamonds and the 13 cards of hearts \\nare red). \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nEXAMPLE-2 \\n \\nA fair coin is tossed three times. What is the probability that at least one head appears? \\n \\nSOLUTION \\n \\nThe sample space for this experiment is \\nS = {HHH, HHT, HTH, THH, \\n HTT, THT, TTH, TTT} \\nand thus the total number of sample points is 8 i.e. n(S) = 8.Let A denote the event that at least one head appears. Then \\n \\nA =  {HHH, HHT, HTH, THH, HTT, THT, TTH} \\nTherefore n(A) = 7. \\n \\n \\n \\n \\n \\n \\nEXAMPLE-3 \\n \\nFour items are taken at random from a box of 12 items and inspected. The box is rejected if more than 1 item is found \\nto be faulty. If there are 3 faulty items in the box, find the probability that the box is accepted. \\n \\nSOLUTION \\n \\nThe sample space S contains           Sample points \\n \\n    \\n \\n \\n(Because there are           ways of selecting four items out of twelve) \\n \\n \\n \\n \\nHence \\n   \\n\\uf028 \\uf029\\n2\\n1\\n52\\n26\\noutcomespossibleofnumberTotal\\noutcomesfavourableofNumber\\nn\\nmAP\\n\\uf03d\\uf03d\\n\\uf03d\\n\\uf03d  \\nThus \\n\\uf028 \\uf029 13\\n1\\n52\\n4BP \\uf03d\\uf03d . \\nHence \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 .8\\n7\\nSn\\nAnAP \\uf03d\\uf03d  \\n4954\\n12 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n4\\n12'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 150}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       146                                                                                                                                           \\nThe box contains 3 faulty and 9 good items. The box is  accepted if there is (i) no faulty items, or (ii) one faulty item in \\nthe sample of 4 items selected. \\nLet A denote the event the number of faulty items chosen is 0 or 1.  \\nThen \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence the probability that the box is accepted is 76% , (in spite of the fact that the box contains 3 faulty items). \\n \\nTHE CLASSICAL DEFINITION HAS THE FOLLOWING SHORTCOMINGS \\n \\n\\uf0b7 This definition is said to involve circular reasoning as the term equally likely really means equally probable.  \\n\\uf0b7 Thus probability is defined by introd ucing concepts that presume a prior knowledge of the meaning of \\nprobability. \\n\\uf0b7 This definition becomes vague when the possible outcomes are INFINITE in number, or uncountable. \\n\\uf0b7 This definition is NOT applicable when the assumption of equally likely does not hold. And the fact of the \\nmatter is that there are NUMEROUS situations where the assumption of equally likely cannot hold. \\nAnd these are the situations where we have to look for another definition of probability! \\n \\nTHE RELATIVE FREQUENCY DEFINITION OF PROBABILITY \\n \\nThe essence of this definition is that if an experiment is repeated a large number of times under (more or less) identical \\nconditions, and if the event of our interest occurs a certain number of times, then the proportion in which this event \\noccurs is regarded as the probability of that event.  \\nFor example, we know that a large number of students sit for the matric examination every year. Also, we know that a \\ncertain proportion of these students will obtain the first division, a certain proportion wi ll obtain the second division, --- \\nand a certain proportion of the students will fail.  \\nSince the total number of students appearing for the matric exam is very large, hence: \\n \\n\\uf0b7 The proportion of students who obtain the first division --- this proportion can be regarded as the probability \\nof obtaining the first division, \\n\\uf0b7 The proportion of students who obtain the second division --- this proportion can be regarded as the \\nprobability of obtaining the second division, and so on. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029\\n.int378252126\\n3\\n9\\n1\\n3\\n4\\n9\\n0\\n3\\nsposample\\nAn\\n\\uf03d\\uf02b\\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02b\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\n\\uf028 \\uf029 76.0495\\n378\\nn\\nmAP \\uf03d\\uf03d\\uf03d\\uf05c'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 151}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       147                                                                                                                                           \\nLECTURE NO. 19 \\n \\n\\uf0b7 Relative Frequency Definition of  Probability \\n\\uf0b7 Axiomatic Definition of Probability \\n\\uf0b7 Laws of Probability \\n\\uf0a7 Rule of Complementation \\n\\uf0a7 Addition Theorem  \\n \\nTHE RELATIVE FREQUENCY DEFINITION OF PROBABILITY  (‘A POSTERIORI’ DEFINITION OF \\nPROBABILITY) \\n \\nIf a random experiment is repeated a large number of times, say n times, under identical conditions and if an event A is \\nobserved to occur m times, then the probability of the event A is defined as the LIMIT of the relative frequency m/n as \\nn tends to infinitely. \\nSymbolically, we write \\n \\n \\n \\n \\nThe definition assumes that as n increases indefinitely, the ratio m/n tends to become stable at the numerical value P(A). \\nThe relationship between relative frequency and probability can also be represented as follows: \\nRelative Frequency \\uf0ae Probability  \\nas n \\uf0ae \\uf0a5 \\nAs its name suggests, the relative frequency definition relates to the relative frequency with which are event occurs in \\nthe long run. In situations where we can say that an experiment has been repeated a very large number of ti mes, the \\nrelative frequency definition can be applied.  \\nAs such, this definition is very useful in those practical situations where we are interested in computing a probability in \\nnumerical form but where the classical definition cannot be applied.(Numerou s real -life situations are such where \\nvarious possible outcomes of an experiment are NOT equally likely). This type of probability is also called empirical \\nprobability as it is based on EMPIRICAL evidence i.e. on OBSERVATIONAL data.  \\nIt can also be called STATISTICAL PROBABILITY for it is this very probability that forms the basis of mathematical \\nstatistics. \\nLet us try to understand this concept by means of two examples: \\n\\uf0b7 from a coin-tossing experiment and \\n\\uf0b7 From data on the numbers of boys and girls born. \\n \\nEXAMPLE-1 \\n \\nCoin-Tossing: \\nNo one can tell which way a coin will fall but we expect the proportion of leads and tails after a large no. of tosses to be \\nnearly equal. An experiment to demonstrate this point was performed by Kerrich in Denmark in 1946. He tossed  a coin \\n10,000 times, and obtained altogether 5067 heads and   4933 tails.  \\nThe behavior of the proportion of heads throughout the experiment is shown as in the following figure:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n.2 \\n.6 \\n.5 \\n.8 \\n1.0 \\n3 \\n0 \\n10 30 100 300 1000 3000 10000 \\nNumber of tosses (logarithmic scale) \\nProportion of heads \\nThe proportion; of heads in a sequence of tosses of a coin (Kerrich, 1946): \\n\\uf028 \\uf029 n\\nmLimAP\\nn \\uf0a5\\uf0ae\\n\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 152}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       148                                                                                                                                           \\nAs you can see, the curve fluctuates widely at first, but begins to settle down to a more or less stable value as the \\nnumber of spins increases. It seems reasonable to suppose that the fluctuations would continue to diminish if the \\nexperiment were continued indefinitely, and the proportion of heads wo uld  cluster more and more closely about a \\nlimiting value which would be very near, if not exactly, one -half. This hypothetical limiting value is the (statistical) \\nprobability of heads. \\nLet us now take an example closely related to our daily lives --- that relating to the sex ratio:- \\nIn this context, the first point to note is that it has been known since the eighteenth century that in reliable birth \\nstatistics based on sufficiently large numbers (in at least some parts of the world), there is always a slig ht excess of \\nboys, Laplace records that, among the 215,599 births in thirty districts of France in the years 1800 to 1802, there were \\n110,312 boys and 105,287 girls. The proportions of boys and girls were thus 0.512 and 0.488 respectively (indicating a \\nslight excess of boys over girls).In a smaller number of births one would, however, expect considerable deviations from \\nthese proportions. This point can be illustrated with the help of the following example: \\n \\nEXAMPLE-2 \\n \\nThe following table shows the proportions of male births that have been worked out for the major regions of England as \\nwell as the rural districts of Dorset (for the year 1956). \\n \\n(Source: Annual Statistical Review) \\n \\nAs you can see, the figures for the rural district s of Dorset, based on about 200 births each, fluctuate between 0.38 and \\n0.59. While those for the major regions of England, which are each based on about 100,000 births, do not fluctuate \\nmuch, rather, they range between 0.512 and 0.517 only. The larger sam ple size is clearly the reason for the greater \\nconstancy of the latter. We can imagine that if the sample were increased indefinitely, the proportion of boys would \\ntend to a limiting value which is unlikely to differ much from 0.514, the proportion of male births for the whole country.  \\nThis hypothetical limiting value is the (statistical) probability of a male birth.  The overall discussion regarding the \\nvarious ways in which probability can be defined is presented in the following diagram: \\nProportions of Male Births in various Regions and Rural Districts of England in 1956 \\nRegion of \\nEngland \\nProportion \\nof Male \\nBirths \\nRural Districts of \\nDorset \\nProportion \\nof Male \\nBirths \\nNorthern .514 Beaminster .38 \\nE. & W. Riding .513 Blandford .47 \\nNorth Western .512 Bridport .53 \\nNorth Midland .517 Dorchester .50 \\nMidland .514 Shaftesbury .59 \\nEastern .516 Sherborne .44 \\nLondon and S. \\nEastern .514 Sturminster .54 \\nSouthern .514 Wareham and \\nPurbeck .53 \\nSouth Western .513 Wimborne & \\nCranborne .54 \\nWhole country .514 All Rural District’s \\nof Dorset .512 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 153}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       149                                                                                                                                           \\n \\n \\nAs far as quantifiable probability is concerned, in those situations where the various possible outcomes of our \\nexperiment are equally likely, we can compute the probability prior to actually conducting the experiment --- otherwise, \\nas is generally the case, we can compute a probability only after the experiment has been conducted (and this is why it \\nis also called ‘a posteriori’ probability). Non-quantifiable probability is the one that is called Inductive Probability.  \\nIt refers to the degree of belief which it is reasonable to place in a proposition on given evidence. \\nAn important point to be noted is that it is difficult to express inductive probabilities numerically –– to construct a \\nnumerical scale of inductive probabilities, with 0 standing for impossibility and for logical certainty. An important point \\nto be noted is that it is difficult to express inductive probabilities numerically –– to construct a numerical scale of \\ninductive probabilities, with 0 standing for impossibility and for l ogical certainty. Most statisticians have arrived at the \\nconclusion that inductive probability cannot, in general, he measured and, therefore cannot be use in the mathematical \\ntheory of statistics. \\nThis conclusion is not, perhaps, very surprising since the re seems no reason why rational degree of belief should be \\nmeasurable any more than, say, degrees of beauty. Some paintings are very beautiful, some are quite beautiful, and \\nsome are ugly, but it would be observed to try to construct a numerical scale of b eauty, on which Mona Lisa had a \\nbeauty value of 0.96.Similarly some propositions are highly probable, some are quite probable and some are \\nimprobable, but it does not seem possible to construct a numerical scale of such (inductive) probabilities .Because of the \\nfact that inductive probabilities are not quantifiable and cannot be employed in a mathematical argument, this is the \\nreason why the usual methods of statistical inference such as tests of significance and confidence interval are based \\nentirely on th e concept of statistical probability. Although we have discussed three different ways of defining \\nprobability, the most formal definition is yet to come. \\nThis is The Axiomatic Definition of Probability. \\n \\nTHE AXIOMATIC DEFINITION OF PROBABILITY \\n \\nThis definition, introduced in 1933 by the Russian mathematician Andrei N. Kolmogrov, is based on a set of AXIOMS.  \\nLet S be a sample space with the sample points E1, E2, … Ei, …En. To each sample point, we assign a real number, \\ndenoted by the symbol P(Ei), and called the probability of Ei, that must  satisfy the following basic axioms: \\nAxiom 1:  \\n For any event Ei,  \\n 0 < P(Ei) < 1. \\n \\nAxiom 2:  \\n P(S) =1  \\n for the sure event S. \\n \\n \\n \\nAxiom 3: \\nIf A and B are mutually exclusive events (subsets of S), then \\n \\n  P (A \\uf0c8 B) = P(A) + P(B). \\nIt is to be emphasized that According to the axiomatic theory of probability:  \\nProbability \\nNon-Quantifiable \\n(Inductive, \\nSubjective or \\nPersonalistic \\nProbability) \\nQuantifiable \\nStatistical \\nProbability  \\n(Empirical or \\n“ A Posteriori ” \\nProbability) \\n\\uf0ad \\n(A statistician’s \\nmain concern) \\n“ A Priori ” \\nProbability \\n(Verifiable \\nthrough \\nEmpirical \\nEvidence) '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 154}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       150                                                                                                                                           \\nSOME probability defined as a non-negative real number is to be ATTACHED to each sample point Ei such that the \\nsum of all such numbers must equal ONE. The ASSIGNMENT of probabilities may be based on past evidence or on \\nsome other underlying conditions. (If this assignment of probabilities is based on past evidence, we are talking about \\nEMPIRICAL probability, and if this assignment is based on underlying conditions that ensure that the various possible \\noutcomes of a random experiment are EQUALLY LIKELY, then we are talking about the CLASSICAL definition of \\nprobability. Let us consider another example: \\n \\nEXAMPLE  \\n \\nTable given below shows the numbers of births in England and W ales in 1956 classified by (a) sex and (b) whether  live \\nborn or stillborn. \\nTable-1 \\nNumber of births in England and Wales in 1956 by sex and whether live- or still born \\n(Source Annual Statistical Review) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThere are four possible events in this double classification:  \\n\\uf0a7 Male livebirth (denoted by A),  \\n\\uf0a7 Male stillbirth (denoted by B),  \\n\\uf0a7 Female livebirth (denoted by C) \\n\\uf0a7 Female stillbirth (denoted by D),  \\n \\nThe relative frequencies corresponding to the figures of  Table-1 are given in Table-2:  \\nTable-2 \\nProportion of births in England and Wales in 1956 by sex and whether live- or stillborn \\n(Source Annual Statistical Review) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe total number of births is large enough for these relative frequencies to be treated for all practical purposes as \\nPROBABILITIES.  \\nLet us denote the compound events ‘Male birth’ and ‘Stillbirth’ by  the letters M and S.  Now a male birth occurs \\nwhenever either a male live birth or a male stillbirth occurs, and so the proportion of male birth, regardless of whether \\nthey are live-or stillborn, is equal to the sum of the proportions of these two types of birth; that is to say, \\n \\np(M) = p(A or B) = p(A) + p(B)  \\n  = .5021 + .0120 = .5141 \\n \\n Similarly, a stillbirth occurs whenever either a male stillbirth or a female stillbirth occurs  and so the proportion of \\nstillbirths, regardless of sex, is equal to the sum of the proportions of these two events: \\np(S)  = p(B or D) = p(B) + p(D) \\n   = .0120 + .0109 = .0229 \\n \\nLet us now consider some basic LAWS of probability.  These laws have important   applications in solving probability \\nproblems. \\n \\n \\n \\n Liveborn Stillborn Total \\nMale 359,881 (A) 8,609 (B) 368,490 \\nFemale 340,454 (B) 7,796 (D) 348,250 \\nTotal 700,335 16,405 716,740 \\n \\n Liveborn Stillborn Total \\nMale .5021 .0120 .5141 \\nFemale .4750 .0109 .4859 \\nTotal .9771 .0229 1.0000 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 155}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       151                                                                                                                                           \\nLAW OF COMPLEMENTATION \\n \\nIf \\uf060A is the complement of an event A relative to the sample space S, then \\n  \\n \\n \\nHence the probability of the complement of an event is equal to one minus the probability of the event.  Complementary \\nprobabilities are very useful when we are wanting to solve questions of the type ‘What is the probability that, in tossing \\ntwo fair dice, at least one even number will appear?’ \\n \\nEXAMPLE \\n \\nA coin is tossed 4 times in succession. What is the probability that at least one head occurs? \\n\\uf0b7 The sample space S for this experiment consists of 24 = 16 sample points (as each toss can result in 2 \\noutcomes),and  \\n\\uf0b7 We assume that each outcome is equally likely. \\nIf we let A represent the event that at least o ne head occurs, then A will consist of MANY sample points, and the \\nprocess of computing the probability of this event will become somewhat cumbersome! So, instead of denoting this \\nparticular event by A, let us denote its complement i.e. “No head” by A.  \\nThus the event A consists of the SINGLE sample point {TTTT}.  \\nTherefore P(A ) = 1/16. \\nHence by the law of complementation, we have  \\n \\n \\n \\n \\nThe next law that we will consider is the Addition Law or the General Addition Theorem of Probability: \\n \\nADDITION LAW \\n \\nIf A and B are any two events defined in a sample space S, then \\nP(A\\uf0c8B) = P(A) + P(B) – P(A\\uf0c7B) \\nIn words, this law may be stated as follows: \\n“If two events A and B are not mutually exclusive, then the probability that at least one of them occurs, is given by th e \\nsum of the separate probabilities of events A and B minus the probability of the joint event A \\uf0c7 B.” \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029.1 APAP \\uf02d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 .16\\n15\\n16\\n11AP1AP \\uf03d\\uf02d\\uf03d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 156}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       152                                                                                                                                           \\nLECTURE NO. 20 \\n\\uf0b7 Application of Addition Theorem \\n\\uf0b7 Conditional Probability \\n\\uf0b7 Multiplication Theorem \\nFirst of all, let us consider in some detail the Addition Law or the General Addition Theorem of Probability: \\n \\nADDITION LAW \\n \\nIf A and B are any two events defined in a sample space S, then P(A\\uf0c8B) = P(A) + P(B) – P(A\\uf0c7B) \\nIn words, this law may be stated as follows: \\n “If two events A and B are not mutually exclusive, then the probability that at least one of them occurs, is \\ngiven by the sum of the separate probabilities of events A and B minus the probability of the joint event A \\uf0c7 B.” \\n \\nEXAMPLE \\n \\nIf one card is selected at random from a deck of 52 playing cards, what is the probability that the card is a club or a face \\ncard or both? \\nLet A represent the event that the card selected is a club, B, the event that the card selected is a face card, and A \\uf0c7 B, \\nthe event that the card selected is both a club and a face card. Then we need P (A \\uf0c8 B) \\nNow P(A) = 13/52, as there are 13 clubs, P(B) = 12/52, as there are 12 faces cards, \\n P(A \\uf0c7 B) = 3/52, since 3 of clubs are also face cards. \\nTherefore the desired probability is  \\nP (A \\uf0c8B) = P (A) + P (B) – P (A \\uf0c7 B) \\n     = 13/52 + 12/52 - 3/52  \\n     = 22/52. \\n \\nCOROLLARY-1 \\n \\nIf A and B are mutually exclusive events, then \\nP (A\\uf0c8B) = P (A) + P (B)   (Since A \\uf0c7 B is an impossible event, hence P(A\\uf0c7B) = 0) \\n \\nEXAMPLE \\n \\nSuppose that we toss a pair of dice, and we are interested in the event that we get a total of 5 or a total of 11.What is the \\nprobability of this event? \\n \\nSOLUTION \\n \\nIn this context, the first thing to note is that ‘getting a total of 5’ and ‘getting a total of 11’ are mutually exclusive \\nevents. Hence, we should apply the special case of the addition theorem. If we denote ‘getting a total of 5’ by A, and \\n‘getting a total of 11’ by B, then P (A) = 4/36 (since there are four outcomes favorable to the occurrence of a total of 5), \\nand P(B) = 2/36 (since there are two outcomes favorable to the occurrence of a total of 11). \\nHence the probability that we get a total of 5 or a total of 11 is given by  \\n \\nP (A\\uf0c8B) = P (A) + P (B) \\n = 4/36 + 2/36 = 6/36 = 16.67%. \\n \\nCOROLLARY-2 \\n \\nIf A1, A2… Ak are k mutually exclusive events, then the probability that one of them occurs, is the sum of the \\nprobabilities of the separate events, i.e. \\nP(A1, \\uf0c8 A2 \\uf0c8 … \\uf0c8 Ak) =   P(A1) + P(A2)+ … + P(Ak). \\nLet us now consider an interesting example to illustrate the way in which probability problems can be solved: \\n \\nEXAMPLE \\n \\nThree horses A, B and C are in a race; A is twice as likely to win as B and B is twice as likely to win as C. What is the \\nprobability that A or B wins? \\nEvidently, the events mentioned in this problem are not equally likely. \\nLet P(C) = p  \\nThen P (B) = 2p as B is twice as likely to win as C. \\nSimilarly  \\n P (A) = 2P (B) = 2(2p) = 4p \\nIn this problem, we assume that no two of the horses A, B and C cannot win the race together (i.e. the race cannot end \\nin a draw).  \\n Hence, the events A, B and C are mutually exclusive. '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 157}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       153                                                                                                                                           \\nSince A, B and C are mutually exclusive and collectively exhaustive, therefore the sum of their probabilities must be \\nequal to 1.  \\n Thus \\n p + 2p + 4p = 1 \\n or p = 1/7  \\n \\n\\uf05c   P(C) = 1/7, \\n    P(B) = 2(1/7) = 2/7,  \\nand  P(A) = 4(1/7) = 4/7.  \\nHence  \\nP(A\\uf0c8B) = P(A) + P(B)  \\n  = 4/7+ 2/7  \\n  = 6/7. \\nHaving discussed the addition theorem in some detail, we would now like to discuss the Multiplication Theorem. \\nBut, before we are in a position to take up the multiplication theorem, we need to consider the concept of conditional \\nprobability. \\n \\nCONDITIONAL PROBABILITY \\n \\nThe sample space for an experiment must often be changed when some additional information pertaining to the \\noutcome of the experiment is received. \\nThe effect of such information is to REDUCE the sample space by excluding some outcomes as being impossible which \\nBEFORE receiving the information were believed possible. The probabilities associated with such a reduced sample \\nspace are called conditional probabilities.  \\nThe following example illustrates the concept of conditional probability \\n \\nEXAMPLE \\n \\n Suppose that we toss a fair die. Then the sample space of this experiment is S = {1, 2, 3, 4, 5, 6}. Suppose we \\nwish to know the probability of the outcome that the die shows 6 (say event A).Also, suppose that, before seeing the \\noutcome, we are told that the die shows an EVEN number of dots (say event B).  \\nThen the information that the die shows an even number excludes the outcomes 1, 3 and 5, and thereby reduces the \\noriginal sample space to a sample space that consists of three outcomes 2, 4 and 6,  \\ni.e. the reduced sample space is  \\nB = {2, 4, 6}.  \\n \\n \\n \\nThen, the desired probability in the reduced sample space B is 1/3. \\n(since each outcome in the reduced sample space is EQUALLY LIKELY). This probability 1/3 is called the conditional \\nprobability of the event A because it is computed under the CONDITION that the die has shown an even number of \\ndots. In other words,  \\nP(die shows 6/die shows even numbers)  \\n= 1/3,  \\n(Where the vertical line is read as given that and the information following the vertical line describes the conditioning \\nevent).  \\nSometimes, it is not very convenient to compute a conditional probability by first determining the number of sample \\npoints that belong to the reduced sample space. \\nIn such a situation, we can utilize the following alternative method of computing a conditional probability \\n \\n \\n \\n1  3  5 \\n2  4  6 \\n\\uf0b4 \\uf0b4 \\uf0b4 \\n(The sample space is reduced.) '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 158}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       154                                                                                                                                           \\nCONDITIONAL PROBABILITY \\n \\nIf A and B are two events in a sample space S and if P(B) is not equal to zero, then the conditional probability of the \\nevent A given that event B has occurred, written as P(A/B), is defined by \\n \\n \\nWhere P (B) > 0 \\n(If P (B) = 0, the conditional probability P(A/B) remains undefined.) \\nSimilarly \\n \\n \\n \\nwhere P(A) > 0. \\nIt should be noted that P(A/B)  SATISFIES  all the basic axioms of probability, namely: \\n\\uf0b7 0 < P(A/B) < 1. \\n\\uf0b7 ii) P( S/B)       = 1 \\n\\uf0b7 P(A1\\uf0c8A2/B) = P(A1/B) + P(A2/B) (provided that the events A1 and A2 are mutually exclusive). \\nLet us now apply this concept to a real-world example \\n \\nEXAMPLE-2 \\n \\nAt a certain elementary school in a Western country, the school-record of the past ten years shows that 75% of the \\nstudents come from a two-parent home and that 20% of the students are low-achievers and belong to two-parent homes. \\nWhat is the probability that such a randomly selected student will be a low achiever GIVEN THAT he or she comes \\nfrom a two-parent home? \\n \\nSOLUTION \\n \\nLet A denote a low achiever and B a student from a two-parent home. Applying the relative frequency definition of \\nprobability, we have \\nP(B) = 0.75 and P(A \\uf0c7 B) = 0.20. \\nThus, we obtain \\n \\n \\n \\n \\n \\nMULTIPLICATION THEOREM OF PROBABILITY \\n \\n It is interesting to note that the multiplication theorem is obtained very conveniently from the formula of conditional \\nprobability: \\n \\n \\n \\n \\nAs discussed earlier, the conditional probability of A given that B has occurred has already been defined as: \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 ,BP\\nBAPB/AP \\uf0c7\\uf03d  Where P (B) > 0 \\nMultiplying both sides by P (B), we get \\n      P (A \\uf0c7 B) = P (B) . P (A/B). \\n \\nAnd if we interchange the roles of A and B, we obtain: \\nP (A \\uf0c7 B) = P (A) P (B/A),  \\nProvided P(A) > 0. \\n \\nMULTIPLICATION LAW \\n \\nIf A and B are any two events defined in a sample space S, then \\nP (A \\uf0c7 B)   \\n = P (A) P (B/A), provided P (A) > 0, \\n = P (B) P (A/B) provided P (B) > 0. \\n(The second form is easily obtained by interchanging A and B. This is called the GENERAL rule of multiplication of \\nprobabilities. It can be stated as follows: \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029BP\\nBAPBAP \\uf0c7\\uf03d/\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029AP\\nBAPA/BP \\uf0c7\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 27.075.0\\n20.0\\nBP\\nBAPB|AP \\uf03d\\uf03d\\uf0c7\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029BP\\nBAPB|AP \\uf0c7\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 159}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       155                                                                                                                                           \\nMULTIPLICATION LAW \\n \\n“The probability that two events A and B will both occur is equal to the probability that one of the events will occur \\nmultiplied by the conditional probability that the other event will occur given that the first event has already occurred.” \\nLet us apply the concept of multiplication theorem to an example  \\n \\nEXAMPLE \\n \\n A box contains 15 items, 4 of which are defective and 11 is good. Two items are selected. What is the \\nprobability that the first is good and the second defective? \\nLet A represent the event that the first item selected is good, and B, the event that the second items is defective. \\nThen we need to calculate the probability of the JOINT event A \\uf0c7 B by the rule  \\nP(A \\uf0c7 B) = P(A)P(B/A). \\nWe have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSince all the items are equally likely to be chosen, hence  \\nP (A) = 11/15. \\nGiven the event A has occurred, there remain 14 items of which 4 are defective. Therefore the probability of selecting a \\ndefective item after a good item has been selected is 4/14 i.e.  \\n \\n   P (B/A) = 4/14. \\nHence  \\n \\nP (A \\uf0c7 B)  = P (A) P (B/A) \\n   = 11/15 \\uf0b4 4/14  \\n   = 44/210  \\n   = 0.16. \\nIn this lecture, the concepts of the Addition Theorem a nd the Multiplication Theorem of probability have been \\ndiscussed in some detail.  \\nIn order to differentiate between the situation where the addition theorem is applicable and the situation where the \\nmultiplication theorem is applicable, the main point to k eep in mind is that whenever we wish to compute the \\nprobability that either A occurs or B occurs, we should think of the Addition Theorem, where as, whenever we wish to \\ncompute the probability that both A and B occur, we should think of the Multiplication Theorem. \\n \\nType of \\nItem \\nNo. of  \\nItems \\nDefective 4 \\nGood 11 \\nTotal 15 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 160}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       156                                                                                                                                           \\nLECTURE NO. 21 \\n \\n\\uf0b7 Independent and Dependent Events \\n\\uf0b7 Multiplication Theorem of Probability for Independent Events \\n\\uf0b7 Marginal Probability \\nBefore we proceed the concept of independent versus dependent events, let us review the Addition and Multiplicatio n \\nTheorems of Probability that were discussed in the last lecture. \\nTo this end, let us consider an interesting example that illustrates the application of both of these theorems in one \\nproblem: \\n \\nEXAMPLE \\n \\nA bag contains 10 white and 3 black balls. Another b ag contains 3 white and 5 black balls. Two balls are transferred \\nfrom first bag and placed in the second, and then one ball is taken from the latter.  \\nWhat is the probability that it is a white ball? \\nIn the beginning of the experiment, we have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet A represent the event that 2 balls are drawn from the first bag and transferred to the second bag. Then A can occur \\nin the following three mutually exclusive ways:  \\nA1 = 2 white balls are transferred to the second bag. \\nA2 = 1 white ball and 1 black ball are transferred to the second bag. \\nA3 = 2 black balls are transferred to the second bag. \\nThen, the total number of ways in which 2 balls can be drawn out of a total of 13 balls is \\n \\n \\n And, the total number of ways in which 2 white balls can be drawn out of 10 white balls is  \\n \\nThus, the probability that two white balls are selected from the first bag containing 13 balls (in order to transfer to the \\nsecond bag) is   \\n \\n \\n \\nSimilarly, the probability that one white ball and one black ball are selected from the  first bag containing 13 balls (in \\norder to transfer to the second bag) is   \\n \\n \\n \\n \\n \\nAnd, the probability that two black balls are selected from the first bag containing 13 balls (in order to transfer to the \\nsecond bag) is   \\n \\n \\n \\n \\nAFTER having transferred 2 balls from the first bag, the second bag contains \\ni) 5 white and 5 black balls (if 2 white balls are transferred) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nColour of \\nBall \\nNo. of  \\nBalls in Bag A \\nNo. of  \\nBalls in Bag B \\nWhite 10 3 \\nBlack 3 5 \\nTotal 13 8 \\n \\n.2\\n13\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n.2\\n10\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf028 \\uf029 ,78\\n45\\n2\\n13\\n2\\n10\\n1 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf0b8\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03dAP\\n\\uf028 \\uf029 ,78\\n30\\n2\\n13\\n1\\n3\\n1\\n10\\n2 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf0b8\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03dAP\\n\\uf028 \\uf029 .78\\n3\\n2\\n13\\n2\\n3\\n3 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf0b8\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03dAP\\nColour of \\nBall \\nNo. of  \\nBalls in Bag A \\nNo. of  \\nBalls in Bag B \\nWhite 10 – 2 = 8 3 + 2 = 5 \\nBlack 3 5 \\nTotal 13 – 2 = 11 8 + 2 = 10 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 161}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       157                                                                                                                                           \\nHence: P(W/A1) = 5/10 \\n \\n \\nii)  4 white and 6 black balls (if 1 white and 1 black ball are transferred) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence: P(W/A2) = 6/10 \\n \\niii)  3 white and 7 black balls (if 2 black balls are transferred) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence: P(W/A3) = 3/10 \\n Let W represent the event that the WHITE ball is drawn from the second bag after having transferred 2 balls \\nfrom the first bag.  \\nThen P (W) = P (A1\\uf0c7W) + P (A2\\uf0c7W) + P (A3\\uf0c7W) \\nNow P (A1 \\uf0c7 W) = P (A1) P (W/A1)  \\n = 45/78 \\uf0b4 5/10 \\n           = 15/52 \\nP (A2 \\uf0c7 W) = P (A2) P (W/A2)  \\n = 30/78 \\uf0b4 4/10  \\n = 2/13,  \\nAnd  \\nP (A3 \\uf0c7 W) = P (A3) P (W/A3)  \\n = 3/78 \\uf0b4 3/10 \\n = 3/260. \\n Hence the required probability is  \\nP (W)  \\n = P (A1\\uf0c7W) + P (A2\\uf0c7W) + P (A3\\uf0c7W)  \\n = 15/52 + 2/13 + 3/260  \\n = 59/130  \\n = 0.45 \\nINDEPENDENT EVENTS \\n \\nTwo events A and B in the same sample space S, are defined to be independent (or statistically independent) if the \\nprobability that one event occurs, is not affected by whether the other event has or has not occurred, that is  \\n P (A/B) = P (A) and P (B/A) = P (B). It then follows that two events A and B are independent if and only if \\n P (A \\uf0c7 B) = P (A) P (B) \\nand this is known as the special case of the Multiplication Theorem of Probability. \\n \\nRATIONALE \\nAccording to the multiplication theorem of probability, we have: \\n  P (A \\uf0c7 B) = P (A). P (B/A) \\nPutting P(B/A) = P(B), we obtain \\n  P (A \\uf0c7 B) = P (A) P (B) \\nThe events A and B are defined to be DEPENDENT if P(A\\uf0c7B) \\uf0b9 P(A) \\uf0b4 P(B).  \\nThis means that the occurrence of one of the events in some way affects the probability of the occurrence of the other \\nevent. Speaking of independent events, it is to be emphasized that two events that are independent, can NEVER be \\nmutually exclusive. \\n \\n \\nColour of \\nBall \\nNo. of  \\nBalls in Bag A \\nNo. of  \\nBalls in Bag B \\nWhite 10 – 1 = 9 3 + 1 = 4 \\nBlack 3 – 1 = 2 5 + 1 = 6 \\nTotal 13 – 2 = 11 8 + 2 = 10 \\n \\nColour of \\nBall \\nNo. of  \\nBalls in Bag A \\nNo. of  \\nBalls in Bag B \\nWhite 10 3 \\nBlack 3 – 2 = 1 5 + 2 = 7 \\nTotal 13 – 2 = 11 8 + 2 = 10 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 162}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       158                                                                                                                                           \\nEXAMPLE \\nTwo fair dice, one red and one green, are thrown.  Let A denote the event that the red die shows an even number and let \\nB denote the event that the green die shows a 5 or a 6. Show that the events A and B are independent. \\nThe sample space S is represented by the following 36 outcomes: \\n         S = {(1, 1), (1, 2), (1, 3), (1, 5), (1, 6); \\n  (2, 1), (2, 2), (2, 3), (2, 5), (2, 6); \\n  (3, 1), (3, 2), (3, 3), (3, 5), (3, 6); \\n  (4, 1), (4, 2), (4, 3), (4, 5), (4, 6); \\n  (5, 1), (5, 2), (5, 3), (5, 5), (5, 6); \\n  (6, 1), (6, 2), (6, 3), (6, 5), (6, 6) } \\nSince \\nA represents the event that red die shows an even number, and B represents the event that green die shows a 5 or a 6,   \\nTherefore A \\uf0c7 B represents the event that red die shows an even number and green die shows a 5 or a 6.  \\nSince A represents the event that red die shows an even number, hence P(A) = 3/6.  Similarly, since B represents the \\nevent that green die shows a 5 or a 6, hence P(B) = 2/6. \\n Now, in order to compute the probability of the joint e vent A \\uf0c7 B, the first point to note is that, in all, there \\nare 36 possible outcomes when we throw the two dice together, i.e. \\n           S = (1, 1), (1, 2), (1, 3), (1, 5), (1, 6); \\n  (2, 1), (2, 2), (2, 3), (2, 5), (2, 6); \\n  (3, 1), (3, 2), (3, 3), (3, 5), (3, 6); \\n  (4, 1), (4, 2), (4, 3), (4, 5), (4, 6); \\n  (5, 1), (5, 2), (5, 3), (5, 5), (5, 6); \\n  (6, 1), (6, 2), (6, 3), (6, 5), (6, 6) \\nThe joint event A \\uf0c7 B contains only 6 outcomes out of the 36 possible outcomes. \\n These are (2, 5), (4, 5), (6, 5), (2, 6), (4, 6), and (6, 6). \\nand  P(A \\uf0c7 B) = 6/36. \\nNow  \\nP (A) P (B)  \\n = 3/6 \\uf0b4 2/6  \\n = 6/36  \\n = P (A \\uf0c7 B). \\n \\nTherefore the events A and B are independent.  Let us now go back to the example pertaining to live births and \\nstillbirths that we considered in the last lect ure, and try to determine whether or not sex of the baby and nature of birth \\nare independent. \\n \\nEXAMPLE  \\n \\n Table-1 below shows the numbers of births in England and Wales in 1956 classified by (a) sex and (b) \\nwhether live born or stillborn. \\nTable-1 \\nNumber of births in England and Wales in 1956 by sex and whether live- or still born \\n(Source Annual Statistical Review) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThere are four possible events in this double classification:  \\n\\uf0b7 Male live birth, \\n\\uf0b7 Male stillbirth,  \\n\\uf0b7 Female live birth, and  \\n\\uf0b7 Female stillbirth.  \\n \\nThe corresponding relative frequencies are given in Table-2.  \\nTable-2 \\nProportion of births in England and Wales in 1956 by sex and whether live- or stillborn \\n(Source Annual Statistical Review) \\n Liveborn Stillborn Total \\nMale 359,881 (A) 8,609 (B) 368,490 \\nFemale 340,454 (B) 7,796 (D) 348,250 \\nTotal 700,335 16,405 716,740 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 163}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       159                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs discussed in the last lecture, the total number of births is large enough for these relative frequencies to be treated for \\nall practical purposes as PROBABILITIES. The compound events ‘Male birth’ and ‘Stillbirth’ may be represented by \\nthe letters M and S. If M represents a male birth and S a stillbirth, we find that  \\n \\n \\n \\n \\n \\nThis figure is the proportion –– and, since the sample size is large, it can be regarded as the probability –– of males who \\nare still born –– in other words, the CONDITIONAL probability of a stillbirth given that  it is a male birth. In other \\nwords, the probability of stillbirths in males. The corresponding proportion of stillbirths among females is  \\n \\n \\n \\n \\nThese figures should be contrasted with the OVERALL, or UNCONDITIONAL, proportion of stillbirths, which is  \\n \\n \\n \\n \\nWe observe that the conditional probability of stillbirths among boys is slightly HIGHER than the overall proportion. \\nWhere as the conditional proportion of stillbirths among girls is slightly LOWER than the overall proportion. It can be \\nconcluded that sex and st illbirth are statistically DEPENDENT, that is to say, the SEX of a baby yet to be born has an \\neffect, (although a small effect), on its chance of being stillborn. The example , that we just considered point out the \\nconcept of MARGINAL PROBABILITY. \\nLet us have another look at the data regarding the live births and stillbirths in England and Wales: \\nTable-2Proportion of births in England and Wales in 1956 by sex  and whether live - or stillborn (Source Annual \\nStatistical Review) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAnd, the figures in Table-2 indicate that the probability of male birth is 0.5141, whereas the probability of female birth \\nis 0.4859.Also, the probability of live birth is 0.9771, where as the probability of stillbirth is 0.0229. And since these \\nprobabilities appear in the mar gins of the Table, they are known as Marginal Probabilities . According to the above \\ntable, the probability that a new born baby is a male and is live born is 0.5021 whereas the probability that a new born \\nbaby is a male and is stillborn is 0.0120.Also, as stated earlier; the probability that a new born baby is a male is 0.5141, \\nand, CLEARLY, 0.5141 = 0.5021 + 0.0120.  Hence, it is clear that the joint probabilities occurring in any row of the \\ntable ADD UP  to yield the corresponding marginal probability. If w e reflect upon this situation carefully, we will \\nrealize that this equation is totally in accordance with the Addition Theorem of Probability for mutually exclusive \\nevents. \\n   \\n \\n \\n \\n \\n \\n Liveborn Stillborn Total \\nMale .5021 .0120 .5141 \\nFemale .4750 .0109 .4859 \\nTotal .9771 .0229 1.0000 \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029 0234.0368490\\n8609 \\uf03d\\uf03dMn\\nSandMn\\n.0224.0348258\\n7796 \\uf03d\\n.0229.0716740\\n16405 \\uf03d\\n Liveborn Stillborn Total \\nMale .5021 .0120 .5141 \\nFemale .4750 .0109 .4859 \\nTotal .9771 .0229 1.0000 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 164}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       160                                                                                                                                           \\n   P (male birth) = P(male live-born or male stillborn)  \\n = P (male live-born) + P (male stillborn)  \\n = 0.5021 + 0.0120  \\n = 0.5141 \\n \\nEXAMPLE \\n \\nP (stillbirth/male birth) \\n P (male birth and stillbirth)/P(male birth) \\n =0.0120/0.5141 \\n                          =   0.0233 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 165}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       161                                                                                                                                           \\nLECTURE NO. 22 \\n\\uf0b7 Bayes’ Theorem \\n\\uf0b7 Discrete Random Variable \\no  Discrete Probability Distribution \\no Graphical Representation of a Discrete Probability Distribution \\no Mean, Standard Deviation and Coefficient of Variation of a Discrete Probability Distribution \\no Distribution Function of a Discrete Random Variable. \\n \\nFirst of all, let us discuss the BAYES’ THEOREM. This theorem deals with conditional probabilities in an interesting \\nway: \\n \\nBAYES’ THEOREM \\n \\n If events A1, A2… Ak form a PARTITION of a sample space S (that is, the events Ai are mutua lly exclusive \\nand exhaustive (i.e. their union is S)),  \\nand if B is any other event of S such that it can occur ONLY IF ONE OF THE Ai OCCURS, then for any i, \\n \\n \\n \\n \\n \\n \\n \\nStated differently: \\nBAYES’ THEOREM: \\nIf A1, A2... and Ak are mutually exclusive events of which one must occur, then \\n \\n \\n \\n \\nIf k = 2, we obtain: \\nBayes’ Theorem for two mutually exclusive events A1 and A2: \\n \\n \\n \\n \\nWhere i = 1, 2. \\nIn other words  \\n \\n  \\nand \\n \\n \\n \\n \\n \\nEXAMPLE \\n \\n           In a developed country where cars are tested for the emission of pollutants, 25 percent of all cars emit excessive \\namounts of pollutants. When tested, 99 percent of all cars that emit excessive amounts of pollutants will fail, but 17 \\npercent of the cars that do not emit excessive amounts of pollutants will also fail. What is the probability that a car that \\nfails the test actually emits excessive amounts of pollutants? \\n \\nSOLUTION \\n \\n           Let A1 denote the event that it emits EXCESSIVE amounts of pollutants, and let A2 denote the event that a car \\ndoes NOT emit excessive amounts of pollutants. (In other words, A2 is the complement of A1.) \\nAlso, let B denote the event that a car FAILS the test.  \\nThe first thing to note is that any car will either emit or not emit excessive amounts of pollutants.  In other words, A1 \\nand A2 are mutually exclusive and exhaustive events i.e. A1 and A2 form a PARTITION of the sample space S. \\nHence, we are in a position to apply the Bayes’ theorem. \\nWe need to calculate P(A1|B), and, according to the Bayes’ theorem: \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\n,\\nA/BPAP\\nA/BPAPB/AP\\nii\\nk\\n1i\\nii\\ni\\n\\uf0e5\\n\\uf03d\\n\\uf03d\\n \\n         for i = 1, 2, …, k. \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029kk2211\\nii\\ni A|BP.AP....A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf02b\\uf02b\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf0292211\\nii\\ni A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf0292211\\n11\\n1 A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf0292211\\n22\\n2 A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf0292211\\n11\\n1 A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 166}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       162                                                                                                                                           \\nNow, according to the data given in this problem: \\n \\nP (A1) = 0.25,  \\n \\nP (A2) = 0.75 (as A2 is simply the complement of A1),  \\n \\nP (B|A1) = 0.99,  \\nand  \\n \\nP (B|A2) = 0.17 \\nSubstituting the above values in the Bayes’ theorem, we obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\nThis is the probability that a car which fa ils the test ACTUALLY emits excessive amounts of pollutants. The example \\nthat we just considered pertained to the simplest case when we have only two mutually exclusive and exhaustive events \\nA1 and A2. \\nAs stated earlier, the Bayes’ theorem can be extended to the case of three, four, five or more mutually exclusive and \\nexhaustive events. \\nLet us consider another example: In the following example, check the percentages of defective bolts from the recorded \\nlecture. \\n \\nEXAMPLE \\n \\n          In a bolt factory, 25% of the bolts are produced by machine A, 35% are produced by machine B, and the \\nremaining 40% are produced by machine C. Of their outputs, 2%, 4% and 5% respectively are defective bolts. If a bolt \\nis selected at random and found to be defective, what is the probability that it came from machine A? \\n \\nIn this example, we realize that “a bolt is produced by machine A”, “a bolt is produced by machine B” and “a bolt is \\nproduced by machine C” represent three mutually exclusive and exhaustive events i.e. we can regard them as A1, A2 \\nand A3. The event “defective bolt” represents the event B. Hence, in this example, we need to determine P(A1/B).  \\nThe students are encouraged to work on this problem on their own, in order to understand the application and \\nsignificance of th e Bayes’ Theorem. This brings us to the END of the discussion of various basic concepts of \\nprobability.  We now begin the discussion of a very important  concept in mathematical statistics, i.e., the concept of \\nPROBABILITY DISTRIBUTIONS. \\nAs stated in the very beginning of this course, there are two types of quantitative variables  --- the discrete variable, and \\nthe continuous variable. Accordingly, we have the discrete probability distribution as well as the continuous probability \\ndistribution. \\nWe begin with the discussion of the discrete probability distribution.  \\nIn this regard, the first concept that we need to consider is the concept of Random variable. \\n \\nRANDOM VARIABLE \\n \\n Such a numerical quantity whose value is determined by the outcome of a random exper iment is called a \\nrandom variable. \\nFor example, if we toss three dice together, and let X denote the number of heads, then the random variable X consists \\nof the values 0, 1, 2, and 3. Obviously, in this example, X is a discrete random variable. Let us now discuss the concept \\nof discrete probability distribution in detail with the help of the following example: \\nExample: \\n If a biologist is interested in the number of petals on a particular flower, this number may take the values \\n3, 4, 5, 6, 7, 8, 9, and each one of these numbers will have its own probability. \\n Suppose that upon observing a large no. of flowers, say 1000 flowers, of that particular species, the \\nfollowing results are obtained: \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf0292211\\n11\\n1 A|BP.APA|BP.AP\\nA|BP.APB|AP \\uf02b\\uf03d\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n66.0\\n3750.0\\n2475.0\\n1275.02475.0\\n2475.0\\n17.075.099.025.0\\n99.025.0\\n\\uf03d\\n\\uf03d\\n\\uf02b\\uf03d\\n\\uf02b\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 167}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       163                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSince 1000 is quite a large number, hence the proportions f/\\uf0e5f can be regarded as probabilities and hence we can write \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPROPERTIES OF A DISCRETE PROBABILITY DISTRIBUTION \\n \\n\\uf0b7 (1)   \\n\\uf0b7 for each Xi   (i = 1, 2, … 7)  \\n \\n\\uf0b7 (2) \\n \\nAnd, since the number of petals on a leaf can only be a whole number, hence the  variable X is known as a discrete \\nrandom variable, and the probability distribution of this variable is known as a DISCRETE probability distribution. \\nIn other words, Any discrete variable that is associated with a random experiment, and attached to whose various values \\nare various probabilities (Such that    \\n \\nis known as a Discrete Random Variable, and its probability distribution is known as a Discrete Probability \\nDistribution. Just as we can depict a frequency distribution graphically, we can draw the G RAPH of a probability \\ndistribution. \\n \\nEXAMPLE \\n \\nGoing back to the probability distribution of the number of petals on the flowers of a particulars species, i.e.: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis distribution can be represented in the form of a line chart. \\nNo. of Petals \\nX f \\n3 50 \\n4 100 \\n5 200 \\n6 300 \\n7 250 \\n8 75 \\n9 25 \\n 1000 \\n \\nNo. of Petals \\nX P(x) \\nx1 = 3 0.05 \\nx2 = 4 0.10 \\nx3= 5 0.20 \\nx4 = 6 0.30 \\nx5 = 7 0.25 \\nx6 = 8 0.075 \\nx7 = 9 0.025 \\n 1 \\n \\n\\uf028 \\uf029 10 \\uf0a3\\uf0a3 iXP\\n\\uf028 \\uf029 1\\uf03d\\uf0e5 iXp\\n\\uf028 \\uf029 )1\\n1\\n\\uf0e5\\n\\uf0a5\\n\\uf03d\\n\\uf03d\\ni\\niXP\\nNo. of Petals \\nX P(x) \\nx1 = 3 0.05 \\nx2 = 4 0.10 \\nx3= 5 0.20 \\nx4 = 6 0.30 \\nx5 = 7 0.25 \\nx6 = 8 0.075 \\nx7 = 9 0.025 \\n 1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 168}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       164                                                                                                                                           \\n \\nEvidently, this particular probability distribution is approximately symmetric. In addition, this graph clearly shows that, \\njust as in the case of a frequency distribution, every discrete probability distribution has a CENTRAL point and a \\nSPREAD. Hence, similar to a frequency distribution, the discrete probability distribution has a MEAN and a \\nSTANDARD DEVIATION. How do we calculate the mean and the standard deviation of a probability distribution? \\nLet us first consider the computation of the MEAN: \\nWe know that in the case of a frequency distribution such as  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nthe mean is given by \\n \\n \\n \\n \\n \\n \\n \\nIn case of a discrete probability distribution, such as the one that we have been considering i.e \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nthe mean is given by: \\n \\n \\n \\n \\n \\nHence we construct the column of XP(X), as shown below: \\n \\nLine Chart Representation  \\nof the \\nDiscrete Probability Distribution \\n             3 4 5 6\\n  7  8  9 No. of  Petals (x) \\nProbability \\nP(x) \\n.05 \\n.10 \\n.25 \\n.20 \\n.15 \\n.30 \\n0 \\nX f \\n1 1 \\n2 2 \\n3 4 \\n4 2 \\n5 1 \\n \\n\\uf03d\\uf03d\\n\\uf0e5\\n\\uf0e5\\nf\\nfXX\\n\\uf0e5\\n\\uf0e5\\nf\\nXf\\nNo. of Petals \\nX P(x) \\nx1 = 3 0.05 \\nx2 = 4 0.10 \\nx3= 5 0.20 \\nx4 = 6 0.30 \\nx5 = 7 0.25 \\nx6 = 8 0.075 \\nx7 = 9 0.025 \\n 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5\\n\\uf0e5\\n\\uf0e5 \\uf03d\\uf03d\\uf03d\\uf03d\\uf06d XXP1\\nXXP\\nXp\\nXXPXE'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 169}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       165                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence \\uf06d = E(X) = \\uf0e5XP(X) = 5.925 i.e. the mean of the given probability distribution is 5.925. In other words, \\nconsidering a very large number of flowers of that particular species, we would expect that, on the average, a flower \\ncontains 5.925 petals --- or, rounding this number, 6 petals. This interpretation points to the reason why the mean of the \\nprobability distribution of a random variable X is technically called the EXPECTED VALUE of the random variable X.  \\n (“Given that the probability that the flower has 3 petals is 5%, the probability that the flower has 4 petals is 10%, and \\nso ON, we EXPECT that on the average a flower contains 5.925 petals.) \\n \\nCOMPUTATION OF THE STANDARD DEVIATION \\n \\nJust as in case of a frequency distribution, we have \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Similarly, in case of a probability distribution, we have \\n \\n    \\n\\uf073    \\n \\n \\n \\n \\n \\n \\nIn the above example \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence \\n \\n \\nNo. of Petals \\nx P(x) xP(x) \\nx1 = 3 0.05 0.15 \\nx2 = 4 0.10 0.40 \\nx3= 5 0.20 1.00 \\nx4 = 6 0.30 1.80 \\nx5 = 7 0.25 1.75 \\nx6 = 8 0.075 0.60 \\nx7 = 9 0.025 0.225 \\nTotal 1 5.925 \\n \\n\\uf028 \\uf029\\n\\uf0e5\\n\\uf0e5 \\uf02d\\uf03d f\\nXXfS\\n2\\n\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n22\\nf\\nfX\\nf\\nfX\\n22\\nf\\nXf\\nf\\nfX\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n  = S.D.(X)  \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n22\\nXP\\nXXP\\nXP\\n)X(PX\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf02d\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5\\n\\uf0e5  \\n    \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d22 XXPXPX \\uf0e5\\uf0e5 \\uf02d\\uf03d  \\n           \\n\\uf028 \\uf029 \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf03d\\uf0e5 1XP\\uf051  \\nNo. of Petals \\nx P(x) xP(x) x2P(x) \\nx1 = 3 0.05 0.15 0.45 \\nx2 = 4 0.10 0.40 1.60 \\nx3= 5 0.20 1.00 5.00 \\nx4 = 6 0.30 1.80 10.80 \\nx5 = 7 0.25 1.75 12.25 \\nx6 = 8 0.075 0.60 4.80 \\nx7 = 9 0.025 0.225 2.025 \\nTotal 1 5.925 36.925 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 170}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       166                                                                                                                                           \\n \\n \\n \\n \\n \\n  \\n \\nNow that we have both the mean and the standard deviation, we are in a position to compute the coefficient of variation \\nof this distribution: \\n \\n \\n \\n \\n \\nCoefficient of Variation \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us consider another example to understand the concept of discrete probability distribution. \\n \\nEXAMPLE \\n \\na) Find the probability distribution of the sum of the dots when two fair dice are thrown \\nb) Use the probability distribution to find the probabilities of obtaining (i) a sum that is greater than 8, and (ii) a sum \\nthat is greater than 5 but less than or equal to 10. \\n \\nSOLUTION \\n \\na) The sample space S is represented by the following 36 outcomes: \\n           S = {(1, 1), (1, 2), (1, 3), (1, 5), (1, 6); \\n  (2, 1), (2, 2), (2, 3), (2, 5), (2, 6); \\n  (3, 1), (3, 2), (3, 3), (3, 5), (3, 6); \\n  (4, 1), (4, 2), (4, 3), (4, 5), (4, 6); \\n  (5, 1), (5, 2), (5, 3), (5, 5), (5, 6); \\n  (6, 1), (6, 2), (6, 3), (6, 5), (6, 6) } \\nSince each of the 36 outcomes is equally likely to occur, therefore each outcome has probability 1/36. \\nLet X be the random variable representing the sum of dots which appear on the dice. Then the values of the r.v. are 2, 3, \\n4… 12.  \\nThe probabilities of these values are computed as below: \\n \\n \\n \\n \\n \\n \\nGraphical Representation: \\n                   3       4       5       6        7       \\n8        9 No. of  Petals \\n(x) \\nProbability \\nP(x) \\n.0\\n5 \\n.1\\n0 \\n.2\\n5 .2\\n0 .1\\n5 \\n.3\\n0 \\n0 \\n \\uf06d = 5.925  \\uf073 = 1.3 \\n\\uf028 \\uf029 \\uf028 \\uf0292925.5925.36X.D.S \\uf02d\\uf03d\\n \\n106.35925.36 \\uf02d\\uf03d\\n \\n3.1819.1 \\uf03d\\uf03d\\n \\n%9.21\\n100925.5\\n3.1\\n100..\\n\\uf03d\\n\\uf0b4\\uf03d\\n\\uf0b4\\uf03d \\uf06d\\n\\uf073VC'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 171}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       167                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTherefore the desired probability distribution of the r.v X is \\n \\n \\n \\n \\n \\n \\n \\n \\nThe probabilities in the above table clearly indicate that if we draw the line chart of this distribution, we will obtain a \\ntriangular-shaped graph. The students are encouraged to draw the graph of this probability distribution, in order to be \\nable to develop a visual picture in their minds. \\nb) Using the probability distribution, we get the required probabilities as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, we consider the concept of the DISTRIBUTION FUNCTION of a discrete random variable: \\n \\n \\n\\uf028 \\uf029 \\uf07b \\uf07d\\uf05b \\uf05d ,36\\n1  1 1,P  2  XP  f(2) \\uf03d\\uf03d\\uf03d\\uf03d\\n as there is only \\none outcome resulting in a sum of 2, \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf07b \\uf07d\\uf05b \\uf05d ,36\\n2  1,2,2 1,P  3  XP  f(3) \\uf03d\\uf03d\\uf03d\\uf03d\\n  \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf07b \\uf07d\\uf05b \\uf05d ,36\\n3  1,3,2,2,3 1,P  4  XP  f(4) \\uf03d\\uf03d\\uf03d\\uf03d\\n  \\nSimilarly  \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 ,36\\n49f,36\\n58f,36\\n67f,36\\n56f,36\\n4f(5) \\uf03d\\uf03d\\uf03d\\uf03d\\uf03d\\n  \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 .36\\n112f and36\\n211f ,36\\n310f \\uf03d\\uf03d\\uf03d\\n \\nxi 2 3 4 5 6 7 8 9 10 11 12 \\nf(xi) \\n36\\n1  \\n36\\n2  \\n36\\n3  \\n36\\n4  \\n36\\n5  \\n36\\n6  \\n36\\n5  \\n36\\n4  \\n36\\n3  \\n36\\n2  \\n36\\n1  \\n \\ni)  P(a sum that is greater than 8) \\n = P(X > 8) \\n = P(X=9) + P(X=10) + P(X=11) + P(X=12) \\n = f(9) + f(10) + f(11) + f(12) \\n = \\n36\\n10\\n36\\n1\\n36\\n2\\n36\\n3\\n36\\n4 \\uf03d\\uf02b\\uf02b\\uf02b  \\nii)  P(a sum that is greater than 5  \\n but less than or equal to 10) \\n  = P(5 < X < 10) \\n  = P(X = 6) + P(X = 7) + P(X = 8)  \\n   + P(X = 9) + P(X = 10) \\n  = f(6) + f(7) + f(8) + f(9) + f(10) \\n  = \\n.36\\n23\\n36\\n3\\n36\\n4\\n36\\n5\\n36\\n6\\n36\\n5 \\uf03d\\uf02b\\uf02b\\uf02b\\uf02b  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 172}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       168                                                                                                                                           \\n \\n \\nDISTRIBUTION FUNCTION \\n \\nThe distribution function of a random variable X, denoted by F(x), is defined by F(x) = P(X < x).  \\nThe function F(x) gives the probability of the event that X takes a value LESS THAN OR EQUAL TO a specified value \\nx. The distribution function is abbreviated to d.f. and is also called the cumulative distribution function (cdf) as it is the \\ncumulative probability function of the random variable X from the smallest value upto a specific value x. \\nLet us illustrate this concept with the help of the same example that we have been considering --- that of the probability \\ndistribution of the sum of the dots when two fair dice are thrown. As explained earlier, the probability distribution of \\nthis example is: \\n \\n \\n \\n \\n \\n \\n \\nThe term ‘distribution function’ implies the cumulating of the probabilities similar to the cumulation of frequencies in \\nthe case of the frequency distribution of a discrete variable. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we are interested in finding the probability that we obtain a sum of five or less, the column of cumulativ e \\nprobabilities immediately indicates that this probability is 10/36. \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nxi 2 3 4 5 6 7 8 9 10 11 12 \\nf(xi) \\n36\\n1  \\n36\\n2  \\n36\\n3  \\n36\\n4  \\n36\\n5  \\n36\\n6  \\n36\\n5  \\n36\\n4  \\n36\\n3  \\n36\\n2  \\n36\\n1  \\n \\nxi 2 3 4 5 6 7 8 9 10 11 12 \\nf(xi) \\n36\\n1  \\n36\\n2  \\n36\\n3  \\n36\\n4  \\n36\\n5  \\n36\\n6  \\n36\\n5  \\n36\\n4  \\n36\\n3  \\n36\\n2  \\n36\\n1  \\nF(xi) \\n36\\n1  \\n36\\n3  \\n36\\n6  \\n36\\n10  \\n36\\n15  \\n36\\n21  \\n36\\n26  \\n36\\n30  \\n36\\n33  \\n36\\n35  \\n36\\n36  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 173}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       169                                                                                                                                           \\nLECTURE NO. 23 \\n \\n\\uf0b7 Graphical Representation of the Distribution Function of a Discrete Random Variable \\n \\n\\uf0b7 Mathematical Expectation  \\n \\n\\uf0b7 Mean, Variance and Moments of a Discrete Probability Distribution \\n \\n\\uf0b7 Properties of Expected Values \\n \\nFirst, let us consider the concept of the DISTRIBUTION FUNCTION of a discrete random variable.  \\n \\nDISTRIBUTION FUNCTION \\n \\nThe distribution function of a random variable X, denoted by F( x), is defined by F(x) = P(X < x). The function F(x) \\ngives the probability of the event that X takes a value LESS THAN OR EQUAL TO a specified value x. The \\ndistribution function is abbreviated to d.f. and is also called the cumulative distribution function  (cdf)  \\nas it is the cumulative probability function of the random variable X from the smallest value up to a specific value x. \\n \\n EXAMPLE \\n \\nFind the probability distribution and distribution function for the number of heads when 3 balanced coins are tossed.  \\nDepict both the probability distribution and the distribution function graphically. Since the coins are balanced, therefore \\nthe equally probable sample space for this experiment is \\n \\nS = {HHH, HHT, HTH, THH, HTT, THT, TTH, TTT}. \\n \\nLet X be the random variable that denotes the number of heads.  \\nThen the values of X are 0, 1, 2 and 3. \\nAnd their probabilities are: \\n \\nf (0) = P(X = 0)  \\n = P [{TTT}] = 1/8 \\nf(1) = P (X = 1)  \\n = P [{HTT, THT, TTH}] = 3/8 \\nf(2) = P (X = 2)  \\n = P [{HHT, HTH, THH}] = 3/8 \\nf(2) = P (X = 3)  \\n = P [{HHH}] = 1/8 \\n \\nExpressing the above information in the tabular form, we obtain the desired probability distribution of X as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNumber of Heads \\n(xi) \\nProbability \\nf(xi) \\n0 \\n8\\n1  \\n1 \\n8\\n3  \\n2 \\n8\\n3  \\n3 \\n8\\n1  \\nTotal 1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 174}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       170                                                                                                                                           \\n \\nThe line chart of the above probability distribution is as follows: \\n \\n \\nIn order to obtain the distribution function of this random variable, we compute the cumulative probabilities as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence the desired distribution function is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWhy has the distribution function been expressed in this manner? The answer to this question is: \\n \\nINTERPRETATION \\n \\nIf x < 0, we have  P(X < x) = 0, the reason being that it is not possible for our random variable X to assume value less \\nthan zero.(The minimum number of heads that we can have in tossing three coins is zero.) \\nIf 0 < x < 1, we note that it is not possible for our random variable X to assume any value between zero and one. (We \\nwill have no head or one head but we will NOT have 1/3 heads or 2/5 heads!) \\nHence, the probabilities of all such valu es will be zero, and hence we will obtain a situation which can be explained \\nthrough the following table:  \\n \\n \\n0 \\n0 1 2 3 X \\nf(x) \\n0 \\n1/8 \\n2/8 \\n3/8 \\n4/8 \\nNumber of \\nHeads \\n(xi) \\nProbability \\n \\nf(xi) \\nCumulative \\nProbability \\nF(xi) \\n0 \\n8\\n1  \\n8\\n1  \\n1 \\n8\\n3  \\n8\\n4\\n8\\n3\\n8\\n1 \\uf03d\\uf02b  \\n2 \\n8\\n3  \\n8\\n7\\n8\\n3\\n8\\n4 \\uf03d\\uf02b  \\n3 \\n8\\n1  \\n18\\n1\\n8\\n7 \\uf03d\\uf02b  \\n \\n\\uf028 \\uf029\\n\\uf0ef\\uf0ef\\n\\uf0ef\\n\\uf0ef\\n\\uf0ef\\n\\uf0ee\\n\\uf0ef\\uf0ef\\n\\uf0ef\\n\\uf0ef\\n\\uf0ef\\n\\uf0ed\\n\\uf0ec\\n\\uf0b3\\n\\uf03c\\uf0a3\\n\\uf03c\\uf0a3\\n\\uf03c\\uf0a3\\n\\uf03c\\n\\uf03d\\n3,1\\n32,8\\n7\\n21,8\\n4\\n10,8\\n1\\n0,0\\nxfor\\nxfor\\nxfor\\nxfor\\nxfor\\nxF'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 175}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       171                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above table clearly shows that the probability that X is LESS THAN any value lying between zero and 0.9999… \\nwill be equal to the probability of X = 0 i.e. For 0 < x < 1, \\n \\n \\nSimilarly, \\n \\n\\uf0b7 For 1 < x < 2, we have \\n \\n \\n \\n \\n \\n \\n\\uf0b7 For 2 < x < 3, we have \\n \\n \\n \\n \\n \\n \\n \\nAnd, finally, for x > 3, we have \\n \\n \\n \\n \\n \\n \\n \\nHence, the graph of the DISTRIBUTION FUNCTION is as follows: \\n \\nNumber of \\nHeads \\n(xi) \\nProbability \\n \\nf(xi) \\nCumulative \\nProbability \\nF(xi) \\n0 \\n8\\n1  \\n8\\n1  \\n0.2 0 \\n8\\n108\\n1 \\uf03d\\uf02b  \\n0.4 0 \\n8\\n108\\n1 \\uf03d\\uf02b  \\n0.6 0 \\n8\\n108\\n1 \\uf03d\\uf02b  \\n0.8 0 \\n8\\n108\\n1 \\uf03d\\uf02b  \\n1 \\n8\\n3  \\n8\\n4\\n8\\n3\\n8\\n1 \\uf03d\\uf02b  \\n \\n;8\\n1  0)  P(X  x) P(X \\uf03d\\uf03d\\uf03d\\uf03c\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n;8\\n4\\n8\\n3\\n8\\n1\\n1XP0XPxXP\\n\\uf03d\\uf02b\\uf03d\\n\\uf03d\\uf02b\\uf03d\\uf03d\\uf03c\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n;8\\n7\\n8\\n3\\n8\\n3\\n8\\n1\\n2XP1XP0XPxXP\\n\\uf03d\\uf02b\\uf02b\\uf03d\\n\\uf03d\\uf02b\\uf03d\\uf02b\\uf03d\\uf03d\\uf03c\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n.18\\n8\\n8\\n1\\n8\\n3\\n8\\n3\\n8\\n1\\n)3X(P2XP1XP0XPxXP\\n\\uf03d\\uf03d\\uf02b\\uf02b\\uf02b\\uf03d\\n\\uf03d\\uf02b\\uf03d\\uf02b\\uf03d\\uf02b\\uf03d\\uf03d\\uf03c'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 176}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       172                                                                                                                                           \\n \\n \\n \\nAs this graph resembles the steps of a staircase, it is known as a step function. It is also known as a jump function (as it \\ntakes jumps at integral values of X).In some books, the graph of the distribution function is given as shown in the \\nfollowing figure: \\n \\n \\n \\nIn what way do we interpret the above distribution function from a REAL -LIFE point of view? If we toss three \\nbalanced coins, the probability that we obtain at the most one head is 4/8, the probability that we ob tain at the most two \\nheads is 7/8, and so on.  Let us consider another interesting example to illustrate the concepts of a discrete probability \\ndistribution and its distribution function: \\n \\nEXAMPLE \\n \\nA large store places its last 15 clock radios in a clearanc e sale. Unknown to any one, 5 of the radios are defective. If a \\ncustomer tests 3 different clock radios selected at random, what is the probability distribution of X, where X represent \\nthe number of defective radios in the sample? \\nSOLUTION \\nWe have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0 1 2 3 X \\nF(x) \\n4/8 \\n6/8 \\n2/8 \\n1 \\n0 1 2 3 X \\nF(x) \\n4/8 \\n6/8 \\n2/8 \\n1 \\nType of \\nClock Radio \\nNumber of  \\nClock Radios \\nGood 10 \\nDefective 5 \\nTotal 15 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 177}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       173                                                                                                                                           \\nThe total number of ways of selecting 3 radios out of 15 is  \\n \\nAlso, the total number of ways of selecting 3 good radios (and no defective radio) is  \\nHence, the probability of X = 0 is  \\n \\n \\n \\n \\n \\n \\n \\n \\nThe probabilities of X = 1, 2, and 3 are computed in a s imilar way. Hence , we obtain the following probability \\ndistribution: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe line chart of this distribution is: \\n \\n \\nAs indicated by the above diagram, it is not necessary for a probability distribution to be symmetric ; it can be positively \\nor negatively skewed. The distribution function of the above probability distribution is obtained as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLINE CHART \\n0 \\n0 1 2 3 X 0 \\n0.1 \\n0.2 \\n0.3 \\n0.4 \\n0.5 \\nf(x) \\n.3\\n15\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n.0\\n5\\n3\\n10\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n.26.0\\n3\\n15\\n0\\n5\\n3\\n10\\n\\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nNumber of defective \\nclock radios in the \\nsample \\nX \\nProbability \\n \\n \\nf(x) \\n0 0.26 \\n1 0.49 \\n2 0.22 \\n3 0.02 \\nTotal 0.99 \\uf0bb1 \\n \\nNumber of defective \\nclock radios in the \\nsample \\nX \\nf(x) F(x) \\n0 0.26 0.26 \\n1 0.49 0.75 \\n2 0.22 0.97 \\n3 0.02 0.99 \\uf0bb 1 \\nTotal 0.99 \\uf0bb 1  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 178}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       174                                                                                                                                           \\nINTERPRETATION \\n \\nThe probability that the sample of 3 clock radios contains at the most one defective radio is 0.75, the probability that the \\nsample contains at the most two defective radios is 0.97, and so on. \\nLet a discrete random variable X have possible values x1, x2, …, xn with corresponding probabilities f(x1), f(x2), …, \\nf(xn) such that \\uf053f(xi) =1. Then the mathematical expectation or the expectation or the expected value of X, denoted by \\nE(x), is defined as \\nE(X) = x1f(x1) + x2f(x2) + … + xnf(xn) \\n \\n \\n \\n \\nE(X) is also called the mean of X and is usually denoted by the letter \\uf06d. \\n \\nThe expression \\n \\n \\nmay be regarded a s a weighted mean of the variab le’s possible values x1, x2, …, xn, each being weighted by the \\nrespective probability. \\nIn case the values are equally likely,   \\n \\n \\n \\nWhich represents the ordinary arithmetic mean of the n possible values \\nIt should be noted that E(X) is the average value of the random variable X over a very large number of trials. \\n \\nEXAMPLE \\nIf it rains, an umbrella salesman can earn $ 30 per day. If it is fair, he can lose $ 6 per day. What is his expectation if the \\nprobability of rain is 0.3? \\n \\nSOLUTION \\n \\nLet X represents the number of dollars the salesman earns. Then X is a random  variable with possible values 30 and –6, \\n(where -6 corresponds to the fact that the salesman loses), and the corresponding  probabilities are 0.3 and 0.7 \\nrespectively. Hence, we have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to compute the expected value of X, we carry out the following computation \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence   \\nE(X) = $ 4.80 per day  \\ni.e. on the average, the salesman can expect to earn 4.8 dollars per day. \\nUntil now, we have considered the mathematical expectation of the random variable X.  \\n\\uf028 \\uf029,xfx ii\\nn\\n1i\\n\\uf0e5\\n\\uf03d\\n\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029ii\\nn\\ni\\nxfxXE \\uf0e5\\n\\uf03d\\n\\uf03d\\n1\\n\\uf028 \\uf029 ,xn\\n1XE i\\uf0e5\\uf03d\\nEVENT \\nAMOUNT \\nEARNED \\n($) \\nx \\nPROBABILITY \\nP(x) \\nRain 30 0.3 \\nNo Rain –6 0.7 \\n Total 1 \\n \\nEVENT \\nAMOUNT \\nEARNED \\n($) \\nx \\nPROBABILITY \\nP(x) xP(x) \\nRain 30 0.3 9.0 \\nNo Rain –6 0.7 -4.2 \\n Total 1 4.8 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 179}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       175                                                                                                                                           \\nBut, in many situations, we may be interested in the mathematical expectation of some FUNCTION of X: \\n \\nEXPECTATION OF A FUNCTION OF A RANDOM VARIABLE \\n \\nLet H(X) be a function of the random variabl e X. Then H(X) is also a random variable and also has an expected value, \\n(as any function of a random variable is also a random variable). If X is a discrete random variable with probability \\ndistribution f(x), then, since H(X) takes the value H(xi) when X = xi, the expected value of the function H(X) is  \\nE[H(X)] = H(x1) f(x1) + H(x2)f(x2) + … + H(xn) f(xn) \\n \\n \\n \\n Provided the series converges absolutely. Again, if H(X) = (X - \\uf06d)2,where \\uf06d is the population mean, then \\n E(X – \\uf06d)2 = \\uf053(xi - \\uf06d)2 f(x). \\nWe call this expected value the variance and denote it by Var (X) or \\uf0732.  \\nAnd, since  \\nE(X – \\uf06d)2 = E(X2) – [E(X)]2,  \\nhence the short cut formula for the variance is \\n\\uf0732 = E(X2) – [E(X)]2 \\nThe positive square root of the variance, a before, is called the standard deviation. More generally, if  \\nH(X) = Xk, k = 1, 2, 3… then \\n  E(Xk) = \\uf053xik f(x) \\nwhich we call the kth moment about the origin  of the random variable X and we denote it by \\uf0a2\\uf06dk. Similarly, if H(X) = \\n(X – \\uf06d)k, k = 1, 2, 3, …, then we get an expected value, called the kth moment about the mean of the random variable \\nX, which we denote by \\uf06dk. That is:  \\n\\uf06dk = E(X – \\uf06d)k = \\uf053(xi – \\uf06d)k f(x) \\nThe skewness of a probability distribution is often measured by \\n \\n \\n \\nand kurtosis by   \\n \\n \\n \\nThese moment-ratios assist us in determining the  Skewness and kurtosis of our probability distribution in exactly the \\nsame way as was discussed in the case of frequency distributions. \\n \\nPROPERTIES OF MATHEMATICAL EXPECTATION \\n \\nThe important properties of the expected values of a random variable are as follows: \\n\\uf0b7 If c is a constant, then E(c) = c. Thus the expected value of a constant is constant itself.  This point can be \\nunderstood easily by considering the following interesting example: Suppose that a very difficult test was \\ngiven to students by a professor, and that every student obtained 2 marks out of 20! It is obvious that the mean \\nmark is also 2. Since the variable ‘marks’ was a constant, therefore its expected value was equal to itself. \\n\\uf0b7 If X is a discrete random variable and if a and b are constants, then  E(aX + b) = a E(X) + b. \\n \\nEXAMPLE \\nLet X represents the number of heads that appear when three fair coins are tossed. The probability distribution of X is: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe expected value of X is obtained as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029,xfxH ii\\ni\\n\\uf0e5\\uf03d\\n3\\n2\\n2\\n3\\n1\\n\\uf06d\\n\\uf06d\\uf03d\\uf062\\n.2\\n2\\n4\\n2\\n\\uf06d\\n\\uf06d\\uf03d\\uf062\\nX P(x) \\n0 1/8 \\n1 3/8 \\n2 3/8 \\n3 1/8 \\nTotal 1 \\n \\nx P(x) xP(x) \\n0 1/8 0 \\n1 3/8 3/8 \\n2 3/8 6/8 \\n3 1/8 3/8 \\nTotal 1 12/8=1.5 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 180}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       176                                                                                                                                           \\nHence, E(X) = 1.5 \\nSuppose tha t we are interested in finding the expected value of the random variable 2X+3.Then we carry out the \\nfollowing computations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence E(2X+3) = 6It should be noted that \\nE(2X+3)  = 6= 2(1.5) + 3= 2E(X) + 3 \\ni.e. E (aX + b) = a E(X) + b. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\nx 2x+3 P(x) (2x+3)P(x) \\n0 3 1/8 3/8 \\n1 5 3/8 15/8 \\n2 7 3/8 21/8 \\n3 9 1/8 9/8 \\n Total 1 48/8=6 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 181}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       177                                                                                                                                           \\nLECTURE NO. 24 \\n\\uf0b7 Chebychev’s Inequality  \\n\\uf0b7 Concept of Continuous Probability Distribution  \\n\\uf0b7 Mathematical Expectation, Variance & Moments of a Continuous Probability Distribution   \\nWe begin with the discussion of the concept of the Ch ebychev’s Inequality in the case of a discrete probability \\ndistribution \\n \\nChebychev’s Inequality \\n \\nIf X is a random variable having mean \\uf06d and variance \\uf0732 > 0, and k is any positive constant, then the probability that a \\nvalue of X falls within k standard deviations of the mean is at least  \\nThat is: \\n \\n \\nAlternatively, we may state Chebychev’s theorem as follow: Given the probability distribution of the random variable \\nX with mean \\uf06d and standard deviation \\uf073, the probability of the observing a value of X that dif fers the \\uf06d by k or more \\nstandard deviations cannot exceed 1/k2. As indicated earlier, this inequality is due to the Russian mathematician P.L. \\nChebychev (1821 -1894), and it provides a means of understanding how the standard deviation measures variability \\nabout the mean of a random variable. It holds for all probability distributions having finite mean and variance.  \\nLet us apply this concept to the example of the number of petals on the flowers of a particular species that we \\nconsidered earlier: \\n \\nEXAMPLE \\n \\nIf a biologist is interested in the number of petals on a particular flower, this number may take the values 3, 4, 5, 6, 7, 8,  \\n9, and each one of these numbers will have its own probability \\n The probability distribution of the random variable X is: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe mean of this distribution is: \\n\\uf06d = E(X) = \\uf0e5XP(X) = 5.925 \\uf040 5.9 \\nAnd the standard deviation of this distribution is: \\n  \\n         \\uf073 = \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAccording to the Chebychev’s inequality, the probability is at least 1 - 1/22 = 1 - 1/4 = 3/4 = 0.75 that X will lie \\nbetween \\uf06d - 2\\uf073 and \\uf06d + 2\\uf073  i.e. between 5.9 - 2(1.3) and 5.9 + 2(1.3) i.e. between 3.3 and 8.5  \\nLet us have another look at the probability distribution: \\n \\n \\n \\n\\uf028 \\uf029 ,11k 2kXkP \\uf02d\\uf0b3\\uf02b\\uf03c\\uf03c\\uf02d \\uf073\\uf06d\\uf073\\uf06d\\nNo. of Petals \\nX P(x) \\nx1 = 3 0.05 \\nx2 = 4 0.10 \\nx3= 5 0.20 \\nx4 = 6 0.30 \\nx5 = 7 0.25 \\nx6 = 8 0.075 \\nx7 = 9 0.025 \\n 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf0292925.5925.36X.D.S \\uf02d\\uf03d\\n \\n106.35925.36 \\uf02d\\uf03d\\n \\n3.1819.1 \\uf03d\\uf03d\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 182}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       178                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAccording to this distribution, the probability that X lies between 3.3 and 8.5 is  \\n0.10 + 0.20 + 0.30 + 0.25 + 0.075  \\n = 0.925 \\nwhich is greater than 0.75(AS indicated by the Chebychev’s inequality). \\nFinally, and most importantly, we will use the concepts in Chebychev's Rule and the Empirical Rule to build the \\nfoundation for statistical inference-making. The method is illustrated in next example. \\n \\nEXAMPLE \\n \\nSuppose you invest a fixed sum of money in each of five business ventures. Assume you know that 70% of such \\nventures are successful, the outcomes of the ventures are indep endent of one another, and the probability distribution \\nfor the number, x, of successful ventures out of five is: \\n \\n \\n \\n \\n \\n \\na)  Find \\uf06d = E(X). \\n   Interpret the result. \\nb)Find \\n \\n \\n \\n \\nInterpret the result. \\nc) Graph P(x).  \\nd) Locate \\uf06d and the interval \\uf06d + 2\\uf073 on the graph. Use either Chebychev’s Rule or the Empirical Rule to approximate \\nthe probability that x falls in this interval. Compare this result with the actual probability. \\ne) Would you expect to observe fewer than two successful ventures out of five? \\n \\nSOLUTION \\n \\na) Applying the formula, \\n\\uf06d= E(X) =\\uf0e5xP(x) \\n  = 0(.002) +1(.029) + 2(.132) + 3(.309) + 4 (.360) + 5(.168)  \\n  = 3.50 \\n \\nINTERPRETATION \\n \\nOn average, the number of successful ventures out of five will equal 3.5. (It should be remembered that this expected \\nvalue has meaning only when the experiment – investing in five business ventures – is repeated a large number of \\ntimes.) \\nb) Now we calculate the variance of X: \\nWe know that \\n\\uf0732 = E[(X - \\uf06d)2] = \\uf0e5(x - \\uf06d)2 P(x) \\nHence, we will need to construct a column of x - \\uf06d: \\n \\n \\n \\n \\n \\n \\n \\nNo. of Petals \\nX P(x) \\nx1 = 3 0.05 \\nx2 = 4 0.10 \\nx3= 5 0.20 \\nx4 = 6 0.30 \\nx5 = 7 0.25 \\nx6 = 8 0.075 \\nx7 = 9 0.025 \\n 1 \\n \\nx 0 1 2 3 4 5 \\nP(x) .002 .029 .132 .309 .360 .168 \\n \\n\\uf028 \\uf029\\uf05b \\uf05d .XE 2\\uf06d\\uf02d\\uf03d\\uf073\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 183}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       179                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThus, the variance is \\uf0732 = 1.05 and the standard deviation is \\n \\n \\n \\n \\nThis value measures the spread of the probability distribution of X, the number of successful ventures out of five. \\n \\n \\n \\nc) The graph of P(x) is shown in the following figure with the mean \\uf06d and the interval  \\n\\uf06d + 2\\uf073 =3.50+2(1.02)  \\n =3.50+2.04  \\n = (1.46, 5.54) shown on the graph.  \\n \\n \\n \\n \\n \\n \\n \\n \\nNote particularly that \\uf06d = 3.5 locate the centre of the probability distribution. Since this distribution is a t heoretical \\nrelative frequency distribution that is moderately mound -shaped, we expect (from Chebychev’s Rule) at least 75% and, \\nmore likely (from the Empirical Rule), approximately 95% of observed x values to fall in the interval \\uf06d + 2\\uf073 ------ that \\nis, between 1.46 and 5.54.  \\n \\nIt can be seen from the above figure that the actual probability that X falls in the interval \\uf06d + 2\\uf073 includes the sum of \\nP(x) for the values  \\nX = 2, X = 3, X = 4, and X = 5.  \\n \\n \\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0 1 2 3 4 5\\np(x)\\nx\\n\\uf06d \\uf06d + 2\\uf073 \\n(5.54) \\n \\n\\uf06d + 2\\uf073 \\n(1.46) \\n \\nx P(x) x-\\uf06d (x-\\uf06d)2 (x-\\uf06d)2P(x) \\n0 .002 –3.5 12.25 0.02 \\n1 .029 –2.5 6.25 0.18 \\n2 .132 –1.5 2.25 0.30 \\n3 .309 –0.5 0.25 0.08 \\n4 .360 +0.5 0.25 0.09 \\n5 .168 +1.5 2.25 0.38 \\n   Total 1.05 \\n \\n02.105.12 \\uf03d\\uf03d\\uf073\\uf03d\\uf073'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 184}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       180                                                                                                                                           \\n \\n \\n \\nThis probability is P(2) + P(3) + P(4) + P(5)  \\n= .132 +.309 + .360 + .168  \\n= .969.  \\nTherefore, 96.9% of the probability distribution lies within 2 standard deviations of the mean. This percentage is \\nCONSISTENT with both the Chebychev’s rule and the Empirical Rule. \\n \\nd) Fewer than two successful ventures out of five implies that x = 0 or x = 1. Since both these values of x lie outside the \\ninterval \\uf06d + 2\\uf073, we know from the Empirical Rule that such a result is unlikely (with approximate probability of only \\n.05).The exact probability, P(x < 1), is P(0) + P(1) = .002 + .029 = .031.  \\n Consequently, in a single experiment where we invest in five business ventures, we would not expect to observe fewer \\nthan two successful ones.  The key question: What is the significance of the Chebychev’s Ineq uality and the Empirical \\nRule? \\nThe answer to this question is that both these rules assist us in having a certain IDEA regarding amount of data lying \\nbetween the mean minus a certain number of standard deviations and mean plus that same number of standard \\ndeviations.  Given any data -set, the moment we compute the mean and standard deviation, we HAVE an idea \\nregarding the two points (i.e. mean minus two standard deviations, and mean plus two standard deviations) between \\nwhich the BULK of our data lies. If our data-set is hump-shaped, we obtain this idea through the Empirical Rule, and if \\nwe don’t have any reason to believe that our data-set is hump-shaped, then we obtain this idea through the Chebychev’s \\nRule \\nWe now begin the discussion of CONTINUOUS RANDOM V ARIABLES – quantities that are measurable. As stated \\nin the very first lecture, continuous variables result from measurement, and can therefore take any value within a certain \\nrange. For example, the height of a normal Pakistani adult male may take any val ue between 5 feet 4 inches and 6 feet. \\nThe temperature at a place, the amount of rainfall, time to failure for an electronic system, etc. are all examples of \\ncontinuous random variable. Formally speaking, a continuous random variable can be defined as follows: \\n \\nCONTINUOUS RANDOM VARIABLE \\n \\n A random variable X is defined to be continuous if it can assume every possible value in an interval [a, \\nb], a < b, where a  and b may be –\\uf0a5 and +\\uf0a5 respectively. The function f(x) is called the probability density functio n, \\nabbreviated to p.d.f., or simply density function of the random variable X.  A continuous probability distribution looks \\nsomething like this: \\n \\n \\n \\n \\n \\n \\nf(x) \\nX \\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0 1 2 3 4 5\\np(x)\\nx\\n\\uf06d \\uf06d + 2\\uf073 \\n(5.54) \\n \\n\\uf06d + 2\\uf073 \\n(1.46) \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 185}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       181                                                                                                                                           \\n \\n \\nA p.d.f. has the following properties: \\n \\n \\n \\n \\n \\n \\niii) The probability that X takes on a value in the interval [c, d], c < d is given by: \\n \\nP(c < x < d) = \\n \\nwhich is the area under the curve y = f(x) between X = c and X = d, as shown in the following figure: \\n \\n \\n \\n \\nThe TOTAL area under the curve is 1. In other words:  \\n\\uf0b7 f(x) a non-negative function,  \\n\\uf0b7 The integration takes place over all possible values of the random variable X  between the specified \\nlimits, and  \\n\\uf0b7 The probabilities are given by appropriate areas under the curve. \\nSince   \\n \\n \\n \\nIt should therefore be not ed that the probability of a continuous random variable X taking any particular value k is \\nalways zero. That is why probability for a continuous random variable is measurable only over a given interval. \\nFurther, since for a continuous random variable X, P( X = x) = 0 for every x, the following four probabilities are \\nregarded as the same: \\n P(c < X < d), P(c < X < d),  \\n P(c < X < d) and P(c < X d). \\n \\nThey may be different for a discrete random variable. The values (expressed as intervals) of a continuous random \\nvariable and their associated probabilities can be expressed by means of a formula. \\n We now discuss the distribution function of a continuous random variable. \\n \\nCONTINUOUS RANDOM VARIABLE \\n \\n A random variable X may also be defined as continuous if its distribution function F(x) is continuous and is \\ndifferentiable everywhere except at isolated points in the given range. In contrast with the graph of the distribution \\nfunction of a discrete variable, the graph of F(x) in the case of a continuous variable has no jumps or steps but is a \\ncontinuous function for all x-values, as shown in the following figure: \\n \\n \\nc d \\nf(x) \\nP(c < x < d) \\ni) f(x) > 0, for all x \\n \\nii) \\n\\uf028 \\uf029\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d1dxxf  \\n\\uf028 \\uf029\\uf0f2\\nd\\nc\\ndxxf\\n\\uf028 \\uf029 \\uf028 \\uf029 ,0\\uf03d\\uf03d\\uf03d \\uf0f2 dxxfkXP\\nk\\nk'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 186}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       182                                                                                                                                           \\n \\n \\n \\nSince F(x) is a non-decreasing function of x, we have \\ni) f(x) > 0, \\nii) \\n\\uf028 \\uf029 \\uf028 \\uf029 ,dxxfxF\\nx\\n\\uf0f2\\n\\uf0a5\\uf02d\\n\\uf03d  for all x. \\nThe relationship between f(x) and F(x) is as follows:  f(x) is obtained by finding the derivative of F(x), i.e. \\n \\n \\n \\nEXAMPLE \\n \\na) Find the value of k so that the function f(x) defined as follows, may be a density function \\n f(x)  = kx, 0 < x < 2 \\n  = 0, elsewhere \\n \\nb) Compute P(X = 1).  \\n \\nc) Compute P(X > 1). \\n \\nd) Compute the distribution function F(x). \\n \\ne) \\n \\n \\nSOLUTION \\n \\na) The function f(x) will be a density function, if \\ni) f(x) > 0 for every x, and \\nii)  \\n \\nThe first condition is satisfied when k > 0. The second condition will be satisfied, if  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWe had \\n0 \\n1 \\nX \\nF(x) \\nF(a) F(b) \\n\\uf028 \\uf029 \\uf028 \\uf029xfdx\\nxFd \\uf03d\\n\\uf028 \\uf0293/23/11/2XP \\uf03c\\uf03c\\uf03c X\\n\\uf028 \\uf029 1\\uf03d\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\ndxxf\\n\\uf028 \\uf029 ,1\\uf03d\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\ndxxf\\ni.e. if  \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0f2 \\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf02b\\uf02b\\uf03d\\n2\\n0 2\\n0\\ndxxfdxxfdxxf1  \\ni.e. if  \\n\\uf0f2 \\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf02b\\uf02b\\uf03d\\n2\\n0 2\\n0\\ndx0dxkxdx01  \\ni.e. if  \\nk20\\n0\\n2\\nxk\\n2\\n01\\n2\\n\\uf03d\\uf02b\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02b\\uf03d\\uf03d  \\nThis gives k = 1/2 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 187}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       183                                                                                                                                           \\nf(x)  = kx, 0 < x < 2 \\n  = 0, elsewhere \\nand since we have obtained  \\nk = 1/2, hence: \\n \\n \\n \\n \\n \\n \\nb) Since f(x) is continuous probability function, therefore (X = 1) = 0. \\n \\nc) P(X > 1) is obtained by computing the area under the curve (in this case, a straight line) between X=1 and X=2: \\n \\n \\nThis area is obtained as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nd) To compute the distribution function, we need to find: \\n \\n \\n \\n \\nWe do so step by step, as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0 1 2 \\nX \\n1 \\nf(x) \\nf(x) = x|2 \\n\\uf028 \\uf029\\n\\uf0ee\\n\\uf0ed\\n\\uf0ec \\uf0a3\\uf0a3\\uf03d elsewhere\\nxforxf\\nx\\n,0\\n20,2\\nP(X > 1) = area of shaded region \\n  =\\n\\uf028 \\uf029\\uf0f2\\n2\\n1\\ndxxf  \\n  =\\n\\uf05b \\uf05d 4\\n3\\n1\\n2\\ndx\\n2\\n1 4\\nx\\n2\\nx 2\\n\\uf03d\\uf03d\\uf0f2  \\n \\nF(x) = P(X < x) = \\n\\uf028 \\uf029\\uf0f2\\n\\uf0a5\\uf02d\\nx\\ndxxf  \\nFor any x such that -\\uf0a5 < x < 0,  \\n F(x) = \\n\\uf0f2\\n\\uf0a5\\uf02d\\n\\uf03d\\nx\\n,0dx0  \\nIf 0 < x < 2, we have \\n\\uf028 \\uf029 \\uf05b \\uf05d\\uf0f2 \\uf0f2\\n\\uf0a5\\uf02d\\n\\uf03d\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf02b\\uf03d\\n0 x\\n0\\n2\\n4\\nx ,4\\nx\\n0\\nx\\ndx2\\nxdx0xF\\n2\\n and, finally, for x > 2 we have \\n\\uf028 \\uf029 \\uf0f2 \\uf0f2\\uf0f2\\n\\uf0a5\\uf02d\\n\\uf03d\\uf02b\\uf02b\\uf03d\\n0 2\\n0\\n2\\n0\\n1dx0dx2\\nxdx0xF\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 188}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       184                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWe will discuss the computation of the conditional probability \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence   \\nF(x)   = 0,  for x < 0 \\n =\\n,4\\nx2  for 0 < x < 2 \\n  =1, for x > 2. \\n\\uf028 \\uf0293/23/11/2XP \\uf03c\\uf03c\\uf03c X'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 189}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       185                                                                                                                                           \\n \\nLECTURE NO. 25 \\n \\n\\uf0b7 Mathematical Expectation, Variance & Moments of a Continuous Probability Distribution  \\n\\uf0b7 BIVARIATE Probability Distribution \\nIn the last lecture, we were dealing with an example of a continuous probability  distribution in which we were \\ninterested in computing a conditional probability. We now discuss this particular concept \\n \\nEXAMPLE \\n \\na) Find the value of k so that the function f(x) defined as follows, may be a density function \\n f(x)  = kx, 0 < x < 2 \\n  = 0, elsewhere \\nb) Compute P(X = 1).  \\nc) Compute P(X > 1). \\nd) Compute the distribution function F(x). \\n \\ne) \\n \\n \\nSOLUTION \\n \\nWe had \\nf(x)  = kx, 0 < x < 2 \\n  = 0, elsewhere \\nand we obtained k = 1/2.  \\n \\nHence: \\n \\n \\n \\n \\ne)   Applying the definition of conditional probability, we get \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above example was of the simplest case when the graph of our continuous probability distribution is in the form of \\na straight line.  \\n Let us now consider a slightly more complicated situation. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf0293/23/11/2XP \\uf03c\\uf03c\\uf03c X\\n\\uf028 \\uf029\\n\\uf0ee\\n\\uf0ed\\n\\uf0ec \\uf0a3\\uf0a3\\uf03d elsewhere\\nxforxf\\nx\\n,0\\n20,2\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf0f2\\n\\uf0f2\\n\\uf03d\\uf0a3\\uf0a3\\n\\uf0a3\\uf0a3\\uf03d\\uf0a3\\uf0a3\\uf0a3\\n3\\n2\\n3\\n1\\n2\\n1\\n3\\n1\\ndx2\\nx\\ndx2\\nx\\nXP\\nXPX|XP\\n3\\n2\\n3\\n1\\n2\\n1\\n3\\n1\\n3\\n2\\n3\\n1\\n2\\n1\\n3\\n1\\n2\\n3\\n2\\n3\\n1\\n2\\n2\\n1\\n4\\nx\\n4\\nx\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\uf0b8\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\uf03d\\nEXAMPLE \\n \\n         A continuous random variable X has \\nthe d.f. F(x) as follows: \\n \\nF(x)  = 0,  for x < 0, \\n  \\n,5\\nx2 2\\n\\uf03d  for 0 < x < 1, \\n \\n,2x1for,2\\nxx35\\n2\\n5\\n3 2\\n\\uf0a3\\uf03c\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf02d\\uf03d  \\n = 1  for x > 2. \\nFind the p.d.f. and P(|X| < 1.5). '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 190}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       186                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us now discuss the mathematical expectation of continuous random variables through the following example: \\n \\nEXAMPLE \\n \\nFind the expected value of the random variable X having the p.d.f \\nf(x)  = 2 (1 – x),  0 < x < 1 \\n  = 0, elsewhere \\n \\nSOLUTION \\n \\nNow  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs indicated earlier, the term ‘expected value’ implies the mean value. The graph of the above probability density \\nfunction and its mean value are presented in the following figure: \\n \\n \\n \\n \\n \\nSuppose that we are interested in verifying the properties of mathematical expectation that are valid in the case of \\nunivariate probability distributions. In the last lecture, we noted that if X is a discrete r andom variable and if a and b are \\nconstants, then  \\n1 0.5 0 X \\nf(x) \\n2 \\n1 \\n0.5 \\n1.5 \\n0.25 0.75 \\nE(X) = 0.33 \\nSOLUTION \\nBy definition, we have \\n\\uf028 \\uf029 \\uf028 \\uf029.xFdx\\ndxf \\uf03d  \\nTherefore \\n\\uf028 \\uf029 5\\nx4xf \\uf03d       for 0 < x < 1 \\n          \\n\\uf028 \\uf029x35\\n2 \\uf02d\\uf03d   for 1 < x < 2 \\n   = 0      elsewhere. \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n3\\n1\\n3\\n1\\n2\\n123\\nx\\n2\\nx2\\ndxx1x2\\ndxxfx)X(E\\n1\\n0\\n32\\n1\\n0\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\n\\uf02d\\uf03d\\n\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 191}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       187                                                                                                                                           \\n E (aX + b) = a E(X) + b. \\nThis property is equally valid in the case of continuous probability distributions . In this example, suppose that a = 3 and \\nb = 5. Then, we wish to verify that \\n E(3X + 5) = 3 E(X) + 5. \\nThe right-hand-side of the above equation is: \\n3 E(X) + 5 = 3(    ) + 5 = 1 + 5 = 6 \\nIn order to compute the left-hand-side, we proceed as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSince the left-hand-side is equal to the right-hand-side, therefore the property is verified. \\n \\nSPECIAL CASE \\n \\nWe have  \\n E(aX + b) = a E(X) + b. \\nIf b = 0, the above property takes the following simple form:  \\n E(aX) = a E(X). \\nNext, let us consider the computation of the moments and moment-ratios in the case of a continuous probability \\ndistribution: \\n \\nEXAMPLE \\n \\nA continuous random variable X has the p.d.f. \\n \\n \\n \\n \\n \\n \\nFind the first four moments about the mean and the moment-ratios. \\nWe first calculate the moments about origin as \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf05b \\uf05d\\n\\uf05b \\uf05d \\uf028 \\uf029 .6321152\\nxxx52\\ndxx3x252\\ndxx15x32)5X3(E\\n1\\n0\\n32\\n21\\n0\\n1\\n0\\n\\uf03d\\uf03d\\uf02d\\uf02d\\uf03d\\n\\uf02d\\uf02d\\uf03d\\n\\uf02d\\uf02d\\uf03d\\n\\uf02d\\uf02b\\uf03d\\uf02b\\n\\uf0f2\\n\\uf0f2\\n\\uf028 \\uf029 \\uf028 \\uf029\\notherwise,0\\n.2x0,x2x4\\n3xf\\n\\uf03d\\n\\uf0a3\\uf0a3\\uf02d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n;112\\n16\\n4\\n3\\n4\\n16\\n3\\n16\\n4\\n3\\n43\\n2\\n4\\n324\\n3\\n'\\n2\\n0\\n43\\n2\\n2\\n0\\n1\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf03d\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\nxxdxxxx\\ndxxfxXE\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n;5\\n6\\n5\\n8\\n4\\n3\\n5\\n3284\\n3\\n54\\n2\\n4\\n324\\n3\\n'\\n2\\n0\\n54\\n22\\n2\\n0\\n22\\n2\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf03d\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\nxxdxxxx\\ndxxfxXE\\uf06d\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 192}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       188                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe first moment-ratio is  \\n \\n \\n \\n \\n \\nThis implies that this particular continuous probability distribution is absolutely symmetric \\nThe second moment-ratio is  \\n \\n \\n \\n \\n \\n \\nThis implies that this particular continuous probability distribution may be regarded as  playkurtic, i.e. flatter than the \\nnormal distribution. \\nThe students are encouraged to draw the graph of this distribution in order to develop a visual picture in their minds. \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n;5\\n8\\n30\\n64\\n4\\n3\\n6\\n64\\n5\\n64\\n4\\n3\\n65\\n2\\n4\\n324\\n3\\n'\\n2\\n0\\n65\\n23\\n2\\n0\\n33\\n3\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf03d\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\nxxdxxxx\\ndxxfxXE\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n.7\\n16\\n21\\n64\\n4\\n3\\n7\\n128\\n3\\n64\\n4\\n3\\n7\\nx\\n6\\nx2\\n4\\n3dxxx2x4\\n3\\ndxxfxXE'\\n2\\n0\\n76\\n242\\n0\\n44\\n4\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf03d\\uf03d\\uf06d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\nNext, we find the moments about the \\nmean as follows: \\n \\n01 \\uf03d\\uf06d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029 5\\n115\\n6'' 22\\n122 \\uf03d\\uf02d\\uf03d\\uf06d\\uf02d\\uf06d\\uf03d\\uf06d\\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 ;025\\n18\\n5\\n8125\\n6135\\n8\\n'2''3'\\n3\\n3\\n12133\\n\\uf03d\\uf02b\\uf02d\\uf03d\\uf02b\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf02b\\uf02d\\uf03d \\uf06d\\uf06d\\uf06d\\uf06d\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n.35\\n335\\n36\\n5\\n32\\n7\\n16\\n135\\n6165\\n8147\\n16\\n'3''6''4'\\n42\\n4\\n12\\n2\\n13144\\n\\uf03d\\uf02d\\uf02b\\uf02d\\uf03d\\n\\uf02d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02b\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf02d\\uf02b\\uf02d\\uf03d \\uf06d\\uf06d\\uf06d\\uf06d\\uf06d\\uf06d\\uf06d\\n.0\\n5\\n1\\n0\\n3\\n2\\n3\\n2\\n2\\n3\\n1 \\uf03d\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\uf03d\\n\\uf06d\\n\\uf06d\\uf062\\n.14.2\\n5\\n1\\n35\\n3\\n22\\n2\\n4\\n2 \\uf03d\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\uf03d\\n\\uf06d\\n\\uf06d\\uf062\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 193}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       189                                                                                                                                           \\nWe begin the concept of Bivariate probability distribution by introducing the term ‘Joint Distributions’: \\n \\nJOINT DISTRIBUTIONS \\n \\nThe distribution of two or more random variables which are observed simultaneously when an experiment is performed \\nis called their JOINT distribution.  It is customary to call the distribution of a single random variable as univariate.  \\nLikewise, a distribution involving two, three or many r.v.’s simultaneously is referred to as bivariate, trivariate or \\nmultivariate. A bivariate distribution may be discrete when the possible values of (X, U) are finite or count ably infinite. \\nIt is continuous if (X, Y) can assume all values in some non -countable set of the plane. A bivariate distribution is said \\nmixed when one r.v. is discrete and the other is continuous. \\n \\nBIVARIATE PROBABILITY FUNCTION \\n \\nLet X and Y be two discrete r.v.’s defined on the same sample space S, X taking the values x1, x2, …, xm and Y taking \\nthe values y1, y2, …, yn. Then the probability that X takes on the value xi and, at the same time, Y takes on the value , \\ndenoted by f(xi, yj) or pij, is defined to be the joint probability function or simply the joint distribution of X and Y.  \\nThus the joint probability function, also called the bivariate probability function f(x, y) is a function whose value at the \\npoint (xi, yj) is given byf(xi, yj) = P(X = xi and Y = yj), \\n     i = 1, 2, …, m. \\n    j = 1, 2, …, n. \\nThe joint or bivariate probability distribution consisting of all pairs of values (xi, yj) and their associated probabilities  \\nf(xi, yj) i.e. the set of triples [xi, yj, f(xi, yj)] can either be shown in the following two-way table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nor be expressed by mean of a formula for f(x, y). The probabilities f(x, y) can be obtained by substituting appropriate \\nvalues of x and y in the table or formula. A joint probability function has the following properties:  \\n \\nPROPERTIES \\n \\ni)    f(xi, yj)>0,for all(xi, yj),i.e. for i=1,2,…,m;  j = 1, 2, …, n. \\n \\nii)  \\n \\n \\nMARGINAL PROBABILITY FUNCTIONS \\n \\nThe point to be understood here is that, from the joint probability function for (X, Y), we can obtain the INDI VIDUAL \\nprobability function of X and Y. Such individual probability functions are called MARGINAL probability functions. \\nLet f(x, y) be the joint probability function of two discrete r.v.’s X and Y. Then the marginal probability \\nfunction of X is defined as \\n \\n \\n \\nf(xi, y1) + f(xi, y2) + … + f(xi, yn)  \\nas xi must occur either with y1 or y2 or … or yn  \\n= P(X = xi); \\nJoint Probability Distribution of X and Y  \\n \\nX\\\\Y y1 y2 … yj … yn P(X = xi) \\nx1 f(x1,y1) f(x1,y2) … f(x1,yj) … f(x1,yn) g(x1) \\nx2 f(x2,y1) f(x2,y2) … f(x2,yj) … f(x2,yn) g(x2) \\n\\uf0bc \\n\\uf0bc     \\n\\uf0bc \\n\\uf0bc \\nxi f(xi,y1) f(xi,y2) … f(xi,yj) … f(xi,yn) g(xi) \\n\\uf0bc \\n\\uf0bc     \\n\\uf0bc \\n\\uf0bc \\nxm f(xm,y1) f(xm,y2) … f(xm,yj) … f(xm,yn) g(xm) \\nP(Y=yj) h(y1) h(y2) … h(yj) … h(yn) 1 \\n \\n\\uf028 \\uf029\\uf0e5\\uf0e5 \\uf03d\\ni j\\nji 1y,xf\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\n\\uf03d\\n\\uf03d\\nn\\nj\\njii yxfxg\\n1\\n,'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 194}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       190                                                                                                                                           \\nthat is, the individual probability function of X is found by adding over the rows of the two -way table. Similarly, the \\nmarginal probability function for Y is obtained by adding over the column as  \\n \\n \\n \\n \\nThe values of the marginal probabilities are often written in the margins of the joint table as they are the row and \\ncolumn totals in the table. The probabilities in each marginal probability function add to 1. \\n \\nCONDITIONAL PROBABILITY FUNCTION \\n \\nLet X and Y be two discrete r.v.’s with joint probability function f(x, y). Then the conditional probability function for X \\ngiven Y = y, denoted as f(x|y), is defined by \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n                                                                                            \\n \\n Where h(y) is the marginal probability, and h(y) > 0  \\n \\nIt gives the probability that X takes on the value xi given that Y has taken on the value yj. The conditional probability \\nf(xi | yj) is n on-negative and (for a given fixed yj) adds to 1 on i and hence is a probability function. Similarly, the \\nconditional probability function for Y given X = x is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nINDEPENDENCE \\n \\n Two discrete r.v.’s X and Y are said to be statistically independent , if and only if, for all possible pairs of \\nvalues (xi, yj) the joint probability function f(x, y) can be expressed as the product of the two marginal probability \\nfunctions.  \\nThat is, X and Y are independent, if \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIt should be noted that the joint probability function of X and Y when they are independent, can be obtained by \\nMULTIPLYING together their marginal probability functions. \\n \\nEXAMPLE \\n \\nAn urn contains 3 black, 2 red and 3 green balls and 2 balls are selected at random from it. If X is the numb er of black \\nballs and Y is the number of red balls selected, then find  \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029j\\nm\\ni\\njij yYPyxfyh \\uf03d\\uf03d\\uf03d\\uf0e5\\n\\uf03d1\\n,\\nf(xi | yj)  = P(X = xi | Y = yj) \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029j\\nji\\nyYP\\nyYandxXP\\n\\uf03d\\n\\uf03d\\uf03d\\uf03d  \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029 ,yh\\ny,xf\\nj\\nji\\uf03d    \\n      for i = 1, 2, …, j = 1, 2, … \\nf(yj | xi)  = P(Y = yj | X = xi) \\n  \\n\\uf028 \\uf029\\n\\uf028 \\uf029i\\nij\\nxXP\\nxXandyYP\\n\\uf03d\\n\\uf03d\\uf03d\\uf03d  \\n  \\n\\uf028 \\uf029\\n\\uf028 \\uf029 ,xg\\ny,xf\\ni\\nji\\uf03d  where g(x) > 0. \\nf(x, y)  = P(X = xi and Y = yj) \\n \\n = P(X = xi). P(Y = yj)   \\n   for all i and j. \\n \\n = g(x) h(y). '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 195}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       191                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\ni) The sample space S for this experiment contains sample points. The possible values of X are 0, 1, and 2, and those for \\nY are 0, 1, and 2. The values that (X, Y) can tak e on are (0, 0), (0, 1), (1, 0), (1, 1), (0, 2) and (2, 0). We desire to find \\nf(x, y) for each value (x, y). \\nThe total number of ways in which 2 balls can be drawn out of a total of 8 balls is   \\n \\n \\n \\n \\nNow f(0, 0) = P(X = 0 and Y = 0), where the event (X = 0 and  Y = 0) represents that neither black nor red ball is \\nselected, implying that the 2 selected are green balls. This event therefore contains                               sample points,  \\n \\nand \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nSimilar calculations give the probabilities of other values and the joint probability function of X and Y is given as: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 .282\\n788\\n2 \\uf03d\\uf03d x\\n\\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029 33\\n2\\n2\\n0\\n3\\n0 \\uf03d\\nf(0, 0) = P(X = 0 and Y = 0) = 3/28 \\nAgain f(0, 1) = P(X = 0 and Y = 1) \\n = P (none is black, 1 is red  \\n     and 1 is green) \\n \\n\\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029\\n28\\n6\\n28\\n3\\n1\\n2\\n1\\n3\\n0 \\uf03d\\uf03d  \\nSimilarly, f(1, 1)  \\n = P(X = 1 and Y = 1) \\n = P(1 is black 1 is red and  \\n    none is green) \\n \\n\\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029\\n28\\n6\\n28\\n3\\n0\\n2\\n1\\n3\\n1 \\uf03d\\uf03d  \\nJoint Probability Distribution \\n \\nY \\n \\nX \\n0 1 2 P(X = xi) \\ng(x) \\n0 3/28 6/28 1/28 10/28 \\n1 9/28 6/28 0 15/28 \\n2 3/28 0 0 3/28 \\nP(Y = yj) \\nh(y) 15/28 12/28 1/28 1 \\n \\ni) the joint probability function f(x,  y); \\nii) P(X + Y < 1); \\niii) the marginal p.d. g(x)  \\nand h(y); \\niv) the conditional p.d. f(x | 1), \\nv) P(X = 0 | Y = 1); and \\nvi) Are x and Y independent? '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 196}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       192                                                                                                                                           \\nLECTURE NO. 26 \\n \\n\\uf0b7 BIVARIATE Probability Distributions (Discrete and Continuous) \\n\\uf0b7 Properties of Expected Values in the case of Bivariate Probability Distributions \\n \\nIn the last lecture we began the discussion of the example in which we were drawing 2 balls out of an urn containing 3 \\nblack, 2 red and 3 green balls, and you will remember that, in this example, we were interested in computing quite a few \\nquantities.  \\n \\nEXAMPLE \\n \\nAn urn contains 3 black, 2 red and 3 green balls and 2 balls are selected at random from it. If X is the number of black \\nballs and Y is the number of red balls selected, then find \\n \\n \\n \\n \\n \\n \\n \\n \\nAs indicated in the last lecture, using the rule of combinations in conjunction with the classical definition of probability, \\nthe probability of the first cell came out to be 3/28. By similar calculations, we obtain all the remaining probabilities, \\nand, as such, we obtain the following bivariate table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis joint p.d. of the two r.v.’s (X, Y) can be represented by the formula \\n \\n \\n \\n \\n \\n \\n \\nii) To compute P(X + Y < 1), we see that x + y < 1 for the cells  \\n(0, 0), (0, 1) and (1, 0).  \\n \\nTherefore \\n P(X + Y < 1)  \\n = f(0, 0) + f(0, 1) + f(1, 0)  \\n = 3/28 +6/28 + 9/28   \\n = 18/28 = 9/14 \\n \\niii) The marginal p.d.’s are: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\ni) the joint probability function f(x, y) \\nii) P(X + Y < 1) \\niii) the marginal p.d. g(x) and h(y) \\niv) the conditional p.d. f(x | 1) \\nv) P(X = 0 | Y = 1) \\nvi) Are x and Y independent? \\nJoint Probability Distribution \\n \\nY \\n \\nX \\n0 1 2 P(X = xi) \\ng(x) \\n0 3/28 6/28 1/28 10/28 \\n1 9/28 6/28 0 15/28 \\n2 3/28 0 0 3/28 \\nP(Y = yj) \\nh(y) 15/28 12/28 1/28 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029 2,1,0x\\n.2yx028 2,1,0yy,xf\\n3\\nyx2\\n2\\ny\\n3\\nx\\n\\uf03d\\n\\uf0a3\\uf02b\\uf0a3\\n\\uf03d\\uf03d\\uf03d\\n\\uf02d\\uf02d\\nx 0 1 2 \\ng(x) 10/28 15/28 3/28 \\n \\ny 0 1 2 \\nh(x) 15/28 12/28 1/28 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 197}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       193                                                                                                                                           \\niv) By definition, the conditional p.d. f(x | 1) is \\n \\n f(x | 1) = P(X = x | Y = 1) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence the conditional p.d. of X given that Y = 1, is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n      v) Finally,  \\n P(X = 0 | Y = 1)  \\n = f(0 | 1) = 1/2 \\n \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf0291\\n1,\\n1\\n1\\nh\\nxf\\nYP\\nYandxXP \\uf03d\\uf03d\\n\\uf03d\\uf03d\\uf03d\\nNow   \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n7\\n3\\n28\\n12\\n028\\n6\\n28\\n6\\n1,xf1h\\n2\\n0x\\n\\uf03d\\uf03d\\n\\uf02b\\uf02b\\uf03d\\n\\uf03d \\uf0e5\\n\\uf03d  \\nTherefore   \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029 2,1,0x,1,xf7\\n3\\n1h\\n1,xf1|xf\\n\\uf03d\\uf03d\\n\\uf03d  \\nThat is, \\n\\uf028 \\uf029 \\uf028 \\uf029 2\\n1\\n28\\n6\\n3\\n71,0f3\\n71|0f \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029 2\\n1\\n28\\n6\\n3\\n71,1f3\\n71|1f \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 003\\n71,2f3\\n71|2f \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d\\uf03d\\n \\nx 0 1 2 \\nf(x|1) 1/2 1/2 0 \\n \\nvi) We find that f(0, 1) = 6/28, \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n28\\n10\\n28\\n1\\n28\\n6\\n28\\n3\\ny,0f0g\\n2\\n0y\\n\\uf03d\\uf02b\\uf02b\\uf03d\\n\\uf03d \\uf0e5\\n\\uf03d  \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n28\\n12028\\n6\\n28\\n6\\n1,xf1h\\n2\\n0x\\n\\uf03d\\uf02b\\uf02b\\uf03d\\n\\uf03d \\uf0e5\\n\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 198}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       194                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCONTINUOUS BIVARIATE DISTRIBUTIONS \\n \\nThe bivariate probability density function of continuous r.v.’s X and Y is an integral function f(x,y) satisfying the \\nfollowing properties: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us try to understand the graphic picture of a bivariate continuous probability distribution: The region of the XY-\\nplane depicted by the interval (x1 < X < x2; y1 < Y < y2) is shown graphically: \\n \\n \\n \\n \\nJust as in the case of a continuous univariate situation, the probability function f(x) gives us a curve under which we \\ncompute areas in order to find various probabilities, in the case of a continuous bivariate situation, the probability \\nfunction f(x,y) gives a SURFACE and, when we compute the probability that our random variable X lies between x1 \\nand x2 AND, simultaneously, the random variable Y lies between y1 and y2, we will be computing the VOLUME under \\nthe surface given by our probability function f(x, y) encompassed by this region.  The MARGINAL p.d.f. of the \\ncontinuous r.v. X is  \\n \\nand that of the r.v. Y is \\n(x1, y2) \\n(x1, y1) \\n \\ny2 \\ny1 \\n0 x1 x2 X \\nY \\n(x2, y2) \\n(x2, y1) \\nNow \\n,28\\n12\\n28\\n10\\n28\\n6 \\uf0b4\\uf0b9  \\n \\ni.e. \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029,1h0g1,0f \\uf0b9  \\ntherefore X and Y are  NOT  \\nSatistically independent.  \\ni) f(x,y) > 0 for all (x, y) \\nii) \\n\\uf028 \\uf029 and,1dydxy,xf \\uf03d\\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf0a5\\n\\uf0a5\\uf02d  \\niii) \\n\\uf028 \\uf029\\n\\uf028 \\uf029 .dxdyy,xf\\ndYc,bXaP\\nd\\nc\\nb\\na\\n\\uf0f2\\uf0f2\\uf03d\\n\\uf0a3\\uf0a3\\uf0a3\\uf0a3  \\n\\uf028 \\uf029 \\uf028 \\uf029dyyxfxg ,\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 199}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       195                                                                                                                                           \\n \\n \\n \\n \\n \\nThat is, the marginal p.d.f. of any of the variables is obtained by integrating out the other variable from the joint p.d.f. \\nbetween the limits –\\uf0a5 and +\\uf0a5.The CONDITIONAL p.d.f. of the continuous r.v. X given that Y takes the value y, is \\ndefined to be \\n \\n \\n \\n \\nwhere f(x,y) and h(y) are respectively the joint p.d.f. of X and Y, and the marginal p.d.f. of Y, and h(y) > 0.  Similarly, \\nthe conditional p.d.f. of the continuous r.v. Y given that X = x, is  \\n \\n \\n \\n \\nprovided that g(x) > 0 \\nIt is worth noting that the conditional p.d.f’s satisfy all the requirements for the UNIVARIATE density function. \\n \\nFINALLY \\n \\nTwo continuous r.v.’s X and Y are said to be Statisticall y Independent, if and only if their joint density f(x,y) can be \\nfactorized in the form f(x,y) = g(x)h(y) for all possible values of X and Y. \\n \\nEXAMPLE \\nGiven the following joint p.d.f \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n c)    Find the marginal p.d.f.  \\n        g(x) and h(y). \\n d)     Find the conditional p.d.f. \\n        f(x | y) and f(y | x). \\n \\nSOLUTION \\n \\na) The joint density f(x,y) will be a p.d.f if \\n(i) f(x,y) > 0 and  \\n(ii)  \\n \\n \\n \\nNow f(x,y) is clearly greater than zero for all x and y in the given region, and \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029dxyxfyh ,\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 ,,| yh\\nyxfyxf \\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 ,,| xg\\nyxfxyf \\uf03d\\nelsewhere,0\\n4, y   2 2;  x  0 y),– – x  (68\\n1  y)f(x,\\n\\uf03d\\n\\uf0a3\\uf0a3\\uf0a3\\uf0a3\\uf03d\\na) Verify that f(x,y) is a joint  \\n density function. \\nb) Calculate  \\n,2\\n5Y,2\\n3XP \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf0a3\\uf0a3   \\n1),( \\uf03d\\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf0a5\\n\\uf0a5\\uf02d\\ndydxyxf\\n\\uf028 \\uf029 dxdyyx68\\n1dydx)y,x(f\\n4\\n2\\n2\\n0\\n\\uf02d\\uf02d\\uf03d \\uf0f2\\uf0f2\\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf0a5\\n\\uf0a5\\uf02d\\n \\n \\ndx2\\nyxyy68\\n1\\n4\\n2\\n22\\n0 \\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d \\uf0f2  \\n \\n\\uf028 \\uf029\\n2\\n0\\n22\\n0\\nxx68\\n1dxx268\\n1\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02d\\uf03d\\uf02d\\uf03d \\uf0f2  \\n \\n\\uf05b \\uf05d 14128\\n1 \\uf03d\\uf02d\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 200}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       196                                                                                                                                           \\n \\nThus f(x,y) has the properties of a joint p.d.f. \\n \\nb) To determine the probability of a value of the r.v. (X, Y) falling in the region X < 3/2, Y < 5/2,  \\n  \\nWe find \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nc) The marginal p.d.f. of X is  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 dxdyyx68\\n1\\n2\\n5Y,2\\n3XP\\n2\\n5\\n2\\n3\\n2y0x\\n\\uf02d\\uf02d\\uf03d\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf0a3\\uf0a3\\n\\uf0f2\\uf0f2\\n\\uf03d\\uf03d\\n \\n        =\\ndx2\\nyxyy68\\n1\\n2\\n5\\n2\\n3\\n2\\n2\\n0 \\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf0f2  \\n        =\\n\\uf05b \\uf05d 32\\n9x2x1564\\n1dx2\\nx\\n8\\n15\\n8\\n1 2\\n32\\n3\\n0\\n2\\n0\\n\\uf03d\\uf02d\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf0f2  \\n\\uf028 \\uf029 \\uf028 \\uf029 ,dyy,xfxg \\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d\\n  \\n\\uf0a5\\uf03c\\uf03c\\uf0a5\\uf02d x  \\n \\n\\uf028 \\uf029 ,dyyx68\\n1 4\\n2\\n\\uf02d\\uf02d\\uf03d \\uf0f2  \\n2x0 \\uf0a3\\uf0a3  \\n \\n4\\n2\\n2\\n2\\nyxyy68\\n1\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d  \\n2x0 \\uf0a3\\uf0a3  \\n \\n\\uf028 \\uf029x34\\n1 \\uf02d\\uf03d ,   \\n2x0 \\uf0a3\\uf0a3  \\n = 0,      \\n2xOR0x \\uf0b3\\uf03c  \\n \\nSimilarly, the marginal p.d.f. of Y is \\n   \\n\\uf028 \\uf029 \\uf028 \\uf029dxyx68\\n1yh\\n2\\n0\\n\\uf02d\\uf02d\\uf03d \\uf0f2 , \\n4y2 \\uf0a3\\uf0a3  \\n   \\n\\uf028 \\uf029y54\\n1 \\uf02d\\uf03d ,    \\n4y2 \\uf0a3\\uf0a3  \\n   = 0,   elsewhere. \\nd) The conditional p.d.f. of X given  \\nY = y, is  \\n    \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029yh\\ny,xfy|xf \\uf03d , where h(y) > 0    \\nHence \\nf(x|y)=\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 2x0,y52\\nyx6\\ny54\\n1\\nyx68\\n1\\n\\uf0a3\\uf0a3\\uf02d\\n\\uf02d\\uf02d\\uf03d\\n\\uf02d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf02d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 201}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       197                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, we consider two important properties of mathematical expectation which are valid in the case of BIVARIATE \\nprobability distributions: \\n \\nPROPERTY NO. 1 \\n \\nThe expected value of the sum of any two random variables is equal to the sum of their expected values, i.e. \\nE(X + Y) = E(X) + E(Y). \\nThe result also holds for the difference of r.v.’s i.e.  \\n \\nE(X – Y) = E(X) – E(Y). \\n \\nPROPERTY NO. 2 \\n \\nThe expected value of the product of two independent r.v.’s is equal to the product of their expected values, i.e. \\n E(XY) = E(X) E(Y). \\nIt should be noted that these properties are valid for continuous random variable’s in which case the summations are \\nreplaced by integrals. \\n \\nEXAMPLE \\n \\nLet X and Y be two discrete r.v.’s with the following joint p.d \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFind E(X), E(Y), E(X + Y), and E(XY). \\n \\nSOLUTION \\n \\nTo determine the expected values of X and Y, we first find the marginal p.d. g(x) and h(y) by adding over the columns \\nand rows of the two-way table as below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nand the conditional p.d.f. of Y given  \\nX = x, is \\n \\n      \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029xg\\ny,xfx|yf \\uf03d , where g(x) > 0 \\nHence  \\n      \\n\\uf028 \\uf029x|yf\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 4y2,x32\\nyx6\\nx34\\n1\\nyx68\\n1\\n\\uf0a3\\uf0a3\\uf02d\\n\\uf02d\\uf02d\\uf03d\\n\\uf02d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf02d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf03d  \\n \\nx \\n \\ny \\n2 4 \\n1 0.10 0.15 \\n3 0.20 0.30 \\n5 0.10 0.15 \\n \\nx \\n \\ny \\n2 4 h(y) \\n1 0.10 0.15 0.25 \\n3 0.20 0.30 0.50 \\n5 0.10 0.15 0.25 \\ng(x) 0.40 0.60 1.00 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 202}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       198                                                                                                                                           \\nNow  E(X) = \\uf0e5 xj g(xj)  \\n   = 2 × 0.40 + 4 × 0.60  \\n   = 0.80 + 2.40 = 3.2 \\n \\nE(Y) = \\uf0e5 yi h(yi)  \\n = 1 × 0.25 + 3 × 0.50 + 5 × 0.25 \\n = 0.25 + 1.50 + 1.25  \\n = 3.0 \\nHence  \\n E(X) + E(Y) = 3.2 + 3.0 = 6.2  \\n \\nIn order to compute E(XY) directly, we apply the formula: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5 \\uf02b\\uf03d\\uf02b\\ni j\\njiji y,xfyxYXE\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5\\uf03d\\ni j\\njiji y,xfyxXYE'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 203}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       199                                                                                                                                           \\n \\nLECTURE NO. 27 \\n\\uf0b7 Properties of Expected Values in the case of Bivariate Probability Distributions (Detailed discussion) \\n\\uf0b7 Covariance & Correlation  \\n\\uf0b7 Some Well-known Discrete Probability Distributions: \\n\\uf0a7 Discrete Uniform Distribution \\n\\uf0a7 An Introduction to the Binomial Distribution \\n \\nEXAMPLE \\n \\n Let X and Y be two discrete r.v.’s with the following joint p.d. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFind E(X), E(Y), E(X + Y), and E(XY). \\n \\nSOLUTION \\n \\nTo determine the expected values of X and Y, we first find the marginal p.d. g(x) and h(y) by adding over the columns \\nand rows of the two-way table as below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow  E(X) = \\uf0e5 xi g(xi)  \\n          = 2 × 0.40 + 4 × 0.60  \\n            = 0.80 + 2.40 = 3.2 \\nE(Y) = \\uf0e5 yj h(yj)  \\n = 1 × 0.25 + 3 × 0.50 + 5 × 0.25 \\n = 0.25 + 1.50 + 1.25  \\n = 3.0 \\nHence  \\n E(X) + E(Y) = 3.2 + 3.0 = 6.2 \\n \\n \\n \\n = (2 + 1) (0.10) + (2 + 3) (0.20) +  \\n    (2 + 5) (0.10) + (4 + 1) (0.15) + \\n    (4 + 3) (0.30) + (4 + 5) (0.15) \\n = 0.30 + 1.00 + 0.70 + 0.75 +  \\n    2.10 + 1.35 = 6.20 \\n = E(X) + E(Y) \\n \\nIn order to compute E(XY) directly, we apply the formula: \\n \\n \\n \\nIn this example,  \\n \\ny \\n \\nx \\n1 3 5 \\n2 0.10 0.20 0.10 \\n4 0.15 0.30 0.15 \\n \\ny \\n \\nx \\n1 3 5 g(x) \\n2 0.10 0.20 0.10 0.40 \\n4 0.15 0.30 0.15 0.60 \\nh(y) 0.25 0.50 0.25 1.00 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5 \\uf02b\\uf03d\\uf02b\\ni j\\njiji y,xfyxYXE\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5\\uf03d\\ni j\\njiji y,xfyxXYE\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0e5\\uf0e5\\uf03d\\ni j\\njiji y,xfyxXYE'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 204}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       200                                                                                                                                           \\n \\n= (2 \\uf0b4 1) (0.10) + (2 \\uf0b4 3) (0.20) +  (2 \\uf0b4 5) (0.10) + (4 \\uf0b4 1) (0.15) +  (4 \\uf0b4 3) (0.30) + (4 \\uf0b4 5) (0.15) \\n= 9.6 \\n \\nNow  \\nE(X) E(Y)  \\n  = 3.2 \\uf0b4 3.0  \\n  = 9.6 \\nHence E(XY) = E(X) E(Y) implying that X and Y are independent. \\nThis was the discrete situation; let us now consider an example of the continuous situation: \\n \\nEXAMPLE \\n Let X and Y be independent r.v.’s with joint p.d.f.  \\n \\n \\n \\n \\n \\n \\n \\n \\nFind E(X), E(Y), E(X + Y) and E(XY). To determine E(X) and E(Y), we first find the marginal p.d.f. g(x) and h(y) as \\nbelow: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029,4\\ny31x)y,x(f\\n2\\uf02b\\uf03d\\n \\n     0 < x < 2, 0 < y < 1 \\n = 0,  elsewhere. \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 dy4\\ny31xdyy,xfxg\\n1\\n0\\n2\\n\\uf0f2\\uf0f2\\n\\uf02b\\uf03d\\uf03d\\n\\uf0a5\\n\\uf0a5\\uf02d\\n \\n         \\n\\uf05b \\uf05d ,2\\nxxyxy4\\n1\\n1\\n0\\n3 \\uf03d\\uf02b\\uf03d  for 0 < x < 2. \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d dxy,xfyh\\n \\n\\uf028 \\uf029\\n2\\n0\\n2\\n22\\n0\\n2\\nxy32\\nx\\n4\\n1dx4\\ny31x\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02b\\uf03d\\uf02b\\uf03d \\uf0f2\\n \\n\\uf028 \\uf029,y312\\n1 2\\uf02b\\uf03d\\n for 0 < y < 1. \\nHence  \\n   \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d dxxgxXE  \\n \\nand,3\\n4\\n3\\nx\\n2\\n1dx2\\nxx\\n2\\n0\\n32\\n0\\n\\uf03d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d \\uf0f2  \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029dyy31y2\\n1dyyhyYE\\n1\\n0\\n2\\n\\uf0f2\\uf0f2 \\uf02b\\uf03d\\uf03d\\n\\uf0a5\\n\\uf0a5\\uf02d\\n \\n          \\n,8\\n5\\n4\\n3\\n2\\n1\\n2\\n1\\n4\\ny3\\n2\\ny\\n2\\n1\\n1\\n0\\n42\\n\\uf03d\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf02b\\uf03d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02b\\uf03d\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 205}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       201                                                                                                                                           \\nAnd \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIt should be noted that \\n \\ni) E(X) + E(Y) = 4/3 + 5/8  \\n        = 47/24 = E(X + Y), and \\n \\nii) E(X) E(Y) = (4/3) (5/8)  \\n     = 5/6 = E(XY). \\nHence, the two properties of mathematical expectation valid in the case of bivariate probability distributions are \\nverified. \\n \\nCOVARIANCE OF TWO RANDOM VARIABLES \\n \\nThe covariance of two r.v.’s X and Y is a numerical measure of the extent to which their values tend to increase or \\ndecrease together. It is denoted by \\uf073XY or Cov (X, Y), and is defined as the expected value of the product  \\n \\n[X – E(X)] [Y – E(Y)]. That is \\nCov (X, Y) = E {[X – E(X)] [Y – E(Y)]} \\nAnd the short cut formula is: \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf0f2 \\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf02b\\uf03d\\uf02b dydxy,xfyxYXE\\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0f2\\uf0f2\\n\\uf02b\\uf02b\\n2\\n0\\n21\\n0\\ndxdy4\\ny31xyx  \\n\\uf0f2\\uf0f2\\uf0f2\\uf0f2\\n\\uf02b\\uf02b\\uf02b\\uf03d\\n2\\n0\\n31\\n0\\n2\\n0\\n2221\\n0\\ndxdy4\\nxy3xydydx4\\nyx3x\\n \\n\\uf05b \\uf05d dx4\\nxy3\\n2\\nxy\\n4\\n1dxyxyx4\\n1 2\\n0\\n0\\n422\\n0 0\\n322\\n1\\n1\\n\\uf0f2\\uf0f2\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02b\\uf02b\\uf02b\\uf03d\\n \\n\\uf028 \\uf029 dx4\\nx3\\n2\\nx\\n4\\n1dxx24\\n1 2\\n0\\n2\\n0\\n2\\n\\uf0f2\\uf0f2 \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\uf02b\\uf03d\\n \\n2\\n0\\n22\\n0\\n3\\n8\\nx3\\n4\\nx\\n4\\n1\\n3\\nx\\n2\\n1\\n2\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02b\\uf03d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf03d\\n \\nand,24\\n47\\n8\\n5\\n3\\n4 \\uf03d\\uf02b\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0f2 \\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf0a5\\n\\uf0a5\\uf02d\\n\\uf03d dydxy,xfxyXYE\\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf0f2\\uf0f2\\uf0f2\\uf0f2\\n\\uf02b\\uf03d\\uf02b\\uf03d\\n2\\n0\\n3221\\n0\\n2\\n0\\n21\\n0\\ndxdy4\\nyx3yxdxdy4\\ny31xxy  \\n \\n6\\n5\\n12\\nx5\\n4\\n1dx4\\nx5\\n4\\n1dx4\\nyx3\\n2\\nyx\\n4\\n1\\n2\\n0\\n322\\n0\\n1\\n0\\n42222\\n0\\n\\uf03d\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02b\\uf03d \\uf0f2\\uf0f2  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 206}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       202                                                                                                                                           \\n \\nCov (X, Y) = E(XY) – E(X) E(Y). \\n \\nIf X and Y are independent, then   \\nE(XY) = E(X) E(Y), and \\nCov (X, Y) = E(XY) – E(X) E(Y)  \\n  = 0 \\nIt is very important to note that covariance is zero when the r.v.’s X and Y are independent but its converse is not \\ngenerally true. The covariance of a r.v. with itself is obviously its variance. \\n \\nCORRELATION CO-EFFICIENT OF TWO RANDOM VARIABLES \\n \\nLet X and Y be two r.v.’s with non-zero variances \\uf0732X and \\uf0732Y. Then the correlation coefficient which is a measure of \\nlinear relationship between X and Y, denoted by \\uf072XY (the Greek letter rho) or Corr(X, Y), is defined as \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf X and Y are independent r.v.’s, then \\uf072XY will be zero but zero correlation does not necessarily imply independence.  \\n \\nEXAMPLE \\n \\n From the following joint p.d. of X and Y, find Var(X), Var(Y), Cov(X,Y) and \\uf072. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow  \\nE(X)  = \\uf053xig(xi)  \\n = 0 \\uf0b4 0.20 + 1 \\uf0b4 0.50 +2 \\uf0b4 0.30 \\n = 0 + 0.50 + 0.60 = 1.10 \\nE(Y)  = \\uf053yjh(yj) \\n = 0 \\uf0b4 0.10 + 1 \\uf0b4 0.30 + 2 \\uf0b4 0.45 + 3 \\uf0b4 0.15 \\n = 0 + 0.30 + 0.90 + 0.45 = 1.65 \\nE(X2)  = \\uf053xi2g(xi)  \\n = 0 \\uf0b4 0.20 + 1 \\uf0b4 0.50 + 4 \\uf0b4 0.30  \\n = 1.70 \\nE(Y2)  = \\uf053yj2h(yj)  \\n = 0 \\uf0b4 0.10 + 1 \\uf0b4 0.30 + 4 \\uf0b4 0.45 + 9 \\uf0b4 0.15 \\n  = 3.45 \\n \\nThus  \\nVar(X) = E(X2) – [E(X)]2  \\n = 1.70 – (1.10)2 = 0.49, \\nand \\n \\nVar(Y) = E(Y2) – [E(Y)]2  \\n = 3.45 – (1.65)2 = 0.7275 \\n \\nAgain: \\nE(XY)  = \\n \\n      = 1 \\uf0b4 0.10  + 2 \\uf0b4 0.15 + 2 \\uf0b4 0.25 + 4 \\uf0b4 0.10 + 3 \\uf0b4 0.10 + 6 \\uf0b4 0.05 \\n\\uf028 \\uf029\\uf05b \\uf05d \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029YVarXVar\\nY,XCov\\nXEYXEXE\\nYX\\nXY\\n\\uf03d\\n\\uf073\\uf073\\n\\uf02d\\uf02d\\uf03d\\uf072\\n       y \\n \\nx \\n0 1 2 3 g(x) \\n0 0.05 0.05 0.10 0 0.20 \\n1 0.05 0.10 0.25 0.10 0.50 \\n2 0 0.15 0.10 0.05 0.30 \\nh(y) 0.10 0.30 0.45 0.15 1.00 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029jiji\\nji\\nyxfyx ,\\uf0e5\\uf0e5'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 207}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       203                                                                                                                                           \\n  = 0.10 + 0.30 + 0.50 + 0.40 + 0.30 + 0.30  \\n  = 1.90 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, we can say that there is a weak positive linear correlation between the random variables X and Y.  \\n \\nEXAMPLE \\n \\nIf f(x, y)  \\n   = x2 + xy/3 , 0 < x < 1, 0 < y < 2 \\n   = 0,  elsewhere, \\nFind   \\nVar(X), Var(Y) and Corr(X,Y) \\n \\nSOLUTION \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf05c Cov(X,Y) = E(XY) – E(X) E(Y)  \\n    = 1.90 – 1.10 \\uf0b4 1.65 = 0.085, and \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n14.0\\n595.0\\n085.0\\n7275.0)49.0(\\n085.0\\nYVarXVar\\nY,XCov\\n\\uf03d\\n\\uf03d\\uf03d\\n\\uf03d\\uf072\\n    \\nThe marginal p.d.f.’s are \\n   \\n\\uf028 \\uf029\\n1x0\\n,x2\\n3x2dy3\\nxyxxg 222\\n0\\n\\uf0a3\\uf0a3\\n\\uf02b\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf03d\\uf0f2  \\nand \\n   \\n\\uf028 \\uf029\\n2y0\\n,6\\ny\\n3\\n1dx3\\nxyxyh 21\\n0\\n\\uf0a3\\uf0a3\\n\\uf02b\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf03d\\uf0f2  \\nNow  \\n   \\n\\uf028 \\uf029 \\uf028 \\uf029\\n,18\\n13dx3\\nx2x2x\\ndxxxgXE\\n21\\n0\\n\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf03d\\n\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d  \\n   \\n\\uf028 \\uf029 \\uf028 \\uf029\\n.9\\n10dy6\\ny\\n3\\n1y\\ndyyyhYE\\n2\\n0\\n\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\uf03d\\n\\uf03d\\n\\uf0f2\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d  \\nThus  \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029 \\uf028 \\uf029dxxgx\\nXEXEXVar\\n2\\nx\\n2\\n\\uf06d\\uf02b\\uf03d\\n\\uf02d\\uf03d\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n \\n \\n1620\\n73dx3\\nx2x218\\n13x 2\\n21\\n0\\n\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf03d\\uf0f2  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 208}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       204                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence we can say that there is a VERY weak negative linear correlation between X and Y. In other words, X and Y are \\nalmost uncorrelated. This brings us to the end of the discussion of the BASIC concepts of discrete and continuous \\nUnivariate and bivariate probable. We now begin the discussion of some probability distributions that are WELL-\\nKNOWN, and are encountered in real-life situations. \\n \\nDISCRETE UNIFORM DISTRIBUTION \\n \\nEXAMPLE \\n \\nSuppose that we toss a fair die and let X denote the number of dots on the upper-most face. Since the die is fair, hence \\neach of the X-values from 1 to 6 is equally likely to occur, and hence the probability distribution of the random variable \\nX is as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we draw the line chart of this distribution, we obtain Line Chart Representation of the  Discrete Uniform Probability \\nDistribution \\nCov(X, Y)   \\n = E{[X – E(X)] [Y – E(Y)]} \\n \\ndxdy3\\nxyx9\\n10y18\\n13x 22\\n0\\n1\\n0\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf03d \\uf0f2\\uf0f2  \\n \\n.162\\n1dxx243\\n26x81\\n25x9\\n2 231\\n0\\n\\uf02d\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02b\\uf02d\\uf03d\\uf0f2  \\nHence  \\n    \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n05.0\\n8126)162073(\\n1621\\nYVarXVar\\nY,XCovY,XCorr\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\n\\uf03d  \\nX P(x) \\n1 1/6 \\n2 1/6 \\n3 1/6 \\n4 1/6 \\n5 1/6 \\n6 1/6 \\nTotal 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029 \\uf028 \\uf029dyyhy\\nYEYEYVar\\n2\\ny\\n2\\n\\uf06d\\uf02d\\uf03d\\n\\uf02d\\uf03d\\n\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d\\n \\n             \\nand,81\\n26dy6\\ny\\n3\\n1\\n9\\n10y\\n22\\n0\\n\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf03d \\uf0f2  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 209}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       205                                                                                                                                           \\n \\n \\nAs all the vertical line segments are of equal height, hence this distribution is called a uniform distribution.  \\nAs this distribution is absolutely symmetrical, therefore the mean lies at the exact centre of the distribution i.e. the mean \\nis equal to 3.5. \\n \\n LINE CHART REPRESENTATION OF THE DISCRETE UNIFORM PROBABILITY DISTRIBUTION \\n \\n \\n \\nWhat about the spread of this distribution? You are encouraged to compute the standard deviation as well as the \\ncoefficient of variation of this distribution on their own. Let us consider another interesting example. \\n \\nEXAMPLE \\n \\nThe lottery conducted in various countries for purposes of money-making provides a good example of the discrete \\nuniform distribution. Suppose that, in a particular lottery, as many as ten thousand lottery tickets are issued, and the \\nnumbering is 0000 to 9999. Since each of these numbers is equally likely to occur, hence we have the following \\nsituation: \\n \\n \\n \\n \\n \\n \\n \\n \\nNo. of  dots on the upper-most face \\n \\nProbability \\nP(x) \\n1/6 \\n2/6 \\n0 \\n1 2 3 4 5 6 X \\nNo. of  dots on the  \\nupper-most face \\n \\nProbability \\nP(x) \\n1/6 \\n2/6 \\n0 \\n1 2 3 4 5 6 \\nX \\n\\uf06d = E(X) = 3.5 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 210}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       206                                                                                                                                           \\n \\n \\n \\n \\n \\n   Discrete Uniform Distribution \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nINTERPRETATION \\n \\nIt reflects the fact that winning lottery numbers are selected by a random procedure which makes all numbers equally \\nlikely to be selected. The point to be kept in mind is that, whenever we have a situation where the various outcomes are \\nequally likely, and of a form such that we have a random variable X with values 0, 1, 2, … or , as in the above example, \\n0000, 0001 …, 9999, we will be dealing with the discrete uniform distribution. \\n \\nBINOMIAL DISTRIBUTION \\n \\nThe binomial distribution is a very important discrete probability distribution. It was discovered by James Bernoulli \\nabout the year 1700.We illustrate this distribution with the help of the following example: \\n \\nEXAMPLE \\n \\nSuppose that we toss a fair coin 5 times, and we are interested in determining the probability distribution of X, where X \\nrepresents the number of heads that we obtain. \\nWe note that in tossing a fair coin 5 times: \\n\\uf0b7 every toss results in either a head or a tail,  \\n\\uf0b7 the probability of heads (denoted by p) is equal to ½ every time (in other words, the probability of \\nheads remains constant),  \\n\\uf0b7 every throw is independent of every other throw, and \\n\\uf0b7 the total number of tosses i.e. 5 is fixed in advance. \\nThe above four points represents the four basic and vitally important PROPERTIES of a binomial experiment \\n \\nPROPERTIES OF A BINOMIAL EXPERIMENT \\n \\n\\uf0b7 Every trial results in a success or a failure. \\n\\uf0b7 The successive trials are independent. \\n\\uf0b7 The probability of success, p, remains constant from trial to trial. \\n\\uf0b7 The number of trials, n, is fixed in advanced. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n000\\n0 000\\n1 000\\n2 000\\n3 000\\n4 000\\n5 000\\n6 000\\n7 000\\n8 000\\n9 \\n999\\n6 999\\n6 999\\n7 999\\n8 999\\n9 \\nProbability  \\nof Winning \\n1/1000\\n0 \\nLottery Number \\nX '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 211}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       207                                                                                                                                           \\n \\nLECTURE NO. 28 \\n\\uf0b7 Binomial Distribution \\n\\uf0b7 Fitting a Binomial Distribution to Real Data \\n\\uf0b7 An Introduction to the Hyper geometric Distribution  \\nThe binomial distribution is a very important discrete probability distribut ion. We illustrate this distribution with the \\nhelp of the following example: \\n \\nEXAMPLE \\n \\nSuppose that we toss a fair coin 5 times, and we are interested in determining the probability distribution of X, where X \\nrepresents the number of heads that we obtain. We note that in tossing a fair coin 5 times: \\n\\uf0b7 Every toss results in either a head or a tail,  \\n\\uf0b7 The probability of heads (denoted by p) is equal to  ½ every time (in other words, the probability of heads \\nremains constant),  \\n\\uf0b7 Every throw is independent of every other throw, and \\n\\uf0b7 The total number of tosses i.e. 5 is fixed in advance. \\nThe above four points represents the four basic and vitally important PROPERTIES of binomial experiment. Now, in 5 \\ntosses of the coin, there can be 0, 1, 2, 3, 4 or 5 heads, and the no. of heads is thus a random variable which can take one \\nof these six values. In order to compute the probabilities of these X-values, the formula is: \\n \\nBinomial Distribution \\n \\nWhere   \\nn = the total no. of trials \\np = probability of success in each trial \\nq = probability of failure in \\neach trial (i.e. q = 1 - p) \\nx =  no. of successes in n trials. \\nx =  0, 1, 2, … n \\n \\nThe binomial distribution has two parameters, n and p.  In this example, n = 5 since the coin was thrown 5 times,  p = ½ \\nsince it is a fair coin, q = 1 – p = 1 – ½ = ½ Hence \\n \\nPutting x = 0 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPutting x = 1 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 xnxn\\nx qpxXP \\uf02d\\uf03d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\nxx\\nxxXP\\n\\uf02d\\n\\uf03d\\uf03d\\n5\\n2\\n1\\n2\\n15\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\n05\\n2\\n10\\n2\\n15\\n00XP\\n\\uf02d\\n\\uf03d\\uf03d\\n \\n\\uf028 \\uf029\\uf028 \\uf029\\n5\\n2\\n11!5!0\\n!5\\uf03d\\n \\n \\n\\uf028 \\uf029\\uf028 \\uf029 32\\n111\\n5\\n2\\n1 \\uf03d\\uf03d  \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\n15\\n2\\n11\\n2\\n15\\n11XP\\n\\uf02d\\n\\uf03d\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n4\\n2\\n11\\n2\\n1\\n!4!1\\n!5\\uf03d\\n \\n\\uf028 \\uf029\\uf028 \\uf0292\\n1\\n1\\n5\\uf03d\\n \\n \\n\\uf028 \\uf029 32\\n5\\n32\\n155\\n5\\n2\\n1 \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 212}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       208                                                                                                                                           \\n \\nSimilarly, we have:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, the binomial distribution for this p articular example is as follows. Binomial Distribution in the case of tossing a \\nfair coin five times: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nGraphical Representation of the above binomial distribution: \\n \\n \\nThe next question is: What about the mean and the standard deviation of this distribution? We can calculate them just as \\nbefore, using the formulas  \\n \\nMean of X = E(X) = \\uf0e5XP(X) \\nVar(X) = \\uf0e5X2 P(X) – [\\uf0e5XP(X)]2  \\n10/32 \\n8/32 \\n6.32 \\n2/32 \\n4/32 \\n0 1 2 3 4 \\nX \\n5 \\nP(x) \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029 32\\n102XP\\n25\\n2\\n12\\n2\\n15\\n2 \\uf03d\\uf03d\\uf03d\\n\\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029 32\\n103XP\\n35\\n2\\n13\\n2\\n15\\n3 \\uf03d\\uf03d\\uf03d\\n\\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029 32\\n54\\n45\\n2\\n14\\n2\\n15\\n4 \\uf03d\\uf03d\\uf03d\\n\\uf02d\\nXP\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029 32\\n15\\n55\\n2\\n15\\n2\\n15\\n5 \\uf03d\\uf03d\\uf03d\\n\\uf02d\\nXP\\nNumber of Heads \\nX \\nProbability \\nP(x) \\n0 1/32 \\n1 5/32 \\n2 10/32 \\n3 10/32 \\n4 5/32 \\n5 1/32 \\nTotal 32/32 = 1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 213}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       209                                                                                                                                           \\nbut it has been mathematically proved that for a binomial distribution given by \\n \\n \\n \\nFor a binomial distribution \\nE(X) = np  \\nand Var(X) = npq \\nso that  \\n \\nFor the above example, n = 5, p = ½ and q = ½ \\nHence \\nMean = E(X) = np = 5(½) = 2.5 \\n \\n \\n \\nWe would have got exactly the same answers if we had applied the LENGTHIER procedure. \\nE(X) = \\uf0e5XP(X) and Var X = \\uf0e5X2 P(X)-[\\uf0e5XP(X)]2 \\nGraphical Representation of the Mean and Standard Deviation of the Binomial Distribution (n=5, p=1/2) \\n \\n \\nWHAT DOES THIS MEAN? \\n \\nWhat this mean is that if 5 fair coins are tossed an INFINITE no. of times, sometimes we will get no head out of 5, \\nsometimes/head… sometimes all 5 heads.  But on the AVERAGE we should expect to get 2.5 heads in 5 tosses of the \\ncoin, or, a total of 25 heads in 50 tosses of the coin And 1.12 gives a measure of the possible variability in the various \\nnumbers of heads that can be obtained in 5 tosses. (As you know, in this problem, the number of heads can range from 0 \\nto 5 had the coin been tossed 10 times, the no. of heads possible would vary from 0 to 10 and the standard deviation \\nwould probably have been different). \\n \\nCoefficient of Variation: \\n \\n \\n \\n \\nNote that the binomial distribution is not always symmetrical as in the above example. It will be symmetrical only when \\np = q = ½ (as in the above example). \\n \\n \\n \\n10/32 \\n8/32 \\n6.32 \\n2/32 \\n4/32 \\n0 1 2 3 4 5 \\nE(X) S.D.(X) \\n1.12 \\nX \\nP(x) \\n\\uf028 \\uf029 \\uf028 \\uf029 xnxn\\nx qpxXP \\uf02d\\uf03d\\uf03d\\n\\uf028 \\uf029 npqXDS \\uf03d..\\nand S.D.(X) \\n\\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf0294\\n5\\n2\\n1\\n2\\n15npq \\uf03d\\uf03d\\uf03d  = 1.12 \\n%8.441005.2\\n12.1100.V.C \\uf03d\\uf0b4\\uf03d\\uf0b4\\uf06d\\n\\uf073\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 214}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       210                                                                                                                                           \\n \\nIt is skewed to the right if p < q: \\n \\n \\n \\n \\nIt is skewed to the left if p > q: \\n \\n0 1 2 3 4 \\nX \\n5 \\nP(x) \\n0 1 2 3 4 \\nX \\n5 \\nP(x) \\n6 7 \\n7 6 5 4 3 \\nX \\n2 1 0 \\nP(x) '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 215}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       211                                                                                                                                           \\nBut the degree of Skewness (or asymmetry) decreases as n increases.  Next, we consider the  Fitting of a \\nBinomial Distribution to Real Data. We illustrate this concept with the help of the following example: \\n \\nEXAMPLE \\n \\nThe following data has been obtained by tossing a LOADED die 5 times, and noting the number of times that we \\nobtained a six. Fit a binomial distribution to this data. \\n \\n \\n \\n \\n \\n \\n \\nSOLUTION \\n \\nTo fit a binomial distribution, we need to find n and p.  \\n Here n = 5, the largest x-value.  \\n To find p, we use the relationship \\uf060x = np.  \\n \\nThe rationale of this step is that, as indicated in the last lecture, the mean of a binomial probability distribution is equal \\nto np, i.e. \\n \\uf06d = np \\nBut, here, we are not dealing with a probability distribution i.e. the entire population of all possible sets of throws of a \\nloaded die --- we only have a sample of throws at our disposal. \\nAs such, \\uf06d is not available to us, and all we can do is to replace it by its estimate \\uf060X. \\nHence, our equation becomes\\uf060X = np.  \\nNow, we have: \\n \\n \\n \\n \\n \\n \\n \\n \\nUsing the relationship \\uf060x = np, we get 5p = 1.99 or p = 0.398.This value of p seems to indicate clearly that the die is not \\nfair at all! (Had it been a fair die, the probability of getting a six would have been 1/ 6 i.e. 0.167; a value of p = 0.398 is \\nvery different from 0.167.) Letting the random variable X represent the number of sixes, the above calculations yield \\nthe fitted binomial distribution as \\n \\n \\n \\nHence the probabilities and expected frequencies are calculated as below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNo. of Sixes 0 1 2 3 4 5 Total \\nFrequency 12 56 74 39 18 1 200 \\n \\n99.1200\\n398\\n200\\n572117148560\\nf\\nxfx\\ni\\nii\\n\\uf03d\\uf03d\\n\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\nxx\\nxxb\\n\\uf02d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\n5\\n602.0398.05398.0,5;\\nNo. of \\nSixes  (x) Probability f(x) Expected \\nfrequency \\n0 \\n\\uf028 \\uf02955 602.0q0\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.07907 15.8 \\n1 \\n\\uf028 \\uf029 \\uf028 \\uf029398.0602.0.5pq1\\n5 45 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.26136 52.5 \\n2 \\n\\uf028 \\uf029 \\uf028 \\uf0292323 398.0602.0.10pq2\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.34559 69.1 \\n3 \\n\\uf028 \\uf029\\uf028 \\uf029332 398.0602.0.10pq3\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.22847 45.7 \\n4 \\n\\uf028 \\uf029\\uf028 \\uf02944 398.0602.0qp4\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.07553 15.1 \\n5 \\n\\uf028 \\uf02955 398.0p5\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.00998 2.0 \\nTotal  = 1.00000 200.0 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 216}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       212                                                                                                                                           \\nIn the above table, the expected frequencies are obtained by multiplying each of the probabilities by 200.  \\n In the entire above procedure, we are assuming that the given frequency distribution has the characteristics of \\nthe fitted theoretical binomial distribution, comparing the observed frequencies with the expected frequencies, we \\nobtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe graphical representation of the observed frequencies as well as the expected frequencies is as follows: \\n \\nThe above graph quite clearly indicates that there is not much discrepancy between the observed and the expected \\nfrequencies. Hence, we can say that it is a reasonably good fit. \\nThere is a procedure known as the Chi -Square Test of Goodness of Fit which enables us to determine in a formal, \\nmathematical manner whether or not the theoretical distribution fits the observed distribution reasonably well.  This test \\ncomes under the realm of Inferential Statistics --- that area which we w ill deal with during the last 15 lectures of this \\ncourse. Let us consider a real-life application of the binomial distribution: \\n \\nAN EXAMPLE FROM INDUSTRY \\n \\nSuppose that the past record indicates that the proportion of defective articles produced by this fac tory is 7%.And \\nsuppose that a law NEWLY instituted in this particular country states that there should not be more than 5% defective. \\nSuppose that the factory -owner makes the statement that his machinery has been overhauled so that the number of \\ndefectives has DECREASED. \\nIn order to examine this claim, the relevant government department decides to send an inspector to examine a sample of \\n20 items. \\nGraphical Representation of the Observed and Expected \\nFrequencies: \\n75 \\n60 \\n45 \\n15 \\n30 \\n0 1 2 3 4 \\nX \\n5 \\nFrequency \\nObserved frequency \\nExpected frequency \\nNo. of \\nSixes  \\nx \\nObserved \\nFrequency \\nf0 \\nExpected \\nFrequency \\nfe \\n0 12 15.8 \\n1 56 52.5 \\n2 74 69.1 \\n3 39 45.7 \\n4 18 15.1 \\n5 1 2.0 \\nTotal 200 200.0 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 217}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       213                                                                                                                                           \\nWhat is the probability that the inspector will find 2 or more defective items in his sample (so that a fine wi ll be \\nimposed on the factory)?  \\n \\nSOLUTION \\n \\nThe first step is to ident ify the NATURE of the situation, If we study this problem closely, we realize that we are \\ndealing with a binomial experiment because of the fact that all four properties of a binomial exp eriment are being \\nfulfilled: \\n \\nPROPERTIES OF A BINOMIAL EXPERIMENT \\n \\n\\uf0b7 Every item selected will either be defective (i.e. success) or not defective (i.e. failure) \\n\\uf0b7 Every item drawn is independent of every other item \\n\\uf0b7 The probability of obtaining a defective item  i.e. 7% is the same (constant) for all items. (This probability \\nfigure is according to relative frequency definition of probability. \\n\\uf0b7 The number of items dr awn is fixed in advance i.e. 20 hence; we are in a position to apply the binomial \\nformula \\n \\n \\n \\n \\n \\n \\n \\nSubstituting n = 20 and p = 0.07, we obtain: \\n \\nNow  \\nP(X > 2) = 1 - P(X < 2) \\n  = 1- [P(X = 0) + P(X =1)] \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence the probability is SUBSTANTIAL i.e. more than 40% that the inspector will find two or more defective articles \\namong the 20 that he will inspect. In other words, there is CONSIDERABLE chance that the factory will be fined. \\nThe point to be realized is that, generally speaking, whenever we are dealing with a ‘success / failure’ situation, we are \\ndealing with what can be a binomial experiment . (For EXAMPLE, if we are interested in determining any of the \\nfollowing proportions, we are dealing with a BINOMIAL situation: \\n\\uf0b7 Proportion of smokers in a city smoker \\uf0ae success, non-smokers \\uf0ae failure. \\n\\uf0b7 Proportion of literates in a community \\uf0ae literacy rate, literate \\uf0ae success, illiterate \\uf0ae failure. \\n\\uf0b7 Proportion of males in a city \\uf0ae sex ratio). \\n \\nHYPERGEOMETRIC PROBABILITY DISTRIBUTION \\n \\nThere are many experiments in which the condition of independence is violated and the probability of success does not \\nremain constant for all trials. Such experiments are called hyper geometric experiments.  \\n In other words, a hyper geometric experiment has the following properties: \\n \\nPROPERTIES OF HYPERGEOMETRIC EXPERIMENT \\n \\n\\uf0b7 The outcomes of each trial may be classified into one of two categories, success and failure. \\n\\uf0b7 The probability of success changes on each trial. \\n\\uf0b7 The successive trials are not independent. \\n\\uf0b7 The experiment is repeated a fixed number of times. \\nThe number of success, X in a hyper geometric experiment is called a hyper  geometric random variable and its \\nprobability distribution is called the hyper geometric distribution. When the hyper geometric random variable X \\nassumes a value x, the hyper geometric probability distribution is given by the formula \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 xnxn\\nx qpxXP \\uf02d\\uf03d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029 x20x20\\nx 93.007.0xXP \\uf02d\\uf03d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n%3.41\\n413.0\\n353.0234.01\\n93.007.02093.0111\\n]93.007.093.007.01\\n1920\\n120120\\n1\\n020020\\n0\\n\\uf03d\\n\\uf03d\\n\\uf02d\\uf02d\\uf03d\\n\\uf0b4\\uf0b4\\uf02d\\uf0b4\\uf0b4\\uf02d\\uf03d\\n\\uf02d\\uf02d\\uf03d \\uf02d\\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 218}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       214                                                                                                                                           \\n \\n \\n \\nWhere  \\nN = number of units in the population,  \\nn = number of units in the sample, and  \\nk = number of successes in the population. \\nThe hyper geometric probability distribution has three parameters N, n and k.  \\nThe hyper geometric probability distribution is appropriate when \\n \\n\\uf0b7 a random sample of size n is drawn WITHOUT REPLACEMENT from a finite population of N units; \\n \\n\\uf0b7 k of the units are of one kind (classified as success) and the remaining N – k of another kind (classified as \\nfailure). \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n,xXP N\\nn\\nkN\\nxn\\nk\\nx\\n\\uf02d\\n\\uf02d\\uf03d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 219}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       215                                                                                                                                           \\nLECTURE NO. 29 \\n\\uf0b7 Hyper geometric Distribution  \\n(in some detail) \\n\\uf0b7 Poisson Distribution  \\n\\uf0b7 Limiting Approximation to the Binomial  \\n\\uf0b7 Poisson Process \\n\\uf0b7 Continuous Uniform Distribution  \\n \\nIn the last lecture, we began the discussion of the HYPERGEOMETRIC PROBABILITY DISTRIBUTION. We now \\nconsider t his distribution in some detail. As indicated in the last lecture, there are many experiments in which the \\ncondition of independence is violated and the probability of success does not remain constant for all trials. Such \\nexperiments are called hyper geometric experiments. In other words, a hyper geometric experiment has the following \\nproperties: \\n \\nPROPERTIES OF HYPERGEOMETRIC EXPERIMENT \\n \\n\\uf0b7 The outcomes of each trial may be classified into one of two categories, success and failure. \\n\\uf0b7 The probability of success changes on each trial. \\n\\uf0b7 The successive trials are not independent. \\n\\uf0b7 The experiment is repeated a fixed number of times. \\nThe number of success, X in a hyper geometric experiment is called a hyper geometric random variable and its \\nprobability distribution is called the hyper geometric distribution. When the hyper geometric random variable X \\nassumes a value x, the hyper geometric probability distribution is given by the formula \\n \\n \\n \\n \\nwhere  \\nN = number of units in the population,  \\nn = number of units in the sample,  \\nand  \\nk = number of successes in the population. \\nThe hyper geometric probability distribution  \\nhas three parameters N, n and k.  \\n\\uf0b7 The hyper geometric probability distribution is appropriate when \\n\\uf0b7 a random sample of size n is drawn WITHOUT REPLACEMENT from a finite population of N units; \\n\\uf0b7 k of the units are of one kind (classified as success) and the remaining N – k of another kind (classified as \\nfailure). \\n \\nEXAMPLE \\n \\nThe names of 5 men and 5 women are written on slips of paper and placed in a hat. Four names are drawn. What is the \\nprobability that 2 are men and 2 are women?  Let us regard ‘men’ as success. Then X will denote the number of \\nmen. We have N = 5 + 5 = 10 names to be drawn from; Also, n = 4, (since we are drawing a sample of size 4 out of a \\n‘population’ of size 10) In addition, k = 5 (since there are 5 men in the population of 10). In this problem, the possible \\nvalues of X are 0, 1, 2, 3, 4, i.e. n): The hyper geometric distribution is given by \\n \\n \\n \\n \\n \\nSince N = 10, k = 5 and n = 4, hence, in this problem, the hyper geometric distribution is given by \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n,xXP N\\nn\\nkN\\nxn\\nk\\nx\\n\\uf02d\\n\\uf02d\\uf03d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n,xXP N\\nn\\nkN\\nxn\\nk\\nx\\n\\uf02d\\n\\uf02d\\uf03d\\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\uf03d\\n4\\n10\\nx4\\n5\\nx\\n5\\n)xX(P'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 220}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       216                                                                                                                                           \\nand the required probability,  \\ni.e  P(X = 2) is \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn other words, the probability is a little less than 50% that two of the four names drawn will be those of MEN. In the \\nabove example, just as we have computed the probability of X = 2, we could also have computed the probabilities of X \\n= 0, X = 1, X = 3 and X = 4 (i.e. the probabilities of having zero, one, three OR four men among the four names \\ndrawn).The students are encouraged to compute these probabilities on their own, to check that the sum of these \\nprobabilities is 1, and to draw the line chart of this distribution. \\nAdditionally, the students are encouraged to think about the centre, spread and shape of the distribution. Next, we \\nconsider some important PROPERTIES of the  Hyper \\ngeometric Distribution: \\n \\nPROPERTIES OF THE HYPERGEOMETRIC DISTRIBUTION \\n \\n\\uf0b7 The mean and the hyper geometric probability distribution are \\nN\\nkn\\uf03d\\uf06d\\n and \\n,1N\\nnN\\nN\\nkN\\nN\\nkn2\\n\\uf02d\\n\\uf02d\\uf02d\\uf03d\\uf073  \\n \\n\\uf0b7 If N becomes indefinitely large, the hyper geometric probability distribution tends to the BINOMIAL \\nprobability distribution. \\nThe above property will be best understood with reference to the following important points: \\n\\uf0b7 There are two ways of drawing a sample from a population, sampling with replacement, and sampling without \\nreplacement. \\n\\uf0b7 Also, a sample can be drawn from either a finite population or an infinite population.  \\nThis leads to the following bivariate table: With reference to sampling, the various possible situations are: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe point to be understood is that, whenever we are sampling with replacement, the population remains undisturbed \\n(because any element that is drawn at any one draw, is re -placed into the population befo re the next draw).Hence, we \\ncan say that the various trials (i.e. draws) are independent, and hence we can use the binomial formula. On the other \\nhand, when we are sampling without replacement from a finite population, the constitution of the population ch anges at \\nevery draw (because any element that is drawn  at any one draw is not re -placed into the population before the next \\ndraw).  Hence, we cannot say that the various trials are independent, and hence the formula that is appropriate in this \\nparticular situation is the hyper geometric formula.  But, if the population size is much larger than the sample size (so \\nthat we can regard it as an ‘infinite’ population), then we note that, although we are not re -placing any element that has \\nbeen drawn back into th e population, the population remains almost undisturbed. As such, we can assume that the \\nvarious trials (i.e. draws) are independent, and, once again, we can apply the binomial formula. \\nIn this regard, the generally accepted rule is that the binomial formula can be applied when we are drawing a sample \\nfrom a finite population without replacement and the sample size n is not more than 5 percent of the population size N, \\nor, to put it in another way, when n < 0.05 N. \\nWhen n is greater than 5 percent of N, the hyper geometric formula should be used.  \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n21\\n10\\n210\\n1010\\n2XP\\n10\\n4\\n5\\n2\\n5\\n2\\n10\\n4\\n5\\n24\\n5\\n2\\n\\uf03d\\n\\uf0b4\\uf03d\\n\\uf03d\\n\\uf03d\\uf03d \\uf02d\\n \\nPopulation \\nSampling \\nFinite Infinite \\nWith \\nreplacement   \\nWithout \\nreplacement   \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 221}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       217                                                                                                                                           \\nNext, we discuss the Poisson Distribution. \\n \\nPOISSON DISTRIBUTION \\n \\nThe Poisson distribution is named after the French mathematician Sime’on Denis Poisson (1781 -1840) who published \\nits derivation in the year 1837.THE  POISSON DISTRIBUTION ARISES IN THE FOLLOWING TWO \\nSITUATIONS: \\n\\uf0b7 It is a limiting approximation to the binomial distribution, when p, the probability of success is very small but \\nn, the number of trials is so large that the product np = \\uf06d is of a moderate size; \\n\\uf0b7 a distribution in its own right by considering a POISSON PROCESS where events occur randomly over a \\nspecified interval of time or space or length.  \\nSuch random events might be the number of typing errors per page in a book, the number of traffic accidents in a \\nparticular city in a 24-hour period, etc. \\nWith regard to the first situation, if we assume that n goes to infinity and p approaches zero in such a way that \\uf06d = np \\nremains constant, then the limiting form of the binomial probability distribution is  \\n \\n \\n \\n \\n \\nwhere e = 2.71828. \\nThe Poisson distribution has only one parameter \\uf06d > 0.  \\n The parameter \\uf06d may be interpreted as the mean of the distribution.  \\nAlthough the theoretical requirement is that n should tend to infinity, and p should tend to zero, but i n PRACTICE, \\ngenerally, most statisticians use the Poisson approximation to the binomial when \\n  p is 0.05 or less,  \\n & n is 20 or more,  \\nbut in fact, the LARGER n is and the SMALLER p is, the better will be the approximation.  We illustrate this particular \\napplication of the Poisson distribution with the help of the following example: \\n \\nEXAMPLE \\n \\nTwo hundred passengers have made reservations for an airplane flight. If the probability that a passenger who has a \\nreservation will not show up is 0.01, what is the probability that exactly three will not show up? \\n \\nSOLUTION \\n \\nLet us regard a “no show” as success. Then this is essentially a binomial experiment with n = 200 and p = 0.01. Since p \\nis very small and n is considerably large, we shall apply the Poisson distribution, using \\n\\uf06d= np = (200) (0.01) = 2. \\nTherefore, if X represents the number of successes (not showing up), we have \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPOISSON PROCESS  \\n \\nmay be defined as a physical process governed at least in part by some random mechanism.  \\nStated differently a poisson process represents a situation where events occur randomly over a specified interval of time \\nor space or length. Such random events might be the number of taxicab arrivals at an intersection per day; the number \\nof traffic deaths per month in a city; the number of radioactive particles emitted in a given period; the number of flaws \\nper unit length of some material; the number of typing errors per page in a book; etc. \\nThe formula valid in the case of a Poisson process is:  \\n \\n \\n \\n\\uf028 \\uf029 \\uf0a5\\uf03d\\uf06d\\uf03d\\n\\uf06d\\uf02d\\n\\uf0ae\\n\\uf0a5\\uf0ae\\n,...,2,1,0x,!x\\nep,n;xb\\nx\\n0p\\nLim\\nn\\n\\uf028 \\uf029 \\uf028 \\uf029\\n!3\\n2e3XP\\n32\\uf02d\\n\\uf03d\\uf03d\\n \\n      \\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf03d\\uf03d\\n\\uf03d\\uf0b4\\uf0b4\\uf03d\\n\\uf02d 1353.0\\n71828.2\\n1e\\n0.1804123\\n81353.0\\n2\\n2\\uf051  \\n\\uf028 \\uf029 \\uf028 \\uf029 ,!x\\ntexXP\\nxt \\uf06c\\uf03d\\uf03d\\n\\uf06c\\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 222}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       218                                                                                                                                           \\nwhere  \\n\\uf06c = average number of \\n occurrences of the outcome  \\n of interest per unit of time, \\nt  =  number of time-units  \\n under consideration, and \\nx =  number of occurrences of the \\n outcome of interest in t units of time. \\nWe illustrate this concept with the help of the following example: \\n \\nEXAMPLE \\n \\nTelephone calls are being placed through a certain exchange at random times on the average of four per minute. \\nAssuming a Poisson Process, determine the probability that in a 15-second interval, there are 3 or more calls.  \\n \\nSOLUTION \\n \\nStep-1: Identify the unit of time: \\nIn this problem we take a minute as the unit of time. \\n \\n \\nStep-2: Identify\\uf06c, the average number of occurrences of the outcome of interest per unit of time,  \\nIn this problem we have the information that, on the average, 4 calls are received per minute, hence:  \\n  \\uf06c = 4 \\nStep-3: Identify t, the number of time-units under consideration. In this problem, we are interested in a 15-second \\ninterval, and since 15 seconds are equal to 15/60 = ¼ minutes i.e. 1/4 units of time, therefore t = 1/4 \\nStep-4: Compute \\uf06ct: In this problem,  \\n  \\uf06c = 4,   & \\n t = 1/4,  \\nHence: \\n \\uf06ct = 4 \\uf0b4 ¼ = 1 \\nStep-5: Apply the Poisson formula  \\n \\n \\n \\n \\nIn this problem, since \\uf06ct = 1, therefore and since we are interested in 3 or more calls in a 15-second interval, therefore  \\n \\nP(X > 3) = 1 - P(X < 3) \\n = 1 - [P(X=0)+P(X=1)+P(X=2)] \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence the probability is only 8% (i.e. a very low probability) that in a 15-second interval, the telephone exchange \\nreceives 3 or more calls. \\n \\nPROPERTIES OF THE POISSON DISTRIBUTION \\n \\nSome of the main properties of the Poisson distribution are given below: \\n\\uf0b7 If the random variable X has a Poisson distribution with parameter \\uf06d, then its mean and variance are given by \\nE(X) = \\uf06d and Var(X) = \\uf06d. \\n\\uf0b7 (In other words, we can say that the mean of the Poisson distribution is equal to  its variance.) \\n\\uf0b7 The shape of the Poisson distribution is positively skewed. The distribution tends to be symmetrical as \\uf06d \\nbecomes larger and larger. \\nComparing the Poisson distribution with the binomial, we note that, whereas the binomial distribution can be \\nsymmetric, positively skewed, or negatively skewed (depending on whether p = 1/2, p < 1/2, or p > 1/2), the Poisson \\ndistribution can never be negatively skewed.  \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 ,!x\\ntexXP\\nxt \\uf06c\\uf06c\\uf02d\\n\\uf03d\\uf03d\\n\\uf028 \\uf029\\uf0e5\\n\\uf03d\\n\\uf02d\\n\\uf02d\\uf03d\\n2\\n0x\\nx\\n!x\\n1e1\\n \\n= \\n\\uf028 \\uf029\\uf028 \\uf029\\uf0e5\\n\\uf03d\\n\\uf02d\\n2\\n0x\\nx\\n!x\\n13679.01  (\\uf05c e-1 = 0.3679) \\n=  1 – (0.91975) = 0.08025 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 223}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       219                                                                                                                                           \\nFITTING OF A POISSON DISTRIBUTION TO REAL DATA \\n \\nJust as we disc ussed the fitting of the binomial distribution to real data in the last lecture, the Poisson distribution can \\nalso be fitted to real -life data.  The procedure is very similar to the one described in the case of the fitting of the \\nbinomial distribution: The population mean \\uf06d is replaced by the sample mean \\uf060X, and the probabilities of the various \\nvalues of X are computed using the Poisson formula.  The chi-square test of goodness of fit  enables us to determine \\nwhether or not it is a good fit i.e. whether or not  the discrepancy between the expected frequencies and the observed \\nfrequencies is small. Next, we discuss some important mathematical points regarding Poisson distribution. \\n\\uf0b7 1) The Poisson approximation to the binomial formula works well when  \\n  n > 20 and p < 0.05.  \\n\\uf0b7 2) Suppose that the Poisson is used to approximate the binomial which, in turn, is being used to approximate \\nthe hyper geometric. Then the Poisson is being used to approximate the hyper geometric Putting the two \\napproximation conditions together, the rule of thumb is that the Poisson distribution can be used to \\napproximate the hyper geometric distribution when n < 0.05N,   n > 20,  and  p < 0.05 \\nThis brings to the end of the discussion of some of the most important and well-known Univariate discrete probability \\ndistributions. We now begin the discussion some of the well-known Univariate continuous probability distribution. \\nThere are different types of continuous distributions e.g. the uniform distribution, the normal distribution, the geometric \\ndistribution, and the exponential distribution. Each one has its own shape and its own mathematical properties. In this \\ncourse, we will discuss the uniform distribution and the normal distribution. \\nWe begin with the continuous UNIFORM DISTRIBUTION (also known as the RECTANGULAR DISTRIBUTION). \\n \\nUNIFORM DISTRIBUTION \\n \\nA random variable X is said to be uniformly distributed if its density function is defined as  \\n \\n \\n \\nThe graph of this distribution is as follows \\n \\nThe above function is a proper probability density function because of the fact that: \\ni) Since a < b, therefore f(x) > 0 \\n \\nii)  \\n \\n \\nSince the shape of the distribution is like that of a rectangle, therefore the total area of this distribution can also be \\nobtained from the simple formula: \\nArea of rectangle  \\n = (Base) × (Height) \\n \\n \\n \\n \\n \\n \\nArea under the Uniform Distribution \\n \\n \\nf(x) \\n0 a b \\nX \\nab \\uf02d\\n1\\n\\uf028 \\uf029 abxf \\uf02d\\uf03d 1\\n\\uf028 \\uf029 bxaabxf \\uf0a3\\uf0a3\\uf02d\\uf03d ,1\\n\\uf028 \\uf029 \\uf05b \\uf05d 111 \\uf03d\\uf02d\\n\\uf02d\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\uf0f2\\uf0f2\\n\\uf0a5\\n\\uf0a5\\uf02d ab\\nabxabdxabdxxf\\nb\\na\\nb\\na\\n\\uf028 \\uf029 1ab\\n1ab \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf0b4\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 224}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       220                                                                                                                                           \\n = Area of the rectangle  \\n = (Base) × (Height) \\n \\n \\n  \\n \\nThe distribution derives its name from the fact that its density is constant or uniform over the interval [a, b] and is 0 \\nelsewhere. It is also called the rectangular distribution because its total probability is confined to a rectangular region \\nwith base equal to (b – a) and height equal to 1/(b – a). The parameters of this distribution are a and b with  \\n \\n \\n \\n \\n \\n \\nPROPERTIES OF THE UNIFORM DISTRIBUTION \\n \\nLet X has the uniform distribution over [a, b]. Then its mean is  \\n \\nThe uniform probability distribution provides a model for continuous random variables that are evenly distributed over \\na certain interval. That is, a uniform random variable is one that is just as likely to assume a value in one interval as it \\nis to assume a value in any other interval of equal size. There is no clustering of values around any value. Instead, there \\nis an even spread over the entire region of possible values.  As far as the real-life application  of the uniform \\ndistribution is concerned, the point to be noted is that, for continuous random variables there is an infinite number of \\nvalues in the sample space, but in some cases, the values may appear to be equally likely. \\n \\nEXAMPLE-1 \\n \\nIf a short exists in a 5 meter stretch of electrical wire, it may have an equal probability of being in any particular 1 \\ncentimeter segment along the line. \\n \\nEXAMPLE-2 \\n \\nIf a safety inspector plans to choose a time at random during the 4 afternoon work-hours to pay a surprise visit to a \\ncertain area of a plant, then each 1 minute time-interval in this 4 work-hour period will have an equally likely chance to \\nbeing selected for the visit. Also, the uniform distribution arises in the study of rounding off errors, etc. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nf(x) \\n0 a b \\nX \\nab \\uf02d\\n1\\n\\uf028 \\uf029 abxf \\uf02d\\uf03d 1\\n\\uf028 \\uf029 1ab\\n1ab \\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf02d\\uf0b4\\uf02d\\uf03d\\n2\\nba \\uf02b\\uf03d\\uf06d\\n and variance is \\n\\uf028 \\uf029\\n12\\nab 2\\n2 \\uf02d\\uf03d\\uf073  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 225}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       221                                                                                                                                           \\nLECTURE NO. 30 \\n \\n\\uf0b7 Normal Distribution. \\n\\uf0a7 Mathematical Definition \\n\\uf0a7 Important Properties \\n\\uf0b7 The Standard Normal Distribution  \\n\\uf0a7 Direct Use of the Area Table \\n\\uf0a7 Inverse Use of the Area Table \\n\\uf0b7 Normal Approximation to the Binomial Distribution \\n \\nThe normal distribution was discovered in 1733. The normal distribution has a bell-shaped curve of the type shown \\nbelow: \\n \\nLet us begin its detailed discussion by considering its formal MATHEMATICAL DEFINITION, and its main  \\nPROPERTIES. \\n \\nNORMAL DISTRIBUTION \\n \\nA continuous random variable is said to be normally distributed with mean \\uf06d and standard deviation \\uf073 if its probability \\ndensity function is given by \\n \\n \\n \\n \\n \\n \\n \\nFor any particular value of \\uf06d and any particular value of \\uf073, giving different values to x and we obtain a set of ordered \\npairs (x, f(x)) that yield the bell-shaped curve given above. The formula of the normal distribution defines a FAMILY of \\ndistributions depending on the values of the two parameters \\uf06d and \\uf073 (as these are the two values that determine the \\nshape of the distribution). \\n \\nPROPERTIES OF THE NORMAL DISTRIBUTION \\nProperty No. 1 \\nIt can be mathematically proved that, for the normal distribution N(\\uf06d,\\uf0732), \\uf06d represents the mean, and \\uf073  represents the \\nstandard deviation of the normal distribution. A change in the mean \\uf06d shifts the distribution to the left or to the right \\nalong the x-axis: \\n \\n \\nThe different values of the standard deviation\\uf073, (whi ch is a measure of dispersion), determine the flatness or \\npeakedness of the normal curve. In other words, a change in the standard deviation on \\uf073 flattens it or compresses it \\nwhile leaving its centre in the same position: \\n \\n\\uf06d1 \\nX \\n\\uf06d2 \\uf06d3 \\n\\uf06d1 < \\uf06d2 < \\uf06d3 \\n(\\uf073 Constant) \\n-\\uf0a5 \\uf0a5 \\n\\uf028 \\uf029 \\uf0a5\\uf03c\\uf03c\\uf0a5\\uf02d\\n\\uf070\\uf073\\n\\uf03d\\n\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9\\n\\uf073\\n\\uf06d\\uf02d\\uf02d\\nx,e\\n2\\n1xf\\n2\\n2\\n1 x\\n\\uf0f7\\n\\uf0f7\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\n\\uf0e7\\n\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf03d\\uf070\\n71828.2~e\\n,722~1416.3\\nwhere'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 226}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       222                                                                                                                                           \\n \\nProperty No. 2 \\n \\nThe normal curve is asymptotic to the x-axis as x \\uf0ae \\uf0b1 \\uf0a5. \\nProperty No. 3 \\n \\nBecause of the symmetry of the normal curve, 50% of the area is to the right of a vertical line erected at the mean, and \\n50% is to the left.(Since the total area under the normal curve from - \\uf0a5 to + \\uf0a5 is unity, therefore the area to the left of \\uf06d \\nis 0.5 and the area to the right of \\uf06d is also 0.5.) \\n \\nProperty No. 4 \\n \\nThe density function attains its maximum value at x = \\uf06d and falls off symmetrically on each side of \\uf06d. This is why the \\nmean, median and mode of the normal distribution are all equal to \\uf06d. \\n \\n \\n \\nProperty No. 5 \\n \\nSince the normal distribution is absolutely symmetrical, hence \\uf06d3 , the third moment about the mean is zero. \\n \\nProperty No. 6 \\n \\nFor the normal distribution, it can be mathematically proved that \\uf06d4 = 3 \\uf0734 \\n \\nProperty No. 7 \\nThe moment ratios of the normal distribution come out to be 0 and 3 respectively: \\n \\nMoment Ratios: \\n \\n \\n \\n\\uf0731 \\n\\uf0732 \\n\\uf0733 \\nX \\n\\uf0731 < \\uf0732 < \\uf0733  \\n(\\uf06d Constant) \\n\\uf06d \\n-\\uf0a5 \\uf0a5 \\nMean = Median = Mode \\n\\uf028 \\uf029\\n,00\\n32\\n2\\n3\\n2\\n32\\n1 \\uf03d\\n\\uf073\\n\\uf03d\\n\\uf06d\\n\\uf06d\\uf03d\\uf062'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 227}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       223                                                                                                                                           \\n \\n \\n \\n \\nNOTE \\nBecause of the fact that, for the normal distribution, \\uf0622 comes out to be 3, this is why this value has been taken as a \\ncriterion for measuring the kurtosis of any distribution: The amount of peakedness of the normal curve has been taken \\nas a standard, and we say that this particular distribution is masochistic.  Any distribution for which \\uf0622 is greater than 3 \\nis more peaked than the normal curve, and is called leptokurtic; Any distribution for which \\uf0622 is less than 3 is less \\npeaked than the normal curve, and is called platykurtic. \\n \\nProperty No. 8 \\nNo matter what th e values of \\uf06d and \\uf073 are, areas under the normal curve remain in certain fixed proportions within a \\nspecified number of standard deviations on either side of \\uf06d. \\nFor the normal distribution: \\n\\uf0b7 The interval \\uf06d \\uf0b1 \\uf073 will always contain 68.26% of the total area. \\n \\n\\uf0b7 The interval \\uf06d + 2\\uf073 will always contain 95.44% of the total area. \\n \\n \\n\\uf0b7 The interval \\uf06d \\uf0b1 3\\uf073 will always contain 99.73% of the total area. \\n \\n \\n \\n0.6826 0.1587 0.1587 \\n\\uf06d – 1\\uf073         \\uf06d          \\uf06d + 1\\uf073 \\nX \\n0.0228 \\n\\uf06d – 2 \\uf073                 \\uf06d                 \\uf06d + 2 \\uf073 \\nX \\n0.0228 0.9544 \\n0.00135 \\n\\uf06d – 3\\uf073                  \\uf06d                  \\uf06d + 3\\uf073 \\nX \\n0.9973 0.00135 \\n\\uf028 \\uf029\\n33\\n22\\n4\\n2\\n2\\n4\\n2 \\uf03d\\n\\uf073\\n\\uf073\\uf03d\\n\\uf06d\\n\\uf06d\\uf03d\\uf062'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 228}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       224                                                                                                                                           \\nCombining the above three results, we have: \\n \\n \\nAt this point, the student are reminded of the Empirical Rule that was discussed during the first part of this course --- \\nthat on descriptive statistics. You will recall that, in the case of any approximately symmetric  hump-shaped frequency \\ndistribution, approximately 68% of the data -values lie between \\uf060X + S, approximately 95% between the \\uf060X + 2S, and \\napproximately 100% between  \\uf060X + 3S.You can now recognize the similarity between the empirical rule and the \\nproperty given above. (In case a distribution is absolutely normal, the areas in the above -mentioned ranges are 68.26%, \\n95.44% and 99.73%; in case a distribution approximately normal, the areas in these ranges will be approximately equal \\nto these percentages.) \\n \\nProperty No. 9 \\n The normal curve contains points of inflection (where the direction of concavity changes) which are \\nequidistant from the mean. Their coordinates on the XY-plane are \\n \\n \\n \\n \\nrespectively.  \\n \\nPoints of Inflection  \\n \\nNext, we consider the concept of the Standard Normal Distribution: \\n \\nTHE STANDARD NORMAL DISTRIBUTION \\nA normal distribution whose mean is zero and whose standard deviation is 1 is known as the standard normal \\ndistribution. \\n \\n \\n \\n\\uf06d-3\\uf073 \\uf06d-2\\uf073 \\uf06d-\\uf073 \\uf06d \\uf06d+\\uf073 \\uf06d+2\\uf073 \\uf06d+3\\uf073 \\n68.26% \\n95.44% \\n \\n  99.73% \\n\\uf06d-\\uf073 \\uf06d+\\uf073 \\uf06d \\n1 0 -1 \\n\\uf073 = 1 \\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\ne\\nand\\ne \\uf070\\uf073\\n\\uf073\\uf06d\\n\\uf070\\uf073\\n\\uf073\\uf06d\\n2\\n1,\\n2\\n1,'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 229}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       225                                                                                                                                           \\nThis distribu tion has a very important role in computing areas  under the normal curve. The reason is that the \\nmathematical equation of the normal distribution is so complicated that it is not possible to find areas under the normal \\ncurve by ordinary integration.  Areas under the normal curve have to be found by the more advanced method of \\nnumerical integration. The point to be noted is that areas under the normal curve have been computed for that particular \\nnormal distribution whose mean is zero and whose standard deviation is equal to 1, i.e. the standard normal distribution. \\n     \\nAreas under the Standard Normal Curve \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn any problem involving the normal distribution, the generally established procedure is that the normal distribution \\nunder consideration is converted to the standard normal distribution. This process is called standardization. The \\nformula for converting N (\\uf06d, \\uf073) to N (0, 1) is: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nZ 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 \\n0.0 0.0000 0.0040 0.0080 0.0120 0.0159 0.0199 0.0239 0.0279 0.0319 0.0359 \\n0.1 0.0398 0.0438 0.0478 0.0517 0.0557 0.0596 0.0636 0.0675 0.0714 0.0753 \\n0.2 0.0793 0.0832 0.0871 0.0910 0.0948 0.0987 0.1026 0.1064 0.1103 0.1141 \\n0.3 0.1179 0.1217 0.1255 0.1293 0.1331 0.1368 0.1406 0.1443 0.1480 0.1517 \\n0.4 0.1554 0.1591 0.1628 0.1664 0.1700 0.1736 0.1772 0.1808 0.1844 0.1879 \\n0.5 0.1915 0.1950 0.1985 0.2019 0.2054 0.2083 0.2123 0.2157 0.2190 0.2224 \\n0.6 0.2257 0.2291 0.2324 0.2357 0.2380 0.2422 0.2454 0.2486 0.2518 0.2549 \\n0.7 0.2580 0.2611 0.2642 0.2673 0.2704 0.2734 0.2764 0.2794 0.2823 0.2852 \\n0.8 0.2881 0.2910 0.2939 0.2967 0.2995 0.3023 0.3051 0.3078 0.3106 0.3133 \\n0.9 0.3159 0.3186 0.3212 0.3238 0.3264 0.3289 0.3315 0.3340 0.3365 0.3389 \\n1.0 0.3413 0.3438 0.3461 0.3485 0.3508 0.3531 0.3554 0.3577 0.3599 0.3621 \\n1.1 0.3643 0.3665 0.3686 0.3708 0.3729 0.3749 0.3770 0.3790 0.3810 0.3880 \\n1.2 0.3849 0.3869 0.3888 0.3907 0.3925 0.3944 0.3962 0.3990 0.3997 0.4015 \\n1.3 0.4032 0.4049 0.4066 0.4082 0.4099 0.4115 0.4131 0.4147 0.4162 0.4177 \\n1.4 0.4192 0.4207 0.4222 0.4236 0.4251 0.4265 0.4279 0.4292 0.4306 0.4319 \\n1.5 0.4332 0.4345 0.4357 0.4370 0.4382 0.4394 0.4406 0.4418 0.4430 0.4441 \\n1.6 0.4452 0.4463 0.4474 0.4485 0.4495 0.4505 0.4515 0.4525 0.4535 0.4545 \\n1.7 0.4554 0.4564 0.4573 0.4582 0.4591 0.4599 0.4608 0.4616 0.4625 0.4633 \\n1.8 0.4641 0.4649 0.4656 0.4664 0.4671 0.4678 0.4686 0.4693 0.4690 0.4706 \\n1.9 0.4713 0.4719 0.4726 0.4732 0.4738 0.4744 0.4750 0.4758 0.4762 0.4767 \\n2.0 0.4772 0.4778 0.4783 0.4788 0.4793 0.4798 0.4803 0.4808 0.4812 0.4817 \\n2.1 0.4821 0.4826 0.4830 0.4834 0.4838 0.4842 0.4846 0.4850 0.4854 0.4857 \\n2.2 0.4861 0.4865 0.4868 0.4871 0.4875 0.4878 0.4881 0.4884 0.4887 0.4890 \\n2.3 0.4893 0.4896 0.4898 0.4901 0.4904 0.4906 0.4909 0.4911 0.4913 0.4916 \\n2.4 0.4918 0.4920 0.4922 0.4925 0.4927 0.4929 0.4931 0.4932 0.4934 0.4936 \\n2.5 0.4938 0.4940 0.4941 0.4943 0.4945 0.4946 0.4948 0.4949 0.4951 0.4952 \\n2.6 0.4953 0.4955 0.4956 0.4957 0.4959 0.4960 0.4961 0.4962 0.4963 0.4964 \\n2.7 0.4965 0.4966 0.4967 0.4968 0.4969 0.4970 0.4971 0.4972 0.4973 0.4974 \\n2.8 0.4974 0.4975 0.4976 0.4977 0.4977 0.4978 0.4979 0.4980 0.4980 0.4981 \\n2.9 0.4981 0.4982 0.4983 0.4983 0.4984 0.4984 0.4985 0.4985 0.4986 0.4986 \\n3.0 0.49865 0.4987 0.4987 0.4988 0.4988 0.4989 0.4989 0.4989 0.4990 0.4990 \\n3.1 0.49903 0.4991 0.4991 0.4991 0.4992 0.4992 0.4992 0.4992 0.4993 0.4993 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 230}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       226                                                                                                                                           \\nTHE PROCESS OF STANDARDIZATION \\nThe standardization formula is: \\n \\n \\n \\n \\nIf X is N (\\uf06d, \\uf073), then Z is N (0, 1). In other words, the standardization formula given above converts our normal \\ndistribution to the one whose mean is 0 and whose standard deviation is equal to 1. \\n \\n \\nWe illustrate this concept with the help of an interesting example: \\n \\nEXAMPLE \\n \\nThe length of life for an automatic dishwasher is approximately normally distributed with a mean life of 3.5 years and a \\nstandard deviation of 1.0 years. If this type of dishwasher is guaranteed for 12 months, what fraction of the sales will \\nrequire replacement? \\nSOLUTION \\n \\nSince 12 months equal one year, hence we need to compute the fraction or proportion of dishwashers that will cease to \\nfunction before a time-span of one year. In other words, we need to find the probability that a dishwasher fails before \\none year. \\n \\n \\n \\nIn order to find this area we nee to standardize normal distribution i.e. to convert N(3.5, 1) to N(0, 1):  \\n \\n \\n \\n \\n \\n1 0 -1 \\n\\uf073 = 1 \\n1.0 3.5 X \\n\\uf073\\n\\uf06d\\uf02d\\uf03d XZ\\nThe method is \\n \\n0.1\\n5.3XXZ \\uf02d\\uf03d\\uf073\\n\\uf06d\\uf02d\\uf03d  \\n \\nThe X -value representing the \\nwarranty  \\nperiod is 1.0 so \\n \\n5.21\\n5.2\\n0.1\\n5.30.1Z \\uf02d\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 231}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       227                                                                                                                                           \\n \\nNow we need to find the area under the normal curve from z= -\\uf0a5 to Z = -2.5. Looking at the area table of the standard \\nnormal distribution, we find that Area from 0 to 2.5 = 0.4938  \\n \\n \\nHence:  The area from X = 2.5 to \\uf0a5 is 0.0062  \\n \\nBut, this means that the area from -\\uf0a5  to -2.5 is also 0.0062, as shown in the following figure: \\n \\n \\n \\n-\\uf0a5 \\n-2.5 \\n3.5 X \\n-\\uf0a5 0 Z \\n1.0 \\n0.4938 \\n0 2.5 \\n0 2.5 \\n0.0062 \\n\\uf0a5 \\n0 -2.5 \\n0.0062 \\n-\\n\\uf0a5 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 232}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       228                                                                                                                                           \\n \\nThis means that the probability of a dishwasher lasting less than a year is 0.0062 i.e. 0.62% --- even less than \\n1%.Hence, the owner of the factory should be quite happy with the decision of placing a twelve-month guarantee on the \\ndishwasher! Next, we discuss the Inverse use of the Table of Areas under the Normal Curve. In the above example, we \\nwere required to find a certain area against a given x-value. In some situations, we are confronted with just the opposite \\n--- we are given certain areas, and we are required to find the corresponding x-values. We illustrate this point with the \\nhelp of the following example: \\n \\nEXAMPLE  \\n \\nThe heights of applicants to the police force in a certain country are normally distributed with mean 170 cm and \\nstandard deviation 3.8 cm. If 1000 persons apply for being inducted into the police force, and it has been decided that \\nnot more than 70% of these applicants will be accepted, (and the shortest 30% of the applicant are to be rejected), what \\nis the minimum acceptable height for the police force? \\n \\nSOLUTION: \\n We have: \\n \\n \\nWe need to compute the x-value to the left of which, there exists 30% area \\n \\n The standardization formula can be re-written as  \\n \\n \\n \\n \\n \\nThe Z value to the left of which there exists 30% area is obtained as follows. \\n170 -\\uf0a5 \\uf0a5 \\n3.8 \\n3.8 \\n170 -\\uf0a5 \\uf0a5 \\n30% 20% 50% \\n\\uf073\\n\\uf06d\\uf02d\\uf03d XZ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 233}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       229                                                                                                                                           \\n \\n \\nBy studying the figures inside the body of the area table of the standard normal distribution, we find that: \\n\\uf0b7  The area between z = 0  \\n and z = 0.52 is 0.1985, and  \\n\\uf0b7  The area between z = 0  \\n and z = 2.53 is 0.2019 \\n Since 0.1985 is closer to 0.2000 than 0.2019, hence 0.52 is taken as the appropriate z-value. \\n \\n \\n \\nBut, we are interested not in the upper 30% but the lower 30% of the applicants. \\n Hence, we have: \\n \\n \\nSince the normal distribution is absolutely symmetrical, hence the z-value to the left of which there exists 30% area (on \\nthe left-hand-side of the mean) will be at exactly the same distance from the mean as the z-value to the right of which \\nthere exists 30% area (on the right-hand-side of the mean). \\nSubstituting z = -0.52 in the standardization formula, we obtain: \\n X  = 170 + 3.8 Z  \\n = 170 + 3.8 (-0.52) \\n = 170 - 1.976  \\n = 168.024   168 cm \\nHence, the minimum acceptable height for the police force is 168 cm. Just as binomial, Poisson and other discrete \\ndistributions can be fitted to real-life data; similarly, the normal distribution can also be FITTED to real data.  \\nThis can be done by equating \\uf06d to \\uf060X, the mean computed from the observed frequency distribution (based on sample \\ndata), and \\uf073 to S, the standard deviation of the observed frequency distribution. Of course, this should be done only if \\n0 Z -\\uf0a5 \\n0.3 0.2 0.5 \\nz \\n0 Z -\\uf0a5 \\n0.3 0.2 0.5 \\n0.52 \\n0 Z -\\uf0a5 \\n0.3 0.2 0.5 \\n-0.52 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 234}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       230                                                                                                                                           \\nwe are reasonably sure that the shape of the observed frequency distribution is quite similar to that of the normal \\ndistribution. (As indicated in the case of the fitting of the binomial distribution to real data), in order to decide whether \\nor not our fitted normal distribution is a reasonably good fit, the proper statistical procedure is the Chi-square Test of \\nGoodness of Fit. \\n \\n NORMAL APPROXIMATION TO THE BINOMIAL DISTRIBUTION \\n \\nThe probability for a binomial random variable X to take the value x is  \\n \\n \\n \\n \\n \\n \\n \\nThe above formula becomes cumbersome to apply if n is LARGE.  In such a situation, as long as neither p nor q is \\nclose to zero, we can compute the required probabilities by applying the normal approximation to the binomial \\ndistribution. The binomial distribution can be quite closely approximated by the normal distribution when n is \\nsufficiently large and neither p nor q is close to zero. As a rule of thumb, the normal distribution provides a reasonable \\napproximation to the binomial distribution if both np and nq are equal to or greater than 5, i.e.  \\n np > 5 and nq > 5 \\n \\nEXAMPLE: \\n \\nSuppose that a past record indicate that, in a particular province of an under-developed country, the death rate from \\nMalaria is 20%. Find the probability that in a particular village of that particular province, the number of deaths is \\nbetween 70 and 80 (inclusive) out of a total of 500 patients of Malaria. \\n \\nSOLUTION: \\n \\nRegarding ‘death from Malaria’ as success, we have  \\n   n = 500  \\nand  p = 0.20. \\n \\nIt is obvious that it is very cumbersome to apply the binomial formula in order to compute P(70 < X < 80). \\nIn this problem,  \\n  np = 500(0.2) = 100 > > > 5, and nq = 500(0.8) = 400 > > > 5, \\n \\ntherefore we can happily apply the normal approximation to the binomial distribution. In order to apply the normal \\napproximation to the binomial, we need to keep in mind the following two points: \\n1) The first point is: The mean and variance of the binomial distribution valid in our problem will be regarded as the \\nmean and variance of the normal distribution that will be used to approximate the binomial distribution.  \\nIn this problem, we have: \\n \\nand \\n \\n \\nHence   \\n \\n2) The second important point is: \\n \\nWe need to apply a correction that is known as the Continuity Correction. The rationale for this correction is as follows: \\nThe binomial distribution is essentially a discrete distribution whereas the normal distribution is a continuous \\ndistribution i.e.: \\n \\nBINOMIAL DISTRIBUTION \\n \\n \\n \\n\\uf028 \\uf029\\n.1pqandnx0for\\n,qpx\\nnxf xnx\\n\\uf03d\\uf02b\\uf0a3\\uf0a3\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d \\uf02d\\n10020.0500 \\uf03d\\uf0b4\\uf03d\\uf03dnp\\uf06d\\n8080.020.05002 \\uf03d\\uf0b4\\uf0b4\\uf03d\\uf03dnpq\\uf073\\n94.880 \\uf03d\\uf03d\\uf03d npq\\uf073'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 235}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       231                                                                                                                                           \\nNORMAL DISTRIBUTION \\n \\n \\n \\n \\nIn applying the normal approximation to the binomial, we have the following situation: \\n \\n \\n \\nTHE NORMAL DISTRIBUTION SUPERIMPOSED ON THE BINOMIAL DISTRIBUTION \\n \\n \\n \\n \\n \\nBut, the question arises: “How can a set of distinct vertical lines be replaced by a continuous curve?” \\nIn order to overcome this problem, what we do is to replace every integral value x of our binomial random variable by \\nan interval x - 0.5 to x + 0.5. By doing so, we will have the following situation. The x-value 70 is replaced by the \\ninterval 69.5 - 70.5, The x-value 71 is replaced by the interval 70.5 - 71.The x-value 72is replaced by the interval 71.5 - \\n72.5 …………..The x-value 80 is replaced by the interval 79.5 - 80.5 \\nHence: \\nApplying the continuity correction,  \\n P(70 < X < 80)  \\nis replaced by  \\n P(69.5 < X < 80.5).  \\nAccordingly, the area that we need to compute is the area under the normal curve between the values 69.5 and 80.5. \\n It is left to the students to compute this area, and thus determine the required probability. (This computation \\ninvolves a few steps.) \\n \\nBy doing so, the students will find that, in that particular village of that province, the probability that the number of \\ndeaths from Malaria in a sample of 500 lies between 70 and 80 (inclusive) is 0.0145 i.e. 1½%.   \\n This brings us to the end of the second part of this course i.e. Probability Theory. \\n In the next lecture, we will begin the third and last portion of this course i.e. Inferential Statistics --- that area \\nof Statistics which enables us to draw conclusions about various phenomena on the basis of data collected on sample \\nbasis.  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 236}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       232                                                                                                                                           \\nLECTURE NO. 31 \\n\\uf0b7 Sampling Distribution of \\nX  \\n\\uf0b7 Mean and Standard Deviation of the Sampling Distribution of \\nX  \\n\\uf0b7 Central Limit Theorem \\n \\nINFERENTIAL STATISTICS \\n \\nThat branch of Statistics which enables us to draw conclusions or inferences about various phenomena on the basis of \\nreal data collected on sample basis.  In this regard, the first poin t to be noted is that statistical inference can be divided \\ninto two main branches --- estimation, and hypothesis-testing.  Estimation itself can be further divided into two \\nbranches --- point estimation, and interval estimation \\n \\n \\n \\n \\nThe second important point is that the concept of sampling distributions  forms the basis for both estimation and \\nhypothesis-testing,  \\n \\nSAMPLING DISTRIBUTION \\n \\nThe probability distribution of any statistic (such as the mean, the standard deviation, the p roportion of successes in a \\nsample, etc.) is known as its sampling distribution. In this regard, the first point to be noted is that there are two ways of \\nsampling --- sampling with replacement, and sampling without replacement. In case of a finite populat ion containing N \\nelements, the total number of possible samples of size n that can be drawn from this population with replacement is Nn.  \\nIn case of a finite population containing N elements, the total number of possible samples of size n that can be draw n \\nfrom this population without replacement.  \\nWe illustrate the concept of the sampling distribution of         with the help of the following example: \\n \\nEXAMPLE \\n \\nLet us examine the case of an annual Ministry of Transport test to which all cars, irrespective  of age, have to be \\nsubmitted. The test looks for faulty breaks, steering, lights and suspension, and it is discovered after the first year that \\napproximately the same numbers of cars have 0, 1, 2, 3, or 4 faults.  \\nThe above situation is equivalent to the following: \\nLet X denotes the number of faults in a car. Then X can take the values 0, 1, 2, 3, and 4,  the probability of each of these \\nX values is 1/5. Hence, we have the following probability distribution: \\n \\n \\n \\nStatistical Inference \\nEstimation Hypothesis \\nTesting \\nPoint \\nEstimation \\nInterval \\nEstimation \\n.\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nn\\nN'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 237}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       233                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn order to compute the mean a nd standard deviation of this probability distribution, we carry  out the following \\ncomputations, \\n \\nMEAN AND VARIANCE OF THE POPULATION DISTRIBUTION \\n \\n \\n \\n                             \\n \\n \\n \\n \\nPractically speaking, only a sample of the cars will be tested at any o ne occasion, and, as such, we are interested in \\nconsidering the results that would be obtained if a sample of vehicles is tested.  Let us consider the situation when only \\ntwo cars are tested after being selected at the roadside by a mobile testing station. The following table gives all the \\npossible situations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above situation is equivalent to drawing all possible samples of size 2 from this probability distribution (i.e. the \\npopulation) WITH REPLACEMENT . From the above list of 25 samples, w e can work out all the possible sample \\nmeans. These are indicated in the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIt is immediately evident that some of these possible samples mean occur several times. In view of this, it would seem \\nreasonable and sensible to constr uct a frequency distribution  from the sample means. This is given in the following \\ntable: \\n \\n \\n \\n \\n \\nNo. of \\nFaulty Items \\n(X) \\nProbability \\nf(x) \\n0 1/5 \\n1 1/5 \\n2 1/5 \\n3 1/5 \\n4 1/5 \\nTotal 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 2\\uf03d\\uf0e5\\uf03d\\uf03d xxfXE\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n24626 2\\n22\\n222\\n\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf0e5\\uf02d\\uf0e5\\uf03d\\n\\uf02d\\uf03d\\uf03d\\nxfxxfx\\nXEXEXVar\\uf073\\nNO. OF FAULTY ITEMS \\nSecond Car \\nFirst Car 0 1 2 3 4 \\n0 (0,0) (0,1) (0,2) (0,3) (0,4) \\n1 (1,0) (1,1) (1,2) (1,3) (1,4) \\n2 (2,0) (2,1) (2,2) (2,3) (2,4) \\n3 (3,0) (3,1) (3,2) (3,3) (3,4) \\n4 (4,0) (4,1) (4,2) (4,3) (4,4) \\n \\nSAMPLE MEANS \\nSecond Car \\nFirst Car 0 1 2 3 4 \\n0 0.0 0.5 1.0 1.5 2.0 \\n1 0.5 1.0 1.5 2.0 2.5 \\n2. 1.0 1.5 2.0 2.5 3.0 \\n3 1.5 2.0 2.5 3.0 3.5 \\n4 2.0 2.5 3.0 3.5 4.0 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 238}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       234                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIf we divide each of the above frequencies by the total frequency 25, we obtain the probabilities of the various values \\nof\\uf060X.(This is so because every one of the 25 possible situations is equally likely to occur, and hence the probabilities of \\nthe various possible values of \\uf060X can be computed using the classical definition of probability i.e. m/n --- number of \\nfavorable outcomes divided by tota l number of possible outcomes) . Hence, we obtain the following probability \\ndistribution: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above is referred to as the SAMPLING DISTRIBUTION  of the mean.  The visual picture of the sampling \\ndistribution is as follows: \\nSampling Distribution of\\uf060X for n = 2 \\n \\nNext, we wish to compute the mean and standard deviation of this distribution.  \\n \\n1/25 \\n0 \\n0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 \\nX\\n2/25 \\n3/25 \\n4/25 \\n5/25 \\n0.0 \\n\\uf028 \\uf029xP\\nSample \\nMean \\nNo. of \\nSamples \\nx\\n f \\n0.0 1 \\n0.5 2 \\n1.0 3 \\n1.5 4 \\n2.0 5 \\n2.5 4 \\n3.0 3 \\n3.5 2 \\n4.0 1 \\nTotal 25 \\n \\nSample Mean No. of Samples Probability \\nx\\n f P(\\uf060X =\\uf060x) \\n0.0 1 1/25 \\n0.5 2 2/25 \\n1.0 3 3/25 \\n1.5 4 4/25 \\n2.0 5 5/25 \\n2.5 4 4/25 \\n3.0 3 3/25 \\n3.5 2 2/25 \\n4.0 1 1/25 \\nTotal 25 25/25=1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 239}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       235                                                                                                                                           \\nAs we are already aware, for the probability distribution of a random variable X, the mean is given by \\n \\uf06d = E(X) = \\uf0e5x f(x) and the variance is given by\\uf0732 = Var(X) = E(X2) - [E(X)]2 \\nThe point to be noted is that, in case of the sampling distribution of \\uf060X, our random variable is not X but\\uf060X.  \\n            Hence, the mean and variance of our sampling distribution are given by \\n \\nMEAN AND VARIANCE OF THE SAMPLING DISTRIBUTION OF \\uf060X \\n \\n \\n \\n \\n \\n \\n \\nThe square root of the variance is the standard deviation, and the standard deviation of a sampling distribution is termed \\nas its standard error. In order to find the mean and standard error of the s ampling distribution of \\uf060X in this example, we \\ncarry out the following computations: \\n In order to find the mean and standard error of the sampling distribution of \\uf060X in this example, we carry out \\nthe following computations: \\n \\nSample Mean Probability   \\nx\\n f(\\uf060x)=P(\\uf060X =\\uf060x) \\uf060x f(\\uf060x) (\\uf060x)2 f(\\uf060x) \\n0.0 1/25 0 0 \\n0.5 2/25 1/25 1/50 \\n1.0 3/25 3/25 6/50 \\n1.5 4/25 6/25 18/50 \\n2.0 5/25 10/25 40/50 \\n2.5 4/25 10/25 50/50 \\n3.0 3/25 9/25 54/50 \\n3.5 2/25 7/25 49/50 \\n4.0 1/25 4/25 32/50 \\nTotal 25/25=1 50/25=2 250/50=5 \\n \\nHence, in this example, we have: \\n \\n \\n \\n  \\n \\nAnd \\n \\n \\n \\n \\n \\n \\n \\n \\nThese computations lead to the following two very important properties of the sampling distribution of \\uf060X \\n \\nProperty No.1 \\n \\nIn the case of sampling with replacement as well as in the case of sampling without replacement, we have: \\n \\n \\nIn this example: \\n \\n \\n \\n \\n \\n \\n \\n \\nProperty No.2 \\n\\uf028 \\uf029 \\uf028 \\uf029xfxXEx \\uf0e5\\uf03d\\uf03d\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n22\\n222\\nxfxxfx\\nXEXEXVarx\\n\\uf0e5\\uf02d\\uf0e5\\uf03d\\n\\uf02d\\uf03d\\uf03d\\uf073\\n\\uf028 \\uf029 \\uf028 \\uf029\\n225/50 \\uf03d\\uf03d\\n\\uf0e5\\uf03d\\uf03d xfxXEx\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n14525 2\\n22\\n222\\n\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf0e5\\uf02d\\uf0e5\\uf03d\\n\\uf02d\\uf03d\\uf03d\\nxfxxfx\\nXEXEXVarx\\uf073\\n112 \\uf03d\\uf03d\\uf03d xx \\uf073\\uf073\\n\\uf06d\\uf06d \\uf03dx\\n\\uf06d\\uf06d\\n\\uf06d\\n\\uf06d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\nx\\nx\\nHence\\nand\\n2\\n2'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 240}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       236                                                                                                                                           \\n \\n In case of sampling with replacement: \\n \\n \\n \\n \\nIn this example: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n NOTE: \\nIn case of sampling without replacement from a finite population: \\n \\n \\n \\n \\n \\n \\nThe factor  \\n \\n \\nis known as the finite population correction (fpc). The point to be noted is that, if the sample size n is much smaller than \\nthe population size N, then is approximately equal to 1, and, as such, the fpc is not required.  Hence, in sampling from a \\nfinite population, we apply the fpc only if the sample size is greater than 5% of the population size. Next, we consider \\nthe shape of the sampling distribution of \\uf060X. As indicated by the line chart, the above sampling distribution is \\nabsolutely symmetric and triangular. But let us consider what will happen to the shape of the sampling distribution with \\nif the sample size is increased. If in the car tests instead of taking samples of 2 we had taken all possible samples of size \\n3, our sampling distribution would contain 53 = 125 sample means, and it would be in the following form: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe graph of this distribution is as follows: \\nSampling Distribution of\\uf060X for n = 3 \\n \\nn\\nx\\n\\uf073\\uf073 \\uf03d\\nn\\nHence\\nand\\nn\\nx\\nx\\n\\uf073\\uf073\\n\\uf073\\n\\uf073\\n\\uf073\\n\\uf03d\\n\\uf03d\\n\\uf03d\\uf03d\\uf05c\\n\\uf03d\\n1\\n1\\n2\\n2\\n2\\n1\\uf02d\\n\\uf02d\\uf03d N\\nnN\\nn\\nx\\n\\uf073\\uf073\\n1\\uf02d\\n\\uf02d\\nN\\nnN\\nSAMPLING DISTRIBUTION \\nFOR SAMPLES OF SIZE 3 \\n \\nx\\n No. of Samples f(\\uf060x) \\n0.00 1 1/125 \\n0.33 3 3/125 \\n0.67 6 6/125 \\n1.00 10 10/125 \\n1.33 15 15/125 \\n1.67 18 18/125 \\n2.00 19 19/125 \\n2.33 18 18/125 \\n2.67 15 15/125 \\n3.00 10 10/125 \\n3.33 6 6/125 \\n3.67 3 3/125 \\n4.00 1 1/125 \\n 125 1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 241}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       237                                                                                                                                           \\n \\nIf in the car tests instead of taking samples of 2 we had taken all possible samples of size 4, our sampling distributions \\nwould contain 54 = 625 sample means, and it would be in the following form: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe graph of this distribution is as follows, Sampling Distribution of\\uf060X for n = 4 \\n \\n4/125 \\n0 \\nX\\n0.\\n00 \\n\\uf028 \\uf029xP\\n0.\\n33 \\n0.\\n67 \\n1.\\n00 \\n1.\\n33 \\n1.\\n67 \\n2.\\n00 \\n2.\\n33 \\n2.\\n67 \\n3.\\n00 \\n3.\\n33 \\n3.\\n67 \\n4.\\n00 \\n8/125 \\n12/125 \\n16/125 \\n20/125 \\nSAMPLING DISTRIBUTION \\nFOR SAMPLES OF SIZE 4 \\nx\\n No. of Samples f(\\uf060x) \\n0.00 1 1/625 \\n0.25 4 4/625 \\n0.50 10 10/625 \\n0.75 20 20/625 \\n1.00 35 35/625 \\n1.25 52 52/625 \\n1.50 68 68/625 \\n1.75 80 80/625 \\n2.00 85 85/625 \\n2.25 80 80/625 \\n2.50 68 68/625 \\n2.75 52 52/625 \\n3.00 35 35/625 \\n3.25 20 20/625 \\n3.50 10 10/625 \\n3.75 4 4/625 \\n4.00 1 1/625 \\n 625 1 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 242}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       238                                                                                                                                           \\n \\n \\n \\nAs in the case of the sampling distribution of \\uf060X based on samples of size 2, each of these two distributions has a mean \\nof 2 defective items. It is clear from the above figures that as larger samples are taken, the s hape of the sampling \\ndistribution undergoes discernible changes.  \\n In all three cases the line charts are symmetrical, but as the sample size increases, the overall configuration \\nchanges from a triangular distribution to a bell-shaped distribution. When re latively large samples are taken, this bell -\\nshaped distribution assumes the form of a ‘normal’ distribution  (also called the ‘Gaussian’ distribution), and this \\nhappens irrespective of the form of the parent population. (For example, in the problem currentl y under consideration, \\nthe population of defective items in a car is rectangular.) \\nThis leads us to the following fundamentally important theorem: \\n \\nCENTRAL LIMIT THEOREM \\n \\nThe theorem states that:  \\n “If a variable X from  a population has mean \\uf06d and finite variance \\uf0732, then the sampling distribution of the \\nsample mean \\uf060X approaches a normal distribution with mean \\uf06d and variance \\uf0732/n as the sample size n approaches \\ninfinity.” As n \\uf0ae \\uf0a5, the sampling distribution of\\uf060X approaches normality. \\n \\nDue to the Central Limit Theorem, the normal distribution has found a central place in the theory of statistical \\ninference.(Since, in many situations, the sample is large enough for our sampling distribution to be approximately \\nnormal, therefore we can utilize the mathematical properties of the normal distribution to draw inferences about the \\nvariable of interest). The rule of thumb in this regard is that if the sample size, n, is greater than or equal to 30 , then we \\ncan assume that the sampling dist ribution of \\uf060X is approximately normally distributed. On the other hand, If the \\nPOPULATION sampled is normally distributed, then the sampling distribution of \\uf060X will also be normal regardless of \\nsample size. In other words, \\uf060X will be normally distributed with mean \\uf06d and variance \\uf0732/n. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n20/625 \\n0 \\nX\\n\\uf028 \\uf029xP\\n40/625 \\n60/625 \\n80/625 \\n100/625 \\n0.\\n75 \\n0.\\n50 \\n0.\\n25 \\n0.\\n00 \\n1.\\n75 \\n1.\\n50 \\n1.\\n25 \\n1.\\n00 \\n2.\\n75 \\n2.\\n50 \\n2.\\n25 \\n2.\\n00 \\n3.\\n75 \\n3.\\n50 \\n3.\\n25 \\n3.\\n00 \\n4.\\n00 \\n \\n \\nnx\\n\\uf073\\uf073 \\uf03d\\n\\uf06d\\uf06d \\uf03dx\\nX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 243}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       239                                                                                                                                           \\nLECTURE NO. 32 \\n\\uf0b7 Sampling Distribution of \\npˆ  \\n \\n\\uf0b7 Sampling Distribution of  \\n21 XX \\uf02d    \\nWe discussed the mean and the standard deviation of the sampling distribution, and, towards the end of the lecture, we \\nconsider the very important theorem known as the Central Limit Theorem. Let us now consider the real-life application \\nof this concept with the help of an example: \\n \\nEXAMPLE \\n \\nA construction company has 310 employees who have an average annual salary of Rs.24,000.The standard deviation of \\nannual salaries is Rs.5,000. \\nSuppose that the employees of this company launch a demand that the government should institute a law by which their \\naverage salary should be at least Rs. 24500, and, suppose that the government decides to check the validity of this \\ndemand by drawing a random sample of 100 employees of this company, and acquiring information regarding their \\npresent salaries. What is the probability that, in a random sample of 100 employees, the average salary will exceed \\nRs.24,500 (so that the government decides that the demand of the employees of this company is unfounded, and hence \\ndoes not pay attention to the demand(although, in reality, it was justified))? \\n \\nSOLUTION \\n \\nThe sample size (n = 100) is large enough to assume that the sampling distribution of\\uf060X is approximately normally \\ndistributed with the following mean and standard deviation: \\nand standard deviation \\n \\n \\n \\n \\n \\n \\nNOTE: \\n Here we have used finite population correction factor (fpc), because the sample size n = 100 is greater than 5 \\npercent of the population size N = 310. Since \\uf060X is approximately N (24000, 412.20), therefore  \\n \\n \\n \\n \\n \\nis approximately N(0, 1).We are required to evaluate P(\\uf060X > 24,500). \\nAt\\uf060x = 24,500, we find that \\n \\n \\n \\n \\n \\n \\n \\nUsing the table of areas under the standard normal curve, we find that the area between z = 0 and z = 1.21 is 0.3869. \\n24000 24500 \\n0 1.21 Z \\nX\\n.000,24.Rsx \\uf03d\\uf03d\\uf06d\\uf06d\\n20.412.Rs\\n1310\\n100310\\n100\\n5000\\n1N\\nnN.\\nn\\nx\\n\\uf03d\\n\\uf02d\\n\\uf02d\\uf03d\\uf02d\\n\\uf02d\\uf073\\uf03d\\uf073\\n20.412\\n24000\\uf02d\\uf03d\\uf02d\\uf03d XXZ\\nx\\nx\\n\\uf073\\n\\uf06d\\n21.120.412\\n2400024500 \\uf03d\\uf02d\\uf03dz'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 244}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       240                                                                                                                                           \\n \\nHence,  \\nP(\\uf060X > 24,500)  \\n = P(Z > 1.21) \\n = 0.5 – P(0 < Z < 1.21) \\n = 0.5 – 0.3869 = 0.1131. \\n \\nHence, the chances are only 11% that in a random sample of 100 employees from this particular construction company, \\nthe average salary will exceed Rs.24,500.In other words, the chances are 89% that, in such a sample, the av erage salary \\nwill not exceed Rs.24,500. \\nHence, the chances are considerably high that the government might pay attention to the employees’ demand. \\n \\n SAMPLING DISTRIBUTION OF THE SAMPLE PROPORTION \\n \\nIn this regard, the first point to be noted is that, whene ver the elements of a population can be classified into two \\ncategories, technically called “success” and “failure”, we may be interested in the proportion of “successes”  in the \\npopulation. If X denotes the number of successes in the population, then the pr oportion of successes in the population is \\ngiven by  \\n \\n \\n \\nSimilarly, if we draw a sample of size n from the population, the proportion of successes in the sample is given by  \\n \\n \\n \\n \\nwhere X represents the number of successes in the sample.  \\nIt is interesting to note that X is a binomial random variable and the binomial parameter p is being called a proportion of \\nsuccesses here. The sample proportion has different values in different samples. It is obviously a random variable and \\nhas a probability distribution. \\nThis probability distribution of the proportions of successes in all possible random samples of size n, is called the \\nsampling distribution of   \\nWe illustrate this sampling distribution with the help of the following examples: \\n \\n \\n \\n24000 24500 \\n0 1.21 Z \\nX\\n0.3869 \\n24000 24500 \\n0 1.21 Z \\nX\\n0.3869 \\n0.1131 \\n.N\\nXp \\uf03d\\n,ˆ\\nn\\nXp \\uf03d\\n.pˆ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 245}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       241                                                                                                                                           \\nEXAMPLE-1 \\n \\nA population consists of six values 1, 3, 6, 8, 9 and 12.Draw all possible samples of size n = 3 without replacement \\nfrom the population and find the proportion of even numbers in each sample. Construct the sampling distribution of \\nsample proportions and verify that \\n \\n \\n \\n \\n \\n         \\nSOLUTION \\n \\nThe number of possible samples of size n = 3 that could be selected without replacement from a population of size N is  \\n \\n \\n \\nLet \\npˆ  represent the proportion of even numbers in the sample.  Then the 20 possible samples and the proportion of \\neven numbers are given as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe sampling distribution of sample proportion is given below; \\n \\n \\n \\n \\n \\n \\n \\n \\ni)    \\nppˆ \\uf03d\\uf06d  \\nii)  \\n\\uf028 \\uf029 .1N\\nnN.n\\npqpˆV ar \\uf02d\\n\\uf02d\\uf03d  \\n.203\\n6 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nSample \\nNo. \\nSample \\nData \\nSample \\nProportion \\n\\uf028 \\uf029pˆ  \\n1 1, 3, 6 1/3 \\n2 1, 3, 8 1/3 \\n3 1, 3, 9 0 \\n4 1, 3, 12 1/3 \\n5 1, 6, 8 2/3 \\n6 1, 6, 9 1/3 \\n7 1, 6, 12 2/3 \\n8 1, 8, 9 1/3 \\n9 1, 8, 12 2/3 \\n10 1, 9, 12 1/3 \\n11 3, 6, 8 2/3 \\n12 3, 6, 9 1/3 \\n13 3, 6, 12 2/3 \\n14 3, 8, 9 1/3 \\n15 3, 8, 12 2/3 \\n16 3, 9, 12 1/3 \\n17 6, 8, 9 2/3 \\n18 6, 8, 12 1 \\n19 6, 9, 12 2/3 \\n20 8, 9, 12 2/3 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 246}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       242                                                                                                                                           \\nSAMPLING DISTRIBUTION OF  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTo verify the given relations, we first calculate the population proportion p.Thus: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe sampling distribution of \\npˆ  has the following important properties. \\nPROPERTIES OF THE SAMPLING DISTRIBUTION OF \\npˆ  \\n \\nProperty No. 1 \\n \\nThe mean of the sampling distribution of proportions, denoted by        is equal to the population proportion p, that is  \\n:pˆ\\n\\uf028 \\uf029pˆ\\n No. of  \\nSamples \\nProbability \\n\\uf028 \\uf029pˆf\\n \\n\\uf028 \\uf029pˆfpˆ  \\n\\uf028 \\uf029pˆfpˆ 2  \\n0 1 1/20 0 0 \\n1/3 9 9/20 3/20 1/20 \\n2/3 9 9/20 6/20 4/20 \\n1 1 1/20 1/20 1/20 \\n\\uf053 20 1 10/20 6/20 \\n \\nNow  \\n \\n\\uf028 \\uf029 ,5.020\\n10pˆfpˆpˆ \\uf03d\\uf03d\\uf03d\\uf06d \\uf0e5  and  \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n.05.020\\n1\\n20\\n10\\n60\\n2\\npˆfpˆpˆfpˆ\\n2\\n222\\npˆ\\n\\uf03d\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf073 \\uf0e5\\uf0e5  \\nXp N\\uf03d\\n;Where X represents the \\nnumber of even numbers in the \\npopulation. In other words, \\n3 0.56p \\uf03d\\uf03d\\n \\nHence, we find that  \\n,p5.0pˆ \\uf03d\\uf03d\\uf06d\\n  \\n\\uf028 \\uf029pˆVar05.05\\n25.0\\n16\\n36.3\\n25.0\\n1N\\nnN.n\\npq\\n\\uf03d\\uf03d\\uf03d\\n\\uf02d\\n\\uf02d\\uf03d\\uf02d\\n\\uf02d\\n \\nHence, two properties of the sampling distribution of \\npˆ  \\nare verified. \\n.ˆ pp \\uf03d\\uf06d\\n,1\\nˆ\\n\\uf02d\\n\\uf02d\\uf03d N\\nnN\\nn\\npq\\np\\uf073\\n,ˆp\\uf06d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 247}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       243                                                                                                                                           \\n \\n \\nProperty No. 2 \\n \\nThe standard deviation of the sampling distribution of proportions, called the standard error of and denoted by  \\n \\nis given as: \\n\\uf0b7 a) \\n \\n \\n \\n\\uf0b7 when the sampling is performed with replacement \\n\\uf0b7 b) when sampling is done without replacement from a finite population \\n(As in the case of the sampling distribution of \\uf060X,is known as the finite population correction factor (fpc) \\n \\n \\n \\n \\n \\n \\nProperty No. 3 \\n \\nSHAPE OF THE DISTRIBUTION \\n \\nThe sampling distribution of         is the binomial distribution. However, for sufficiently large sample sizes, the \\nsampling distribution of is approximately normal.  As n \\uf0ae \\uf0a5, the sampling distribution of approaches normality. \\n \\n \\nAs a rule of thumb, the sampling distribution of       will be approximately normal whenever both np and nq are equal to \\nor greater than 5.Let us apply this concept to a real-world situation: \\n \\nEXAMPLE-2 \\n \\nTen percent of the 1 -kilogram boxes of sugar in a large warehouse are underweight. Suppose a retailer buys a random \\nsample of 144 of these boxes. What is the probability that at least 5 percent of the sample boxes will be underweight? \\n \\nSOLUTION \\n \\nHere the statistic is the sample proportion, the sample size (n = 144) is large enough to assume that the sample \\nproportion is approximately normally distributed with mean \\n      \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\npˆ\\n.ˆ pp \\uf03d\\uf06d\\n,n\\npq\\npˆ \\uf03d\\uf073\\n  \\npˆ\\n,ˆp\\uf073\\n,n\\npq\\npˆ \\uf03d\\uf073\\n  \\n,1N\\nnN\\n\\uf02d\\n\\uf02d\\npˆ\\npˆ\\nMean of the sampling distribution of\\npˆ  \\n \\n,10.0ppˆ \\uf03d\\uf03d\\uf06d   \\n \\nStandard Error of \\npˆ  \\n        \\n\\uf028 \\uf029\\uf028 \\uf029\\n.025.012\\n3.0\\n144\\n90.010.0\\nn\\npq\\npˆ\\n\\uf03d\\uf03d\\n\\uf03d\\uf03d\\uf073  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 248}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       244                                                                                                                                           \\n \\n \\nTherefore, the sampling distribution of   is approximately N(0.10, 0.025); and hence \\n \\n \\n \\n \\n \\n \\nis approximately N(0, 1). \\n \\nWe are required to find the probability that the proportion of underweight boxes in the sample is equal to or greater than \\n5% i.e., we require \\n \\n \\n \\nIn this regard, a very important point to be noted is that, just as we use a continuity correction of  + ½ whenever we \\nconsider the normal approximation to the binomially distributed random variable X, in this situation, since  \\n \\n \\n \\n \\ntherefore, we need to use the following continuity correction; We need to use a continuity correction of  \\nin the case of  the sampling distribution of  \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, the probability that at least 5% of the sample boxes are under-weight is as high as 98% . \\nThe sampling distributions of \\uf060X and  pertain to the situation when we are drawing all possible samples of a  \\n \\n0.10 \\n0 -2.14 Z \\npˆ\\n0.4838 0.5 \\n025.0\\n10.0pˆ\\nn/pq\\nppˆpˆ\\nZ\\npˆ\\npˆ\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf073\\n\\uf06d\\uf02d\\uf03d\\n\\uf028 \\uf029.05.0ˆ \\uf0b3pP\\n,n\\nXpˆ \\uf03d\\nn2\\n1\\uf0b1\\n.pˆ\\n   Applying the continuity correction in this problem, we \\nhave: \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf0b3\\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf0b3\\uf0de\\uf0b3\\n288\\n105.0pˆP\\n1442\\n105.0pˆP05.0pˆP\\n \\n\\uf028 \\uf029 \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02d\\uf02d\\uf0b3\\uf02d\\uf03d 025.0\\n10.0288/105.0\\n025.0\\n10.0pˆP\\n \\n\\uf028 \\uf02914.2ZP \\uf02d\\uf0b3\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0a5\\uf0a3\\uf0a3\\uf02b\\uf0a3\\uf0a3\\uf02d\\uf03d Z0P0Z14.2P\\n \\n9838.05.04838.0 \\uf03d\\uf02b\\uf03d\\n \\npˆ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 249}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       245                                                                                                                                           \\nparticular size from one particular population. Next, we will discuss the case when we are dealing with all possible \\nsamples drawn from two populations, such that the samples from the two populations are independent.  \\nIn this regard, we will consider the sampling distributions of       and \\n  \\nWe begin with the sampling distribution of  \\n \\nSAMPLING DISTRIBUTION OF DIFFERENCES BETWEEN MEANS \\n Suppose we have two distinct populations with means \\n21 and \\uf06d\\uf06d  and variances \\n2\\n2\\n2\\n1 and \\uf073\\uf073  respectively. \\nLet independent random samples of sizes \\n21 nandn  be selected from the respective populations, and the \\ndifferences \\n21 xx \\uf02d  between the means of all possible pairs of samples be computed.  \\nThen, a probability distribution of the differences \\n21 XX \\uf02d  can be obtained. Such a distribution is called the sampling \\ndistribution of the differences of sample means\\n21 XX \\uf02d . We illustrate the sampling distribution of               with the help \\nof the following example. \\n \\nEXAMPLE \\n \\nDraw all possible random samples of size n1 = 2 with replacement from a finite population consisting of 4, 6, similarly, \\ndraw all possible random samples of size n = 2 with replacement from another finite population consisting of 1, 2, 3. \\na) Find the possible differences between the sample means of the two populations \\nb) Construct the sampling distribution of           and compute its mean and variance \\nc) Verify that  \\n \\n \\n \\n \\nSOLUTION \\n \\nWhenever we are sampling with replacement from a finite population, the total number of possible samples is Nn \\n(where N is the population size, and n is the sample size).Hence, in this example, there are (3)2 = 9 possible samples \\nwhich can be drawn with replacement from each population. These two sets of samples and their means are given \\nbelow: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\na) Since there are 9 samples from the first population as well as 9 from the second, hence, there are 81 possible \\ncombinations of \\uf060x1 and\\uf060x2  \\nThe 81 possible differences\\uf060x1 –\\uf060x2 are presented in the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n21 XX \\uf02d\\n:ˆˆ 21 pp \\uf02d\\n:21 XX \\uf02d\\n21 XX \\uf02d\\nand21xx 21\\n\\uf06d\\uf02d\\uf06d\\uf03d\\uf06d \\uf02d\\n.\\n1\\n2\\n2\\n1\\n2\\n12\\n21\\nnn\\nxx\\n\\uf073\\uf073\\uf073 \\uf02b\\uf03d\\uf02d\\nFrom Population 1 From Population 2 \\nSampl\\ne No. \\nSampl\\ne \\nValue \\n\\uf060x\\n1 \\nSampl\\ne No. \\nSampl\\ne \\nValue \\n\\uf060x\\n2 \\n1 4, 4 4 1 1, 1 1.0 \\n2 4, 6 5 2 1, 2 1.5 \\n3 4, 8 6 3 1, 3 2.0 \\n4 6, 4 5 4 2, 1 1.5 \\n5 6, 6 6 5 2, 2 2.0 \\n6 6, 8 7 6 2, 3 2.5 \\n7 8, 4 6 7 3, 1 2.0 \\n8 8, 6 7 8 3, 2 2.5 \\n9 8, 8 8 9 3, 3 3.0 \\n \\n21 XX \\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 250}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       246                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nb)The sampling distribution of        is as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThus the mean and the variance are \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nc) In order to verify the properties of the sampling distribution of   we first need to compute the mean and \\nvariance of the first population: \\n2x\\n \\n2x \\n4 5 6 5 6 7 6 7 8 \\n1.0 3.0 4.0 5.0 4.0 5.0 6.0 5.0 6.0 7.0 \\n1.5 2.5 3.5 4.5 3.5 4.5 5.5 4.5 5.5 6.5 \\n2.0 2.0 3.0 4.0 3.0 4.0 5.0 4.0 5.0 6.0 \\n1.5 2.5 3.5 4.5 3.5 4.5 5.5 4.5 5.5 6.5 \\n2.0 2.0 3.0 4.0 3.0 4.0 5.0 4.0 5.0 6.0 \\n2.5 1.5 2.5 3.5 2.5 3.5 4.5 3.5 4.5 5.5 \\n2.0 2.0 3.0 4.0 3.0 4.0 5.0 4.0 5.0 6.0 \\n2.5 1.0 2.5 3.5 2.5 3.5 4.5 3.5 4.5 5.5 \\n3.0 1.0 2.0 3.0 2.0 3.0 4.0 3.0 4.0 5.0 \\n \\n21 XX \\uf02d\\nd\\nxx 21\\n\\uf03d\\n\\uf02d\\n Tally f \\nProbability \\n\\uf028 \\uf029\\n\\uf028 \\uf029df\\nxxf 21\\n\\uf03d\\n\\uf02d\\n df (d) d2 f(d) \\n1.0 |  1 1/81 1/81 1.0/81 \\n1.5 || 2 2/81 3/81 4.5/81 \\n2.0 |||| 5 5/81 10/81 20.0/81 \\n2.5 ||||   | 6 6/81 15/81 37.5/81 \\n3.0 ||||   |||| 10 10/81 30/81 90.0/81 \\n3.5 ||||   |||| 10 10/81 35/81 122.5/81 \\n4.0 ||||   ||||  ||| 13 13/81 52/81 208.0/81 \\n4.5 ||||   |||| 10 10/81 45/81 202.5/81 \\n5.0 ||||   |||| 10 10/81 50/81 250.0/81 \\n5.5 ||||   | 6 6/81 33/81 181.5/81 \\n6.0 |||| 5 5/81 30/81 180.0/81 \\n6.5 || 2 2/81 13/81 84.5/81 \\n7.0 | 1 1/81 7/81 49.0/81 \\nTotal --- 81 1 324/81 1431/81 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 andddf\\nxxfxxxx\\n,481\\n324\\n212121\\n\\uf03d\\uf03d\\uf03d\\n\\uf02d\\uf02d\\uf03d\\n\\uf0e5\\n\\uf0e5\\uf02d\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\n67.13\\n5163\\n53\\n81\\n324\\n81\\n1431\\nddfdfd\\n2\\n222\\nxx 21\\n\\uf03d\\uf03d\\uf02d\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf073 \\uf0e5\\uf0e5\\uf02d\\n21 XX \\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 251}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       247                                                                                                                                           \\nThe mean and standard deviation of the first population are: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe mean and variance of the second population are: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, two properties of the sampling distribution of             are satisfied. The sampling distribution of the \\ndifferences \\n21 XX \\uf02d  has the following properties: \\nPROPERTIES OF THE SAMPLING DISTRIBUTION OF\\n21 XX \\uf02d  \\n \\nProperty No. 1: \\nThe mean of the sampling distribution of \\n21 XX \\uf02d , denoted by \\n,\\n21 XX \\uf02d\\uf06d  is equal to the difference \\nbetween population means, that is \\n \\n \\nProperty No. 2: \\n   In case of sampling with or without replacement from two infinite populations, the standard deviation of the sampling \\ndistribution of \\n21 XX \\uf02d  (i.e. standard error of \\n21 XX \\uf02d ), denoted by \\n,\\n21 XX \\uf02d\\uf073  is given by \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 .3\\n2\\n3\\n232221\\nand,23\\n321\\n222\\n2\\n2\\n2\\n\\uf03d\\uf02d\\uf02b\\uf02d\\uf02b\\uf02d\\uf03d\\uf073\\n\\uf03d\\uf02b\\uf02b\\uf03d\\uf06d\\nandNow xx ,264 2121\\n\\uf06d\\uf06d\\uf06d \\uf02d\\uf03d\\uf02d\\uf03d\\uf03d\\uf02d\\n2\\nxx\\n2\\n2\\n2\\n1\\n2\\n1\\n21\\n67.1\\n3\\n5\\n3\\n1\\n3\\n4\\n2\\n1.3\\n2\\n2\\n1.3\\n8\\nnn\\n\\uf02d\\uf073\\uf03d\\n\\uf03d\\n\\uf03d\\uf02b\\uf03d\\n\\uf02b\\uf03d\\uf073\\uf02b\\uf073\\n2\\nxx\\n2\\n2\\n2\\n1\\n2\\n1\\n21\\n67.1\\n3\\n5\\n3\\n1\\n3\\n4\\n2\\n1.3\\n2\\n2\\n1.3\\n8\\nnn\\n\\uf02d\\uf073\\uf03d\\n\\uf03d\\n\\uf03d\\uf02b\\uf03d\\n\\uf02b\\uf03d\\uf073\\uf02b\\uf073\\n21 XX \\uf02d\\n21XX 21\\n\\uf06d\\uf02d\\uf06d\\uf03d\\uf06d \\uf02d\\n2\\n2\\n2\\n1\\n2\\n1\\nXX nn21\\n\\uf073\\uf02b\\uf073\\uf03d\\uf073 \\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 .3\\n8\\n3\\n686664\\nand,63\\n864\\n222\\n2\\n1\\n1\\n\\uf03d\\uf02d\\uf02b\\uf02d\\uf02b\\uf02d\\uf03d\\uf073\\n\\uf03d\\uf02b\\uf02b\\uf03d\\uf06d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 252}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       248                                                                                                                                           \\nThe above expression for the Standard Error of \\n21 XX \\uf02d  also holds for finite population when sampling is performed \\nwith replacement. In case of sampling without replacement from a finite population, the formula for the standard error  \\nof will be suitably modified. \\n \\nProperty No. 3: \\n \\nShape of the distribution:  \\na) If the POPULATIONS are normally distributed , the sampling distribution of \\n21 XX \\uf02d , regardless of sample \\nsizes, will be normal with mean \\n21 \\uf06d\\uf02d\\uf06d  and variance \\n2\\n2\\n2\\n1\\n2\\n1\\nnn\\n\\uf073\\uf02b\\uf073 .  \\nIn other words, the variable \\n \\n \\n \\n \\n \\n \\n \\nis normally distributed with zero mean and unit variance. \\n \\nb) If the POPULATIONS are non-normal and if both sample sizes are large, (i.e., greater than or equal to 30), then the \\nsampling distribution of the differences between means is approximately a normal distribution by the Central Limit \\nTheorem. \\n In this case too, the variable  \\n \\n \\n \\n \\n \\n \\n \\n \\nwill be approximately normally distributed with mean zero and variance one. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2121\\nnn\\nXXZ\\n\\uf073\\uf073\\n\\uf06d\\uf06d\\n\\uf02b\\n\\uf02d\\uf02d\\uf02d\\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2121\\nnn\\nXXZ\\n\\uf073\\uf073\\n\\uf06d\\uf06d\\n\\uf02b\\n\\uf02d\\uf02d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 253}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       249                                                                                                                                           \\nLECTURE NO. 33 \\n\\uf0b7 Sampling Distribution of    (continued)  \\n\\uf0b7  Point Estimation \\n\\uf0b7 Desirable Qualities of a Good Point Estimator \\no Unbiasedness \\no Consistency \\nWe illustrate the real-life application of the sampling distribution of                 with the help of the following example: \\n \\nEXAMPLE \\n \\nCar batteries produced by company A have a mean life of 4.3 years with a standard deviation of 0.6 years. A similar \\nbattery produced by company B has a mean life of 4.0 years and a standard deviation of 0.4 years. What is the \\nprobability that a random sample of 49 batteries from company A will have a mean life of at least 0.5 years more than \\nthe mean life of a sample of 36 batteries from company B? \\n \\nSOLUTION \\n \\nWe are given the following data: \\nPopulation A: \\n\\uf06d1 = 4.3 years, \\uf0731 = 0.6 years,  \\nSample size: n1 = 49 \\nPopulation B: \\n\\uf06d2 = 4.0 years, \\uf0732 = 0.4 years,  \\nSample size: n2 = 36 \\nBoth sample sizes (n1 = 49, n2 = 36) are large enough to assume that the sampling distribution of the differences               \\nis approximately a normal such that: \\n \\nMEAN \\n \\n \\nand standard deviation: \\n \\n \\n \\n \\n \\nThus the variable \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nis approximately N (0, 1) \\nWe are required to find the probability that the mean life of 49 batteries produced by company A will have a mean life \\nof at least 0.5 years longer than the mean life of 36 batteries produced by company B, i.e. \\nWe are required to find: \\n \\n \\n \\n \\n \\n \\nto z-value, we find that: \\n \\n \\n \\n \\n \\n21 XX \\uf02d\\nyears3.00.43.421xx 21 \\uf03d\\uf02d\\uf03d\\uf06d\\uf02d\\uf06d\\uf03d\\uf06d \\uf02d\\n.1086.0\\n36\\n16.0\\n49\\n36.0\\n2\\n2\\n2\\n1\\n2\\n1\\n21\\nyears\\nnn\\nxx\\n\\uf03d\\n\\uf02b\\uf03d\\uf02b\\uf03d\\uf02d\\n\\uf073\\uf073\\uf073\\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2121\\nnn\\nXXZ\\n\\uf073\\uf073\\n\\uf06d\\uf06d\\n\\uf02b\\n\\uf02d\\uf02d\\uf02d\\uf03d\\n\\uf028 \\uf029\\n1086.0\\n3.021 \\uf02d\\uf02d\\uf03d XX\\n\\uf028 \\uf029.5.021 \\uf0b3\\uf02dXXP\\n5.0ngTransformi 21 \\uf03d\\uf02dXX\\n84.11086.0\\n3.05.0 \\uf03d\\uf02d\\uf03dz\\n21 XX \\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 254}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       250                                                                                                                                           \\n \\nHence, using the table of areas under normal curve, we find: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn other words, (given that the real difference between the mean lifetimes of batteries of company A and batteries of \\ncompany B is  \\n4.3 - 4.0 = 0.3 years), the probability that a sample of 49 batteries produced by company A will have a mean life of at \\nleast 0.5 years longer than the mean life of a sample of 36 batteries produced by company B, is only 3.3%. \\n \\nSAMPLING DISTRIBUTION OF THE DIFFERENCES BETWEEN PROPORTIONS \\n \\nSuppose there are two binomial populations with proportions of successes p1 and p2 respectively.  Let independent \\nrandom samples of sizes n 1 and n2 be drawn from the respective populations, and the differences \\n21 pˆpˆ \\uf02d  between \\nthe proportions of all possible  pairs of samples be computed. Then, a probability distribution of the differences \\n21 pˆpˆ \\uf02d\\n can be obtained. Such a probability distribution is called the sampling distribution  of the differences \\nbetween the proportions \\n21 pˆpˆ \\uf02d  .We illustrate the sampling distribution of \\n21 pˆpˆ \\uf02d  with the help of the following \\nexample: \\n \\nEXAMPLE \\n \\nIt is claimed that 30% of the households in Community A and 20% of the households in Community B have at least one \\nteenager. A simple random sample of 100 households from each community yields the following results: \\nWhat is the probability of observing a difference this large or larger if the claims are true? \\n \\n \\nSOLUTION \\nWe assume that if the claims are true, the sampling distribution of \\nBA pˆpˆ \\uf02d  is approximately normally distributed \\n(as, in this example, both the sa mple sizes are large enough for us to apply the normal approximation to the binomial \\ndistribution).Since we are reasonably confident that our sampling distribution is approximately normally distributed, \\nhence we will be finding any required probability by computing the relevant areas under our normal curve, and, in order \\nto do so, we will first need to convert our variable \\nBA pˆpˆ \\uf02d  to Z. In order to convert                to Z, we need the \\nvalues of                      as well as \\nIt can be mathematically proved that: \\nPROPERTIES OF THE SAMPLING DISTRIBUTION OF \\n21 pˆpˆ \\uf02d  \\nProperty No. 1: \\nThe mean of the sampling distribution of \\n21 pˆpˆ \\uf02d , denoted by \\n,\\n21 PˆPˆ \\uf02d\\uf06d  is equal to the difference between the \\npopulation proportions, that is \\n.pp 21pˆpˆ 21 \\uf02d\\uf03d\\uf06d \\uf02d  \\n0.3 0.5 \\n0 1.84 Z \\n21 XX \\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf02984.1ZP5.0XXP 21 \\uf0b3\\uf03d\\uf0b3\\uf02d\\n \\n \\n\\uf028 \\uf029\\n0329.0\\n4671.05.0\\n84.1Z0P5.0\\n\\uf03d\\n\\uf02d\\uf03d\\n\\uf03c\\uf03c\\uf02d\\uf03d  \\n.13.0ˆ,34.0ˆ \\uf03d\\uf03d BA pp\\nBA pp ˆˆ \\uf02d\\nBA PˆPˆ \\uf02d\\uf06d\\n.\\nBA PˆPˆ \\uf02d\\uf073'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 255}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       251                                                                                                                                           \\nProperty No. 2: \\nThe standard deviation of the sampling distribution of \\n21 pˆpˆ \\uf02d , (i.e. the standard error of \\n21 pˆpˆ \\uf02d ) denoted by \\n21 pˆpˆ \\uf02d\\uf073\\n is given by \\n,n\\nqp\\nn\\nqp\\n2\\n22\\n1\\n11\\npˆpˆ 21 \\uf02b\\uf03d\\uf073 \\uf02d\\n \\nwhere q = 1 – p \\nHence, in this example, we have: \\n \\n10.020.030.0BA pˆpˆ \\uf03d\\uf02d\\uf03d\\uf06d \\uf02d\\n \\n\\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 0037.0100\\n80.020.0\\n100\\n70.030.02\\npˆpˆ BA \\uf03d\\uf02b\\uf03d\\uf073 \\uf02d\\n \\nThe observed difference in sample proportions is \\n21.013.034.0pˆpˆ BA \\uf03d\\uf02d\\uf03d\\uf02d\\n \\n \\nThe probability that we wish to determine is represented by the area to the right of 0.21 in the sampling distribution of \\nBA pˆpˆ \\uf02d\\n.To find this area, we compute \\n83.106.0\\n11.0\\n0037.0\\n10.021.0z \\uf03d\\uf03d\\uf02d\\uf03d\\n \\n \\nBy consulting the Area Table of the standard normal distribution, we find that the area between z = 0 and z = 1.83 is \\n0.4664. Hence, the area to the right of z = 1.83 is 0.0336. \\nThis probability is shown in following figure: \\n \\n \\n0.10 \\n1.83 0 \\n0.21 \\nBA pp ˆˆ \\uf02d\\nZ \\n0.10 \\n1.83 0 \\n0.21 \\nBA pp ˆˆ \\uf02d\\nZ \\n0.4664 0.0336 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 256}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       252                                                                                                                                           \\n \\nThus, if the claim is true, the probability of observing a difference as larger as or larger than  the actually observed is \\nonly 0.0336 i.e. 3.36%.   The students are encouraged to try to interpret this result with reference to the situation at \\nhand, as, in attempting to solve a statistical problem, it is very important not just to apply various formula e and obtain \\nnumerical results, but to interpret the results with reference to the problem under consideration.  Does the result indicate \\nthat at least one of the two claims is untrue, or does it imply something else? Before we close the basic discussion \\nregarding sampling distributions, we would like to draw the students’ attention to the following two important points: \\n\\uf0b7 We have discussed various sampling distributions with reference to the simplest technique of random \\nsampling, i.e. simple random sampling. \\n\\uf0b7 And, with reference to simple random sampling, it should be kept in mind that this technique of sampling is \\nappropriate in that situation when the population is homogeneous. \\n\\uf0b7 Let us consider the reason why the standard deviation of the sampling distribution  of any statistic is known as \\nits standard error: \\nTo answer this question, consider the fact that any statistic, considered as an estimate of the corresponding population \\nparameter, should be as close in magnitude to the parameter as possible. The difference between the value of the \\nstatistic and the value of the parameter can be regarded as an error --- and is called ‘sampling error’. Geometrically, \\neach one of these errors can be represented by horizontal line segment below the X-axis, as shown below \\nSampling Distribution of \\n \\n \\n \\nThe above diagram clearly indicates that there are various magnitudes of this error, depending on how far or how close \\nthe values of our statistic are in different samples. \\nThe standard deviation of \\uf060X gives us a ‘standard’ value of this error, and hence the term ‘Standard Error’. \\nHaving presented the basic ideas regarding sampling distributions, we now begin the discussion regarding POINT \\nESTIMATION: \\n \\nPOINT ESTIMATION \\n \\nPoint estimation of a population parameter provides as an estimate a single value calculated from the sample that is \\nlikely to be close in magnitude to the unknown parameter. \\n \\nDIFFERENCE BETWEEN ‘ESTIMATE’ AND ‘ESTIMATOR’ \\n \\nAn estimate is a numerical value of the unknown parameter obtained by applying a rule or a formula, called an \\nestimator, to a sample X1, X2, …, Xn of size n, taken from a population. In other words, an estimator stands for the \\nrule or method that is used to estimate a parameter whereas an estimate stands for the numerical value obtained by \\nsubstituting the sample observations in the rule or the formula. \\nFor instance:  \\nIf X1, X2, …, Xn is a random sample of size n from a population with mean \\uf06d, then \\ni\\nn\\n1i\\nXn\\n1X \\uf0e5\\n\\uf03d\\n\\uf03d  is an estimator of \\uf06d, \\nand \\uf060x, the numerical value of \\uf060X, is an estimate of \\uf06d (i.e. a point estimate of \\uf06d). \\nIn general, the (the Greek letter \\uf071) is customarily used to denote an unknown parameter that could be a mean, median, \\nproportion or standard deviation, while an estimator of \\uf071 is commonly denoted by \\n\\uf071ˆ , or sometimes by T. \\nIt is important to note that an estimator is always a statistic which is a function of the sample observations and hence is \\na random variable as the sample observations are likely to vary from sample to sample. \\nIn other words: \\n\\uf06d \\nx\\n3x\\n1x\\n2x\\n4x\\n5x\\n6x'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 257}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       253                                                                                                                                           \\nIn repeated sampling, an estimator is a random variable, and has a probability distribution, which is known as its \\nsampling distribution. Having presented the basic definition of a point estimator, we now consider some desirable \\nqualities of a good point estimator. In this regard, the point to be understood is that a point estimator is considered a \\ngood estimator if it satisfies various criteria. Three of these criteria are: \\n \\nDESIRABLE QUALITIES OF A GOOD POINT ESTIMATOR \\n \\n\\uf0b7 unbiasedness \\n\\uf0b7 consistency \\n\\uf0b7 efficiency \\n \\nUNBIASEDNESS \\n \\nAn estimator is defined to be unbiased if the statistic used as an estimator has its expected value equal to the true value \\nof the population parameter being estimated. In other words, let \\n\\uf071ˆ  be an estimator of a parameter\\uf071. Then  \\n\\uf071ˆ  will be \\ncalled an unbiased estimator if \\n\\uf028 \\uf029 .ˆE \\uf071\\uf03d\\uf071 If \\n\\uf028 \\uf029 ,ˆE \\uf071\\uf0b9\\uf071  the statistic is said to be a biased estimator \\n \\nEXAMPLE \\nLet us consider the sample mean \\uf060X as an estimator of the population mean\\uf06d. Then we have \\uf071 = \\uf06d \\nand \\n.Xn\\n1Xˆ i\\nn\\n1i\\n\\uf0e5\\n\\uf03d\\n\\uf03d\\uf03d\\uf071  \\n \\nNow, we know that \\n\\uf028 \\uf029 \\uf06d\\uf03dXE  \\ni.e. \\n\\uf028 \\uf029 .ˆE \\uf071\\uf03d\\uf071  \\nHence, \\nX  is an unbiased estimator of\\uf06d. Let us illustrate the concept of unbiasedness by considering the example of \\nthe annual Ministry of Transport test that was presented in the last lecture: \\n \\nEXAMPLE \\n \\nLet us examine the case of an annual Ministry of Transport test to which all cars, irrespective of age, have to be \\nsubmitted. The test looks for faulty breaks, steering, lights and suspension, and it is discovered after the first year that \\napproximately the same number of cars have 0, 1, 2, 3, or 4 faults. The above situation is equivalent to the following: \\nIf we let X denote the number of faults in a car, then X can take the values 0, 1, 2, 3, and 4, and the probability of each \\nof these X values is 1/5. Hence, we have the following probability distribution: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nMEAN OF THE POPULATION DISTRIBUTION \\n \\n \\n \\nWe are interested in considering the results that would be obtained if a sample of only two cars is tested. \\nYou will recall that we obtained 52 = 25 different possible samples, and, computing the mean of each possible sample, \\nwe obtained the following sampling distribution of \\uf060X: \\n \\n \\nNo. of \\nFaulty Items \\n(X) \\nProbability \\nf(x) \\n0 1/5 \\n1 1/5 \\n2 1/5 \\n3 1/5 \\n4 1/5 \\nTotal 1 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 2\\uf03d\\uf0e5\\uf03d\\uf03d xxfXE\\uf06d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 258}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       254                                                                                                                                           \\nSample Mean Probability \\nx\\n P(\\uf060X =\\uf060x) \\n0.0 1/25 \\n0.5 2/25 \\n1.0 3/25 \\n1.5 4/25 \\n2.0 5/25 \\n2.5 4/25 \\n3.0 3/25 \\n3.5 2/25 \\n4.0 1/25 \\nTotal 25/25=1 \\n \\nWe computed the mean of this sampling distribution, and found that the mean of the sample means i.e. comes out to be \\nequal to 2 --- exactly the same as the mean of the population. We find that: \\n \\n \\n \\n \\ni.e the mean of the sampling distribution of\\uf060X is equal to the population mean. By virtue of this property, we say that \\nthe sample mean is an UNBIASED estimate of the population mean. It should be noted that this property,    \\nalways holds   regardless of the sample size. Unbiasedness is a property that requires that the probability \\ndistribution of \\n\\uf071ˆ  be necessarily centered at the parameter\\uf071, irrespective of the value of n. \\n \\n  \\nVISUAL REPRESENTATION OF THE CONCEPT OF UNBIASEDNESS \\n \\n \\n \\n    implies that the distribution of       is centered at \\uf06d.What this means is that, although many of the individual \\nsample means are either under-estimates or over-estimates of the true population mean, in the long run, the over-\\nestimates balance the under-estimates so that the mean value of the sample means comes out to be equal to the \\npopulation mean. \\nLet us now consider some other estimators which possess the desirable property of being unbiased: The sample median \\nis also an unbiased estimator of \\uf06d when the population is normally distributed (i.e. If X is normally distributed, then \\nAlso, as far as p, the proportion of successes in the sample is concerned, we have considering the binomial random \\nvariable X (which denotes the number of successes in n trials), we have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf06d \\nX\\n\\uf028 \\uf029 \\uf06d\\uf06d \\uf03d\\uf03d\\uf03d\\uf03d\\uf0e5 225\\n50xfxx\\n,x \\uf06d\\uf03d\\uf06d\\n\\uf028 \\uf029 \\uf06d\\uf03dXE\\n\\uf028 \\uf029 ).~ \\uf06d\\uf03dXE\\n\\uf028 \\uf029 \\uf028 \\uf029\\npn\\nnp\\nXEnn\\nXEpE\\n\\uf03d\\uf03d\\n\\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d 1ˆ\\nX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 259}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       255                                                                                                                                           \\nHence, the sample proportion is an unbiased estimator of the population parameter p. But As far as the sample v ariance \\nS2 is concerned; it can be mathematically proved that E(S2) \\uf0b9 \\uf0732.Hence, the sample variance S2 is a biased estimator \\nof \\uf0732.For any population parameter \\uf071 and its estimator \\n\\uf071ˆ , the quantity \\n\\uf028 \\uf029 \\uf071\\uf02d\\uf071ˆE  is known as the amount of bias. \\nThis quantity is positive if \\n\\uf028 \\uf029 ,ˆE \\uf071\\uf03e\\uf071  and is negative if \\n\\uf028 \\uf029 ,ˆE \\uf071\\uf03c\\uf071 and, hence, the estimator is said to be positively \\nbiased when \\n\\uf028 \\uf029 \\uf071\\uf03e\\uf071ˆE  and negatively biased when \\n\\uf028 \\uf029 \\uf071\\uf03c\\uf071ˆE .Since unbiasedness is a desirable quality, we would \\nlike the sample variance to be an unbiased estimator of \\uf0732.In order to achieve this end, the formula of the sample \\nvariance is modified as follows: \\nModified formula for the sample variance: \\n \\n \\n \\n \\nSince E(s2) = \\uf0732, hence s2 is an unbiased estimator of \\uf0732.Why is unbiasedness consider a desirable property of an \\nestimator? In order to obtain an answer to this question, consider the following: With reference to the estimation of the \\npopulation mean \\uf06d, we note that, in an actual study, the probability is very high that the mean of our sample i.e. \\uf060X will \\neither be less than \\uf06d or more than \\uf06d. \\nHence, in an actual study, we can never guarantee that our \\uf060X  will coincide with \\uf06d. \\nUnbiasedness implies that, although in an actual study, we cannot guarantee that our sample mean will coincide with \\uf06d, \\nour estimation procedure (i.e. formula) is such that, in repeated sampling, the average value of our statistic will be \\nequal to \\uf06d. \\nThe next desirable quality of a good point estimator is consistency: \\n \\nCONSISTENCY \\nAn estimator \\n\\uf071ˆ  is said to be a consistent estimator of the parameter \\uf071 if, for any arbitrarily small positive quantity e, \\n \\n    \\n\\uf05b \\uf05d .1eˆPLim\\nn\\n\\uf03d\\uf0a3\\uf071\\uf02d\\uf071\\n\\uf0a5\\uf0ae  \\nIn other words, an estimator \\n\\uf071ˆ  is called a consistent estimator of \\uf071 if the probability that \\n\\uf071ˆ  is very close to  \\uf071, \\napproaches unity with an increase in the sample size. It should be noted that consistency is a large sample property. \\nAnother point to be noted is that a consistent estimator may or may not be unbiased. \\nThe sample mean\\ni\\nn\\n1i\\nXn\\n1X \\uf0e5\\n\\uf03d\\n\\uf03d , which is an unbiased estimator of \\uf06d, is a consistent estimator of the mean \\uf06d.The \\nsample proportion     is also a consistent estimator of the parameter p of a population that has a binomial distribution. \\nThe median is not a consistent estimator of \\uf06d when the population has a skewed distribution. The sample variance \\n \\n \\n \\nthough a biased estimator, is a consistent estimator of the population variance \\uf0732. Generally speaking, it can be proved \\nthat a statistic whose STANDARD ERROR decreases with an increase in the sample size, will be consistent. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029\\n1\\n2\\n2\\n\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\nn\\nxxs\\npˆ\\n\\uf028 \\uf029 ,1 2\\n1\\n2 XXnS i\\nn\\ni\\n\\uf02d\\uf03d \\uf0e5\\n\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 260}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       256                                                                                                                                           \\nLECTURE NO. 34 \\n \\n\\uf0b7 Desirable Qualities of a Good Point Estimator: \\n\\uf0a7 Efficiency \\n\\uf0b7 Methods of Point Estimation: \\n\\uf0a7 The Method of Moments \\n\\uf0a7 The Method of Least Squares \\n\\uf0a7 The Method of Maximum Likelihood \\n\\uf0b7 Interval Estimation: \\n\\uf0a7 Confidence Interval for \\uf06d \\nAs a sample is only a part of the population, it is obvious that the larger the sample size, the more representative we \\nexpect it to be of the population from which it has been drawn. In agreement with the above argument, we will expect \\nour estimator to be close to the corresponding parameter if the sample size is large. Hence, we will naturally be happy if \\nthe probability of our estimator being close to the parameter increases with an increase in the sample size. As such, \\nconsistency is a desirable property. \\nAnother important desirable quality of a good point estimator is EFFICIENCY:  \\n \\nEFFICIENCY \\n \\nAn unbiased estimator is defined to be efficient if the variance of its sampling distribution is smaller than that of the \\nsampling distribution of any other unbiased estimator of the same parameter. In other words, suppose that there are two \\nunbiased estimators T1 and T2 of the same parameter\\uf071.Then, the estimator T1 will be said to be more efficient than T2 if \\nVar (T1) < Var (T2).  \\nIn the following diagram, since Var (T1) < Var (T2),  \\nhence T1 is more efficient than T2 : \\n \\n \\n \\nThe relative efficiency of T1 compared to T2 (where both T1 and T2 are unbiased estimators) is given by the ratio \\n\\uf028 \\uf029\\n\\uf028 \\uf029.TVar\\nTVarE\\n1\\n2\\nf \\uf03d\\n \\nAnd, if we multiply the above expression by 100, we obtain the relative efficiency in percentage form. It thus provides \\na criterion for comparing different unbiased estimators of a parameter. Both the sample mean and the sample median \\nfor a population that has a normal distribution, are unbiased and consistent estimators of \\uf06d but the variance of the \\nsampling distribution of sample means  is smaller than the variance of the sampling distribution of sample medians. \\nHence, the sample mean is more efficient than the sample median as an estimator of \\uf06d.The sample mean may therefore \\nbe preferred as an estimator.  \\nNext, we consider various methods of point estimation. A point estimator of a parameter can be obtained by several \\nmethods. We shall be presenting a brief account of the following three methods: \\n \\nMETHODS OF POINTESTIMATION \\n \\n\\uf0b7 The Method of Moments \\n\\uf0b7 The Method of Least Squares \\n\\uf0b7 The Method of Maximum Likelihood  \\nThese methods give estimates which may differ as the methods are based on different theories of estimation. \\nSampling \\nDistribution of T1 \\nSampling \\nDistribution of T2 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 261}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       257                                                                                                                                           \\nTHE METHOD OF MOMENTS \\n \\nThe method of moments which is due to Karl Pearson (1857-1936), consists of calculating a few moments of the sample \\nvalues and equating them to the corresponding moments of a population, thus getting as many equations as are needed \\nto solve for the unknown parameters.  The procedure is described below: \\nLet X1, X2, …, Xn be a random sample of size n from a population. Then the rth sample moment about zero is \\n \\n \\n \\nand the corresponding rth population moment is       We then match these moments and get as many equations as we \\nneed to solve for the unknown parameters. The following examples illustrate the method: \\n \\nEXAMPLE-1 \\n \\nLet X be uniformly distributed on the interval (0, \\uf071). Find an estimator of \\uf071 by the method of moments. \\n \\nSOLUTION \\n \\nThe probability density function of the given uniform distribution is  \\n  \\n \\n \\nSince the uniform distribution has only one parameter, (i.e. \\uf071), therefore, in or der to find the maximum likelihood \\nestimator of \\uf071 by the method of moments, we need to consider only one equation. \\nThe first sample moment about zero is \\n \\n \\n \\nAnd, the first population moment about zero is  \\n \\n \\n \\n \\n \\nMatching these moments, we obtain: \\n \\n \\n \\n \\n \\nHence, the moment estimator of \\uf071 is equal to   \\ni.e.  \\n  \\n \\n \\nIn other words, the moment estimator of \\uf071 is just twice the sample mean. It should be noted that, for the above uniform \\ndistribution, the mean is given by  \\n \\n \\n \\n \\n \\n(This is so due to the absolute symmetry of the uniform distribution around the value  \\n \\nNow,   implies that \\n \\nIn other words, if we wish to have the exact value of \\uf071, all we need to do is to multiply the population mean \\uf06d by 2. \\nGenerally, it is not possible to determine \\uf06d, and all we can do is  to draw a sample from the probability distribution, and \\ncompute the sample mean \\uf060X. Hence, naturally, the equation will be replaced by the equation \\n(As provides an estimate of \\uf071, hence a ‘hat’ is placed on top of \\uf071.) \\nIt is interesting to note hat  is exactly the same quantity as what we obtained as an estimate of \\uf071 by the method of \\nmoments!(The result obtained by the method of moments coincides  with what we obtain through simple logic \\n \\nEXAMPLE-2 \\n \\n,...2,1,' \\uf03d\\uf0e5\\uf03d rn\\nXm\\nr\\ni\\nr\\n.'r\\uf06d\\n\\uf028 \\uf029 \\uf071\\uf071 \\uf0a3\\uf0a3\\uf03d xxf 0,1\\n.'1\\nn\\nXm i\\uf0e5\\uf03d\\n\\uf028 \\uf029 2\\n0\\n2\\nx1dx1.xdxxf.x'\\n2\\n00\\n1\\n\\uf071\\uf03d\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf071\\n\\uf071\\uf03d\\uf071\\uf03d\\uf03d\\uf06d \\uf0f2\\uf0f2\\n\\uf071\\uf071\\n.X2or2n\\nXi \\uf03d\\uf071\\uf071\\uf03d\\uf0e5\\nX2\\n.X2ˆ \\uf03d\\uf071\\n.2\\n\\uf071\\uf06d \\uf03d\\n).2\\n\\uf071\\n2\\n\\uf071\\uf06d \\uf03d\\n.2\\uf06d\\uf071 \\uf03d\\nx2\\nx2\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 262}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       258                                                                                                                                           \\nLet X1, X2 … Xn be a random sample of size n from a normal  population with parameters \\uf06d and \\uf0732. Find these \\nparameters by the method of moments. \\n \\nSOLUTION \\n \\nHere we need two equations as there are two unknown parameters, \\uf06d  and \\uf0732. The first two sample moments about zero \\nare \\n \\n \\n \\n \\nThe corresponding two moments of a normal distribution are \\n \\n \\uf0a2\\uf06d1 = \\uf06d and \\uf0a2\\uf06d2 = \\uf0732 + \\uf06d2. \\n \\n (    \\uf0732  = \\uf0a2\\uf06d2 – \\uf0a2\\uf06d12 = \\uf0a2\\uf06d2 – \\uf06d2) \\nTo get the desired estimators by the method of moments, we match them.  \\nThus, we have : \\n \\n \\n \\n \\nSolving the above equations simultaneously, we obtain: \\nand,XXn\\n1ˆ i \\uf03d\\uf03d\\uf06d \\uf0e5\\n \\n\\uf028 \\uf029\\uf0e5\\uf0e5 \\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\uf073 .SXXn\\n1Xn\\nXˆ 22\\ni\\n2\\n2\\ni2\\n \\nas the moment estimators for \\uf06d and \\uf0732. A shortcoming of this method is that the moment estimators are, in general, \\ninefficient. \\n \\n \\nTHE METHOD OF LEAST SQUARES \\n \\nThe method of Least Squares, which is due to Gauss (1777-1855) and Markov (1856-1922), is based on the theory of \\nlinear estimation. It is regarded as one of the important methods of point estimation. An estimator found by minimizing \\nthe sum of squared deviations of the sample values from some function that has been hypothesized as a fit for the data, \\nis called the least squares estimator.  The method of least -squares has already been discussed in connection with \\nregression analysis that was presented in Lecture No. 15. \\n You will recall that, when fitting a straight line y = a+bx to real data, ‘a’ and ‘b’ were determined by minimizing the \\nsum of squared deviations between the fitted line and the data-points. \\nThe y-intercept and the slope of the fitted line i.e. ‘a’ and ‘b’ are least-square estimates (respectively) of the y-intercept \\nand the slope of the TRUE line that would have been obtained by considering the entire population of data -points, and \\nnot just a sample. \\n \\nMETHOD OF MAXIMUM LIKELIHOOD \\n \\nThe method of maximum likelihood is regarded as the MOST important method of estimation, and is the most widely \\nused method. This method was introduced in 1922 by Sir Ronald A. Fisher (1890 -1962).The mathematical technique of \\nfinding Maximum Likelihood Estimators is a bit advanced, and involves the concept of the Likelihood Function. \\n \\nRATIONALE OF THE METHOD OF MAXIMUM LIKELIHOOD (ML) \\n \\n“To consider every possible value that the parameter might have, and for each value, compute the probability that the \\ngiven sample would have occurred if that were the true value of the parameter.  That v alue of the parameter for which \\nthe probability of a given sample is greatest, is chosen as an estimate.” An estimate obtained by this method is called \\nthe maximum likelihood estimate (MLE). It should be noted that the method of maximum likelihood is appli cable to \\nboth discrete and continuous random variables. \\n \\nEXAMPLES OF MLE’s IN CASE OF DISCRETE DISTRIBUTIONS \\n \\nExample-1:  \\nFor the Poisson distribution given by \\n \\n \\n.1'1' 2\\n21 \\uf0e5\\uf0e5 \\uf03d\\uf03d\\uf03d ii XnmandXXnm\\n\\uf0e5\\uf0e5 \\uf03d\\uf02b\\uf03d 222 11\\nii XnandXn \\uf06d\\uf073\\uf06d\\n......,,2,1,0,!x \\ne   x) P(X\\n-\\n\\uf03d\\uf03d\\uf03d x\\nx\\uf06d\\uf06d\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 263}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       259                                                                                                                                           \\n \\nthe MLE of \\uf06d is \\uf060X (the sample mean). \\n \\n \\nEXAMPLE-2 \\n \\nFor the geometric distribution given by the MLE of p is Hence, the MLE of p is equal to the reciprocal of the mean. \\n \\nEXAMPLE-3 \\nFor the Bernoulli distribution given by  \\n \\n \\nthe MLE of p is (the sample mean). \\n \\nEXAMPLES OF MLE’s IN CASE OF CONTINUOUS DISTRIBUTIONS \\nExample-1 \\nFor the exponential distribution given by \\n \\n \\n \\nthe MLE of \\uf071 is (the reciprocal of the sample mean     ) \\n \\nEXAMPLE-2 \\n \\nFor the normal distribution with parameters \\uf06d and \\uf0732, the joint ML estimators of \\uf06d and \\uf0732 is the sample mean  \\nand the sample variance S2(which is not an unbiased estimator of \\uf0732).As indicated many times earlier, the normal \\ndistribution is encountered frequently in practice, and, in this regard, it is both interesting and important to note that, in \\nthe case of this frequently encountered distribution, the simplest formulae (i.e. the sample mean and the sample \\nvariance) fulfill the criteria of the relatively advanced method of maximum likelihood estimation !The last example \\namong the five presented above (the one on the normal distribution) points to another important  fact --- and that is : \\nThe Maximum Likelihood Estimators are consistent and  efficient but not necessarily unbiased. (As we know, S2 is not \\nan unbiased estimator of \\uf0732.) \\n \\nEXAMPLE \\n \\nIt is well-known that human weight is an approximately normally distributed variable. Suppose that we are interested in \\nestimating the mean and the variance of the weights of adult males in one particular province of a country.  A random \\nsample of 15 adult males from this particular population yields the following weights (in pounds): \\n \\n131.5 136.9 133.8 130.1 133.9 \\n135.2 129.6 134.4 130.5 134.2 \\n131.6 136.7 135.8 134.5 132.7 \\n \\nFind the maximum likelihood estimates for \\uf0711 = \\uf06d and \\uf0712 = \\uf0732. \\n \\nSOLUTION \\n \\nThe above data is that of a random sample of size 15 from N(\\uf06d, \\uf0732).  It has been mathemat ically proved that the joint \\nmaximum likelihood estimators of \\uf06d and \\uf0732 are\\uf060X and S2. We compute these quantities for this particular sample, and \\nobtain \\uf060X = 133.43, and S2 = 5.10 .These are the Maximum Likelihood Estimates of the mean and variance of the \\npopulation of weights in this particular example.  Having discussed the concept of point estimation in some detail, we \\nnow begin the discussion of the concept of interval estimation: \\nAs stated earlier, whenever a single quantity computed from the sample acts  as an estimate of a population parameter, \\nwe call that quantity a point estimate e.g. the sample mean     is a point estimate of the population mean \\uf06d.  \\nThe limitation of point estimation is that we have no way of ascertaining how close our point estimate  is to the true \\nvalue (the parameter). \\nFor example, we know that     is an unbiased estimator of \\uf06d i.e. if we had taken all possible samples of a particular size \\nfrom the population and calculated the mean   of each sample, then the mean of the sample mean s      would have been \\nequal to the population mean ( \\uf06d), but in an actual survey we will be selecting only one sample from the population and \\nwill calculate its mean    .  \\nWe will have no way of ascertaining how close this particular is to\\uf06d. Whereas a point estimate is a single value that acts \\nas an estimate of the population parameter, interval estimation  is a procedure of estimating the unknown parameter \\nwhich specifies a range of values within which the parameter is expected to lie.  A confidence interval is an interval \\ncomputed from the sample observations x1, x2….xn, with a statement of how confident we are that the interval does \\ncontain the population parameter. \\n,1,0,   x) P(X 1 \\uf03d\\uf03d\\uf03d \\uf02d xqp xx\\n\\uf028 \\uf029 ,0,0, \\uf03e\\uf03e\\uf03d \\uf02d \\uf071\\uf071 \\uf071 xexf x\\n.1\\nX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 264}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       260                                                                                                                                           \\nWe develop the concept of interval estimation with the help of the example of the Ministry o f Transport test to which \\nall cars, irrespective of age, have to be submitted. \\n \\nEXAMPLE \\n  \\nLet us examine the case of an annual Ministry of Transport test to which all cars, irrespective of age, have to be \\nsubmitted. The test looks for faulty breaks, steeri ng, lights and suspension, and it is discovered after the first year that \\napproximately the same number  of cars has 0, 1, 2, 3, or 4 faults. You will recall that when we drew all possible \\nsamples of size 2 from this uniformly distributed population, the sampling distribution of \\uf060X was triangular: \\nSampling Distribution of\\uf060X for n = 2 \\n \\n \\nBut when we considered what happened to the shape of the sampling distribution with if the sample size is increased, \\nwe found that it was somewhat like a normal distribution: \\nSampling Distribution of\\uf060X for n = 3 \\n \\nAnd, when we increased the sample size to 4, the sampling distribution resembled a normal distribution even more \\nclosely, Sampling Distribution of\\uf060X for n = 4 \\n4/125 \\n0 \\nX\\n0.\\n00 \\n\\uf028 \\uf029xP\\n0.\\n33 \\n0.\\n67 \\n1.\\n00 \\n1.\\n33 \\n1.\\n67 \\n2.\\n00 \\n2.\\n33 \\n2.\\n67 \\n3.\\n00 \\n3.\\n33 \\n3.\\n67 \\n4.\\n00 \\n8/125 \\n12/125 \\n16/125 \\n20/125 \\n \\n1/25 \\n0 \\n0.\\n5 \\n1.\\n0 \\n1.\\n5 \\n2.\\n0 \\n2.\\n5 \\n3.\\n0 \\n3.\\n5 \\n4.\\n0 \\nX\\n2/25 \\n3/25 \\n4/25 \\n5/25 \\n0.\\n0 \\n\\uf028 \\uf029xP'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 265}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       261                                                                                                                                           \\n \\n \\nIt is clear from the above discussion that as larger samples are taken, the shape of the sampling distribution of \\uf060X \\nundergoes discernible changes.  \\nIn all three cases the line charts are symmetrical, but as the sample size inc reases, the overall configuration changed \\nfrom a triangular distribution to a bell-shaped distribution. In other words, for large samples, we are dealing with a \\nnormal sampling distribution of    .In other words: When sampling from an infinite population such that the sample size \\nn is large,\\uf060X is normally distributed with mean \\uf06d and variance  \\n \\n \\ni.e. \\uf060X is \\n \\nHence, the standardized version of \\uf060X i.e. \\n \\n \\n \\n \\n \\nis normally distributed with mean 0 and variance 1 i.e.  Z is N(0, 1).  Now, for the standard normal dis tribution, we \\nhave: For the standard normal distribution, we have: \\n \\n \\nThe above is equivalent to P(-1.96 < Z < 1.96) \\n  = 0.4750 + 0.4750 = 0.95 \\n1.96 0 -1.96 \\n0.4750 0.4750 \\n0.0250 0.0250 \\nZ \\n20/62\\n5 0 \\nX\\n\\uf028 \\uf029xP\\n40/62\\n5 \\n60/62\\n5 \\n80/62\\n5 \\n100/625 \\n0.\\n75 \\n0.\\n50 \\n0.\\n25 \\n0.\\n00 \\n1.\\n75 \\n1.\\n50 \\n1.\\n25 \\n1.\\n00 \\n2.\\n75 \\n2.\\n50 \\n2.\\n25 \\n2.\\n00 \\n3.\\n75 \\n3.\\n50 \\n3.\\n25 \\n3.\\n00 \\n4.\\n00 \\nx\\nn\\n2\\uf073\\n.,\\n2\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nnN \\uf073\\uf06d\\nn\\nXZ \\uf073\\n\\uf06d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 266}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       262                                                                                                                                           \\n \\nIn other words: \\n \\n \\n \\n \\n \\n \\n \\nThe above can be re-written as: \\n \\n \\n \\n \\nOr \\n \\n \\n \\n \\nor \\n \\n \\n \\nor \\n \\n \\n \\n \\n \\nThe above equation yields the 95% confidence interval for \\uf06d : \\nThe 95% confidence interval for \\uf06d is  \\n \\n \\n \\n \\nIn other words, the 95% C.I. for \\uf06d is given by \\n \\n \\n \\nIn a real-life situation, the population standard deviation is usually not known and hence it has to be estimated. \\nIt can be mathematically proved that the quantity \\n \\n \\n \\n \\nis an unbiased estimator of \\uf0732 (the population variance). (just as the sample mean     is an unbiased estimator of \\uf06d). \\nIn this situation, the 95% Confidence Interval for \\uf06d is given by: \\n \\n \\nThe points \\n \\n \\n \\nare called the lower and upper limits of the 95% confidence interval. \\n1.96 0 -1.96 \\n0.95 \\n0.025 0.025 \\nZ \\n95.096.196.1 \\uf03d\\n\\uf0f7\\uf0f7\\n\\uf0f7\\n\\uf0f7\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e7\\n\\uf0e7\\n\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf0a3\\uf02d\\uf0a3\\uf02d\\nn\\nXP \\uf073\\n\\uf06d\\n95.096.196.1 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf0a3\\uf02d\\uf0a3\\uf02d\\nn\\nX\\nn\\nP \\uf073\\uf06d\\uf073\\n95.096.196.1 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf02d\\uf0a3\\uf02d\\uf0a3\\uf02d\\uf02d\\nn\\nX\\nn\\nXP \\uf073\\uf06d\\uf073\\n95.096.196.1 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf0b3\\uf0b3\\uf02b\\nn\\nX\\nn\\nXP \\uf073\\uf06d\\uf073\\n95.096.196.1 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf0a3\\uf0a3\\uf02d\\nn\\nX\\nn\\nXP \\uf073\\uf06d\\uf073\\n.96.1,96.1 \\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf02d\\nn\\nX\\nn\\nX \\uf073\\uf073\\nn\\n96.1X \\uf073\\uf0b1\\n\\uf028 \\uf029\\n1n\\nXXs\\n2\\n2\\n\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\n%95\\nn\\ns96.1X\\nn\\ns96.1XP \\uf03d\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\uf03c\\uf06d\\uf03c\\uf02d\\nn\\ns96.1Xand\\nn\\ns96.1X \\uf02b\\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 267}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       263                                                                                                                                           \\nLECTURE NO. 35 \\n\\uf0b7 Confidence Interval for \\uf06d (continued).  \\n\\uf0b7 Confidence Interval for \\uf06d1-\\uf06d2. \\nIn the last lecture, we discussed the construction of the 95% confidence interval regarding the mean of a population i.e. \\n\\uf06d. \\n \\nEXAMPLE-1 \\n \\nConsider a car assembly plant employing something over 25,000 men. In planning its future labour requirements, the \\nmanagement wants an estimate of the number of days lost per man each year due to illness or absenteeism.  \\nA random sample of 500 employment records shows the following situation: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nConstruct a 95% confidence interval for the mean number of days lost per man each year due to illness or absenteeism. \\n \\nSOLUTION \\n \\n\\uf0b7 The point estimate of \\uf06d is \\uf060X, which in this example comes out to be \\uf060X = 5.38 days \\n\\uf0b7 In order to construct a confidence interval for \\uf06d, we need to compute s, which in this example comes out to be \\ns = 3.53 days. \\nHence, the 95% confidence interval for \\uf06d comes out to be \\n  \\n \\n \\n \\n or 5.38 \\uf0b1 0.31 days \\n = 5.07 days to 5.69 days. \\nIn other words, we can say that the mean number of days lost per man each year due to illness or absenteeism lies \\nsomewhere between 5.07 days and 5.69 days, and this statement is be ing made on the basis of 95% confidence.  A very \\nimportant point to be noted here is that we should be very careful regarding the interpretation of confidence intervals \\nWhen we set 1 - \\uf061 = 0.95, it means that the probability is 95% that the interval \\n  \\n \\n \\nwill actually contain the true population mean \\uf06d.In other words, if we construct a large number of intervals of this type, \\ncorresponding to the large number of samples that we can draw from any particular population, then out of every 100 \\nsuch intervals, 95 will contain the true population mean \\uf06d whereas 5 will not. \\nThe above statement pertains to the overall situation in repeated sampling --- once a sample has actually been chosen \\nfrom a population,\\uf060X computed and the interval constructed, then this interval either contains \\uf06d, or does not contain \\uf06d. \\nSo, probability that our interval corresponding to sample values have actually occurred, is either one (i.e. cent per cent), \\nor zero. The statement 95% probability is valid before any sample has actually materialized. In other words, we can say \\nthat our procedure of interval estimation is such that, in repeated sampling, 95% of the intervals will contain\\uf06d. The \\nabove example pertained to the 95% confidence interval for \\uf06d.In general; the lower and upper limits of th e confidence \\ninterval for \\uf06d are given by \\n \\n \\n \\nWhere the value of z\\uf061/2 depends on how much confidence we want to have in our interval estimate. \\n \\nNumber of Days Lost Number of Employees \\nNone 48 \\n1 or 2 43 \\n3 or 4 90 \\n5 or 6 186 \\n7 or 8 78 \\n9 to 12 34 \\n13 to 20 21 \\nTotal 500 \\n \\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf0b4\\uf02b\\uf0b4\\uf02d\\n500\\n53.396.138.5,\\n500\\n53.396.138.5\\nn\\n96.1Xto\\nn\\n96.1Xfrom \\uf073\\uf02b\\uf073\\uf02d\\nn\\nszx 2\\uf061\\uf0b1'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 268}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       264                                                                                                                                           \\n \\nThe above situation leads to the (1-\\uf061) 100% C.I. for \\uf06d . If (1-\\uf061) = 0.95, then z\\uf061/2 = 1.96 whereas , If (1-\\uf061) = 0.99, then \\nz\\uf061/2 = 2.58 and If (1-\\uf061) = 0.90, then z\\uf061/2 = 1.645 . \\n(The above values of z \\uf061/2 are easily obtained from the area table of the standard normal distribution).An important to \\nnote is that, as indicated earlier, the above formula for the conference interval is valid when we are sampling from an \\ninfinite population in such a way that the sample size n is large. How large should n be in a practical situation? \\nThe rule of thumb in this regard is that whenever n \\uf0b3 30,  we can use the above formula. \\n \\nCONFIDENCE INTERVAL FOR\\uf06d, THE MEAN OF AN INFINITE POPULATION \\n \\nFor large n (n \\uf0b3 30), the confidence interval is given by \\n \\n \\n \\n \\nwhere  is the sample mean \\n \\nand  \\n \\n \\n \\nis the sample standard deviation.  \\n \\nEXAMPLE-1 \\n \\nThe Punjab Highway Department is studying the traffic pattern on the G.T. Road near Lahore. As part of the study, the \\ndepartment needs to estimate the average number of vehicles that pass the Ravi Bridge each day. A random sample of \\n64 days gives  X = 5410 and s = 680. Find the 90  per cent confidence interval estimate for \\uf06d, the average number of \\nvehicles per day. \\n \\nSOLUTION \\n \\nThe 90% confidence interval for \\uf06d is  \\n \\n \\n \\nwhere \\n = 5410, \\ns = 680, n = 64 and z0.05 = 1.645. \\n \\nSubstituting these values, we obtain \\n \\n \\n \\n \\nor 5410 \\uf0b1 (1.645) ( 85) \\nor 5410 \\uf0b1 139.8  \\nor 5270.2 to 5549.8 \\nor, rounding the above two figures correct to the nearest whole number, we have  \\n 5270 to 5550 \\n \\nHence, we can say that the average number of vehicles that pass the Ravi bridge each day lies somewhere between 5270 \\nand 5550, and this statement is being made on the basis of 90% confidence. \\nZ \\n\\uf061\\uf02d1\\n2\\uf061\\n2\\uf061\\n2\\uf061z\\n2\\uf061z\\uf02d\\n0 \\nn\\nszx 2\\uf061\\uf0b1\\nn\\nxx \\uf0e5\\uf03d\\n\\uf028 \\uf029\\n1\\n2\\n\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\nn\\nxxs\\n,\\nn\\nszx 2\\uf061\\uf0b1\\nx\\n\\uf028 \\uf029 \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf0b1\\n64\\n680645.15410'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 269}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       265                                                                                                                                           \\nEXAMPLE-2 \\n \\nSuppose a car rental firm wants to estimate the average number of miles traveled per day by each of its cars rented in \\none particular city. A random sample of 110 cars rented in this particular city reveals that the mean travel distance per \\nday is 85.5 miles, with a standard deviation of 19.3 miles.  \\nCompute a 99% confidence interval to estimate\\uf06d. \\n \\nSOLUTION \\n \\nHere, n = 110,\\uf060X = 85.5, and S = 19.3. For a 99% level of confidence, a z-value of 2.575 is obtained.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe point estimate indicates that the average number of miles traveled per day by a rental car in this particular city is \\n85.5. With 99% confidence, we estimate that the population mean is somewhere between 80.8 and 90.2 miles per day. \\nNext, we consider a very interesting and important way of interpreting a confidence interval. An Important Way of \\nInterpreting a Confidence Interval, Because of the fact that \\n \\n \\n \\nHence,  \\n \\n \\n \\n \\n(where        represents the standard error of \\uf060X ,Hence The C.I. for \\uf06d can be defined as X \\uf0b1 a certain number of \\nstandard errors of \\uf060X . efining a Confidence Interval as: \\n“A point estimate plus/minus a few times the standard error of that estimate”, The question arises: “How many times?” \\nThe answer is:That depends on the level of confidence that we wish to have. In the case of 99% confidence, z\\uf061/2 ~ 2.5, \\n(so that, in this case, we can say that our confidence interval is \\n \\n \\n \\nSimilarly, \\nin the case of 95% confidence, z \\uf061/2 ~ 2, (so that, in this case, we can say that our confidence interval is                     \\nand so on. \\n \\n \\nAnother important point to be noted is that: \\nIt is a matter of common sense that, in any situation, the narrower our confidence interval, the better.  \\n(Ideally, the width of a confidence interval should be zero --- i.e. we should simply have a point estimate.) \\nIt would be quite unwise to say: “I am 99.999% confident that the mean height of the adult males of this particular city \\nlies somewhere between 4 feet and 12 feet.” _!  \\nThe important question is: How do we achieve a narrow confidence interval with a high level of confidence? \\nTo answer this question, we should have a closer look at the expression of the confidence interval: \\n \\n \\n \\nThis expression shows clearly that if the quantity                  is small, we will achieve a narrow confidence interval.  \\n  \\nThis quantity will be small if either      is small or         is small. \\nNow, \\n \\n \\n \\nand hence  will be small if the sample size n is large. \\nn\\nSZX\\nn\\nSZX 2/2/ \\uf061\\uf061 \\uf02b\\uf0a3\\uf06d\\uf0a3\\uf02d\\n \\n110\\n3.19575.25.85\\n110\\n3.19575.25.85 \\uf02b\\uf0a3\\uf06d\\uf0a3\\uf02d\\n \\n7.45.857.45.85 \\uf02b\\uf0a3\\uf06d\\uf0a3\\uf02d\\n \\n2.908.80 \\uf0a3\\uf06d\\uf0a3\\n \\n,\\nn\\ntoequalisx\\n\\uf073\\uf073\\ntoequalis\\nn\\nzx 2/\\n\\uf073\\uf0b1 \\uf061\\nx2/zx \\uf073\\uf0b1 \\uf061\\nx\\uf073\\n;)2x x2\\n1 \\uf073\\uf0b1\\n;)2x x\\uf073\\uf0b1\\nx2/zx \\uf073\\uf0b1 \\uf061\\nx2/z \\uf073\\uf061\\n2/\\uf061z\\nx\\uf073\\n,\\nn\\ntoequalisx\\n\\uf073\\uf073\\nx\\uf073'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 270}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       266                                                                                                                                           \\n \\nOn the other hand,              will be small if the level of confidence 1-\\uf061 is relatively low. As far as the first point that of n \\nbeing small is concerned, it should be noted that, in many real-life situations, due to practical constraints, we cannot \\nincrease the sample size beyond a certain limit.(We may not have the resources to be able to draw a relatively large \\nsample --- our budget may be limited, the time-period at our disposal may be short, etc. As far as the second point, that \\nof fixing a relatively low level of confidence, is concerned, this is in our own hands, and we can fix our level of \\nconfidence as low as we wish --- but, obviously, it will not make much sense to say; “I have estimated that the mean \\nheight of adult males of this particular city lies somewhere between 5 feet, 6 inches and 5 feet, 7 inches, and I am \\nsaying this with 20% confidence.” _! \\nThe gist of the above discussion is that, in any real-life situation, given a particular sample size, we need to strike a \\ncompromise between how low a level of confidence can we tolerate, or how wide an interval can we tolerate. \\nNext, we consider the confidence interval for the difference between two population means i.e. \\uf06d1-\\uf06d2: \\n \\nCONFIDENCE INTERVAL FOR THE DIFFERENCE BETWEEN THE MEANS OF TWO POPULATIONS  \\n \\nFor large samples drawn independently from two populations, the C.I. for \\uf06d1 – \\uf06d2 is given by \\n \\n \\n \\n \\nwhere  \\nSubscript 1 denotes the first population, and subscript 2 denotes the second population. We illustrate this concept with \\nthe help of a few examples: \\n \\nEXAMPLE-1: \\n \\nThe means and variances of the weekly incomes in rupees of two samples of workers are given in the following table, \\nthe samples being randomly drawn from two different factories: \\n \\n \\n \\n \\n \\nCalculate the 90% confidence interval for the real difference in the incomes of the workers from the two factories. \\n \\nSOLUTION \\n \\n1. If both n1 and n2 are large, the confidence limits are given by \\n \\n \\n \\n \\n2. We know that \\n \\nz\\uf061/2 = 1.645 for 90% confidence \\n \\n \\n \\n \\n3.Hence, Substituting the values in the formula, we obtain \\n \\n (12.80 – 11.25) \\uf0b1 1.645  \\n \\n  \\n0 z\\uf061/2=1.645 \\nZ \\n-z\\uf061/2= -1.645 \\n0.90 0.05 0.05 \\n2/z\\uf061\\n\\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2/21 n\\ns\\nn\\nszxx \\uf02b\\uf0b1\\uf02d \\uf061\\nFactory Sample Size Mean Variance \\nA 160 12.80 64 \\nB 220 11.25 47 \\n \\n\\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2/21 n\\ns\\nn\\nszxx \\uf02b\\uf0b1\\uf02d \\uf061\\n220\\n47\\n160\\n64 \\uf02b\\n21.04.0 \\uf02b'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 271}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       267                                                                                                                                           \\n or  1.55 \\uf0b1 1.645 \\n  \\n or 1.55 \\uf0b1 1.645  \\n or 1.55 \\uf0b1 1.28 \\n or 0.27 and 2.83 \\nHence we can say that we are 90% confident that, on the average, the difference in the incomes of the workers from the \\ntwo factories lies somewhere between Rs.0.27 and Rs.2.83. \\n \\nEXAMPLE-2 \\n \\nSuppose a study is conducted in a developed country to estimate the difference between middle -income shoppers and \\nlow-income shoppers in terms of the average amount saved on grocery bills per week by using coupo ns. Random \\nsamples of 60 middle-income shoppers and 80 low -income shoppers are taken, and their purchases are monitored for 1 \\nweek. The average amounts saved with coupons, as well as sample sizes and sample standard deviations are given \\nbelow: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUse this information to construct a 98% confidence interval to estimate the difference between the mean amounts saved \\nwith coupons by middle-income shoppers and low-income shoppers. \\nSOLUTION: \\n \\nThe value of     associated with a 98% level of confidence is 2.33.  \\n \\n \\nUsing this value, we can determine the confidence interval as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, the 98% confidence interval for the difference between the mean amounts saved with coupons by middle -\\nincome shoppers and low -income shoppers is ($2.72, $3.62). The point estimate for the difference in mean savings is \\n$3.17. Note that a zero difference in the population means of these two groups is unlikely, because the number zero is \\nnot in the 98% range. The data seems to provid e a strong indication that, on the average, the  middle income shoppers \\nare saving a little more than the low income shoppers. \\n0 z\\uf061/2=2.33 \\nZ \\n-z\\uf061/2= -2.33 \\n0.98 0.01 0.01 \\n61.0\\nMiddle-Income  \\nShoppers \\nLow-Income  \\nShoppers \\nn1 = 60 n2 = 80 \\n1X\\n = $5.84 \\n2X  = $2.67 \\nS1 = $1.41 S2 = $0.54 \\n \\n2/\\uf061z\\n\\uf028 \\uf029\\n\\uf028 \\uf029 80\\n54.0\\n60\\n41.133.267.284.5\\n80\\n54.0\\n60\\n41.133.267.284.5\\n22\\n21\\n22\\n\\uf02b\\uf02b\\uf02d\\uf0a3\\n\\uf06d\\uf02d\\uf06d\\uf0a3\\n\\uf02b\\uf02d\\uf02d\\n \\n45.017.345.017.3 21 \\uf02b\\uf0a3\\uf06d\\uf02d\\uf06d\\uf0a3\\uf02d\\n \\n62.372.2 21 \\uf0a3\\uf06d\\uf02d\\uf06d\\uf0a3\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 272}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       268                                                                                                                                           \\nLECTURE NO 36 \\n\\uf0b7 Large Sample Confidence Intervals for p and p1-p2  \\n\\uf0b7 Determination of Sample Size (with reference to Interval Estimation) \\n\\uf0b7 Hypothesis-Testing (An Introduction) \\nIn the last lecture, we discussed the construction and the interpretation of the confidence intervals for \\uf06d and \\uf06d1 - \\uf06d2. We \\nbegin today’s lecture by focusing on the confidence intervals for p and p1 -p2. First, we consider the confidence interval \\nfor p, the proportion of successes in a binomial population: \\n \\nCONFIDENCE INTERVAL FOR A POPULATION PROPORTION (P) \\n \\nFor a large sample drawn from a binomial population, the C.I. for p is given by \\n \\n \\n \\n \\nwhere \\n = proportion of “successes” in the sample \\n n   = sample size \\nz\\uf061/2  = 1.96 for 95% confidence \\n = 2.58 for 99% confidence \\n(In a practical situation, the criterion for deciding whether or not n is sufficiently large is that if both np and nq are \\ngreater than or equal to 5, then we say that n is sufficiently large).We illustrate this concept with the help of a few \\nexamples: \\n \\nEXAMPLE-1 \\n \\nAs a practical illustration, let us look at a survey of teenagers who have appeared in a juvenile court three times or \\nmore. A survey of 634 of these shows that 291 are orphans (one or both parents dead). What proportion of all teenagers \\nwith three or more appearances in court are orphans? The estimate is to be made with 99% confidence. \\n \\nSOLUTION \\n \\nIn this problem, we have n = 634, and \\n         =291/634 = 0.459, \\n          \\n                         = 0.541,       \\nHence, the 99% confidence limits for p are: \\n  \\n 0.459 \\uf0b1 2.58  \\n  \\n = 0.459 \\uf0b1 0.051  \\n = 0.408 and 0.510 \\nHence, we estimate that the percentage of teenagers of this type who are orphans lies between 40.8 per cent and 51.0 \\nper cent. It should be noted that, in this problem, happily, the confidence interval has come out to be pretty narrow, and \\nthis is happening in spite of the fact that the level of confidence is very high ! This very desirable situation can be \\nascribed to the fact that the sample size of 634 is pretty large. \\n \\nEXAMPLE-2 \\n \\nAfter a long career as a member of the City Council, Mr. Scott decided to run for Mayor.  \\nThe campaign against the present Mayor has been strong with large sums of money spent by each candidate on \\nadvertisements. In the final weeks, Mr. Scott has pulled ahead according to polls published in a leading daily \\nnewspaper. To check the results, Mr.  Scott’s staff conducts their own poll over the weekend prior to the election. The \\nresults show that for a random sample of 500 voters 290 will vote for Mr. Scott. Develop a 95 percent confidence \\ninterval for the population proportion who will vote for Mr. Scott. Can he conclude that he will win the election? \\n \\nSOLUTION \\n \\nWe begin by estimating the proportion of voters who will vote for Mr. Scott. The sample included 500 voters and 290 \\nfavored Mr. Scott.  Hence, the sample proportion is 290/500 = 0.58. The value 0.58 is a point estimate of the unknown \\npopulation proportion p.  \\nThe 95% Confidence Interval for p is: \\n \\n \\n \\n \\n\\uf028 \\uf029\\nn\\npˆ1pˆzpˆ 2/\\n\\uf02d\\uf0b1 \\uf061\\npˆ\\npˆ\\npq ˆ1ˆ \\uf02d\\uf03d\\n634\\n541.0459.0 \\uf0b4\\n\\uf028 \\uf029\\nn\\npˆ1pˆzpˆ 2/\\n\\uf02d\\uf0b1 \\uf061'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 273}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       269                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\nThe end points of the confidence interval are 0.537 and 0.623. The lower point of the confidence interval is greater than \\n0.50. So, we conclude that the proportion of voters in the population supporting Mr.  Scott is greater than 50 percent. He \\nwill win the election, based on the polling results. \\n \\nEXAMPLE-3 \\n \\nA group of statistical researchers surveyed 210 chief executives of fast -growing small companies. Only 51% of these \\nexecutives had a management -succession plan in place. A spokesman for the group made the statement that many \\ncompanies do not worry about management succession unless it is an immediate problem. However, the unexpected \\nexit of a corporate leader can disrupt and unfocused a company for long enough to cause it to lose its momentum. \\n Use the survey -figure to compute a 92% confidence interval to estimate the proportion of all fast -growing \\nsmall companies that have a management-succession plan. \\n \\nSOLUTION \\n \\n The point estimate of the proportion of al l fast-growing small companies that have a management -succession \\nplan is the sample proportion found to be 0.51 for that particular sample of size 210 which was surveyed by the group \\nof researchers. Realizing that the point estimate might change with anoth er sample selection, we calculate a confidence \\ninterval, as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\nBecause the level of confidence  \\nis 92%, the value of Z.04 = 1.75.  \\n \\n \\n \\n \\nThe confidence interval is computed as: \\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n210\\n49.051.075.151.0\\n210\\n49.051.075.151.0\\n\\uf02b\\uf0a3\\n\\uf0a3\\uf02d p\\n \\n06.051.0p06.051.0 \\uf02b\\uf0a3\\uf0a3\\uf02d\\n \\n57.0p45.0 \\uf0a3\\uf0a3\\n \\n\\uf028 \\uf029 .92.057.0p45.0P \\uf03d\\uf0a3\\uf0a3\\n \\n0 z\\uf061/2= 1.75 \\nZ \\n-z\\uf061/2= -1.75 \\n0.92 0.04 0.04 \\n\\uf028 \\uf029\\n\\uf028 \\uf029623.0,537.0\\n043.058.0\\n500\\n58.0158.096.158.0\\n\\uf03d\\n\\uf0b1\\uf03d\\n\\uf02d\\uf0b1\\uf03d\\n    The value of n is 210;  \\n \\npˆ\\nis 0.51  \\n \\nand  \\n \\n \\n.49.0pˆ1qˆ \\uf03d\\uf02d\\uf03d   '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 274}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       270                                                                                                                                           \\n \\n \\nCONCLUSION \\n \\n It is estimated with 92% confidence that the proportion of the population of fast-growing small companies \\nthat have a management-succession plan is between 0.45 and 0.57. \\n Next, we consider the Confidence Interval for the difference in the population proportions (p1 – p2): \\n \\nCONFIDENCE INTERVAL FOR P1-P2 \\n \\n For large samples drawn independently from two binomial populations, the C.I. for p1-p2  is given by \\n \\n \\n \\nwhere  \\nsubscript 1 denotes the first population, and subscript 2 denotes the second population. \\nWe illustrate this concept with the help of an example: \\n \\nEXAMPLE \\n \\nIn a poll of college students in a large university, 300 of 400 students living in students’ residences (hostels) approved a \\ncertain course of action, whereas 200 of 300 students not living in students’ residences approved it. Estimate the \\ndifference in the proportions favoring the course of action, and compute the 90% confidence interval for this difference. \\n \\nSOLUTION \\n \\nLet           be the proportion of students favouring the course of action in the first sample (i.e. the sample of resident \\nstudents). And, let          be the proportion of students favouring the course of action in the second sample (i.e. the  \\nsample of students not residing in students’ residences).  \\nThen \\n \\n \\nAnd   \\n \\n \\n \\n\\uf05cDifference in proportions  \\n      =                =   0.75 – 0.67 = 0.08 \\n \\nThe required level of confidence is 0.90. Therefore z0.05 = 1.645, and hence, the 90% confidence interval for p1 – p2 is \\n90% C.I. for p1-p2: \\n \\n \\n \\n \\n \\n \\n \\nor 0.08 \\uf0b1 (1.645) \\nor 0.08 \\uf0b1 (1.645) (0.0347)  \\nor 0.08 \\uf0b1 0.057 \\nor  0.023 to 0.137 \\nHence the 90 per cent confidence interval for p1 – p2 is (0.023, 0.137). In other words, on the basis of 90% confidence, \\nwe can say that the difference between the proportions of resident students and non-resident students who favor this \\nparticular course of action lies somewhere between 2.3% and 13.7%.Evidently, this seems to be a rather wide interval, \\neven though the level of confidence is not extremely high. Hence, it is obvious that, in this example, sample sizes of \\n400 and 300 respectively, although apparently quite large, are not large enough to yield a desirably narrow confidence \\ninterval. \\nIn the last lecture, we discussed the construction and interpretation of confidence intervals. Next, we consider the \\ndetermination of sample size. In this regard, the first point to be noted is that, in any statistical study based on primary \\ndata, the first question is what is going to be the size of the sample that is to be drawn from the population of interest? \\nWe present below a method of finding the sample size in such a way that we obtain a desired level of precision with a \\ndesired level of confidence, first, we consider the determination of sample size in that situation when we are trying to \\nestimate\\uf06d, the   population mean: \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n2\\n22\\n1\\n11\\n2/21 n\\npˆ1pˆ\\nn\\npˆ1pˆzpˆpˆ \\uf02d\\uf02b\\uf02d\\uf0b1\\uf02d \\uf061\\n,75.0400\\n300ˆ1 \\uf03d\\uf03dp\\n.67.0300\\n200ˆ2 \\uf03d\\uf03dp\\n21 ˆˆ pp \\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n22\\n1\\n11\\n21\\nˆˆˆˆ645.1ˆˆ\\nn\\nqp\\nn\\nqppp \\uf02b\\uf0b1\\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n300\\n33.067.0\\n400\\n25.075.0645.108.0 \\uf02b\\uf0b1or\\n1ˆp\\n2ˆp'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 275}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       271                                                                                                                                           \\nSample size for Estimating Population Mean  \\n In deriving the 100(1–\\uf061) per cent confidence Interval for \\uf06d, we have the expression \\n \\n    \\n \\n \\nwhich implies that the maximum allowable difference between\\uf060X and \\uf06d is: \\n    \\n,\\nn\\nzx 2/\\n\\uf073\\uf03d\\uf06d\\uf02d \\uf061  \\nwhere \\nn\\n\\uf073  is the standard error of \\nX  when sampling is performed with replacement of  population is very large \\n(infinite).   The quantity \\n\\uf06d\\uf02dx  is also called the error of the estimator \\nX  and is denoted by e. Thus a 100(1 –\\uf061) per \\ncent error bound for estimating \\uf06d is given by \\n.\\nn\\nz 2/\\n\\uf073\\n\\uf061 In other words, in order to have a 100(1–\\uf061) per cent \\\\confidence \\nthat the error is estimating \\uf06d with\\uf060X to be less than e, we need n such that  \\n \\nn\\nze 2/\\n\\uf073\\uf03d \\uf061  \\nor \\nezn 2/\\n\\uf073\\uf03d \\uf061  \\nor \\n2\\n2/\\ne\\nzn \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf073\\uf03d \\uf061  \\nHence the desired sample size for being 100(1–\\uf061)% confident that the error in estimating \\uf06d will be less than e, when \\nsampling is with replacement or the population is very large, is given by \\n \\n \\n \\n \\n \\n \\nIt is important to note that the population standard deviation \\uf073 is generally not known, and hence, its estimate is found \\neither from past experience or from a pilot sample of size n > 30. In case of fractional result, it is always to be rounded \\nto the next higher integer for the sample size. \\n \\nEXAMPLE \\n \\nA research worker wishes to estimate the mean of a population using a sample sufficiently large that the probability will \\nbe 0.95 that the sample mean will not differ from the true mean by more than 25 percent of the standard deviation. How \\nlarge a sample should be taken? \\n \\nSOLUTION \\n \\nIf the sample mean is not being allowed to differ from the true mean by more than 25% of \\uf073 with a probability of 0.95, \\nthen \\n \\n \\n \\nSubstituting these values in the formula \\n \\n   \\n,e\\nzn\\n2\\n2/ \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf073\\uf03d \\uf061  we get \\n   \\n.4656.614/\\n96.1n\\n2\\n\\uf03d\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\n\\uf073\\n\\uf073\\uf0b4\\uf03d  \\nHence the required sample size is 62, (the next higher integer), as the sample size cannot be fractional. \\n\\uf061\\uf073\\uf06d\\uf073\\n\\uf061\\uf061 \\uf02d\\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf0a3\\uf02d\\uf0a3\\uf02d 12/2/\\nn\\nzX\\nn\\nzP\\n2\\n/2zn e\\n\\uf061 \\uf073\\uf0e6\\uf0f6\\uf03d\\uf0e7\\uf0f7\\uf0e8\\uf0f8\\n.96.1,4100\\n25\\n2/ \\uf03d\\uf03d\\uf03d\\uf02d\\uf03d \\uf061\\n\\uf073\\uf073\\uf06d zandxe'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 276}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       272                                                                                                                                           \\nNext, we consider the determination of sample size in that situation when we are trying to estimate p, the proportion of \\nsuccesses in the population: \\n \\nSAMPLE SIZE FOR ESTIMATING POPULATION PROPORTION \\n \\nThe large sample confidence interval for p is given by \\n \\nn\\nqˆpˆzpˆ 2/\\uf061\\uf03d  \\nThis implies that \\nn\\nqˆpˆze 2/\\uf061\\uf03d  \\nTherefore, solving for n, we obtain \\n \\n\\uf028 \\uf029\\n2\\n2\\n2/\\ne\\nqˆpˆzn \\uf061\\uf03d  \\nSince the values of \\nqˆandpˆ  are not known as the sample has not yet been selected, we therefore use an estimate \\npˆ\\n obtained from pilot sample information.  \\n \\nEXAMPLE \\n \\nIn a random sample of 75 axle shafts, 12 have a surface finish that is rougher than the specification will allow. \\nHow large a sample is required if we want to be 95% confident that the error in using      to estimate p is less than 0.05? \\nSolution: \\nHere  \\n,16.075\\n12pˆ\\n,05.0ppˆe\\n\\uf03d\\uf03d\\n\\uf03d\\uf02d\\uf03d  \\n \\n    \\n\\uf028 \\uf029025.02/\\n96.1zand84.0pˆ1qˆ 025.0\\n\\uf03d\\uf061\\n\\uf03d\\uf02d\\uf02d\\uf03d\\n\\uf051  \\nSubstituting these values in the formula \\n    \\n,qˆpˆ\\ne\\nzn\\n2\\n2/ \\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d \\uf061  we obtain \\n    \\n\\uf028 \\uf029\\uf028 \\uf029 52.20684.016.005.0\\n96.1n\\n2\\n\\uf03d\\uf0b4\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6\\uf03d  \\nwhich, upon rounding upward, yields 207 as the desired sample size. As stated earlier, Inferential Statistics can be \\ndivided into two parts, estimation and hypothesis-testing. Having discussed the concepts of point and interval \\nestimation in considerable detail, We now begin the discussion of Hypothesis-Testing:  \\n \\nHYPOTHESIS-TESTING IS A VERY IMPORTANT AREA OF STATISTICAL INFERENCE \\n  \\nIt is a procedure which enables us to decide on the basis of information obtained from sample data whether to accept or \\nreject a statement or an assumption about the value of a population parameter. Such a statement or assumption which \\nmay or may not be true is called a statistical hypothesis. We accept the hypothesis as being true, when it is supported by \\nthe sample data. We reject the hypothesis when th e sample data fail to support it. It is important to understand what we \\nmean by the terms ‘reject’ and ‘accept’ in hypothesis -testing. The rejection of a hypothesis is to declare it false. The \\nacceptance of a hypothesis is to conclude that there is insufficient evidence to reject it.  Acceptance does not necessarily \\nmean that the hypothesis is actually true. The basic concepts associated with hypothesis testing are discussed below: \\n \\nNULL AND ALTERNATIVE HYPOTHESES \\n \\nNULL HYPOTHESIS \\n \\nA null hypothesis, generally denoted by the symbol H0, is any hypothesis which is to be tested for possible rejection or \\nnullification under the assumption that it is true.  \\npˆ'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 277}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       273                                                                                                                                           \\nA null hypothesis should always be precise such as ‘ the given coin is unbiased ’ or ‘ a drug is ineffective i n curing a \\nparticular disease’ or ‘ there is no difference between the two teaching methods ’. The hypothesis is usually assigned a \\nnumerical value. For example, suppose we think that the average height of students in all colleges is 62\\uf0b2. This statement \\nis taken as a hypothesis and is written symbolically as H0 : \\uf06d = 62\\uf0b2. In other words, we hypothesize that \\uf06d = 62\\uf0b2. \\n \\nALTERNATIVE HYPOTHESIS \\n \\nAn alternative hypothesis is any other hypothesis which we are willing to accept when the null hypothesis H0 is \\nrejected. It is customarily denoted by H1 or HA.  A null hypothesis H0 is thus tested against an alternative hypothesis \\nH1. For example, if our null hypothesis is H0 : \\uf06d = 62\\uf0b2, then our alternative hypothesis may be H1 : \\uf06d \\uf0b9 62\\uf0b2 or H1 : \\uf06d < \\n62\\uf0b2. \\n \\nLEVEL OF SIGNIFICANCE \\n \\nThe probability of committing Type-I error can also be called the level of significance of a test.  Now, what do we mean \\nby Type -I error?  In order to obtain an answer to this question, consider the fact that, as far as the actual reality is \\nconcerned, H0 is either actually true, or it is false. Also, as far as our decision regarding H0 is concerned, there are two \\npossibilities --- either we will accept H0, or we will reject H0. The above facts lead to the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nA close look at the four cells in the body of the above table reveals that the situations depicted by the top-left corner and \\nthe bottom right-hand corner are the ones where we are taking a correct decision. On the other hand, the situation \\ndepicted by the top-right corner and the bottom left-hand corner are the ones where we are taking an incorrect decision. \\nThe situation depicted by the top-right corner of the above table is called an error of the first kind or a Type I-error, \\nwhile the situation depicted by the bottom left-hand corner is called an error of the second kind or a Type II-error.  \\nIn other words: \\n \\nTYPE-I AND TYPE-II ERRORS \\n \\nOn the basis of sample information, we may reject a null hypothesis H0, when it is, in fact, true or we may accept a null \\nhypothesis H0, when it is actually false. The probability of making a Type I error is conventionally denoted by \\uf061 and \\nthat of committing a Type II error is indicated by \\uf062. In symbols, we may write \\n\\uf061  =  P (Type I error)  \\n = P (reject H0|H0 is true), \\n\\uf062 =  P (Type II error)  \\n =  P (accept H0|Ho is false). \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  Decision \\n  Accept H0 \\nReject H0 \\n(or accept \\nH1) \\nH0 is  \\ntrue \\nCorrect \\ndecision \\n(No error) \\nWrong \\ndecision \\n(Type-I error) True  \\nSituatio\\nn H0 is  \\nfalse \\nWrong \\ndecision \\n(Type-II \\nerror) \\nCorrect \\ndecision \\n(No error) \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 278}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       274                                                                                                                                           \\n \\nLECTURE NO. 37 \\n \\n\\uf0b7 Hypothesis-Testing (continuation of basic concepts) \\n\\uf0b7 Hypothesis-Testing regarding \\uf06d (based on Z-statistic) \\n \\nIn the last lecture, we commenced the discussion of the concept of Hypothesis -Testing. We introduced the concepts of \\nthe Null and Alternative hypotheses as well as the concepts of Type -I and Type -II error.  We now continue the \\ndiscussion of the basic concepts of hypothesis-testing: \\n \\nTEST-STATISTIC \\n \\nA statistic (i.e. a function of the sa mple data not containing any parameters), which provides a basis for testing a null \\nhypothesis, is called a test-statistic. Every test -statistic has a probability distribution (i.e. sampling distribution) which \\ngives the probability that our test-statistic will assume a value greater than or equal to a specified value OR a value less \\nthan or equal to a specified value when the null hypothesis is true.  \\n \\nACCEPTANCE AND REJECTION REGIONS \\n \\nAll possible values which a test -statistic may assume can be divided in to two mutually exclusive groups: one group \\nconsisting of values which appear to be consistent with the null hypothesis (i.e. values which appear to support the null \\nhypothesis), and the other having values which lead to the rejection of the null hypothesis. The first group is called the \\nacceptance region and the second set of values is known as the rejection region for a test.  The rejection region is also \\ncalled the critical region. The value(s) that separates the critical region from the acceptance regio n, is called the critical \\nvalue(s): \\n \\n  \\nThe critical value which can be in the same units as the parameter or in the standardized units, is to be decided by the \\nexperimenter. The most frequently used values of \\uf061, the significance  level, are 0.05 and 0.01, i.e. 5 percent and 1 \\npercent.  By \\uf061 = 5%, we mean that there are about 5 chances in 100 of incorrectly rejecting a true null hypothesis.  \\n \\nRELATIONSHIP BETWEEN THE LEVEL OF SIGNIFICANCE AND THE CRITICAL REGION  \\n \\nThe level of sign ificance acts as a basis for determining the CRITICAL REGION of the test. For example, if we are \\ntesting H0: \\uf06d = 45 against H1: \\uf06d \\uf0b9 45, our test statistic is the standard normal variable Z, and the level of significance is \\n5%, then the critical values are Z =  +1.96 Corresponding to a level of significance of 5%, we have: \\n0 Z \\nAcceptance  \\nRegion \\nCritical  \\nRegion \\nCritical  \\nRegion \\nCritical  \\nValue \\nCritical  \\nValue '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 279}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       275                                                                                                                                           \\n \\nONE-TAILED AND TWO-TAILED TESTS \\n \\nA test, for which the entire rejection region lies in only one of the two tails – either in the right tail or in the left tail – of \\nthe sampling distribution of the test -statistic, is called a one-tailed test or one-sided test. A one-tailed test is used when \\nthe alternative hypothesis H1 is formulated in the following form: \\n H1 : \\uf071 > \\uf0710  \\nor \\n H1 : \\uf071 < \\uf0710 \\nFor example, if we are int erested in testing a hypothesis regarding the population mean, if n is large, and we are \\nconducting a one-tailed test, then our alternative hypothesis will be stated as  \\n H1 : \\uf06d > \\uf06d0  \\nor \\n H1 : \\uf06d < \\uf06d0 \\nIn this case, the rejection region consists of either al l z-values which are greater than + z \\uf061 or less than – z\\uf061 (where \\uf061 is \\nthe level of significance):  \\nIf  H0 : \\uf06d > \\uf06d0 \\n H1 : \\uf06d < \\uf06d0    \\n \\nThen (in case of large n): \\n \\n   \\n REJECT H0  if  z < –z\\uf061 \\n \\nIf  \\n H0 : \\uf06d < \\uf06d0 \\n H1 : \\uf06d > \\uf06d0    \\nThen (in case of large n): \\n0 –z\\uf061 Z REJECTION  \\nREGION \\n\\uf061 \\n0 1.96 Z -1.96 \\n2.5% 2.5% \\nAcceptance  \\nRegion \\nCritical  \\nRegion \\nCritical  \\nRegion '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 280}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       276                                                                                                                                           \\n \\n   REJECT H0  if  z > z\\uf061/2 \\nIf, on the other hand , the rejection region is divided equally between the two tails of the sampling distribution of the \\ntest-statistic, the test is referred to as a two-tailed test or two-sided test.  \\n In this case, the alternative hypothesis H1 is set up as: \\n H1 : \\uf06d \\uf0b9 \\uf06d0  \\n meaning thereby \\n H1 : \\uf06d < \\uf06d0 or \\uf06d > \\uf06d0  \\nIf  H0 : \\uf06d = \\uf06d0 \\n H1 : \\uf06d \\uf0b9 \\uf06d0    \\nThen (in case of large n): \\n \\n \\n \\n   REJECT H0  if  z < –z\\uf061/2  or  z > z\\uf061/2 \\n \\nThe location of critical region can be determined only after the alternative hypothesis H1 has been stated. It is important \\nto note that the one -tailed and the two -tailed tests differ only in location of the critical region, not in the size. We  \\nillustrate the concept and methodology of hypothesis-testing with the help of an example: \\n \\nEXAMPLE \\n \\nA steel company manufactures and assembles desks and other office equipment at several plants in a particular country. \\nThe weekly production of the desks o f Model A at Plant -I has a mean of 200 and a standard deviation of 16.  Recently, \\ndue to market expansion, new production methods have been introduced and new employees hired.  The vice president \\nof manufacturing would like to investigate whether there has been a change in the weekly production of the desks of \\nModel A. To put it another way, is the mean number of desks produced at Plant -I different from 200 at the 0.05 \\nsignificance level? The mean number of desks produced last year (50 weeks, because the pla nt was shut down 2 weeks \\nfor vacation) is 203.5.  On the basis of the above result, should the vice president conclude that the there has been a \\nchange in the weekly production of the desks of Model A. \\n \\nSOLUTION: \\n \\nWe use the statistical hypothesis-testing procedure to investigate whether the production rate has changed from 200 per \\nmonth. \\n \\nStep-1: \\nFormulation of the Null and Alternative Hypotheses: \\n The null hypothesis is “The population mean is 200.”  \\n The alternative hypothesis is ‘The mean is different from 200” or “The mean is not 200.”  \\nThese two hypotheses are written as follows: \\n \\n H0 : \\uf06d =  200 \\n0 –z\\uf061/2 \\n\\uf061/2 \\uf061/2 \\nz\\uf061/2 REJECTION  \\nREGION \\nREJECTION  \\nREGION \\n0 z\\uf061 Z REJECTION  \\nREGION \\n\\uf061 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 281}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       277                                                                                                                                           \\n H1 : µ \\uf0b9  200 \\n \\n \\nNote: \\n This is a two -tailed test because the alternative hypothesis does not state a direction. In other words, it does \\nnot state whether the m ean production is greater than 200 or less than 200. The vice president only wants to find out \\nwhether the production rate is different from 200. \\n \\nStep-2: \\nDecision Regarding the Level of Significance (i.e. the Probability of Committing Type-I Error): \\n Here, the level of significance is 0.05.  \\n This is \\uf061, the probability of committing a Type-I error (i.e. the risk of rejecting a true null hypothesis).  \\nStep-3: \\n  \\nTest Statistic (that statistic that will enable us to test our hypothesis): \\n The test statistic for a large sample mean is \\n \\n \\n  \\n \\nTransforming the production data to standard units (z values) permits the use of the area table of the standard normal \\ndistribution.  \\n \\n \\nStep-4:  \\nCalculations: \\n \\n In this problem, we have n = 50,  \\uf060X = 203.5, and \\uf073 = 16. \\n Hence, the computed value of z comes out to be: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep-5: \\nCritical Region (that portion of the X-axis which compels us to reject the null hypothesis):Since this is a two-tailed test, \\nhalf of 0.05, or 0.025, is in each tail.  \\n The area where H0 is not rejected, located between the two critical values, is therefore 0.95. \\nApplying the inverse use of the Area Table, we find that, corresponding to \\uf061 = 0.05, the critical values   are   1.96 and -\\n1.96, as shown below: \\n \\n \\nScale to z \\n0 -1.96 -1.96 +1.96 \\nH0 is not rejected Region of \\nrejection \\nRegion of \\nrejection \\nCritical \\nValue \\nCritical \\nValue \\n0.4750 0.4750 \\n0.5000 \\n025.02\\n05.0\\n2 \\uf03d\\uf03d\\uf061\\n025.02\\n05.0\\n2 \\uf03d\\uf03d\\uf061 0.5000 \\nn\\nXz\\n\\uf073\\n\\uf06d\\uf02d\\uf03d\\n55.1\\n5016\\n2005.203 \\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\nn\\nXz\\n\\uf073\\n\\uf06d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 282}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       278                                                                                                                                           \\nDECISION RULE FOR THE 0.05 SIGNIFICANCE LEVEL THE DECISION RULE IS, THEREFORE \\n \\nReject the null hypothesis and accept the alternative hypothesis if the computed value of z is not between –1.96 and \\n+1.96.  Do not reject the null hypothesis if z falls between –1.96 and + 1.96. \\n \\nStep-6: \\nConclusion: \\nThe computed value of z i.e. 1.55 lies between -1.96 and + 1.96, as shown below: \\n \\n \\nBecause 1.55 lies between -1.96 and + 1.96, therefore, it does not fall in the rejection region, and hence H0 is not \\nrejected. In other words, we conclude that the population mean is not different from 200. So, we would report to the \\nvice president of manufacturing that the sample evidence does not show that the production rate at Plant -I has changed \\nfrom 200 per week. The difference of 3.5 units between the historical weekly production rate and the production rate of \\nlast year can reasonably be attributed to chance. The above example pertained to a two-tailed test. Let us now consider a \\nfew examples of one-tailed tests: \\n \\nEXAMPLE \\n \\nA random sample of 100 workers with children in day care show a mean day -care cost of Rs.2650 and a standard \\ndeviation of Rs.500. Verify the department’s claim that the mean exceeds Rs.2500 at the 0.05 level with this \\ninformation. \\n \\nSOLUTION \\nIn this problem, we regard the department’s claim, that the mean exceeds Rs.2500, as H1,  \\nand regard the negation of this claim as H0.  \\n Thus, we have \\n      i) H0 : \\uf06d < 2500 \\n H1 : \\uf06d > 2500 (exceeds 2500) \\n \\n(Important Note: We should always regard that hypothesis as the null hypothesis which contains the equal sign.) \\nii) We are given the significance level at \\uf061 = 0.05. \\n \\niii)  The test-statistic, under H0 is \\n \\n \\n \\n \\n \\nwhich is approximately normal as n = 100 is large enough to make use of the central limit theorem. \\niv)   The rejection region is  \\n   Z > Z0.05 = 1.645 \\n \\n \\n \\n \\nz scale 0 - 1.96 1.96 1.55 \\nComputed \\nvalue of z \\nDo not reject H0 Reject H0 Reject H0 \\n,0\\nnS\\nXZ \\uf06d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 283}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       279                                                                                                                                           \\n \\n \\n \\nv) Computing the value of Z from sample information, we find  \\n \\n \\n \\n \\nvi)  Conclusion:  \\nSince the calculated value z = 3 is greater than 1.645, hence it falls in the rejection region, and, therefore, we reject H0, \\nand may conclude that the department’s claim is supported by the sample evidence. \\nAn Interesting and Important Point: \\n    For \\uf061 = 0.01, Z\\uf061 = 2.33. \\nAs our computed value of Z i.e. 3 is even greater than 2.33, the computed value of   \\uf060X is highly significant.  \\n(With only 1% chance of being wrong, the department’s claim was correct). \\n \\n \\n \\n0 Z0.05 \\n=1.645 \\nZ REJECTION  \\nREGION \\n0.05 \\n350\\n150\\n100500\\n25002650z \\uf03d\\uf03d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 284}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       280                                                                                                                                           \\nLECTURE NO. 38 \\n \\n\\uf0b7 Hypothesis-Testing regarding \\uf06d1 - \\uf06d2    (based on Z-statistic) \\n\\uf0b7  Hypothesis Testing regarding p      (based on Z-statistic) \\n \\nIn the last lecture, we discussed the basic concepts involved in hypothesis -testing. Also, we applied this concept to a \\nfew examples regarding the testing of the population mean \\uf06d. These examples pointed to the six main steps involved in \\nany hypothesis-testing procedure. \\n \\nGENERAL PROCEDURE FOR TESTING HYPOTHESES \\n \\nTesting a hypothesis about a population parameter involves the following six steps: \\n\\uf0b7 State your problem and formulate an appropriate null hypothesis H0 with an alternative hypothesis H1, which \\nis to be accepted when H0 is rejected. \\n\\uf0b7 Decide upon a significance level of the test, \\uf061, which is the probability of rejecting the Null Hypothesis if it is \\ntrue. \\n\\uf0b7 Choose a test-statistic such as the normal distribution, the t-distribution, etc. to test H0. \\n\\uf0b7 Determine the rejection or critical region in such a way that the probability of rejecting the null hypothesis \\nH0, if it is true, is equal to the significance level, \\uf061. The location of the critical region depends upon the form \\nof H1 (i.e. whether we are carrying out a one-tailed test or a two-tailed test). The critical value(s) will separate \\nthe acceptance region from the rejection region. \\n\\uf0b7 Compute the value of the test -statistic from the sample data in order to decide whether to accept or reject the \\nnull hypothesis H0. \\n\\uf0b7 Formulate the decision rule (i.e. draw a conclusion) as follows: \\n a) Reject the null hypothesis H0, if the computed value of the test statistic falls in the rejection region. \\n b) Accept the null hypothesis H0, otherwise. \\n \\nIMPORTANT NOTE \\n \\nIt is very important to realize that when applying a hypothesis-testing procedure of the type explained above, we always \\nbegin by assuming that the null hypothesis is true. \\n \\nIMPORTANT NOTE: \\nAs s2 is an unbiased estimator of \\uf0732 whereas S2 is a biased estimator, hence we wo uld like to use this estimator \\nwhenever \\uf0732 is unknown. However, when n is large, s2 is approximately equal to S2, as explained below: \\nWe know that \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow, as n \\uf0ae \\uf0a5,  \\n \\nHence, if n is large, \\n \\n \\n \\nHence, in case of a large sample drawn from a po pulation with unknown variance \\uf0732, we may replace \\uf0732 by S2.We \\nnow consider the case when we are interested in testing the equality of two population means. \\nWe illustrate this situation with the help of the following example. \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029 22222\\n22\\n2\\n2\\n22\\n2\\n2\\n1111\\n.\\n11\\nsnsn\\nnSnSsn\\nHence\\nnSxxn\\nxxS\\nwhereas\\nsnxxn\\nxxs\\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02d\\uf03d\\uf02d\\uf03d\\uf0de\\uf03d\\uf02d\\n\\uf03d\\uf02d\\uf0de\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf02d\\uf0de\\uf02d\\n\\uf02d\\uf03d\\n\\uf0e5\\uf0e5\\n\\uf0e5\\uf0e5\\n.01 \\uf0aen\\n.~ 22 sS \\uf02d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 285}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       281                                                                                                                                           \\nEXAMPLE \\n \\nA survey conducte d by a market -research organization five years ago  showed that the estimated hourly wage for \\ntemporary computer analysts was essentially the same as the hourly wage for registered nurses.  This year, a random \\nsample of 32 temporary computer analysts from ac ross the country is taken. The analysts are contacted by telephone \\nand asked what rates they are currently able to obtain in the market -place A similar random sample of 34 registered \\nnurses is taken. The resulting wage figures are listed in the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nConduct a hypothesis test at the 2% level of significance to determine whether the hourly wages of the computer \\nanalysts are still the same as those of registered nurses.  \\n \\nSOLUTION \\n \\nHypothesis Testing Procedure: \\nStep-1:  \\nFormulation of the Null and Alternative Hypotheses: \\n \\nH0 : \\uf06d1 – \\uf06d2 = 0  \\nHA : \\uf06d1 – \\uf06d2 \\uf0b9 0 \\n(Two-tailed test) \\n \\nStep-2: \\n  \\n Level of Significance: \\n \\uf061 = 0.02 \\nStep-3: \\n  \\n Test Statistic: \\n \\n \\n \\n \\n \\n \\n \\nStep-4:  \\n \\nCalculations: \\nThe sample size, sample mean and sample standard deviation for each of the two samples are given below: \\nComputer Analysts: \\n    n1 = 32 \\n  \\uf060X 1 = $23.14 \\n    S12 = 1.854 \\n \\n \\nRegistered Nurses: \\nComputer Analysts Registered Nurses \\n$ 24.10 $25.00 $24.25 $20.75 $23.30 $22.75 \\n23.75 22.70 21.75 23.80 24.00 23.00 \\n24.25 21.30 22.00 22.00 21.75 21.25 \\n22.00 22.55 18.00 21.85 21.50 20.00 \\n23.50 23.25 23.50 24.16 20.40 21.75 \\n22.80 22.10 22.70 21.10 23.25 20.50 \\n24.00 24.25 21.50 23.75 19.50 22.60 \\n23.85 23.50 23.80 22.50 21.75 21.70 \\n24.20 22.75 25.60 25.00 20.80 20.75 \\n22.90 23.80 24.10 22.70 20.25 22.50 \\n23.20   23.25 22.45  \\n23.55   21.90 19.10  \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2121\\nnn\\nXXZ\\n\\uf073\\uf073\\n\\uf06d\\uf06d\\n\\uf02b\\n\\uf02d\\uf02d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 286}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       282                                                                                                                                           \\n    n2  = 34 \\n  \\uf060X2 = $21.99 \\n    S22 = 1.845 \\nSince the sample sizes are larger than 30, hence, the unknown population va riances \\uf07312 and \\uf07322 can be replaced by \\nS12 and S22. Hence, our formula becomes: \\n \\n \\n \\n \\n \\n \\n \\nHence, the computed value of Z comes out to be : \\n \\n \\n \\n \\n \\n \\n \\n \\nStep-5:  \\n \\nCritical Region: \\nAs the level of significance is 2%, and this is a two-tailed test, hence, we have the following situation: \\n \\n \\n \\nHence, the critical region is given by \\n | Z | > 2.33 \\n \\nStep-6: \\n Conclusion: \\nAs the computed value i.e. 3.43 is greater than the tabulated value 2.33, hence, we reject H0. \\n \\nZ = 0 Z.01 = -2.33 Z.01 = +2.33 Z \\nCalculated Z = 3.43 \\n  \\n \\n21 XX \\uf02d\\n15.121 \\uf03d\\uf02dXX\\n021 \\uf03d\\uf06d\\uf02d\\uf06d\\n0 Z.01 = -2.33 Z.01 = +2.33 \\n\\uf061/2 = .01 \\uf061/2 = .01 0.49 0.49 \\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n1\\n2\\n1\\n2121\\nn\\nS\\nn\\nS\\nXXZ\\n\\uf02b\\n\\uf02d\\uf02d\\uf02d\\uf03d \\uf06d\\uf06d\\n\\uf028 \\uf029 \\uf028 \\uf029 43.3335.0\\n15.1\\n34\\n845.1\\n32\\n854.1\\n099.2114.23Z \\uf03d\\uf03d\\n\\uf02b\\n\\uf02d\\uf02d\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 287}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       283                                                                                                                                           \\n \\nThe researcher can say that there  is a significant difference between the average hourly wage of a temporary computer \\nanalyst and the average hourly wage of a temporary registered nurse. The researcher then examines the sample means \\nand uses common sense t o conclude that, on the average, temporary computer analyst earn more than temporary \\nregistered nurses. Let us consolidate the above concept by considering another example: \\n \\nEXAMPLE \\n \\nSuppose that the workers of factory B believe that the average income of the workers of factory A exceeds their average \\nincome. A random sample of workers is drawn from each of the two factories, an the two samples yield the following \\ninformation: \\n \\n \\n \\n \\n \\n \\n \\n \\nTest the above hypothesis? \\n \\nSOLUTION \\n \\nLet subscript 1 denote values pert aining to Factory A, and let subscript 2 denote values pertaining to Factory B. Then, \\nwe proceed as follows: \\nHypothesis-testing Procedure: \\n \\nStep 1:  \\n H0 : \\uf06d1 < \\uf06d2 (or \\uf06d1 - \\uf06d2 < 0) \\n HA : \\uf06d1 > \\uf06d2 (or \\uf06d1 - \\uf06d2 > 0). \\n \\n \\nStep 2: \\nLevel of significance  \\n= 5%. \\nSteps 3 & 4: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep 5: \\nCritical Region: \\n Since it is a right-tailed test, hence the critical region is given by \\n Z > Z0.05 \\n i.e. Z > 1.645 \\n \\nStep 6:  \\nConclusion: \\nSince 1.99 is greater than 1.645, hence H0 should be rejected in favour of HA. The sample ev idence has consolidated \\nthe belief of the workers of factory B.  Next, we consider the case when we are interested in conducting a test regarding \\np, the proportion of successes in the population.  We illustrate this situation with the help of the following example: \\n \\nEXAMPLE \\n \\nA sociologist has a hunch that not more than 50% of the children who appear in a particular juvenile court three times \\nor more are orphans. To test this hypothesis, a sample of 634 such children is taken and it is found that 341 of these  \\nchildren are orphans, (one or both parents dead). Test the above hypothesis using 1% level of significance. \\n \\n \\n \\n \\n \\nFactory Sample  \\nSize Mean Variance \\nA 160 12.80 64 \\nB 220 11.25 47 \\n \\n220\\n47\\n160\\n64\\n25.1180.12\\nn\\ns\\nn\\ns\\n0xxZ\\n2\\n2\\n2\\n1\\n2\\n1\\n21\\n\\uf02b\\n\\uf02d\\uf03d\\n\\uf02b\\n\\uf02d\\uf02d\\uf03d\\n \\n    \\n99.178.0\\n55.1\\n61.0\\n55.1 \\uf03d\\uf03d\\uf03d  '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 288}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       284                                                                                                                                           \\nSOLUTION \\n \\nHypothesis-testing Procedure: \\n \\nStep 1: \\n \\nH0 :  p < 0.50 \\nHA : p > 0.50    \\n(one-tailed test) \\n \\nStep 2: \\n Level of significance: \\uf061 = 1% \\n \\n \\nStep 3:  \\nTest statistic: \\n \\n \\n \\n \\n \\n(where + ½ denotes the continuity correction) \\n \\nStep 4: \\n Computation: \\n \\nHere  np0 = 634 (0.50) = 317 \\nand X = 341 \\nHence X > np0 so use X - ½ \\n \\n \\n \\n \\n \\n \\n \\n \\nStep 5:  \\nCritical region: \\n Since \\uf061 = 0.01, hence the critical region is given by \\n   Z > 2.33 \\nStep 6:  \\nConclusion: \\nSince 1.87 < 2.33, \\nHence the computed Z does not fall in the critical region. Hence, we conclude that the sociologist’s hunch is acceptable. \\n \\n \\n \\n\\uf028 \\uf02900\\n02\\n1\\np1pn\\npnXZ\\n\\uf02d\\n\\uf02d\\uf0b1\\uf03d\\nSo   \\n\\uf028 \\uf029\\uf028 \\uf029 59.12\\n5.23\\n50.050.0634\\n317341Z 2\\n1\\n\\uf03d\\uf02d\\uf02d\\uf03d  \\n \\n = 1.87 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 289}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       285                                                                                                                                           \\n \\nLECTURE NO. 39 \\n \\n\\uf0b7 Hypothesis Testing Regarding p1-p2 (based on Z-statistic) \\n\\uf0b7 The Student’s t-distribution  \\n\\uf0b7 Confidence Interval for \\uf06d based on the t-distribution \\n \\nIn the last lecture, we discussed hypothesis -testing regarding p, the proportion of successes in a binomial population. \\nNext, we consider the case when we are interested in testing the equality of two population proportions . We illustrate \\nthis situation with the help of the following example: \\n \\nEXAMPLE \\n \\nA leading perfume company in a western country recently developed a new perfume which they plan to market under \\nthe name 'Fragrance'. A number of comparison tests indicate that 'Fragrance' has very good market potential. The Sales \\nDepartments of the company want to plan their strategy so as to reach and impress the largest possible segments of the \\nbuying public. One of the qu estions is whether the perfume is preferred by younger or older women. These are two \\nindependent populations, a population consisting of the younger women and a population consisting of the older \\nwomen. A standard scent test will be used where each sampled  woman is asked to sniff several perfumes, one of which \\nis 'Fragrance', and indicate the one that she likes best. \\nA total of 100 young women were selected at random, and each was given the standard scent test. Twenty of the 100 \\nyoung women chose 'Fragrance ' as the perfume they liked best.  Two hundred older women were selected at random, \\nand each was given the same standard scent test. Of the 200 older women, 100 preferred 'Fragrance \\nTest the hypothesis that there is no difference between the proportions of younger and older women who prefer \\n‘Fragrance’. \\n \\nSOLUTION \\n \\n We designate p1 as the proportion of younger women who prefer 'Fragrance' and p2 as the proportion of older \\nwomen who prefer 'Fragrance'. \\nHypothesis-Testing Procedure: \\nStep-1:  \\n H0 : p1 =  p2 (i.e. p1-p2 = 0) \\n (There is no difference between the proportions of young women and older  women who prefer \\n'Fragrance’.)  \\n H1 : p1 \\uf0b9  p2 (i.e. p1-p2 \\uf0b9 0) \\n (The two proportions are not equal.) \\nStep-2:  \\nLevel of Significance \\n \\uf061 = 0.05. \\nStep-3: \\nTest Statistic \\n \\n \\n \\n \\n \\n \\nwhere the combined or pooled proportion,  is given by: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis can also be written as \\n \\n \\n \\n \\nwhich means that      is the weighted mean of     n1 and n2 acting as the weights. \\n\\uf028 \\uf029\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\n\\uf02d\\uf02d\\uf03d\\n21\\ncc\\n21\\nn\\n1\\nn\\n1qˆpˆ\\n0pˆpˆZ\\n,ˆcp\\n21\\n21\\nc\\nnn\\nXX\\ncombinedsamplestwotheinnsobservatioofnumberTotal\\ncombinedsamplestwotheinsuccessesofnumberTotalpˆ\\n\\uf02b\\n\\uf02b\\uf03d\\n\\uf03d\\n21\\n2211\\nc nn\\npˆnpˆnpˆ\\n\\uf02b\\n\\uf02b\\uf03d\\ncpˆ\\n,pˆandpˆ 21\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 290}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       286                                                                                                                                           \\nImportant Note: \\nIn this example, as the hypothesized value of p1 - p2 is equal to zero; therefore both    are estimating the \\ncommon population proportion p. Hence, we use the pooled proportion of the two samples to estimate p.   \\n(The rationale is that the pooled estimator  is a better estimator of the common Population proportion p (as \\ncompared with   ), as it is based on n1 + n2 observations (i.e. based on a greater amount of information). \\nStep-4:  \\nCalculations: \\nX1is the number of Preferring 'Fragrance' = 20. n1 is the number is the sample = 100. \\n \\n \\n \\nX2 is the number of preferring 'Fragrance' = 100. n2 is the number is the sample = 200.  \\n \\n \\n \\n \\nNow, the pooled or weighted proportion            is computed as follows: \\n \\n \\n \\n \\n \\n \\nComputation: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep-5: \\nCritical Region \\nSince H1 does not state any direction (such as p1 < p2), the test is two-tailed. Thus, the critical values for the .05 level \\nare –1.96 and + 1.96. Two-Tailed Test, Areas of Rejection and Non-rejection, .05 Level of Significance:  \\n \\n \\nStep-6:  \\n \\nCONCLUSION \\nThe computed z of –5.00 is in the area of rejection, that is, to the left of –1.96. Therefore, the null hypothesis is rejected \\nat the .05 level of significance.  \\nZ \\n.95 \\n-1.96 \\n.025 .025 \\n1.96 \\nH0 is not \\nrejected \\nH0 is \\nrejected \\nH0 is \\nrejected \\ncpˆ\\n21 pˆorpˆ\\n21 ˆˆ pandp\\n20.0100\\n20\\nn\\nXpˆ\\n1\\n1\\n1 \\uf03d\\uf03d\\uf03d\\n50.0200\\n100\\nn\\nXpˆ\\n2\\n2\\n2 \\uf03d\\uf03d\\uf03d\\n,ˆcp\\n40.0300\\n120\\n200100\\n10020\\nnn\\nXXpˆ\\n21\\n21\\nc \\uf03d\\uf03d\\uf02b\\n\\uf02b\\uf03d\\uf02b\\n\\uf02b\\uf03d\\n\\uf028 \\uf029\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6 \\uf02b\\n\\uf02d\\uf02d\\uf03d\\n21\\ncc\\n21\\nn\\n1\\nn\\n1qˆpˆ\\n0pˆpˆZ\\n \\n   \\n\\uf028 \\uf029\\uf028 \\uf029\\n00.506.0\\n30.0\\n200\\n1\\n100\\n160.040.0\\n50.020.0\\n\\uf02d\\uf03d\\uf02d\\uf03d\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf02b\\n\\uf02d\\uf03d\\n \"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 291}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       287                                                                                                                                           \\nIn other words, we conclude that the proportion of young women in the population who prefer 'Fragrance' is not equal \\nto the proportion of older women in the population who prefer 'Fragrance'.(The difference between the two sample \\nproportion i.e. 0.30 is so large  that it is highly unlikely  that such a large difference could be due to chance (i.e. \\nattributable to sampling fluctuations).) \\nIn fact, the value z = -5.00 is even larger than -2.58, the critical value lying on the left tail of the sampling distribution if \\n\\uf061 = 0.01. As such, we can say that our statistic is highly significant.(In such a situation, the statistic is said to be highly \\nsignificant because of the fact that we are allowing as small a risk of committing Type-I error as 1%.) \\nNow, consider another situation: \\nSuppose that the computed value of our test-statistic comes out to be such that it falls between -1.96 and -2.58. In such a \\nsituation, we will reject H0 at the 5% level of significance, but we cannot reject H0 at the 1% level. This means that, if \\nwe are willing to allow as much as 5% risk of committing type I error, then we say that we are going to reject H0. But if \\nwe are willing to allow only 1% risk of committing type I error, then we conclude that the sample does not provide \\nsufficient evidence to reject H0.Going back to the example of the perfume, obviously, the company would be interested \\nin determining, which category of women prefers this perfume in greater numbers than the other? \\nThe data clearly indicates that the proportion of women who prefer this particular perfume is higher in the population of \\nolder women. (This is the reason why the com puted value of our test -statistic has come out to be negative.) Let us \\nconsolidate the above ideas by considering another example: \\n \\nEXAMPLE \\n \\nA candidate for mayor in a large city believes that he appeals to at least 10 per cent more of the educated voters than the \\nuneducated voters. He hires the services of a poll -taking organization, and they find that 62 of 100 educated voters \\ninterviewed support the candidate, and 69 of 150 uneducated voters support him at the 0.05 significance level. \\nStep-1: \\n \\nThe null and alternative hypothesis is  \\nH0 : p1 – p2 > 0.10, and \\nH1 : p1 – p2 < 0.10,         where p1 = proportion of educated voters, and p2 =  proportion of uneducated voters. \\n \\nStep-2: \\n \\nLevel of Significance: \\n \\uf061 = 0.05. \\n \\nStep-3:  \\n \\nTest Statistic: \\n \\n \\n \\n \\n \\nwhich for large sample sizes, is approximately standard normal. \\n \\nImportant Note \\nIn this example, as the hypothesized value of p1 - p2 is not equal to zero, therefore are note estimating the same \\nquantity, and, as such, we do not use in the formula of the test statistic. \\n \\nStep-4:  \\n \\nComputation: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nStep-5: \\n\\uf028 \\uf029\\n2\\n22\\n1\\n11\\n21\\nˆˆˆˆ\\n10.0ˆˆ\\nn\\nqp\\nn\\nqp\\nppZ\\n\\uf02b\\n\\uf02d\\uf02d\\uf03d\\nHere \\n,38.0qˆthatso,62.0100\\n62pˆ 11 \\uf03d\\uf03d\\uf03d  \\n \\n.54.0qˆthatso,46.0150\\n69pˆ 22 \\uf03d\\uf03d\\uf03d  \\n Thus \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n150\\n54.046.0\\n100\\n38.062.0\\n10.046.062.0z\\n\\uf02b\\n\\uf02d\\uf02d\\uf03d  \\n \\n \\n.95.0063.0\\n06.0\\n001656.0002356.0\\n06.0 \\uf03d\\uf03d\\n\\uf02b\\n\\uf03d  \"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 292}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       288                                                                                                                                           \\nCritical Region: \\nAs this is a one-tailed test, therefore the critical region is given by  \\n   Z < -z0.05 = -1.645 \\nStep-6:  \\nConclusion: \\nSince the calculated value z = 0.95 does not fall in the critical region, so we accept the null hypothesis  \\nH0 : p1 – p2 > 0.10.The data seems to support the candidate’s view. \\nUntil now, we have discussed in considerable detail interval estimation and hypothesis -testing based on the standard \\nnormal distribution and the Z-statistic. \\nNext, we begin the discussion of interval estimation hypothesis-testing based on the t-distribution. \\n \\nt-DISTRIBUTION \\n \\nWe begin by presenting the formal definition of the t-distribution and stating some of its main properties: \\n \\nThe Student’s t-Distribution: \\n \\nThe mathematical equation of the t-distribution is as follows: \\n \\n \\n \\n \\n \\n \\n \\nThis distribution has only one parameter \\uf06e, which is known as the degrees of freedom of the t-distribution \\n \\nPROPERTIES OF STUDENT’S t-DISTRIBUTION \\n \\nThe t-distribution has the following properties: \\n \\ni) The t-distribution is bell-shaped and symmetric about the value t = 0, ranging from – \\uf0a5 to \\uf0a5. \\nii) The number of degrees of freedom determines the shape of the t-distribution.  \\nThus there is a different t-distribution for each number of degrees of freedom.  \\nAs such, it is a whole family of distributions. \\nThe t -distribution, for small values of \\uf06e, is flatter than the standard normal distribution which means that the t -\\ndistribution is more spread out in the tails than is the standard normal distribution. \\n \\n \\nAs the degrees of freedom increase, the t -distribution becomes narrower and narrower, until,  as n tends to infinity, it \\ntends to coincide with the standard normal distribution. \\n(The t-distribution can never become narrower than the standard normal distribution.) \\niii) The t-distribution has a mean of zero, when \\uf06e \\uf0b3 2. (The mean does not exist when \\uf06e = 1.) \\niv) The median of the t-distribution is also equal to zero. \\nv) The t-distribution is unimodal.The density of the distribution reaches its maximum at t = 0 and thus the mode of the \\nt-distribution is t = 0. \\n(The students will recall that, for any hump-shaped symmetric distribution, the mean, median and mode are equal.) \\nvi)  The variance of the t-distribution is given by \\n2\\n2\\n\\uf02d\\uf06e\\n\\uf06e\\uf03d\\uf073  for \\uf06e > 2.  \\n \\nStandard Normal \\nDistribution \\nt-distribution \\n3 degrees of \\nfreedom \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf0a5\\uf03c\\uf03c\\uf0a5\\uf02d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n\\uf06e\\uf02b\\n\\uf0f7\\uf0f8\\n\\uf0f6\\uf0e7\\uf0e8\\n\\uf0e6 \\uf06e\\uf062\\uf06e\\n\\uf03d\\n\\uf02b\\uf06e\\uf02d\\nx,x1\\n2,2\\n1\\n1xf\\n212'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 293}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       289                                                                                                                                           \\nIt is always greater than1, the variance of the standard normal distribution. (This indicates that the t-distribution is more \\nspread out than the standard normal distribution.) \\nFor \\uf06e \\uf0a3 2, the variance does not exist. Next, we discuss the application of the t-distribution in statistical inference --- \\nthose situations where we need to carry out interval estimation and hypothesis - testing on the basis of the t-distribution. \\n(Situations where the t-distribution is the appropriate sampling distribution) \\nWith reference to interval estimation and hypothesis -testing about \\uf06d, it has been mathematically proved that, if  the \\npopulation from which the sample has been drawn is normally distributed, the population varianc e is unknown, and the \\nsample size is small (less than 30), then the statistic \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFollows the t-distribution having n-1 degrees of freedom. First, we discuss the construction of a Confidence Interval for \\n\\uf06d based on the t-distribution with the help of an example: \\n \\nEXAMPLE \\n \\nThe masses, in grams, of thirteen ball bearings seen at random from a batch are \\n 21.4, 23.1, 25.9, 24.7, 23.4, 24.5, 25.0, 22.5, 26.9, 26.4, 25.8, 23.2, 21.9 \\nCalculate a 95% confidence interval for the mean mass of the population,  supposed normal, from which these masses \\nwere drawn. \\n \\nSOLUTION \\n \\nThe 95% confidence interval for the mean mass of the population \\uf06d, is given by \\n \\n \\n \\n(The derivation of the above confidence interval is very similar to that of the confidence interval for \\uf06d based on the Z -\\nstatistic.) \\nNow, in this problem, the sample mean\\uf060X and s come out to be: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe question is: ‘How do we find  \\n \\nFor this purpose, we will need to consult the table of areas under the t-distribution: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nn\\ns\\nXt 0\\uf06d\\uf02d\\uf03d\\n\\uf028 \\uf029 )1n\\nXXswhere(\\n2\\n\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\n\\uf028 \\uf029 n\\nstX 1n2 \\uf02d\\uf061\\uf02b\\n,21.2413\\n7.314\\nn\\nXX \\uf03d\\uf03d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\uf0e5\\uf0e5\\nn\\nXX1n\\n1\\n1n\\nXXs\\n2\\n2\\n2\\n \\n\\uf05b \\uf05d 77.112.312\\n43.3716.761859.765512\\n1 \\uf03d\\uf03d\\uf03d\\uf02d\\uf03d\\n \\n \\n\\uf028 \\uf029 ?t 1n2 \\uf02d\\uf061'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 294}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       290                                                                                                                                           \\nTABLE OF AREAS UNDER THE T-DISTRIBUTION \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above table is an abridged version of the table by Fisher and Yates, and the entries in this table are values of t \\uf061,(\\uf06e) \\nfor which the area to their right under the t-distribution with \\uf06e degrees of freedom is equal to \\uf061, as shown below: \\nUpper Percentage Points of the t-Distribution \\n\\uf061 \\n\\uf06e 0.25 0.10 0.05 0.025 0.01 0.005 0.001 \\n1 1.000 3.078 6.314 12.706 31.821 63.657 318.310 \\n2 0.816 1.886 2.920 4.303 6.965 9.925 22.327 \\n3 0.765 1.838 2.353 3.182 4.541 5.841 10.214 \\n4 0.741 1.533 2.132 2.776 3.747 4.604 7.173 \\n5 0.727 1.476 2.015 2.571 3.365 4.032 5.893 \\n6 0.718 1.440 1.943 2.447 3.143 3.707 5.208 \\n7 0.711 1.415 1.895 2.365 2.998 3.499 4.785 \\n8 0.706 1.397 1.860 2.306 2.896 3.355 4.501 \\n9 0.703 1.383 1.833 2.262 2.821 3.250 4.297 \\n10 0.700 1.372 1.812 2.228 2.764 3.169 4.144 \\n11 0.697 1.363 1.796 2.201 2.718 3.106 4.025 \\n12 0.695 1.356 1.782 2.179 2.681 3.055 3.930 \\n13 0.694 1.350 1.771 2.160 2.650 3.012 3.852 \\n14 0.692 1.345 1.761 2.145 2.624 2.977 3.787 \\n15 0.691 1.341 1.753 2.131 2.602 2.947 3.733 \\n \\nUpper Percentage Points of the t-Distribution \\n\\uf061 \\n\\uf06e 0.25 0.10 0.05 0.025 0.01 0.005 0.001 \\n16 0.690 1.337 1.746 2.120 2.583 2.921 3.686 \\n17 0.689 1.333 1.740 2.110 2.567 2.898 3.646 \\n18 0.688 1.330 1.734 2.101 2.552 2.878 3.610 \\n19 0.688 1.328 1.729 2.093 2.539 2.861 3.579 \\n20 0.687 1.325 1.725 2.086 2.528 2.845 3.552 \\n21 0.686 1.323 1.721 2.080 2.518 2.831 3.527 \\n22 0.686 1.321 1.717 2.074 2.508 2.819 3.505 \\n23 0.685 1.319 1.714 2.069 2.500 2.807 3.485 \\n24 0.685 1.318 1.711 2.064 2.492 2.797 3.467 \\n25 0.684 1.316 1.708 2.060 2.485 2.787 3.450 \\n26 0.684 1.315 1.706 2.056 2.479 2.779 3.435 \\n27 0.684 1.314 1.703 2.052 2.473 2.771 3.421 \\n28 0.683 1.313 1.701 2.048 2.467 2.763 3.408 \\n29 0.683 1.311 1.699 2.045 2.462 2.756 3.396 \\n30 0.683 1.310 1.697 2.042 2.457 2.750 3.385 \\n40 0.681 1.303 1.684 2.021 2.423 2.704 3.307 \\n60 0.679 1.296 1.671 2.000 2.390 2.660 3.232 \\n120 0.677 1.289 1.658 1.980 2.358 2.617 3.160 \\n\\uf0a5 0.674 1.282 1.645 1.960 2.326 2.576 3.090 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 295}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       291                                                                                                                                           \\n \\n \\nNow, in this problem, since n – 1 = 12, and the desired level of confidence is 95%, therefore, the right -tail area is 2½%, \\nand, hence, (using the t-table) we obtain \\n  \\nt0.025 (12) = 2.179 \\n \\nSubstituting these values, we obtain the 95% confidence interval for \\uf06d as follows: \\n\\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf0b1\\n13\\n77.1179.221.24\\n   \\nor 24.21 \\uf0b1 2.179 (0.49) \\nor 24.21 \\uf0b1 1.07 or 23.14 to 25.28 \\n \\nHence, the 95% confidence interval for the mean mass of  the ball bearings calculated from the given sample is (23.1, \\n25.3) grams. \\n\\uf061 \\nt\\uf061 0 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 296}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       292                                                                                                                                           \\nLECTURE NO. 40 \\n \\n\\uf0b7 Tests and Confidence Intervals based on the t-distribution  \\nIn the last lecture, we introduced the t -distribution, and began the discussion of statistical inference  based on the t -\\ndistribution. In particular, we discussed the construction of the confidence interval for \\uf06d in that situation when we are \\ndrawing a small sample from a normal population having unknown variance \\uf0732. When the parent population is normal, \\nthe population variance is unknown, and the sample size n is small (less than 30), then the confidence interval for \\uf06d is \\ngiven by \\n \\n \\n \\nwhere \\nn\\nxx \\uf0e5\\uf03d  is the sample mean  \\n\\uf028 \\uf029\\n1n\\nxxs\\n2\\n\\uf02d\\n\\uf0e5 \\uf02d\\uf03d  is the sample standard deviation n = sample size and t(\\uf061/2, \\uf06e) is \\nfound by looking in the t-table under the appropriate value of \\uf061 against \\uf06e = n – 1; \\n\\uf061/2 =  0.005 if we desire 99% confidence: \\n \\n\\uf061/2 =  0.025 if we desire 95% confidence: \\n \\n \\n \\n \\n\\uf061/2 =  0.05 if we desire 90% confidence: \\n \\n  \\n \\nNext, we discuss hypothesis - testing regarding the mean of a normally distributed population for which \\uf0732 is unknown \\nand the sample size is small (n < 30).  \\nThis procedure is illustrated through the following example:  \\n \\n \\n0 \\n0.95 \\n0.025 0.025 \\n\\uf028 \\uf029\\uf06e025.0t\\n\\uf028 \\uf029\\uf06e025.0t\\uf02d\\n0 \\n0.99 \\n0.005 0.005 \\n\\uf028 \\uf029\\uf06e005.0t\\n\\uf028 \\uf029\\uf06e005.0t\\uf02d\\n0 \\n0.90 \\n0.05 0.05 \\n\\uf028 \\uf029\\uf06e05.0t\\n\\uf028 \\uf029\\uf06e05.0t\\uf02d\\n\\uf028 \\uf029\\nn\\nstx n 12/ \\uf02d\\uf0b1 \\uf061'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 297}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       293                                                                                                                                           \\nEXAMPLE-1 \\n \\nJust as human height is approximately normally distributed, we can expect the heights of animals of any particular \\nspecies to be normally distributed.  Suppose that, for the past five years, a zoologist has been involved  in an extensive \\nresearch-project regarding the animals of one particular species. Based on his research -experience, the zoologist \\nbelieves that the average height of the animals of this particular species is 66 centimeters.  He selects a random sample \\nof ten animals of this particular species, and, upon measuring their heights, the following data is obtained. \\n63, 63, 66, 67, 68, 69, 70, 70, 71, 71 \\nIn the light of these data, test the hypothesis that the mean height of the animals of this particular species  is 66 \\ncentimeters. \\n \\nSOLUTION: \\n \\nHypothesis-Testing Procedure: \\n \\ni) We state our null and alternative hypotheses as \\n H0 : \\uf06d = 66 and H1 : \\uf06d \\uf0b9 66. \\n \\nii) We set the significance level at \\uf061 = 0.05. \\niii) Test Statistic: \\n The test-statistic to be used is \\n \\n \\n \\n \\n \\nwhich, if H0 is true, has the t-distribution with n – 1 = 9 degrees of freedom. \\n \\nImportant Note: \\n As indicated in the previous discussion, we always begin by assuming that H0 is true.(The entire \\nmathematical logic of the hypothesis-testing procedure is based on the assumption that H0 is true.) \\niv) CALCULATIONS \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow \\n8.6710\\n678\\nn\\nxx i \\uf03d\\uf03d\\uf0e5\\uf03d  inches, \\nand  \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0e5 \\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf0e5 \\uf0e5\\uf02d\\uf02d\\uf03d\\uf02d\\uf02d\\uf03d n\\nxx1n\\n1xx1n\\n1s\\n2\\n22\\ni\\n2   \\n        \\n\\uf05b \\uf05d ,0667.94.45968460509\\n1 \\uf03d\\uf02d\\uf03d  \\n01.30667.9s \\uf03d\\uf03d\\n inches. \\n \\nns\\nXt 0\\uf06d\\uf02d\\uf03d\\nIndividual No. xi xi\\n2 \\n1 63 3969 \\n2 63 3969 \\n3 66 4356 \\n4 67 4489 \\n5 68 4624 \\n6 69 4761 \\n7 70 4900 \\n8 70 4900 \\n9 71 5041 \\n10 71 5041 \\nTotal 678 46050 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 298}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       294                                                                                                                                           \\n\\uf028 \\uf029\\uf028 \\uf029\\n89.1\\n01.3\\n1623.38.1\\n1001.3\\n668.67\\nns\\nxt 0\\n\\uf03d\\n\\uf03d\\n\\uf02d\\uf03d\\n\\uf06d\\uf02d\\uf03d\\uf05c\\n \\nV) Critical Region:  \\n Since this is a two-tailed test, hence the critical region is given by \\n | t | > t0.025(9) = 2.262. \\n \\n \\n \\n \\n \\n \\nvi) Conclusion: \\nSince the computed value of t = 1.89 does not fall in the critical region, we therefore do not reject H0 and may conclude \\nthat the mean height of the animals of this particular species is 66 centimeters. \\n Next, we consider the construction of the confidence interval for \\uf06d1-\\uf06d2 in that situation when we are drawing \\nsmall samples from two normally distributed populations having unknown but equal variances: \\nWe illustrate this concept with the help of the following example: \\n \\n \\nEXAMPLE: \\nA record company executive is interested in estimating the difference in the average play -length of songs pertaining to \\npop music and semi-classical music. To do so, she randomly selects 10 semi-classical songs and 9 pop songs.  \\n  \\n \\nTHE PLAY-LENGTHS (IN MINUTES)  OF THE SELECTED SONG S ARE LISTED IN THE FOLLOW ING \\nTABLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n2.262 0 -2.262 \\nREJECT REJECT ACCEPT \\nSemi-Classic Music Pop Music \\n3.80 3.88 \\n3.30 4.13 \\n3.43 4.11 \\n3.30 3.98 \\n3.03 3.98 \\n4.18 3.93 \\n3.18 3.92 \\n3.83 3.98 \\n3.22 4.67 \\n3.38  \\n  \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 299}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       295                                                                                                                                           \\nCalculate a 99% confidence interval to estimate the difference in population means for these two types of recordings.  \\n \\nSOLUTION: \\n \\nIn this problem, we are dealing with a t-distribution with n1+n2 - 2 = 10 + 9 – 2 = 17 degrees of freedom. The table t-\\nvalue for a 99% level of confidence and 17 degrees of freedom is t005.17 = 2.898.  \\nCalculations: \\n \\nSemi-Classical Music Pop Music \\nn1 = 10 \\n1X\\n= 3.465 \\nS1 = .0.3575 \\nn2 = 9 \\n2X\\n= 4.064 \\nS2 = .0.2417 \\n \\nHence:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe confidence interval is  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWith 99% confidence, the record company executive can conclude that the true difference in population average length \\nof play is between –1.01 minutes and –.188 minute. Zero is not in this interval, so she could conclude that there is a \\nsignificant difference in the average length of play time between semi-classical music and pop music songs’ recordings. \\nExamination of the sample results indicates that pop music songs’ recordings are longer. The result and conclusion \\nobtained above can be used in the tactical and strategic planning for programming, marketing, and production of \\nrecordings. \\n \\nEXAMPLE \\n \\nFrom an area planted in one variety of guayule (a rubber producing plant), 54 plants were selected at random. Of these, \\n15 were off types and 12 were aberrant. Rubber percentages for these plants were: \\n \\n \\n \\n \\n \\n \\n \\nTest the hypothesis that the mean rubber percentage of the Aberrants is at least 1 percent more than the mean rubber \\npercentage of off types. Assume the populations of rubber percentages are approximately normal and have equal \\nvariances. Let subscript 1 stand for Aberrants, and let subscript 2 stand for off types. Then, we proceed as follows: \\ni) We formulate our null and alternative hypotheses as \\nH0 : \\uf06d1 - \\uf06d2 > 1,  \\nand \\n H1 : \\uf06d1 - \\uf06d2 < 1  \\nii) We set the significance level at \\uf061 = 0.05. \\niii) The test-statistic, if H0 is true, is \\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\n31.0\\n0952.017\\n6177.1\\n17\\n4674.01503.1\\n2910\\n82417.93575.\\n22\\n\\uf03d\\n\\uf03d\\uf03d\\n\\uf02b\\uf03d\\n\\uf02d\\uf02b\\n\\uf02b\\uf03dps\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n188.010.1\\n:....\\n411.0599.09\\n1\\n10\\n131.0898.2\\n064.4465.3\\n21 \\uf02d\\uf0a3\\uf02d\\uf0a3\\uf02d\\n\\uf0b1\\uf02d\\uf03d\\uf02b\\uf0b1\\n\\uf02d\\n\\uf06d\\uf06d\\nisICtheei\\nOfftypes 6.21, 5.70, 6.04, 4.47, 5.22, 4.45, 4.84, \\n5.88, 5.82, 6.09, 6.06, 5.59, 6.74, 5.55 \\nAberrant 4.28, 7.71, 6.48, 7.71, 7.37, 7.20, 7.06, \\n6.40, 8.93, 5.91, 5.51, 6.36 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 300}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       296                                                                                                                                           \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n21\\np\\n2121\\nn\\n1\\nn\\n1s\\nXXt\\n\\uf02b\\n\\uf06d\\uf02d\\uf06d\\uf02d\\uf02d\\uf03d  \\nwhich has a Student’s t-distribution with  \\n\\uf06e = n1 + n2 – 2, i.e. 25 degrees of freedom. \\niv) Computations:  \\nWe have \\n \\n \\n \\n \\n \\n \\nAnd  \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n12\\n92.806402.561\\nn\\nxxxx\\n2\\n1\\n2\\n12\\n1\\n2\\n11\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf02d\\uf0e5 \\uf0e5 \\uf0e5\\n \\n9697.15\\n6705.5456402.561\\n\\uf03d\\n\\uf02d\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029\\n15\\n25.849779.478\\n2\\n2\\n2\\n22\\n2\\n2\\n22\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf02d\\uf0e5 \\uf0e5 \\uf0e5\\nn\\nxxxx\\n \\n7737.5\\n2042.4739779.478\\n\\uf03d\\n\\uf02d\\uf03d\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n = 0.8697, \\nso that \\n \\n \\nHence, the computed value of our test statistic comes out to be \\n \\n \\n \\n \\n \\nv) Critical Region: \\nSince this is a left-tailed test, therefore the critical region is given by   \\n t < -t0.05(25) i.e. t < -1.708 \\nvi) Conclusion: \\nSince the computed value of t = 0.33 falls in the acceptance region, therefore we accept H0. We may conclude \\nthat the mean rubber percentage of the Aberrants is at least 1 percent more than the mean rubber percentage of Off \\ntypes. \\n \\n \\nT-DISTRIBUTION IN THE CASE OF PAIRED OBSERVATIONS \\n,74.612\\n92.80\\nn\\nxx\\n1\\n1\\n1 \\uf03d\\uf03d\\uf03d \\uf0e5\\n,62.515\\n25.84\\n2\\n2\\n2 \\uf03d\\uf03d\\uf03d \\uf0e5\\nn\\nxx\\n\\uf028 \\uf029 \\uf028 \\uf029\\n21512\\n7737.59697.5\\n221\\n2\\n22\\n2\\n11\\n2\\n\\uf02d\\uf02b\\n\\uf02b\\uf03d\\n\\uf02d\\uf02b\\n\\uf02d\\uf02b\\uf02d\\n\\uf03d\\n\\uf0e5\\uf0e5\\nnn\\nxxxx\\nsNow p\\n,93.08697.0 \\uf03d\\uf03dps\\n\\uf028 \\uf029 33.036.0\\n12.0\\n15\\n1\\n12\\n193.0\\n162.574.6t \\uf03d\\uf03d\\n\\uf02b\\n\\uf02d\\uf02d\\uf03d\\uf05c'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 301}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       297                                                                                                                                           \\nIn testing hypotheses about two means, until now we have used independent samples, but there are many situations in \\nwhich the two samples are not independent. This happen when the observation are found in pairs such that the two \\nobservations of a pair are related to each other. Pairing occurs either naturally or by design. Natural pairing occurs \\nwhenever measurement is taken on the same unit or individual at two different times. For example, suppose ten you ng \\nrecruits are given a strenuous physical training programme by the Army. Their weights are recorded before they begin \\nand after they complete the training. The two observations obtained for each recruit i.e. the before-and-after \\nmeasurement constitute natural pairing. The above is natural pairing. \\n \\nEXAMPLE: \\nTen young recruits were put through a strenuous physical training programme by the Army. Their weights were \\nrecorded before and after the training with the following results: \\n \\n \\n \\n \\n \\n \\nUsing \\uf061 = 0.05, would you say that the programme affects the average weight of recruits?  \\nAssume the distribution of weights before and after to be approximately normal. When the observations from two \\nsamples are paired, we find the difference between the two observations of  each pair, and the test -statistic in this \\nsituation is:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRecruit 1 2 3 4 5 6 7 8 9 10 \\nWeight before \\nWeight after \\n125 \\n136 \\n195 \\n201 \\n160 \\n158 \\n171 \\n184 \\n140 \\n145 \\n201 \\n195 \\n170 \\n175 \\n176 \\n190 \\n195 \\n190 \\n139 \\n145 \\n \\nns\\nd\\nns\\nd\\nns\\ndt\\nd\\nd\\nd\\nd\\n\\uf03d\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\n0\\n\\uf06d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 302}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       298                                                                                                                                           \\nLECTURE NO. 41 \\n \\n\\uf0b7 Hypothesis-Testing regarding Two Population Means in the Case of Paired Observations (t-distribution)  \\n\\uf0b7  The Chi-square Distribution \\n\\uf0b7  Hypothesis Testing and Interval Estima tion Regarding a Population Variance (based on Chi -square \\nDistribution) \\nIn the last lecture, we began the discussion of hypothesis -testing regarding two population means in the case of paired \\nobservations. It was mentioned that, in many situati ons, pairing  occurs naturally. Observations are also paired to \\neliminate effects in which there is no interest.   For example, suppose we wish to test which of two types (A or B) of \\nfertilizers is the better one. The two types of fertilizer are applied to a number of plots and the results are noted. \\nAssuming that the two types are found significantly different, we may find that part of the difference may be due to the \\ndifferent types of soil or different weather conditions, etc. Thus the real difference between the fertilizers can be found \\nonly when the plots are paired according to the same types of soil or same weather conditions, etc.  \\nWe eliminate the undesirable sources of variation by taking the observations in pairs. This is pairing by design. \\nWe illustrate the p rocedure of hypothesis -testing regarding the equality of two population means in the case of paired \\nobservations with the help of the same example that we quoted at the end of the last lecture: \\n \\nEXAMPLE \\nTen young recruits were put through a strenuous physi cal training programme by the Army. Their weights were \\nrecorded before and after the training with the following results: \\n \\n \\n \\n \\n \\n \\n \\nUsing \\uf061 = 0.05, would you say that the programme affects the average weight of recruits? Assume the distribution of \\nweights before and after to be approximately normal.  \\n \\nSOLUTION \\n \\nThe pairing was natural here, since two observations are made on the same recruit at two different times. The sample \\nconsists of 10 recruits with two measurements on each. The test is carried out as below: \\nHypothesis-Testing Procedure: \\ni) We state our null and alternative hypotheses as  \\n H0 : \\uf06dd = 0 and  \\n H1 : \\uf06dd \\uf0b9 0 \\nii) The significance level is set at \\uf061 = 0.05. \\niii) The test statistic under H0 is \\n \\n \\n \\n \\nwhich has a t-distribution with n – 1 degrees of freedom. \\n \\niv) Computations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRecruit 1 2 3 4 5 6 7 8 9 10 \\nWeight before \\nWeight after \\n125 \\n136 \\n195 \\n201 \\n160 \\n158 \\n171 \\n184 \\n140 \\n145 \\n201 \\n195 \\n170 \\n175 \\n176 \\n190 \\n195 \\n190 \\n139 \\n145 \\n \\n,\\nns\\ndt\\nd\\n\\uf03d\\nWeight Recruit Before After \\nDifference, di (after \\nminus before) d1\\n2 \\n1 125 136 11 121 \\n2 195 201 6 36 \\n3 160 158 – 2 4 \\n4 171 184 13 169 \\n5 140 145 5 25 \\n6 201 195 6 36 \\n7 170 175 – 6 25 \\n8 176 190 5 196 \\n9 195 190 14 25 \\n10 139 145 – 5 36 \\n\\uf0e5 1672 1719 6 673 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 303}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       299                                                                                                                                           \\n,7.410\\n47\\nn\\ndd \\uf03d\\uf03d\\uf03d \\uf0e5\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d\\uf02d\\n\\uf02d\\uf03d \\uf0e5\\uf0e5\\uf0e5\\nn\\ndd1n\\n1\\n1n\\ndds\\n2\\n2\\n2\\nd2\\n \\n\\uf028 \\uf029 ,23.509\\n9.220673\\n10\\n476739\\n1 2\\n\\uf03d\\uf02d\\uf03d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf03d\\n \\n \\nso that \\n \\n \\nHence, the computed value of our test-statistic comes out to be : \\n \\n \\n \\n \\n \\nv) The critical region is |t| \\uf0b3 t0.025(9)   \\n  = 2.262.  \\nvi) Conclusion:  \\n Since the calculated value of t = 2.09 does not fall in the critical region, so we accept H0 and may conclude \\nthat the data do not provide sufficient evidence to indicate that the programme affects average weight. \\n  \\nFrom the above example, it is clear that the hypothesis-testing procedure regarding the equality of means in \\nthe case of paired observations is very similar to the t-test that is applied for testing  \\nH0 : \\uf06d = 0.(The only difference is that when we are testing H0 : \\uf06d = 0, our variable is X, whereas when we are testing \\nH0 : \\uf06dd=0, our variable is d.) \\n \\n \\nHYPOTHESIS-TESTING PROCEDURE REGARDING TWO POPULATIONS \\nMEANS IN THE CASE OF PAIRED OBSERVATIONS \\n \\nWhen the observations from two samples are paired either naturally or by design, we find the difference between the \\ntwo observations of each pair. Treating the differences as a random sample from a normal population with mean \\uf06dd = \\n\\uf06d1 - \\uf06d2 and unknown standard deviation \\uf073d, we perform a one-sample t-test on them. This is called a paired difference \\nt-test or a paired t-test. \\nTesting the hypothesis  \\n \\nH0 : \\uf06d1 = \\uf06d2 against  \\nHA : \\uf06d1 \\uf0b9 \\uf06d2 is equivalent to testing H0 : \\uf06dd = 0 against  \\nHA : \\uf06dd \\uf0b9 0. \\nLet d = x1 – x2 denote the difference between the two samples observations in a pair. Then the sample m ean and \\nstandard deviation of the differences are \\n \\n  \\n \\n \\nwhere n represents the number of pairs. \\nAssuming that  \\n \\n1)  d1, d2, …, dn is a random sample of differences, and  \\n \\n2)  the differences are normally distributed,  \\nthe test-statistic \\n \\n \\nns\\nd\\nns\\n0dt\\ndd\\n\\uf03d\\uf02d\\uf03d  \\nfollows a t-distribution with \\uf06e = n – 1 degrees of freedom. The rest of the procedure for testing the null hypothesis H0 : \\n\\uf06dd = 0 is the same \\nEXAMPLE \\n.09.723.50 \\uf03d\\uf03dds\\n\\uf028 \\uf029\\uf028 \\uf029 .09.209.7\\n16.37.4\\n1009.7\\n7.4\\nns\\ndt\\nd\\n\\uf03d\\uf03d\\uf03d\\uf03d\\n\\uf028 \\uf029\\n1n\\nddsandn\\ndd\\n2\\nd \\uf02d\\n\\uf02d\\uf03d\\uf03d \\uf0e5\\uf0e5'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 304}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       300                                                                                                                                           \\n \\nThe following data give paired yields of two varieties of wheat.  \\n \\n \\n \\n \\n \\n \\nEach pair was planted in a different locality.  \\na) Test the hypothesis that, on the average,  the yield of variety-1 is less than the mean yield of variety-2. \\n State the assumptions necessary to conduct this test. \\nb) How can the experimenter make a Type-I error?  \\n What are the consequences of his doing so? \\nc) How can the experimenter make a Type-II error?  \\n What are the consequences of his doing so? \\nd) Give 90 per cent confidence limits for the difference in mean yield. \\n \\nNote: The pairing was by design here, as the yields are affect ed by many extraneous factors such as fertility of land, \\nfertilizer applied, weather conditions and so forth.  \\n \\nSOLUTION: \\n \\na) In order to conduct this test, we make the following assumptions:  \\n \\nASSUMPTIONS \\n \\n\\uf076 The differences in yields are a random sample from the population of differences, \\n\\uf076 The population of differences is normally distributed.  \\ni) We state our null and alternative hypotheses as \\n \\n \\n\\uf028 \\uf02921d0 or0:H \\uf06d\\uf0b3\\uf06d\\uf0b3\\uf06d ,  \\n i.e. the mean yields are equal and  \\n \\n \\n\\uf028 \\uf02921d1 or0:H \\uf06d\\uf03c\\uf06d\\uf03c\\uf06d . \\nii) We select the level of significance at \\uf061 = 0.05.  \\n \\niii) The test statistic to be used is \\n \\n \\n \\n \\nwhere          and sd2 is the variance of the differences di. \\n \\nIf the populations are normal, this statistic, when H0 is true, has a Student’s t-distribution with (n – 1)    d. f. \\niv) Computations: \\n Let X1i and X2i represent the yields of Variety I and Variety II respectively. Then the necessary \\ncomputations are given below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nVariety I 45 32 58 57 60 38 47 51 42 38 \\nVariety II 47 34 60 59 63 44 49 53 46 41 \\n \\nns\\nd\\nns\\n0dt\\ndd\\n\\uf03d\\uf02d\\uf03d\\n21 xxd \\uf02d\\uf03d\\nX1i X2i di = X1i – X2i di\\n2 \\n45 47 –2 4 \\n32 34 –2 4 \\n58 60 –2 4 \\n57 59 –2 4 \\n60 63 –3 9 \\n38 44 –6 36 \\n47 49 –2 4 \\n51 53 –2 4 \\n42 46 –4 16 \\n38 41 –3 9 \\n\\uf053 –– –28 94 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 305}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       301                                                                                                                                           \\nNow  \\n8.210\\n28\\nn\\ndd i \\uf02d\\uf03d\\uf02d\\uf03d\\uf03d \\uf0e5 , and  \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02d\\uf02d\\uf03d\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d \\uf0e5 \\uf0e5\\n10\\n28949\\n1\\nn\\ndd1n\\n1s\\n22\\ni2\\ni\\n2\\nd  \\n \\n \\n7333.19\\n6.15 \\uf03d\\uf03d , so that sd = 1.32 \\n\\uf028 \\uf029\\uf028 \\uf029 71.632.1\\n1623.38.2\\n1032.1\\n8.2\\nns\\ndt\\nd\\n\\uf02d\\uf03d\\uf02d\\uf03d\\uf02d\\uf03d\\uf03d\\uf05c\\n \\nv) As this is a one-tailed test therefore, the critical region is given by  \\n t < t0.05(9) = -1.833 \\nvi) Conclusion \\n \\nSince the calculated value of t = –6.71 falls in the critical region, we therefore reject H0.  The data  present sufficient \\nevidence to conclude that the mean yield of variety-1 is less than the mean yield of variety-2. \\nb) The experimenter can make a Type-I error by rejecting a true null hypothesis. \\nIn this case, the Type -I error is make by rejecting the null hypothesis when the mean yield of variety -1 is actually not \\ndifferent from the mean yield of variety-2. \\nIn so doing, the consequences would be that we will be saying that variety -2 is better than variety -1 although in reality \\nthey are equally good. \\nc)  The experimenter can make a Type-II error by accepting of false null hypothesis.  \\nIn this case, the Type -II error is made by accepting the null hypothesis when in reality the mean yield of variety -1 is \\nless than the mean yield of variety -2 and the consequen ce of committing this error would be a loss of potential \\nincreased yield by the use of variety-2. \\nd) The 90% confidence limits for the difference in means \\uf06d1 – \\uf06d2 in case of paired observations, are given by \\n \\n \\n \\nSubstituting the values, we get \\n \\n \\n \\n \\nor -2.8 + 0.765 \\nor -3.565 to -2.035 \\n \\n Hence the 90% confidence limits for the difference in mean yields, \\uf06d1 – \\uf06d2, are (-3.6, -2.0) . \\nUntil now, we have discussed statistical inference regarding population means based on the Z -statistic as well as the t -\\nstatistic.  \\n Also, we have discussed inference regarding the population proportion based on the Z-statistic. \\nIn certain situations, we would be interested in drawing conclusions about the variability that exists in the population \\nvalues, and for this purpose, we wou ld like to carry out estimation or hypothesis -testing regarding the population \\nvariance \\uf0732. \\n \\nStatistical Inference regarding the population variance is based on the chi-square distribution.  \\nWe begin this topic by presenting the formal definition of the  \\nChi-Square distribution and stating some of its main properties: \\n \\nTHE CHI-SQUARE (\\uf0632) DISTRIBUTION \\n \\nThe mathematical equation of the Chi-Square distribution is as follows: \\n \\n \\n \\n \\nThis distribution has only one parameter \\uf06e, which is known as the degrees of freedom of the Chi-Square distribution. \\n \\n \\n \\n\\uf028 \\uf029 n\\ns.td d\\n1n,2/ \\uf02d\\uf061\\uf0b1\\n10\\n32.1833.18.2 \\uf0b1\\uf02d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029 \\uf0a5\\uf03c\\uf03c\\n\\uf06e\\uf047\\n\\uf03d \\uf02d\\uf02d\\uf06e\\n\\uf06e x0,e.x\\n2/2\\n1xf 2/x12/\\n2/'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 306}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       302                                                                                                                                           \\nPROPERTIES OF THE CHI-SQUARE DISTRIBUTION \\n \\nThe Chi-Square (\\uf0632) distribution has the following properties: \\n1. It is a continuous distribution ranging from 0 to +\\uf0a5 . \\nThe number of degrees of freedom determines the shape of the chi -square distribution. Thus there is a different chi -\\nsquare distribution for each number of degrees of freedom. As such, it is a whole family of distributions. \\n2. The curve of a chi-square distribution is positively skewed.  \\nThe skewness decreases as \\uf06e increases. \\n \\n \\n  \\uf0632-distribution for various values of \\uf06e \\n \\nAs indicated by the above figures, the chi -square distribution tends to the normal distribution as the number of degrees \\nof freedom approaches infinity. \\n3. The mean of a chi-square distribution is equal to \\uf06e, the number of degrees of freedom. \\n4. Its variance is equal to 2\\uf06e. \\n5. The moments about the origin are given by  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs such, the moment-ratios come out to be  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHaving discussed the basic definition and properties of the chi-square distribution, we begin the discussion of its role in \\ninterval estimation  and hypothesis-testing. We begin with interval estimation  regarding the variance of a normally \\ndistributed population:  \\n \\nEXAMPLE: \\n \\nSuppose that an aptitude test carrying a total of 20 marks is devised, and administered on a large population of students, \\nand, upon doing so, it was found that the marks of the students were normally distributed. A random sample of size n = \\n8 is drawn from this population, and the sample values are 9, 14, 10, 12, 7, 13, 11, 12. \\nFind the 90 percent confidence interval for the population variance \\uf0732, representing the variability in the marks of the \\nstudents.  \\n \\nSOLUTION: \\n0.5 \\n0.4 \\n0.3 \\n0.1 \\n0.2 \\n0 2 4 6 8 10 12 14 \\nX \\n\\uf06e=2 \\n\\uf06e =6 \\n\\uf06e=10 \\nf(x) \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\uf028 \\uf029642'\\n42'\\n2'\\n'\\n4\\n3\\n2\\n1\\n\\uf02b\\uf02b\\uf02b\\uf03d\\n\\uf02b\\uf02b\\uf03d\\n\\uf02b\\uf03d\\n\\uf03d\\n\\uf06e\\uf06e\\uf06e\\uf06e\\uf06d\\n\\uf06e\\uf06e\\uf06e\\uf06d\\n\\uf06e\\uf06e\\uf06d\\n\\uf06e\\uf06d\\n\\uf06e\\uf062\\n\\uf06e\\uf062\\n123\\n8\\n1\\n1\\n\\uf02b\\uf03d\\n\\uf03d\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 307}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       303                                                                                                                                           \\nThe 90% confidence interval for \\uf0732 is given by \\n \\n \\n \\n \\n \\n \\nThe above formula is linked with the fact that if we keep 90% area under the chi -square distribution in the middle, then \\nwe will have 5% area on the left-hand-side, and 5% area on the right-hand-side, as shown below: \\n \\n\\uf0632(N-1)-DISTRIBUTION \\n \\n In order to apply the above formula, we first need to calculate the sample mean\\nX , which is  \\n \\n118\\n88\\nn\\nXX \\uf03d\\uf03d\\uf03d \\uf0e5  \\nThen, we obtain \\n \\n \\n \\n \\nNext, we need to find : \\n1) the value of \\uf0632 to the left of which the area under the chi-square distribution is 5% \\n2) the value of \\uf0632 to the right of which the area under the chi-square distribution is 5% \\nFor this purpose, we will need to consult the table of areas under the chi-square distribution. \\n \\nTHE CHI-SQUARE TABLE \\n \\nThe entries in this table are values of x2 \\uf061(\\uf06e), for which the area to their right under the chi -square distribution with \\uf06e \\ndegrees of freedom is equal to \\uf061. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n2\\n1n95.0\\n2\\ni2\\n2\\n1n05.0\\n2\\nXXXXi\\n\\uf02d\\uf02d \\uf063\\n\\uf02d\\uf03c\\uf073\\uf03c\\uf063\\n\\uf02d \\uf0e5\\uf0e5\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029 361112...1114119\\n22228\\n1\\n\\uf03d\\uf02d\\uf02b\\uf02b\\uf02d\\uf02b\\uf02d\\uf03d\\uf02d\\uf0e5\\n\\uf03d\\nXXi\\ni\\nUpper Percentage Points of the Chi-square Distribution \\n\\uf061 \\n\\uf06e 0.99 0.98 0.975 0.95 0.10 0.05 0.03 0.02 0.01 \\n1 0.0002 0.001 0.001 0.004 2.71 3.84 5.02 5.41 6.64 \\n2 0.020 0.040 0.051 0.103 4.61 5.99 7.38 7.82 9.21 \\n3 0.115 0.185 0.216 0.352 6.25 7.82 9.35 9.84 11.34 \\n4 0.297 0.429 0.484 0.711 7.78 9.49 11.14 11.67 13.28 \\n5 0.554 0.752 0.831 1.145 9.24 11.07 12.83 13.39 15.09 \\n6 0.87 1.13 1.24 1.64 10.64 12.59 14.45 15.03 16.81 \\n7 1.24 1.56 1.69 2.17 12.02 14.07 16.01 16.62 18.48 \\n8 1.65 2.03 2.18 2.73 13.36 15.51 17.54 18.17 20.09 \\n9 2.09 2.53 2.70 3.32 14.68 16.92 19.02 19.68 21.67 \\n10 2.56 3.06 3.25 3.94 15.99 18.31 20.48 21.16 23.21 \\n11 3.05 3.61 3.82 4.58 17.28 19.68 21.92 22.62 24.72 \\n12 3.57 4.18 4.40 5.23 18.55 21.03 23.34 24.05 26.22 \\n13 4.11 4.76 5.01 5.89 19.81 22.36 24.74 25.47 27.69 \\n14 4.66 5.37 5.63 6.57 21.06 23.68 26.12 26.87 29.14 \\n15 5.23 5.98 6.26 7.26 22.31 25.00 27.49 28.26 30.58 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 308}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       304                                                                                                                                           \\nChi-Square Table (continued): \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nFrom the \\uf0632-table, we find that \\n \\uf06320.05 (7) = 14.07  \\nand  \\n \\uf06320.95 (7) = 2.17  \\nHence the 90 percent confidence interval for \\uf0732 is  \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n2\\n7,95.0\\n2\\ni2\\n2\\n7,05.0\\n2\\nXXXXi\\n\\uf063\\n\\uf02d\\uf03c\\uf073\\uf03c\\n\\uf063\\n\\uf02d \\uf0e5\\uf0e5  \\nor \\n17.2\\n36\\n07.14\\n36 2 \\uf03c\\uf073\\uf03c  \\nor \\n61.1656.2 2 \\uf03c\\uf073\\uf03c  \\nThus the 90% confidence interval for \\uf0732 is (2.56, 16.61). \\nIf we take the square root of the lower limit as well as the upper limit of the above confidence interval, we obtain (1.6, \\n4.1). \\n So, we may conclude that, on the basis of 90% confidence, we can say that the standard deviation \\uf073 of our \\npopulation lies between 1.6 and 4.1 .We can obtain a confide nce interval for \\uf073 by taking the square root of the end \\npoints of the interval for \\uf0732, but experience has shown that \\uf073 cannot be estimated with much precision for small sample \\nsizes. \\nThe formula of the confidence interval for \\uf0732 that we have applied in the above example is based on the fact that: \\nIf\\uf060X and S2 are the mean and variance (respectively) of a random sample X1, X2, …, Xn of size n drawn from a \\nnormal population with variance \\uf0732, then the statistic \\n \\n \\n \\n \\nfollows a chi-square distribution with (n – 1) degrees of freedom. \\nNext, we consider hypothesis - testing regarding the population variance \\uf0732 : \\nWe illustrate this concept with the help of an example: \\n \\nEXAMPLE \\n \\nThe variability in the tensile strength of a type of steel wire must be controlled carefully. A sample of the wire is \\nsubjected to test, and it is found that the sample variance is S2 = 31.5. The sample size was n = 16 observations. \\nTest the hypothesis that the population variance is 25 against the alternative that the variance is greater than 25. Use a \\n0.05 level of significance. \\n \\uf061 \\n\\uf06e 0.99 0.98 0.975 0.95 0.10 0.05 0.025 0.02 0.01 \\n16 5.81 6.61 6.91 7.96 23.54 26.30 28.84 29.63 32.00 \\n17 6.41 7.26 7.56 8.67 24.77 27.59 30.19 31.00 33.41 \\n18 7.02 7.91 8.23 9.39 25.99 28.87 31.53 32.35 34.81 \\n19 7.63 8.57 8.91 10.12 27.20 30.14 32.85 33.69 36.19 \\n20 8.26 9.24 9.59 10.85 28.41 31.41 34.17 35.02 37.57 \\n21 8.90 9.92 10.28 11.59 29.62 32.67 35.48 36.34 38.93 \\n22 9.54 10.60 10.98 12.34 30.81 33.92 36.78 37.66 40.29 \\n23 10.20 11.29 11.69 13.09 32.01 35.17 38.08 38.97 41.64 \\n24 10.86 11.99 12.40 13.85 33.00 36.42 39.36 40.27 42.92 \\n25 11.52 12.70 13.12 14.61 34.38 37.65 40.65 41.57 44.31 \\n26 12.20 13.41 13.84 15.38 35.56 38.88 41.92 42.86 45.64 \\n27 12.88 14.12 14.57 16.15 36.74 40.11 43.19 44.14 46.96 \\n28 13.56 14.85 15.31 16.93 37.92 41.34 44.46 45.42 48.28 \\n29 14.26 15.57 16.05 17.71 39.09 42.56 45.72 46.69 49.59 \\n30 14.95 16.31 16.79 18.49 40.26 43.77 46.98 47.96 50.89 \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\n2\\n2\\n2\\n2\\n2\\n2\\ni s1nnSXX\\n\\uf073\\n\\uf02d\\uf03d\\n\\uf073\\n\\uf03d\\n\\uf073\\n\\uf02d\\uf0e5'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 309}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       305                                                                                                                                           \\n \\n \\nSOLUTION \\n \\na)i) We have to decide between the hypotheses  \\n \\n  H0 : \\uf0732 = 25, and  \\n  H1 : \\uf0732 > 25 \\nii) The level of significance is \\uf061 = 0.05. \\n \\niii) The test statistic is \\n,nS\\n2\\n0\\n2\\n2\\n\\uf073\\n\\uf03d\\uf063  which under H0, has a \\uf0632-distribution with (n–1) degrees of freedom, assuming \\nthat the population is normal. \\niv) We calculate the value of \\uf0632 from the sample data as \\n \\n\\uf028 \\uf029 .16.2025\\n5.3116nS\\n2\\n0\\n2\\n2 \\uf03d\\uf03d\\n\\uf073\\n\\uf03d\\uf063  \\nv)  The critical region is \\uf0632 > \\uf0632\\n0.05,(15) = 25.00  (one tailed test) \\nvi)  Conclusion. \\n Since the calculated value of \\uf0632 falls in the acceptance region, so we accept our null \\nHypothesis, i.e. we have reasonable evidence to conclude that \\uf0732 = 25.The Chi-Square \\nDistribution with 15 degrees of Freedom: \\n \\n \\n \\nThe above example points to the following general procedure for testing a hypothesis regarding the population variance \\n\\uf0732: Suppose we desire to test a null hypothesis H0 that the variance \\uf0732 of a normally distributed population has some \\nspecified value, say \\uf07302. To do th is, we need to draw a random sample X 1, X 2, …, X n of size n from the no rmal \\npopulation and compute the value of the sample variance S 2.  If the null hypothesis H 0 : \\uf0732 = \\uf0732\\n0 is true, then the \\nstatistic \\n2\\n0\\n2\\n2 nS\\n\\uf073\\n\\uf03d\\uf063  has a \\uf0632-distribution with (n–1) degrees of freedom. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nX 0 \\n0.05 \\n25.00 \\nf(x) \\n20.16 \\n \\nCritical Region Acceptance Region '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 310}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       306                                                                                                                                           \\n \\nLECTURE NO. 42 \\n \\n\\uf0b7 The F-Distribution \\n\\uf0b7 Hypothesis Testing and Interval Estimation in order to Compare the Variances of Two Normal \\nPopulations (based on F-Distribution)  \\nBefore we describe you statistical inference based on t he F-distribution, let us consolidate the idea of hypothesis-testing \\nregarding the population variance with the help of an example: \\n \\nEXAMPLE \\n \\nThe manager of a bottling plant is anxious to reduce the variability in net weight of fruit bottled. Over a long period, the \\nstandard deviation has been 15.2 gm. A new machine is introduced and the net weights (in grams) in 10 randomly \\nselected bottles (all of the same nominal weight) are 987, 966, 955, 977, 981, 967, 975, 980, 953, 972.  Would you \\nreport to the manager that the new machine has a better performance? \\n \\nSOLUTION \\n \\ni) We have to decide between the hypotheses \\n H0 : \\uf073 = 15.2, i.e. the  standard deviation is 15.2gm \\n H1 : \\uf073 < 15.2 i.e. the standard deviation has  been reduced. \\nii) We choose the significance level at \\uf061 = 0.05. \\niii) The test-statistic is \\n\\uf028 \\uf029\\n2\\n0\\n2\\ni\\n2\\n0\\n2\\n2 XXnS\\n\\uf073\\n\\uf02d\\uf0e5\\uf03d\\n\\uf073\\n\\uf03d\\uf063\\n \\nwhich under H0, has a \\uf0632 -distribution with (n – 1) degrees of freedom, assuming that the weights are normally \\ndistributed. \\niv) Computations.  \\n  n = 10, \\uf0e5Xi = 9713,  \\uf0e5X2i = 9435347 \\nv) The critical region is \\uf063 2 < \\uf06320.95 (9) = 3.32 (the lower 5% point)  \\nNOW  \\n nS2 = \\uf0e5(Xi –\\uf060X)2 = \\uf0e5X2\\ni – (\\uf0e5Xi)2/n \\n        = 9435347 – (9713)2/10 = 1110.1 \\n\\uf028 \\uf029\\n81.404.231\\n1.1110\\n2.15\\n1.1110\\n2\\n2 \\uf03d\\uf03d\\uf03d\\uf063\\uf05c\\n  \\nvi) Conclusion:  \\n       Since the calculated value of \\uf0632 = 4.81 does not fall in the cr itical region, we therefore cannot reject the null \\nhypothesis that the standard deviation is 15.2 gm and hence we would not report to the manager that the new machine \\nhas a better performance. \\nThe above example points to the fact that, if we wish to test a  null hypothesis H0 that the variance \\uf0732 of a normally \\ndistributed population has some specified value, say \\uf07302, then, (having drawn a random sample X1, X2, …, Xn of size \\nn from the normal population), we will compute the value of the sample variance S2.  \\nThe mathematics underlying this hypothesis-testing procedure states that: \\n If the null hypothesis \\n2\\n0\\n2\\n0 :H \\uf073\\uf03d\\uf073   is true, then the statistic \\n2\\n0\\n2\\n2 nS\\n\\uf073\\n\\uf03d\\uf063  has a \\uf0632-distribution with (n –1) \\ndegrees of freedom. \\nA point to be noted is that, since the random variable X is distributed as chi-square, therefore we call it \\uf0632. \\n If we do so, our equation of the chi-square distribution can be written as \\n \\n \\n \\nIt should be obvious that the standard deviation of the normal population will be tested in the same way as the \\npopulation variance is tested. \\nNext, we begin the discussion of statistical inference regarding the ratio of two population variances.  \\n As this particular inference is based on the F -distribution, therefore we begin with the discussion  of the \\nmathematical definition and the main properties of the F-distribution. \\n \\n \\n \\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf0a5\\uf03c\\uf03c\\n\\uf047\\n\\uf03d \\uf02d\\uf02d 22/12/2\\n2/\\n2 0,.\\n2/2\\n1 2\\n\\uf063\\uf063\\uf06e\\uf063 \\uf063\\uf06e\\n\\uf06e ef'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 311}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       307                                                                                                                                           \\n \\nTHE F-DISTRIBUTION \\n \\nThe mathematical equation of the F-distribution is as follows: \\n \\n \\n \\n \\n \\nThis distribution has two parameters \\uf06e1 and \\uf06e2, which are known as the degrees of freedom of the F-distribution.The F-\\ndistribution having the above equation have \\uf06e1 degrees of freedom in the numerator and \\uf06e2 degrees of freedom in the \\ndenominator. It is usually abbreviated as F(\\uf06e1, \\uf06e2).  \\n \\nPROPERTIES OF F-DISTRIBUTION \\n \\n1. The F-distribution is a continuous distribution ranging from zero to plus infinity. \\n2. The curve of the F-distribution is positively skewed.  \\n \\n \\nBut as the degrees of freedom \\uf06e1 and \\uf06e2  become large, the F-distribution approaches the normal distribution. \\n \\n3. For \\uf06e2 > 2, the mean of the F-distribution is  \\n \\n \\n \\n \\nwhich is greater than 1. \\n4.For \\uf06e2 > 4, the variance of the F-distribution is \\n \\n \\n \\n \\n \\n5. The F-distribution for \\uf06e1 > 2, \\uf06e2 > 2 is unimodal, and the mode of the distribution with \\uf06e1 > 1 is at \\n \\n \\n \\nwhich is always less than 1. \\n6. If F has an F-distribution with \\uf06e1 and \\uf06e2 degrees of freedom, then the reciprocal has an F-distribution with \\uf06e2 and \\uf06e1 \\ndegrees of freedom.  Next, we consider the tables of the F-distribution. As the F-distribution involves two parameters, \\nF 0 \\nf(F) \\n \\nF 0 \\nf(F\\n) \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\uf028 \\uf029 \\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf05b \\uf05d\\uf028 \\uf029 \\uf0a5\\uf03c\\uf03c\\n\\uf02b\\uf047\\uf047\\n\\uf02b\\uf047\\uf03d \\uf02b\\n\\uf02d\\nx\\nx\\nxxf 0,\\n122\\n2\\n2\\n2121\\n122\\n2121\\n21\\n11\\n\\uf06e\\uf06e\\n\\uf06e\\uf06e\\n\\uf06e\\uf06e\\uf06e\\uf06e\\n\\uf06e\\uf06e\\uf06e\\uf06e\\n22\\n2\\n\\uf02d\\uf06e\\n\\uf06e\\n\\uf028 \\uf029\\n\\uf028 \\uf029 \\uf028 \\uf02942\\n22\\n2\\n2\\n21\\n21\\n2\\n22\\n\\uf02d\\uf06e\\uf02d\\uf06e\\uf06e\\n\\uf02d\\uf06e\\uf02b\\uf06e\\uf06e\\uf03d\\uf073\\n\\uf028 \\uf029\\n\\uf028 \\uf0292\\n2\\n21\\n12\\n\\uf02b\\n\\uf02d\\n\\uf06e\\uf06e\\n\\uf06e\\uf06e'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 312}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       308                                                                                                                                           \\n\\uf06e1 and \\uf06e2, hence separate tables have been constructed for 5%, 2½ % and 1% right-tail areas respectively, as shown \\nbelow: \\n \\n \\n \\nThe F-table pertaining to 5% right-tail areas is as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUpper 5 Percent Points of The F-Distribution i.e., F0.05 (v1, v2) \\n\\uf06e1 \\n\\uf06e2 1 2 3 4 5 6 8 12 24 \\uf0a5 \\n1 161.4 199.5 215.7 224.6 230.2 234.0 238.9 243.9 249.0 254.3 \\n2 18.51 19.00 19.16 19.25 19.30 19.33 19.37 19.41 19.45 19.50 \\n3 10.13 9.55 9.28 9.12 9.01 8.94 8.84 8.74 8.64 8.53 \\n4 7.71 6.94 6.59 6.39 6.26 6.16 6.04 5.91 5.77 5.63 \\n5 6.61 5.79 5.41 5.19 5.05 4.95 4.82 4.68 4.53 4.36 \\n6 5.99 5.14 4.76 4.53 4.39 4.28 4.15 4.00 3.84 3.67 \\n7 5.59 4.74 4.35 4.12 3.97 3.87 3.73 3.57 3.41 3.23 \\n8 5.32 4.46 4.07 3.84 3.69 3.58 3.44 3.28 3.12 2.93 \\n9 5.12 4.26 3.86 3.63 3.48 3.37 3.23 3.07 2.90 2.71 \\n10 4.96 4.10 3.71 3.48 3.33 3.22 3.07 2.91 2.74 2.54 \\n11 4.84 3.98 3.59 3.36 3.20 3.09 2.95 2.79 2.61 2.40 \\n12 4.75 3.88 3.49 3.26 3.11 3.00 2.85 2.69 2.50 2.30 \\n13 4.67 3.80 3.41 3.18 3.03 2.92 2.77 2.60 2.42 2.21 \\n14 4.60 3.74 3.34 3.11 2.96 2.85 2.70 2.53 2.35 2.13 \\n15 4.54 3.68 3.29 3.06 2.90 2.79 2.64 2.48 2.29 2.07 \\n \\n \\n \\n\\uf06e1 \\n\\uf06e2 1 2 3 4 5 6 8 12 24 \\uf0a5 \\n16 4.49 3.63 3.24 3.01 2.85 2.74 2.59 2.42 2.24 2.01 \\n17 4.45 3.59 3.20 2.96 2.81 2.70 2.55 2.38 2.19 1.96 \\n18 4.41 3.55 3.16 2.93 2.77 2.66 2.51 2.34 2.15 1.92 \\n19 4.38 3.52 3.13 2.90 2.74 2.63 2.48 2.31 2.11 1.88 \\n20 4.35 3.49 3.10 2.87 2.71 2.60 2.45 2.28 2.08 1.84 \\n21 4.32 3.47 3.07 2.84 2.68 2.57 2.42 2.25 2.05 1.81 \\n22 4.30 3.44 3.05 2.82 2.66 2.55 2.40 2.23 2.03 1.78 \\n23 4.28 3.42 3.03 2.80 2.64 2.53 2.38 2.20 2.00 1.76 \\n24 4.26 3.40 3.01 2.78 2.62 2.51 2.36 2.18 1.98 1.73 \\n25 4.24 3.38 2.99 2.76 2.60 2.49 2.34 2.16 1.96 1.71 \\n26 4.22 3.37 2.98 2.74 2.59 2.47 2.32 2.15 1.95 1.69 \\n27 4.21 3.35 2.96 2.73 2.57 2.46 2.30 2.13 1.93 1.67 \\n28 4.20 3.34 2.95 2.71 2.56 2.44 2.29 2.12 1.91 1.65 \\n29 4.18 3.33 2.93 2.70 2.54 2.43 2.28 2.10 1.90 1.64 \\n30 4.17 3.32 2.92 2.69 2.53 2.42 2.27 2.09 1.89 1.62 \\n40 4.08 3.23 2.84 2.61 2.45 2.34 2.18 2.00 1.79 1.51 \\n60 4.00 3.15 2.76 2.52 2.37 2.25 2.10 1.92 1.70 1.39 \\n120 3.92 3.07 2.68 2.45 2.29 2.17 2.02 1.83 1.61 1.25 \\n\\uf0a5 3.84 2.99 2.60 2.37 2.21 2.10 1.94 1.73 1.52 1.00 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 313}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       309                                                                                                                                           \\n \\n \\n \\n \\nSimilarly, the F-table pertaining to 2½% right-tail areas is as follows \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUpper 2.5 Percent Points of the F-Distribution i.e. F0.025 (\\uf06e1, \\uf06e2) \\n \\n\\uf06e1 \\n\\uf06e2 \\n1 2 3 4 5 6 8 12 24 \\uf0a5 \\n1 647.8 799.5 864.2 899.6 921.8 937.1 956.7 976.7 997.2 1018 \\n2 38.51 39.00 39.17 39.25 39.30 39.33 39.37 39.41 39.46 39.50 \\n3 17.44 16.04 15.44 15.10 14.88 14.73 14.54 14.34 14.12 13.90 \\n4 12.22 10.65 9.98 9.60 9.36 9.20 8.98 8.75 8.51 8.26 \\n5 10.07 8.43 7.76 7.39 7.15 6.98 6.76 6.52 6.28 6.02 \\n6 8.81 7.26 6.60 6.23 5.99 5.82 5.60 5.37 5.12 4.85 \\n7 8.07 6.54 5.89 5.52 5.29 5.12 4.90 4.67 4.42 4.14 \\n8 7.57 6.06 5.42 5.05 4.82 4.65 4.43 4.20 3.95 3.67 \\n9 7.21 5.71 5.08 4.72 4.48 4.32 4.10 3.87 3.61 3.33 \\n10 6.94 5.46 4.83 4.47 4.24 4.07 3.85 3.62 3.37 3.08 \\n11 6.72 5.26 4.63 4.28 4.04 3.88 3.66 3.43 3.17 2.88 \\n12 6.55 5.10 4.47 4.12 3.89 3.73 3.51 3.28 3.02 2.72 \\n13 6.41 4.97 4.35 4.00 3.77 3.60 3.39 3.15 2.89 2.60 \\n14 6.30 4.86 4.24 3.89 3.66 3.50 3.29 3.05 2.79 2.49 \\n15 6.20 4.77 4.15 3.80 3.58 3.41 3.20 2.96 2.70 2.40 \\n \\nUpper 2.5 Percent Points of the F-Distribution i.e. F0.025 (\\uf06e1, \\uf06e2) (Continued): \\n\\uf06e1 \\n\\uf06e2 \\n1 2 3 4 5 6 8 12 24 \\uf0a5 \\n16 6.12 4.69 4.08 3.73 3.50 3.34 3.12 2.89 2.63 2.32 \\n17 6.04 4.62 4.01 3.66 3.44 3.28 3.06 2.82 2.56 2.25 \\n18 5.98 4.56 3.95 3.61 3.38 3.22 3.01 2.77 2.50 2.19 \\n19 5.92 4.51 3.90 3.56 3.33 3.17 2.96 2.72 2.45 2.13 \\n20 5.87 4.46 3.86 3.51 3.29 3.13 2.91 2.68 2.41 2.09 \\n21 5.83 4.42 3.82 3.48 3.25 3.09 2.87 2.64 2.37 2.04 \\n22 5.79 4.38 3.78 3.44 3.22 3.05 2.84 2.60 2.33 2.00 \\n23 5.75 4.35 3.75 3.41 3.18 3.02 2.81 2.57 2.30 1.97 \\n24 5.72 4.32 3.72 3.38 3.15 2.99 2.78 2.54 2.27 1.94 \\n25 5.69 4.29 3.69 3.35 3.13 2.97 2.75 2.51 2.24 1.91 \\n26 5.66 4.27 3.67 3.33 3.10 2.94 2.73 2.49 2.22 1.88 \\n27 5.63 4.24 3.65 3.31 3.08 2.92 2.71 2.47 2.19 1.85 \\n28 5.61 4.22 3.63 3.29 3.06 2.90 2.69 2.45 2.17 1.83 \\n29 5.59 4.20 3.61 3.27 3.04 2.88 2.67 2.43 2.15 1.81 \\n30 5.57 4.18 3.59 3.25 3.06 2.87 2.65 2.41 2.14 1.79 \\n40 5.42 4.05 3.46 3.13 2.90 2.74 2.53 2.29 2.01 1.64 \\n60 5.49 3.93 3.34 3.01 2.79 2.63 2.41 2.17 1.88 1.48 \\n120 5.15 3.80 3.23 2.89 2.67 2.52 2.30 2.05 1.76 1.31 \\n\\uf0a5 5.02 3.69 3.12 2.79 2.57 2.41 2.19 1.94 1.64 1.00 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 314}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       310                                                                                                                                           \\n \\nAnd, the F-table pertaining to 1% right-tail areas is as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n0.025 \\nF0.025 0 \\nUpper 1 Percent Points of the F-Distribution i.e. F0.01 (\\uf06e1, \\uf06e2) \\nv1 \\nv2 1 2 3 4 5 6 8 12 24 \\uf0a5 \\n1 4052 5000 5403 5625 5764 5859 5982 6106 6235 6366 \\n2 98.50 99.00 99.17 99.25 99.30 99.33 99.37 99.42 99.46 99.50 \\n3 34.12 30.82 29.46 28.71 28.24 27.91 27.49 27.05 26.60 26.12 \\n4 21.20 18.00 10.69 15.98 15.52 15.21 14.80 14.37 13.93 13.46 \\n5 16.26 13.27 12.06 11.39 10.97 10.67 10.29 9.89 9.47 9.02 \\n6 13.75 10.92 9.78 9.15 8.75 8.47 8.10 7.72 7.31 6.88 \\n7 12.25 9.55 8.45 7.85 7.46 7.19 6.84 6.47 6.07 5.65 \\n8 11.26 8.65 7.59 7.01 6.63 6.37 6.03 5.67 5.28 4.86 \\n9 10.56 8.02 6.99 6.42 6.06 5.80 5.47 5.11 4.73 4.31 \\n10 10.04 7.56 6.55 5.99 5.64 5.39 5.06 4.71 4.33 3.91 \\n11 9.65 7.21 6.22 5.67 5.32 5.07 4.74 4.40 4.02 3.61 \\n12 9.33 6.93 5.95 5.41 5.06 4.82 4.50 4.16 3.78 3.36 \\n13 9.07 6.70 5.74 5.20 4.86 4.62 4.30 3.96 3.59 3.17 \\n14 8.86 6.51 5.56 5.03 4.69 4.46 4.14 3.80 3.43 3.00 \\n15 8.68 6.36 5.42 4.89 4.56 4.32 4.00 3.67 3.29 2.87 \\n \\nUpper 1 Percent Points of the F-Distribution i.e. F0.01 (\\uf06e1, \\uf06e2) (continued) \\nv1 \\nv2 \\n1 2 3 4 5 6 8 12 24 \\uf0a5 \\n16 8.53 6.23 5.29 4.77 4.44 4.20 3.89 3.55 3.18 2.75 \\n17 8.40 6.11 5.18 4.67 4.34 4.10 3.79 3.45 3.08 2.65 \\n18 8.28 6.01 5.09 4.58 4.25 4.01 3.71 3.37 3.03 2.57 \\n19 8.18 5.93 5.01 4.50 4.17 3.94 3.63 3.30 2.92 2.49 \\n20 8.10 5.85 4.94 4.43 4.10 3.87 3.56 3.23 2.86 2.42 \\n21 8.02 5.78 4.87 4.37 4.04 3.81 3.51 3.17 2.80 2.36 \\n22 7.95 5.72 4.82 4.31 3.99 3.76 3.45 3.12 2.75 2.31 \\n23 7.88 5.66 4.76 4.26 3.94 3.71 3.41 3.07 2.70 2.26 \\n24 7.82 5.61 4.72 4.22 3.90 3.67 3.36 3.03 2.66 2.21 \\n25 7.77 5.57 4.68 4.18 3.86 3.63 3.32 2.99 2.62 2.17 \\n26 7.72 5.53 4.64 4.14 3.82 3.59 3.29 2.96 2.58 2.13 \\n27 7.68 5.49 4.60 4.11 3.78 3.56 3.26 2.93 2.55 2.10 \\n28 7.64 5.45 4.57 4.07 3.75 3.53 3.23 2.90 2.52 2.06 \\n29 7.60 5.42 4.54 4.04 3.73 3.50 3.20 2.87 2.49 2.03 \\n30 7.56 5.39 4.51 4.02 3.70 3.47 3.17 2.84 2.47 2.01 \\n40 7.31 5.18 4.31 3.83 3.51 3.29 2.99 2.66 2.29 1.80 \\n60 7.08 4.98 4.13 3.65 3.34 3.12 2.82 2.50 2.12 1.60 \\n120 6.85 4.79 3.95 3.48 3.17 2.96 2.66 2.34 1.94 1.38 \\n\\uf0a5 6.63 4.61 3.78 3.32 3.02 2.80 2.51 2.18 1.79 1.00 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 315}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       311                                                                                                                                           \\n \\n \\nHaving discussed the basic definition and the main properties of the F-distribution, we now begin the discussion of the \\nrole of the F-distribution in statistical inference: First, we discuss interval estimation regarding the ratio of two \\npopulation variances: \\n \\nCONFIDENCE INTERVAL FOR THE VARIANCE RATIO \\uf07312/\\uf07322 \\n \\nLet two independent random samples of size n1 and n2 be taken from two normal population with variances \\uf07312 and \\n\\uf07322 and let s12 and s22 be the unbiased estimators of \\uf07312 and \\uf07322.  \\nThen, it can be mathematically proved that the quantity  \\n \\n \\n \\nhas an F-distribution with (n1 – 1, n2 – 1) degrees of freedom. \\nThe confidence interval for \\uf07312/\\uf07322 is given by  \\n \\n \\n \\n \\nWe can also find a confidence interval for \\uf0731/\\uf0732 by taking the square root of the end points of the above interval. \\nWe illustrate this concept with the help of the following example: \\n \\nEXAMPLE \\n \\nA random sample of 12 salt-water fish was taken, and the girth of the f ish was measured. The standard deviation s1 \\ncame out to be 2.3 inches. Similarly, a random sample of 10 fresh-water fish was taken, and the girth of the fish was \\nmeasured. The standard deviation of this sample i.e. s2 came out to be 1.5 inches. Find a 90% confidence interval for \\nthe ratio between the 2 population variances \\uf07312/\\uf07322. Assume that the populations of girth are normal. \\n \\nSOLUTION \\n \\n The 90% confidence interval for \\uf07312/\\uf07322 is given by  \\n \\n \\n \\n \\n \\nHere  s12 = (2.3)2 = 5.29, \\ns22 = (1.5)2 = 2.25, \\nn1– 1 = 12 – 1 = 11 and  n2 – 1 = 10 – 1 = 9 \\nHence,  \\nF0.05 (n1 – 1, n2 – 1) = F0.05 (11, 9) = 3.1  \\nand  \\nF0.05 (n2 – 1, n1 – 1) = F0.05 (9, 11) = 2.9 \\nWith reference to the F -table, it should be noted that if it is an abridged table and the F -values are not available for all \\npossible pairs of degrees of freedom, then the required F -values are obtained by the method of interpolation. In this \\nexample, for the lower limit of our confidence interval, we need the value of F0.05(11, 9), but in the above table \\npertaining to 5% right-tail area, values are available for \\uf06e1 = 8 and \\uf06e1 = 12, but not for \\uf06e1 = 11. Hence, we can find the \\nF-value corresponding to \\uf06e1 = 11 by the method of interpolation: The F -value corresponding to \\uf06e2 = 9 and \\uf06e1 = 8 is \\n3.23 whereas the F-value corresponding to \\uf06e2 = 9 and \\uf06e1 = 12  is  3.07.If we wish to find the F -value corresponding to \\n\\uf06e2 = 9 and \\uf06e1 = 10, we can find the arithmetic mean of 3.23 and 3.07 which is 3.15.If we wish to find the F -value \\ncorresponding to \\uf06e2 = 9 and \\uf06e1 = 11, we can find the ari thmetic mean of 3.15 and 3.07 which is 3.11, which, upon \\n0.01 \\nF0.01 0 \\n2\\n2\\n2\\n2\\n2\\n1\\n2\\n1\\n\\uf073\\n\\uf073\\ns\\nsF \\uf03d\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02d\\uf02d\\uf02d\\uf02d 1,1.,1,1\\n1. 122/2\\n2\\n2\\n1\\n212/\\n2\\n2\\n2\\n1 nnF\\ns\\ns\\nnnFs\\ns\\n\\uf061\\n\\uf061\\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9 \\uf02d\\uf02d\\uf02d\\uf02d 1,1.,1,1\\n1. 1205.02\\n2\\n2\\n1\\n2105.0\\n2\\n2\\n2\\n1 nnF\\ns\\ns\\nnnFs\\ns'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 316}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       312                                                                                                                                           \\nrounding, is equal to 3.1.The above method of interpolation is based on the assumption that the F -values between any \\ntwo successive F-values (printed in any row of the F-table) are equally spaced between the two given values.  \\nIf we do not wish to go through the rigorous procedure of interpolation, we can note that \\uf06e1 = 11 is close to \\uf06e1 = 12, \\nand hence, we can consider that F -value which corresponds to \\uf06e1 = 12 (which in this case is 3.07 ~ 3.1 ----- exactly the \\nsame as what we obtained above (correct to one decimal place) by the method of interpolation).  Going back to our \\nexample, the 90% confidence interval is  \\n \\n \\n \\nor  (0.76, 6.81). \\nTaking the square root of the end points (0.76, 6.81), we obtain the 90% confidence interval for \\uf0731/\\uf0732 as (0.87, 2.61). \\nNext, we discuss hypothesis - testing regarding the equality of two population variances : Suppose that we have two \\nindependent random samples of size n1 and n2 from two normal populations with variances \\uf07312 and \\uf07322, we wish to \\ntest the hypothesis that the two variances are equal. The main steps of the hypothesis - testing procedure are similar to \\nthe ones that we have been discussing earlier. We illustrate this concept with the help of an example: \\n \\nEXAMPLE \\n \\n In two series of hauls to determine the number of plankton organisms inhabiting the waters of a lake, the \\nfollowing results were found: \\nSeries I: 80, 96, 102, 77, 97, 110, 99, 88, 103, 1089 \\nSeries II: 74, 122, 92, 81, 104, 92, 92 \\nIn series I, the hauls were made in succession at the same place. In series II, they were made in different parts scattered \\nover the lake. Does there appear to be a greater variability between different places than between different times at the \\nsame place? \\n \\nSOLUTION \\n \\nIf X denot es the number of plankton organisms per haul, then for each of the two series, X can be assumed to be \\nnormally distributed. \\nHypothesis-testing Procedure: \\nStep 1 :  \\nH0 : \\uf07312 \\uf0b3 \\uf07322  i.e. \\uf07322 \\uf0a3 \\uf07312 \\nHA : \\uf07312 < \\uf07322  i.e. \\uf07322 > \\uf07312 \\nStep 2: Level of significance: \\uf061 = 0.05 \\nStep 3: Test-statistic: \\nSince both the populations are normally distributed, hence, the statistic \\n \\n \\n \\n \\nwill follow the F-distribution having (n2 - 1, n1 - 1) degrees of freedom. \\nStep 4 : Computations:  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow \\n \\n \\n \\n \\n\\uf028 \\uf029\\uf0fa\\uf0fb\\n\\uf0f9\\n\\uf0ea\\uf0eb\\n\\uf0e9 \\uf0f7\\n\\uf0f8\\n\\uf0f6\\uf0e7\\n\\uf0e8\\n\\uf0e6 9.225.2\\n29.5,1.3\\n1.25.2\\n29.5\\n2\\n1\\n2\\n1\\n2\\n2\\n2\\n2\\ns\\nsF\\n\\uf073\\n\\uf073\\uf03d\\nX1 X1\\n2 \\n X2 X2\\n2 \\n80 6400  74 5476 \\n96 9216  122 14884 \\n102 10404  92 8464 \\n77 5929  81 6561 \\n97 9409  104 10816 \\n110 12100  92 8464 \\n99 9801  92 8464 \\n88 7744  657 63129 \\n103 10609    \\n108 11664    \\n960 93276    \\n \\n\\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d \\uf0e5 \\uf0e5\\n1\\n2\\n12\\n1\\n1\\n2\\n1\\n1\\n1\\nn\\nXXns'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 317}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       313                                                                                                                                           \\nand \\n \\n \\n \\n \\n  So \\n\\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d 10\\n9609326110\\n1s\\n2\\n2\\n1  \\n\\uf05b \\uf05d92160932769\\n1 \\uf02d\\uf03d\\n \\n\\uf05b \\uf05d 12411169\\n1 \\uf03d\\uf03d\\n \\nSimilarly   \\n\\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d \\uf0e5\\uf0e5\\n2\\n2\\n22\\n2\\n2\\n2\\n2 n\\nXX1n\\n1s  \\n \\n\\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d 7\\n6576312917\\n1 2  \\n \\n\\uf05b \\uf05d14.61664631296\\n1 \\uf02d\\uf03d  \\n \\n\\uf05b \\uf05d 14.24486.14646\\n1 \\uf03d\\uf03d  \\nHence \\n97.1124\\n14.244\\ns\\nsF 2\\n1\\n2\\n2 \\uf03d\\uf03d\\uf03d  \\nStep 5 : Critical Region: \\n  F > F0.05 (6, 9) = 3.37 \\nStep 6: Conclusion:  \\nSince 1.97 is less than 3.37, we do not reject H0; our data does not provide sufficient evidence to indicate that there is \\ngreater variability (in the number of plankton organisms per haul) between different places than between different times \\nat the same place. \\nLet us consider another example: \\n \\nEXAMPLE \\n \\nTwo methods of determining the moisture content of samples of canned corn have been proposed and both have been \\nused to make determinations on proportions taken from each of 21 c ans.  Method I is easier to apply but appears to be \\nmore variable than Method II.  \\nIf the variability of Method I were not more than 25 per cent greater than that of Method II, then we would prefer \\nMethod I.  \\nThe sample results are as follows: \\n \\n \\n \\n \\n \\n \\nBased on the above sample results, which method would you recommend? \\n \\nSOLUTION \\n \\nIn order to solve this problem, the first point to be noted is that, in this problem, our null and alternative hypotheses wil l \\nbe  \\n H0: \\uf07312 \\uf0a3 1.25 \\uf07322  \\nand \\n H1: \\uf07312 > 1.25 \\uf07322. \\nNull and Alternative Hypotheses: \\n\\uf028 \\uf029\\n\\uf0fa\\n\\uf0fa\\n\\uf0fb\\n\\uf0f9\\n\\uf0ea\\n\\uf0ea\\n\\uf0eb\\n\\uf0e9\\n\\uf02d\\uf02d\\uf03d \\uf0e5 \\uf0e5\\n2\\n2\\n22\\n2\\n2\\n2\\n2 n\\nXX1n\\n1s\\n53X;50X;21nn 2121 \\uf03d\\uf03d\\uf03d\\uf03d\\n \\n\\uf028 \\uf029 \\uf028 \\uf029\\uf0e5 \\uf0e5 \\uf03d\\uf02d\\uf03d\\uf02d .340XX;720XX\\n2\\n22\\n2\\n11\\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 318}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       314                                                                                                                                           \\nIn this problem, we need to test \\nH0 : \\uf07312 \\uf0a3 1.25 \\uf07322  \\nagainst  \\nH1 : \\uf07312 > 1.25 \\uf07322. \\nThis is so, because 1.25 \\uf07322 means 125% of \\uf07322, and this means 25% greater than \\uf07322. You are encouraged to work \\non this point on their own. The second point to be noted is that, in this problem, our test-statistic is not but is \\n \\n \\n \\nTest Statistic: \\n \\n \\n \\n \\n \\n(Under the null hypothesis, s12 / 1.25 s22 has an F-distribution with \\uf06e1 = \\uf06e2 = 21-1 = 20 degrees of freedom.) \\nThis is so because, (in accordance with the fact that has an F-distribution with (n1 – 1, n2 – 1) degrees of freedom), \\nit can be shown that: \\n \\n \\n \\nIf we have  \\n H0: \\uf07312/ \\uf07322 = k  \\nthen \\n \\n \\n \\n \\nhas an F-distribution with (n1 - 1, n2 - 1) degrees of freedom.  (In this problem, k = 1.25.)You are enco uraged to work \\non this problem also on their own, and to carry out the rest of the steps of the hypothesis -testing procedure (which are \\nthe usual ones), and to decide whether to accept or to reject the null hypothesis. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n.\\n25.1\\n2\\n2\\n2\\n1\\ns\\nsF \\uf03d\\n.\\ns25.1\\nsF 2\\n2\\n2\\n1\\uf03d\\n2\\n2\\n2\\n2\\n2\\n1\\n2\\n1\\n\\uf073\\n\\uf073\\ns\\nsF \\uf03d\\nks\\nsF 1.2\\n2\\n2\\n1\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 319}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       315                                                                                                                                           \\n \\nLECTURE NO. 43 \\n\\uf0b7 Analysis of Variance   \\n\\uf0b7 Experimental Design  \\nEarlier, we compared two -population means by using a two -sample t-test. However, we are often required to compare \\nmore than two population means simultaneously.  We might be tempted to apply the tw o-sample t-test to all possible \\npairwise comparisons of means. For example, if we wish to compare 4 population means, there will be   \\n separate pairs, and to test the null hypothesis that all four population means are equal, we would require six two-sample  \\nt-tests. Similarly, to test the null hypothesis that 10 population means are equal, we would need   \\n \\n \\n \\n \\nSeparate two-sample t -tests. This procedure of running multiple two -sample t -tests for comparing means would \\nobviously be tedious and time-consuming. Thus a series of two-sample t-tests is not an appropriate procedure to test the \\nequality of several means simultaneously. Evidently, we require a simpler procedure for carrying out this kind of a test. \\nOne such procedure is the Analysis of Variance, introduced by Sir R.A. Fisher (1890-1962) in 1923:  \\n \\nANALYSIS OF VARIANCE (ANOVA) \\n \\nIt is a procedure which enables us to test the hypothesis of equality of several population means \\n(i.e.  \\n  H0 : \\uf06d1 = \\uf06d2 = \\uf06d3 = …… = \\uf06dk \\nagainst \\n  HA: not all the means are equal) \\nThe concept of Analysis of Variance is closely related with the concept of Experimental Design: \\n \\nEXPERIMENTAL DESIGN \\n \\nBy an experimental design, we mean a plan used to collect the data relevant to the problem under study in such a way as \\nto provide a basis for valid and objective inference about the stated problem. The plan usually includes:  \\n\\uf0b7  the selection of treatments whose effects are to be studied, \\n\\uf0b7  the specification of the experimental layout, and \\n\\uf0b7  the assignment of treatments to the experimental units. \\nAll these steps are accomplished before any experiment is performed. Experimental Design is a very vast area. In this \\ncourse, we will be presenting only a very basic introduction of this area. There are two types of designs:  \\n \\nSYSTEMATIC AND RANDOMIZED DESIGNS \\n  \\nIn this course, we will be discussing only the randomized designs, and, in this regard, it should be noted that for the \\nrandomized designs, the analysis of the collected data is carried out through the technique known as Analysis of \\nVariance. \\nTwo of the very basic randomized designs are: \\n\\uf0b7 The Completely Randomized (CR) Design, \\n\\uf0b7 The Randomized Complete \\n\\uf0b7 Block (RCB) Design  \\nWe will consider these one by one. We begin with the simplest design i.e. the Completely Randomized (CR) Design: \\n \\nTHE COMPLETELY RANDOMIZED DESIGN (CR DESIGN) \\n \\nA completely randomized (CR) design, which is the simplest type of the basic designs, may be defined as a design in \\nwhich the treatments are assigned to experimental units completely at random , i.e. the randomization is done without \\nany restrictions. This design is applicable in that situation where the entire experimental material is homogeneous (i.e. \\nall the experimental units can be regarded as being similar to each other).  We illustrate the concept of the Completely \\nRandomized (CR) Design (pertaining to the case when each treatment is repeated equal number of times) with the help  \\nof the following example. \\n \\nEXAMPLE \\nAn experiment was conducted to compare the yields of three varieties of potatoes. Each variety as assigned at ra ndom \\nto equal-size plots, four times. The yields were as follow: \\n \\n \\n  \\n \\n \\n \\n62\\n4 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\n452\\n10 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\nVariety \\nA B C \\n23 18 16 \\n26 28 25 \\n20 17 12 \\n17 21 14 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 320}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       316                                                                                                                                           \\n \\nTest the hypothesis that the three varieties of potatoes are not different in the yielding capabilities. \\n \\nSOLUTION \\n \\nThe first thing to note is that this is an example of the Complete ly Randomized (CR) Design. We are assuming that all \\ntwelve of the plots (i.e. farms) available to us for this experiment are homogeneous (i.e. similar) with regard to the \\nfertility of the soil, the weather conditions, etc., and hence, we are assigning the four varieties to the twelve plots totally \\nat random. Now, in order to test the hypothesis that the mean yields of the three varieties of potato are equal, we carry \\nout the six-step hypothesis-testing procedure, as given below: \\nHypothesis-Testing Procedure: \\ni) H0 : \\uf06dA = \\uf06dB = \\uf06dC   \\n HA : Not all the three means \\n are equal \\n \\nii) Level of Significance: \\n \\uf061 = 0.05 \\niii) Test Statistic: \\n \\n \\n    \\nwhich, if H0 is true, has an F distribution with \\uf0751 = k-1 = 3 – 1 = 2 and \\uf0752 = n-k = 12 – 3 = 9 degree of freedom \\n \\niv) Computations: \\nThe computation of the test statistic presented above involves quite a few steps, including the formation of what is \\nknown as the ANOVA Table.  \\nFirst of all, let us consider what is meant by the ANOVA Table (i.e. the Analysis of Variance Table). \\nIn the case of the Completely Randomized (CR) Design, the ANOVA Table is a table of the type given below: \\n \\n \\nANOVA TABLE IN THE CASE OF THE COMPLETELY RANDOMIZED (CR) DESIGN \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nLet us try to understand this table step by step: \\n The very first column is headed ‘Source of Variation’, and under this heading, we have three distinct sources \\nof variation: \\n \\n‘Total’ stands for the overall variation in the twelve values that we have in our data-set. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs you can see, the values in our data -set are 23, 26, 20, 17, 18, 28, and so on. Evidently, there is a variation in these \\nvalues, and the term ‘Total’ in the lowest row of the ANOVA Table stands for this overall variation. \\nThe term ‘Variation between Treatments’ stands for the variability that exis ts between the three varieties of potato that \\nwe have sown in the plots.  \\n(In this example, the term ‘treatments’ stands for the three varieties of potato that we are trying to compare) \\nErrorMS\\nTreatmentsMSF \\uf03d\\nSource of Variation d.f. Sum of \\nSquares \\nMean \\nSquare F \\nBetween treatments \\nWithin treatments (Error) \\nk-1 \\nn-k \\nSST \\nSSE \\nMST \\nMSE \\nMST/MSE \\n-- \\nTotal n-1 TSS -- -- \\n \\nVariety \\nA B C \\n23 18 16 \\n26 28 25 \\n20 17 12 \\n17 21 14 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 321}, page_content=\"STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       317                                                                                                                                           \\n(The term ‘variation between treatments’ points to the fact that: \\nIt i s possible that the three varieties or, at least two of the varieties are significantly different from each other with \\nregard to their yielding capabilities. This variability between the varieties can be measured by measuring the differences \\nbetween the mean yields of the three varieties.) \\nThe third source of variation is ‘variation within treatments’. This point  to the fact that even if only one particular \\nvariety of potato is sown more than once, we do not get the same yield every time \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIn this example, variety A was sown four times, and the yields were 23, 26, 20, and 17 --- all different from one \\nanother! Similar is the case for variety B as well as variety C. The variability in the yields of variety A can be called \\n‘variation within variety A’. \\n Similarly, the variability in the yields of variety B can be called ‘variation within variety B’. Also, the \\nvariability in the yields of variety C can be called ‘variation within variety C’. We can say that the term ‘variability \\nwithin treatments’ stand s for the combined effect of the above -mentioned three variations. The ‘variation within \\ntreatments’ is also known as the ‘ error variation’.  This is so because we can argue that if we are sowing the same \\nvariety in four plots which are very similar to each other, then we should have obtained the same yield from each plot!  \\n If it is not coming out to be the same every time, we can regard this as some kind of an ‘error’.  \\nThe second, third and fourth columns of the ANOVA Table are entitled ‘degrees of free dom’, ‘Sum of Squares’ and \\n‘Mean Square’. \\n \\nANOVA TABLE IN THE CASE OF THE COMPLETELY RANDOMIZED (CR) DESIGN \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe point to understand is that the sources of variation corresponding to treatments and error will be measured by \\ncomputing quantities that are called Mean Squares, and ‘Mean Square’ can be defined as: \\n \\n \\n \\nCorresponding to these two sources of variation, we have the following two equations: \\n \\n \\n \\n \\nAND \\n \\n \\n \\nIt has been mathematically proved that, with reference to Analysis of Variance pertai ning to the Completely \\nRandomized (CR) Design, the degrees of freedom corresponding to the Treatment Sum of Squares are k -1, and the \\ndegrees of freedom corresponding to the Error Sum of Squares are n -k. Hence, the above two equations can be written \\nas: \\n \\n \\n \\n \\nAND \\n \\n \\nVariety \\nA B C \\n23 18 16 \\n26 28 25 \\n20 17 12 \\n17 21 14 \\n \\n \\nSource of Variation d.f. Sum of \\nSquares \\nMean \\nSquare F \\nBetween treatments \\nWithin treatments (Error) \\nk-1 \\nn-k \\nSST \\nSSE \\nMST \\nMSE \\nMST/MSE \\n-- \\nTotal n-1 TSS -- -- \\nFreedomofDegrees\\nSquaresofSumSquareMean \\uf03d\\n..\\n'''')1 fd\\nTreatmentSSTreatmentMS \\uf03d\\n..\\n'''')2 fd\\nErrorSSErrorMS \\uf03d\\n1\\n'''')1 \\uf02d\\uf03d k\\nTreatmentSSTreatmentMS\\nkn\\nErrorSSErrorMS \\uf02d\\uf03d '''')2\"), Document(metadata={'source': 'Statistics-book.pdf', 'page': 322}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       318                                                                                                                                           \\nHow do we compute the various sums of squares? The three sums of squares occurring in the third column of the above \\nANOVA Table are given by: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nwhere C.F. stands for ‘Correction Factor’, and is given by \\n \\n \\n \\n \\nand r denotes the number of da ta-values per column (i.e. the number of rows).  (It should be noted that this example \\npertains to that case of the Completely Randomized (CR) Design where each treatment is being repeated equal number \\nof times, and the above formulae pertain to this particular situation. With reference to the CR Design, it should be noted \\nthat, in some situations, the various treatments are not repeated an equal number of times. \\n For example, with reference to the twelve plots (farms) that we have been considering above, we  could have \\nsown variety A in five of the plots, variety B in three plots, and variety C in four plots.  Going back to the formulae of \\nvarious sums of squares, the sum of squares for error is given by  \\n \\n \\n \\n \\n \\n \\n \\nIt is interesting to note that,  \\nTotal SS = SS Treatment + SS Error \\nIn a similar way, we have the equation: \\nTotal d.f.  = d.f. for Treatment + d.f. for Error \\nIt can be shown that the degrees of freedom pertaining to ‘Total’ are n - 1.  \\nNow,  \\n n-1 = (k-1) + (n-k) \\ni.e. \\nTotal d.f.  = d.f. for Treatment + d.f. for Error \\nThe notations and terminology given in the above equations relate to the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe entries in the body of the table i.e. 23, 26, 20, 17, and so on are the yields of the three varieties of potato that we \\nhad sown in the twelve farms. The entries written in brackets next to the above-mentioned data-values are the squares of \\nthose values. \\nFor example: \\n 529 is the square of 23,  \\n 676 is the square of 26, \\n 400 is the square of 20,  \\n..)1 2 FCXTSSSSTotal\\nj\\nij\\ni\\n\\uf02d\\uf03d\\uf03d \\uf0e5\\uf0e5\\n..\\n.\\n)2\\n2\\nFCr\\nT\\nSSTTreatmentSS\\nj\\nj\\n\\uf02d\\uf03d\\uf03d\\n\\uf0e5\\nn\\nTFC\\n2\\n.... \\uf03d\\nSSTTSSSSE\\nei\\nTreatmentSSSSTotalErrorSS\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\n..\\n)3\\nVariety \\n \\nA B C \\nTotal \\n2\\nij\\nj\\nX\\uf0e5\\n \\n 23 (529) 18 (324) 16 (256) -- 1109 \\n 26 (676) 28 (784) 25 (625) -- 2085 \\n 20 (400) 17 (289) 12 (144) -- 833 \\n 17 (289) 21 (196) 14 (196) -- 926 \\nT.j 86 84 67 237 4953 \\n2j.T\\n 7396 7056 4489 18941 \\n\\uf0e5\\ni\\n2\\nijX\\n 1894 1838 1221 4953 \\n      \\uf0ad \\n      | \\nCheck \\n\\uf0ac \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 323}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       319                                                                                                                                           \\n and so on. \\n \\nAdding all these squares, we obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe notation T.j stands for the total of the jth column.(You must already be aware that, in general, the rows of a \\nbivariate table are denoted by the letter ‘i’, whereas the columns of a bivariate table are denoted by the letter ‘j’. \\n In other words, we talk about the ‘ith row’, and the ‘jth column’ of a bivariate table.)The ‘dot’ in the notation \\nT.j indicates the fact that summation has been carried out over i (i.e. over the rows).  \\nIn this example, the total of th e values in the first column is 86, the total of the values in the second column is 84, and \\nthe total of the values in the third column is 67.  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, \\uf053T.j is equal to 237. \\n \\uf053T.j is also denoted by T..  \\ni.e.  \\nT.. = \\uf053T.j The ‘double dot’ in the notation T.. indicates that summation has been carried out over i as well as over j. \\nThe row below T.j is that of T.j2, and squaring the three values of T.j, we obtain the quantities 7396, 7056 and 4489.  \\nAdding these, we obtain \\uf053T.j2 = 18941. \\n \\n \\n \\n \\n \\n49532 \\uf03d\\uf0e5\\uf0e5\\nj\\nij\\ni\\nX\\nVariety \\n \\nA B C \\nTotal \\n2\\nij\\nj\\nX\\uf0e5\\n \\n 23 (529) 18 (324) 16 (256) -- 1109 \\n 26 (676) 28 (784) 25 (625) -- 2085 \\n 20 (400) 17 (289) 12 (144) -- 833 \\n 17 (289) 21 (196) 14 (196) -- 926 \\nT.j 86 84 67 237 4953 \\n2j.T\\n 7396 7056 4489 18941 \\n\\uf0e5\\ni\\n2\\nijX\\n 1894 1838 1221 4953 \\n      \\uf0ad \\n      | \\nCheck \\n\\uf0ac \\n \\nVariety \\n \\nA B C \\nTotal \\n2\\nij\\nj\\nX\\uf0e5\\n \\n 23 (529) 18 (324) 16 (256) -- 1109 \\n 26 (676) 28 (784) 25 (625) -- 2085 \\n 20 (400) 17 (289) 12 (144) -- 833 \\n 17 (289) 21 (196) 14 (196) -- 926 \\nT.j 86 84 67 237 4953 \\n2j.T\\n 7396 7056 4489 18941 \\n\\uf0e5\\ni\\n2\\nijX\\n 1894 1838 1221 4953 \\n      \\uf0ad \\n      | \\nCheck \\n\\uf0ac \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 324}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       320                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow that we have obtained all the required quantities, we are ready to compute SS Total, SS Treatment, and SS Error: \\nWe have \\n \\n \\n \\n \\nHence, the total sum of squares is given by \\n \\n \\n \\n \\n \\n \\n \\n \\nAlso, we have  \\n \\n \\n \\n \\n \\n \\n \\nAnd, hence:  \\nSS Error = SSE = TSS - SST \\n = 272.25 - 54.50 = 217.75 \\n \\nIn this example, we have n = 12, and k = 3, hence: \\n n-1=11,  \\n k- 1 = 2,           and  n - k = 9. \\nSubstituting the above sums of squares and degree of freedom in the ANOVA table, we obtain: \\nANOVA TABLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nVariety \\n \\nA B C \\nTotal \\n2\\nij\\nj\\nX\\uf0e5\\n \\n 23 (529) 18 (324) 16 (256) -- 1109 \\n 26 (676) 28 (784) 25 (625) -- 2085 \\n 20 (400) 17 (289) 12 (144) -- 833 \\n 17 (289) 21 (196) 14 (196) -- 926 \\nT.j 86 84 67 237 4953 \\n2j.T\\n 7396 7056 4489 18941 \\n\\uf0e5\\ni\\n2\\nijX\\n 1894 1838 1221 4953 \\n      \\uf0ad \\n      | \\nCheck \\n\\uf0ac \\n \\n\\uf028 \\uf029 75.468012\\n237..\\n22\\n.. \\uf03d\\uf03d\\uf03d n\\nTFC\\n25.272\\n75.46804953\\n..2\\n\\uf03d\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d \\uf0e5\\uf0e5 FCXTSS\\nj\\nij\\ni\\n50.54\\n75.46804\\n18941\\n..\\n.2\\n\\uf03d\\n\\uf02d\\uf03d\\n\\uf02d\\uf03d\\uf03d\\n\\uf0e5\\nFCr\\nT\\nSSTTreatmentSS\\nj\\nj\\nSource of \\nVariation d.f. Sum of \\nSquares \\nMean  \\nSquare \\nComputed \\nF \\nBetween \\ntreatments \\n(i.e. Between \\nvarieties) \\n2 54.50   \\nError 9 217.75   \\nTotal 11 272.25   \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 325}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       321                                                                                                                                           \\nNow, the mean squares for treatments and for error are very easily found by dividing the sums of squares by the \\ncorresponding degrees of freedom. Hence, we have  \\nANOVA TABLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAs indicated earlier, the test-statistic appropriate for testing the null hypothesis \\nH0 : \\uf06dA = \\uf06dB = \\uf06dC   \\nversus  \\nHA : Not all the three means  are equal is: \\n \\n \\n \\n \\nwhich, if H0 is true, has an F distribution with \\uf0751 = k-1 = 3 – 1 = 2 and \\uf0752 = n-k = 12 – 3 = 9 degree of freedom Hence, \\nit is obvious that F will be fou nd by dividing the first entry of the fourth column of our ANOVA Table by the second \\nentry of the same column i.e.  \\n \\n \\n \\n \\n \\nWe insert this computed value of F in the last column of our ANOVA table, and thus obtain: \\nANOVA TABLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe fifth step of the hypothesis - testing procedure is to determine the critical region.  With reference to the Analysis of \\nVariance procedure, it can be shown that it is appropriate to establish the critical region in such a way that ou r test is a \\nright-tailed test. In other words, the critical region is given by: \\n \\nCritical Region: \\n F > F\\uf061 ( k - 1, n - k)  \\nIn this example: \\nThe critical region is F > F0.05 (2,9) = 4.26 \\nvi)  Conclusion:  \\nSince the computed value of F = 1.13 does not fall in the critical region, so we accep t our null hypothesis and \\nmay conclude that, on the average, there is no difference among the yielding capabilities of the three varieties of \\npotatoes.  \\nIn this course, we will not be discussing the details of the mathematical points underlying One -Way Ana lysis of \\nVariance that is applicable in the case of the Completely Randomized (CR) Design. One important point that the \\nstudents should note is that the ANOVA technique being presented here is valid under the following assumptions: \\nSource of \\nVariation d.f. Sum of \\nSquares \\nMean  \\nSquare \\nComputed \\nF \\nBetween \\ntreatments \\n(i.e. Between \\nvarieties) \\n2 54.50 27.25  \\nError 9 217.75 24.19  \\nTotal 11 272.25 --  \\n \\nErrorMS\\nTreatmentsMSF \\uf03d\\n13.124.19\\n27.25\\nErrorMS\\nTreatment MS  F \\uf03d\\uf03d\\uf03d\\nSource of \\nVariation d.f. Sum of \\nSquares \\nMean  \\nSquare \\nComputed \\nF \\nBetween \\ntreatments \\n(i.e. Between \\nvarieties) \\n2 54.50 27.25 1.13 \\nError 9 217.75 24.19 -- \\nTotal 11 272.25 -- -- \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 326}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       322                                                                                                                                           \\n\\uf0b7 The k populations (whose means are to be compared) are normally distributed; \\n\\uf0b7 All k populations have equal variances i.e. \\uf07312 = \\uf07322 = … = \\uf073k2. (This property is called homoscedasticity) \\n\\uf0b7 The k samples have been drawn randomly and independently from the respective populations.  \\nNext, we begin the discussion of the Randomized Complete Block (RCB) Design: \\n \\nTHE RANDOMIZED COMPLETE BLOCK DESIGN (RCB DESIGN) \\n \\nA randomized complete block (RCB) design is the one in which \\n\\uf0b7 The experimental material (which is not homogeneous overall) is divide d into groups or blocks in such a \\nmanner that the experimental units within a particular block are relatively homogeneous. \\n\\uf0b7 Each block contains a complete set of treatments, i.e., it constitutes a replication of treatments.  \\n\\uf0b7 The treatments are allocated at random to the experimental units within each block , which means the \\nrandomization is restricted.(A new randomization is made for every block.)The object of this type of \\narrangement is to bring the variability of the experimental material under control.  \\n In simple words, the situation is as follows:  \\nWe have experimental material which is not homogeneous overall. For example, with reference to the example that we \\nhave been considering above, suppose that the plots which are closer to a canal are the most fertile ones, the ones a little \\nfurther away are a little less fertile, and the ones still further away are the least fertile. \\nIn such a situation, we divide the experimental material into groups or blocks which are relatively \\nhomogeneous. The randomized com plete block design is perhaps the most widely used experimental design. Two-way \\nanalysis of variance is applicable in case of the randomized complete block (RCB) design. \\nWe illustrate this concept with the help of an example: \\n \\nEXAMPLE \\n \\nIn a feeding experim ent of some animals, four types of rations were given to the animals that were in five groups of \\nfour each. The following results were obtained \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe values in the above table represent  the gains in weights in pounds.  Perform an analysis of varia nce and state your \\nconclusions. In the next lecture, we will discuss this example in detail, and will analyze the given data to carry out the \\nfollowing test: \\nH0  :  \\uf06dA = \\uf06dB = \\uf06dC = \\uf06dD  \\nHA :  Not all the treatment-means are equal \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRations Groups A B C D \\nI 32.3 33.3 30.8 29.3 \\nII 34.0 33.0 34.3 26.0 \\nIII 34.3 36.3 35.3 29.8 \\nIV 35.0 36.8 32.3 28.0 \\nV 36.5 34.5 35.8 28.8 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 327}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       323                                                                                                                                           \\nLECTURE NO. 44 \\n \\n \\n\\uf0b7 Randomized Complete Block Design    \\n \\n\\uf0b7   The Least Significant Difference (LSD) Test  \\n \\n\\uf0b7   Chi-Square Test of Goodness of Fit \\n \\nAt the end of the last lecture, we introduced the concept of the Randomized Complete Block (RCB) Design, and we \\npicked up an example to illustrate the concept. In this lecture, we begin with a detailed discussion of the same example: \\n \\nEXAMPLE \\n \\nIn a feeding experiment of some animals, four types of rations were given to the animals that were in five groups of \\nfour each. The following results were obtained: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe values in the above table represent the gains in weights in pounds. Perform an analysis of variance and state your \\nconclusions.  \\n \\nSOLUTION \\n \\nHypothesis-Testing Procedure: \\ni a) Our primary interest is in testing: \\n H0  :  \\uf06dA = \\uf06dB = \\uf06dC = \\uf06dD  \\n HA :  Not all the ration-means   \\n    (treatment-means)  \\n    are equal \\ni b) In addition, we can also test: \\n H\\uf0a20  :  \\uf06dI = \\uf06dII = \\uf06dIII = \\uf06dIV = \\uf06dV \\n H\\uf0a2A :  Not all the group-means   (block-means)   are equal \\n \\nii) Level of significance  \\n  \\uf061 = 0.05 \\n \\niii a) Test Statistic for testing  \\nH0 versus HA:  \\n \\n  \\n \\n \\nwhich, if H0 is true, has  \\nan F-distribution with v1 = c-1= 4-1= 3 and v2 = (r-1)(c-1) =(5-1)(4-1) =4 \\uf0b4 3 = 12 \\ndegrees of freedom. \\n \\niii b) Test Statistic for testing  \\n H \\uf0a20 versus H \\uf0a2A:  \\n \\n \\n \\nwhich, if H0 is true, has  \\nan F-distribution with v1 = r-1 = 5-1= 4 and  \\nv2 = (r-1)(c-1) = (5-1)(4-1) =4 \\uf0b4 3 = 12 degrees of freedom. \\n \\nNow, the given data leads to the following table: \\n \\n \\nRations Groups A B C D \\nI 32.3 33.3 30.8 29.3 \\nII 34.0 33.0 34.3 26.0 \\nIII 34.3 36.3 35.3 29.8 \\nIV 35.0 36.8 32.3 28.0 \\nV 36.5 34.5 35.8 28.8 \\n \\nErrorMS\\nTreatmentMSF \\uf03d\\nErrorMS\\nBlockMSF \\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 328}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       324                                                                                                                                           \\n \\n \\niv) Computations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, we have Total   SS \\nn\\n..TX\\n22\\nij \\uf02d\\uf03d\\uf0e5\\uf0e5  \\n \\n\\uf028 \\uf029\\n20\\n4.65622.21725\\n2\\n\\uf02d\\uf03d  \\n \\n05.2154322.21725 \\uf02d\\uf03d  \\n \\n17.182\\uf03d  \\nTreatment SS \\nn\\n..T\\nr\\n.T 2\\nj\\n2\\nj\\n\\uf02d\\uf03d\\n\\uf0e5  \\n  \\n\\uf028 \\uf029\\n20\\n4.656\\n5\\n108387.48 2\\n\\uf02d\\uf03d  \\n  = 21677.50 – 21543.05 \\n  = 134.45 \\nBlock SS  \\nn\\n..T\\nc\\nB 2\\ni\\n2\\n.i\\n\\uf02d\\uf03d\\n\\uf0e5  \\n  \\n\\uf028 \\uf029\\n20\\n4.656\\n4\\n86258.04 2\\n\\uf02d\\uf03d  \\n      \\n05.2154351.21564 \\uf02d\\uf03d   \\n \\n  = 21.46 \\nwhere c represents the number of observations per block (i.e. the number of columns) \\nAnd  \\nError SS= Total SS – (Treatment SS + Block SS) \\n= 182.17 – (134.45 + 21.46)  \\n= 26.26 \\nThe degrees of freedom corresponding to the various sums of squares are as follows: \\n\\uf0b7  Degrees of freedom for treatments: c - 1 (i.e. the number of treatments - 1) \\nRation \\nGroups A B C D \\nBi. Bi.2 \\n2\\nij\\nj\\nX\\uf0e5  \\nI 32.3  \\n(10.43.29) \\n33.3 \\n(1108.89) \\n30.8 \\n(948.64) \\n29.3 \\n(858.49) 125.7 15800.49 3959.31 \\nII 34.00 \\n(1156.00) \\n33.0 \\n(1089.00) \\n34.3 \\n(1176.49) \\n26.0 \\n(676.00) 127.3 16205.29 4097.49 \\nIII 34.3 \\n(1176.49) \\n36.3 \\n(1317.69) \\n35.3 \\n(1246.09) \\n29.8 \\n(888.04) 135.7 18414.49 4628.31 \\nIV 35.0 \\n(1225.00) \\n36.8 \\n(1354.24) \\n32.3 \\n(1043.29) \\n28.0 \\n(784.00) 132.1 17450.41 4406.53 \\nV 36.5 \\n(1332.25) \\n34.5 \\n(1190.25) \\n35.8 \\n(1281.64) \\n28.8 \\n(829.44) 135.6 18387.36 4633.58 \\nT.j 172.1 173.9 168.5 141.9 656.4 86258.04 21725.22 \\n2j.T\\n 29618.41 30241.21 28392.25 20135.61 108387.48  \\n\\uf0e5\\ni\\n2\\nijX\\n 5933.03 6060.07 5696.15 4035.97 21725.22 \\uf0ac \\n      \\uf0ad \\n      | \\nCheck \\n\\uf0ac–– \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 329}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       325                                                                                                                                           \\n\\uf0b7   Degrees of freedom for blocks:  \\nr - 1 (i.e. the number of blocks - 1) \\n\\uf0b7  Degrees of freedom for Total:  \\nrc - 1 (i.e. the total number of observations - 1) \\n\\uf0b7   Degrees of freedom for error: degrees of freedom for Total minus degrees of freedom for treatments minus \\ndegrees of freedom for blocks  \\ni.e. (rc-1) - (r-1) - (c-1)  \\n = rc - r - c + 1  \\n = (r-1) (c-1) \\nHence the ANOVA-Table is: \\nANOVA-TABLE \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nv a)  Critical Region for Testing H0 against HA is given by  \\nF > F0.05 (3, 12) = 3.49 \\n \\nv b) Critical Region for Testing H\\uf0a20 against H\\uf0a2A is given by  \\nF > F0.05 (4, 12) = 3.26 \\nvi a) Conclusion Regarding Treatment Means \\n \\nSince our com puted value F1 = 20.47 exceeds the critical value F0.05 (3, 12) = 3.49, therefore we reject the null \\nhypothesis, and conclude that there is a difference among the means of at least two  of the treatments (i.e. the mean \\nweight-gains corresponding to at least two of the rations are different).  \\nvi b) Conclusion Regarding Block Means \\n \\nSince our computed value F2 = 2.45 does not exceed the critical value F0.05(4, 12) = 3.26, therefore we accept the null \\nhypothesis regarding the equality of block means and thus conclude that blocking (i.e. the grouping of animals) was \\nactually not required in this experiment. As far as the conclusion regarding the block means is concerned, this \\ninformation can be used when designing a similar experiment in the future.  \\n[If blocking is actually not required, then a future experiment can be designed according to the Completely Randomized \\ndesign, thus retaining more degrees of freedom for Error. (The more degrees of freedom we have for Error, the better, \\nbecause an estimate of the error variation based on a greater number of degrees of freedom implies an estimate based on \\na greater amount of information (which is obviously good).) ] \\nAs far as the conclusion regarding the treatment means is concerned, the situation is as follows:  \\n Now that we have concluded that there is a significant difference between the treatment means (i.e. we have \\nconcluded that the mean weight -gain is not the same for all four rations, then it is obvious that we would be interested \\nin finding out, “Which of the four rations produces the greatest weight-gain?” \\nThe answer to this question can be found by applying a technique known as the Least Significant Difference (LSD) Test.  \\n \\nTHE LEAST SIGNIFICANT DIFFERENCE (LSD) TEST  \\n \\nAccording to this procedure, we compute t he smallest difference that would be judged significant, and compare the \\nabsolute values of all differences of means with it.  This smallest difference is called the least significant difference or \\nLSD, and is given by: \\nLEAST SIGNIFICANT DIFFERENCE (LSD): \\n \\n \\n \\n \\nwhere MSE is the Mean Square for Error, r is the size of equal samples, and t\\uf061/2 (\\uf06e) is the value of t at \\uf061/2 level taken \\nagainst the error degrees of freedom (\\uf06e).  \\nThe test-criterion that uses the least significant difference is called the LSD test.  \\n Two sample-means are declared to have come from populations with significantly different means, when the \\nabsolute value of their difference exceeds the LSD.  \\nSource of  \\nVariation d.f. Sum of \\nSquares \\nMean \\nSquare F \\nBetween Treatments \\n(i.e. Between Rations) 3 134.45 44.82 F1 = 20.47 \\nBetween Blocks  \\n(i.e. Between Groups) 4 21.46 5.36 F2 = 2.45 \\nError 12 26.26 2.19 -- \\nTotal 19 182.17 -- -- \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029,r\\nMSE2tLSD ,2 \\uf06e\\uf061\\uf03d'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 330}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       326                                                                                                                                           \\nIt is customary to arrange the sample means in ascending order of magnitude, and to draw a line under any pair of \\nadjacent means (or set of means) that are not significantly different. \\nThe LSD test is applied only if the null hypotheses is rejected in the Analysis of Variance. We will not be going into the \\nmathematical details of this procedure, but it is useful to note that this procedure can be regarded as an alternative way \\nof conducting the t-test for the equality of two population means. \\nIf we were to apply the usual two-sample t-test, we would have had to repeat this procedure quite a few times!  \\n(The six possible tests are: \\nH0 : \\uf06dA = \\uf06dB \\nH0 : \\uf06dA = \\uf06dC \\nH0 : \\uf06dA = \\uf06dD \\nH0 : \\uf06dB = \\uf06dC \\nH0 : \\uf06dB = \\uf06dD \\nH0 : \\uf06dC = \\uf06dD     ) \\nThe LSD test is a procedure by which we can compare all the treatment means simultaneously. \\nWe illustrate this procedure through the above example: \\nThe Least Significant Difference is given by \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nGoing back to the given data: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nWe find that the four treatment means are: \\n \\n \\n \\n \\n \\n \\n \\n \\nArranging the above means in ascending order of magnitude, we obtain: \\n \\n \\n \\n \\nDrawing lines under pairs of adjacent means (or sets of means) that are not significantly different, we have: \\n \\n \\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n\\uf028 \\uf029\\n.04.2\\n936.0179.2\\n5\\n19.22179.2\\n5\\n19.22t\\nr\\nMSE2tLSD\\n12025.0\\n,2\\n\\uf03d\\n\\uf0b4\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d \\uf06e\\uf061\\nRations Groups A B C D \\nI 32.3 33.3 30.8 29.3 \\nII 34.0 33.0 34.3 26.0 \\nIII 34.3 36.3 35.3 29.8 \\nIV 35.0 36.8 32.3 28.0 \\nV 36.5 34.5 35.8 28.8 \\nTotal 172.1 173.9 168.5 141.9 \\nMean 34.42 34.78 33.70 28.38 \\n \\n38.28\\n70.33\\n78.34\\n42.34\\n\\uf03d\\n\\uf03d\\n\\uf03d\\n\\uf03d\\nD\\nC\\nB\\nA\\nX\\nX\\nX\\nX\\n78.3442.3470.3338.28\\nBACD XXXX\\n78.3442.3470.3338.28\\nBACD XXXX'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 331}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       327                                                                                                                                           \\n \\n \\nFrom the above, it is obvious that rations C, A and B are not significantly different from each other with regard to \\nweight-gain. The only ration which is significantly different from the others is ration D.  \\nInterestingly, ration D has the poorest performance with regard to weight -gain. As such, if our primary objective is to \\nincrease the weights of the animals under study, then we may recommend any of the other three rations i.e. A, B and C \\nto the farmers (depending upon availability, price, etc.), but we must not recommend ration D. \\nNext, we will consider two important tests based on the  \\nchi-square distribution. These are: \\n•  The chi-square test of goodness of fit \\n•  The chi-square test of independence \\nBefore we begin the discussion of these tests, let us review the basic properties of the chi-square distribution: \\n \\nPROPERTIES OF THE CHI-SQUARE DISTRIBUTION \\n \\nThe Chi-Square (\\uf0632) distribution has the following properties: \\n1. It is a continuous distribution ranging from 0 to +\\uf0a5 .The number of degrees of freedom determines the shape of the \\nchi-square distribution. (Thus, there is a different chi-square distribution for each number of degrees of freedom.  \\nAs such, it is a whole family of distributions.) \\n2. The curve of a chi-square distribution is positively skewed. The skewness decreases as \\uf06e increases. \\n \\n \\n\\uf0632-distribution for various values of \\uf06e \\n \\nAs indicated by the above figures, the chi -square distribution tends to the normal distribution as the number of degrees \\nof freedom approaches infinity. Having reviewed the basic properties of the chi -square distribution; we begin the \\ndiscussion of the Chi-Square Test of Goodness of Fit: \\n \\nCHI-SQUARE TEST OF GOODNESS OF FIT \\n \\nThe chi-square test of goodness -of-fit is a test of hypothesis concerned with the comparison of observed frequencies of \\na sample, and the corresponding expected frequencies based on a theoretical distribution. We illustrate this concept with \\nthe help of the same example that we considered in Lecture No. 28 --- the one pertaining to the fitting of a binomial \\ndistribution to real data: \\n \\nEXAMPLE: \\n \\nThe following data has been obtained by tossing a LOADED die 5 times, and noting the number of times that we \\nobtained a six. Fit a binomial distribution to this data. \\n \\n \\n \\n \\n \\nSOLUTION \\nTo fit a binomial distribution, we need to find n and p.  \\nHere n = 5, the largest x-value.  \\nTo find p, we use the relationship \\uf060x = np. \\nWe have: \\n0.5 \\n0.4 \\n0.3 \\n0.1 \\n0.2 \\n0 2 4 6 8 10 12 14 \\nX \\n\\uf06e=2 \\n\\uf06e =6 \\n\\uf06e=10 \\nf(x) \\nNo. of Sixes \\n(x) 0 1 2 3 4 5 Total \\nFrequency \\n(f) 12 56 74 39 18 1 200 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 332}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       328                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nTherefore: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUsing the relationship \\uf060x = np,  \\n    we obtain \\n p = 1.99 or p = 0.398. \\nLetting the random variable X represent the number of sixes, the above calculations yield the fitted binomial \\ndistribution as \\n \\n \\n \\n \\nHence the probabilities and expected frequencies are calculated as below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNo. of Sixes \\n(x) 0 1 2 3 4 5 Total \\nFrequency \\n(f) 12 56 74 39 18 1 200 \\nfx 0 56 148 117 72 5 398 \\n \\n99.1200\\n398\\n200\\n572117148560\\nf\\nxfx\\ni\\nii\\n\\uf03d\\uf03d\\n\\uf02b\\uf02b\\uf02b\\uf02b\\uf02b\\uf03d\\n\\uf03d\\n\\uf0e5\\n\\uf0e5\\n\\uf028 \\uf029 \\uf028 \\uf029 \\uf028 \\uf029\\nxx\\nxxb\\n\\uf02d\\n\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6\\uf03d\\n5\\n602.0398.05398.0,5;\\nNo. of \\nSixes  (x) Probability f(x) Expected \\nfrequency \\n0 \\n\\uf028 \\uf02955 602.0q0\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.07907 15.8 \\n1 \\n\\uf028 \\uf029 \\uf028 \\uf029398.0602.0.5pq1\\n5 45 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.26136 52.5 \\n2 \\n\\uf028 \\uf029 \\uf028 \\uf0292323 398.0602.0.10pq2\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.34559 69.1 \\n3 \\n\\uf028 \\uf029\\uf028 \\uf029332 398.0602.0.10pq3\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.22847 45.7 \\n4 \\n\\uf028 \\uf029\\uf028 \\uf02944 398.0602.0qp4\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.07553 15.1 \\n5 \\n\\uf028 \\uf02955 398.0p5\\n5 \\uf03d\\uf0f7\\uf0f7\\n\\uf0f8\\n\\uf0f6\\n\\uf0e7\\uf0e7\\n\\uf0e8\\n\\uf0e6  = 0.00998 2.0 \\nTotal  = 1.00000 200.0 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 333}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       329                                                                                                                                           \\n \\nComparing the observed frequencies with the expected frequencies, we obtain: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThe above table seems to indicate that there is not much discrepancy between the obse rved and the expected \\nfrequencies. Hence, in Lecture No.28, we concluded that it was a reasonably good fit. But, it was indicated that proper \\ncomparison of the expected frequencies with the observed frequencies can be accomplished by applying the chi-square \\ntest of goodness of fit . The Chi -Square Test of Goodness of Fit enables us to determine in a mathematical manner \\nwhether or not the theoretical distribution fits the observed distribution reasonably well. \\nThe procedure of the chi-square of goodness of fit is very similar to the general hypothesis-testing procedure: \\nHYPOTHESIS-TESTING PROCEDURE \\nStep-1:  \\n H0 : The fit is good \\n HA : The fit is not good \\nStep-2: \\n Level of Significance: \\uf061 = 0.05 \\nStep-3: Test-Statistic: \\n \\n \\n \\nwhich, if H0 is true, follows the chi-square distribution having k - 1 - r degrees of freedom(where k = No. of x-values \\n(after having carried out the necessary mergers), and  r = number of parameters that we estimate from the sample data). \\nStep-4: Computations: \\n \\n \\n \\nIMPORTANT NOTE \\n \\nIn the above table, the category x = 4 has been merged with the category x = 5 because of the fact that the expected \\nfrequency corresponding to x = 5 was less than 5. \\nNo. of \\nSixes  \\nx \\nObserved \\nFrequency \\noi \\nExpected \\nFrequency \\nei \\noi – ei  (oi - ei)2 (oi- ei)2/ei \\n0 12 15.8 -3.8 14.44 0.91 \\n1 56 52.5 3.5 12.25 0.23 \\n2 74 69.1 4.9 24.01 0.35 \\n3 39 45.7 -6.7 44.89 0.98 \\n4 \\n5 \\n18 \\n1 \\n15.1 \\n2.0 1.9 3.61 0.21 \\nTotal 200 200.0   2.69   \\n \\n \\n19  \\n17.1 \\nNo. of \\nSixes  \\nx \\nObserved \\nFrequency \\noi \\nExpected \\nFrequency \\nei \\n0 12 15.8 \\n1 56 52.5 \\n2 74 69.1 \\n3 39 45.7 \\n4 18 15.1 \\n5 1 2.0 \\nTotal 200 200.0 \\n \\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d\\uf063\\ni i\\n2\\nii2\\ne\\neo'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 334}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       330                                                                                                                                           \\n[It is one of the basic requirements of the chi-square test of goodness of  fit that the expected frequency of any x -value \\n(or any combination of x -values) should not be less than 5.]Since we have combined the category x = 4 with the \\ncategory x = 5, hence k = 5. Also, since we have estimated one parameter of the binomial distribu tion (i.e. p) from the \\nsample data, hence r = 1. (The other parameter n is already known.) \\nAs such, our statistic follows the chi -distribution having k - 1 - r = 5 - 1 - 1 = 3 degrees of freedom. Going back to the \\nabove calculations, the computed value of our test-statistic comes out to be \\uf0632 = 2.69. \\nStep-5: Critical Region: \\nSince \\uf061 = 0.05, hence, from the Chi-Square Tables, it is evident that the critical region is:\\uf0632 \\uf0b3 \\uf06320.05 (3) = 7.82 \\nStep-6: \\nConclusion: \\n Since the computed value of \\uf0632 i.e. 2.69 is less than the critical value 7.82, hence we accept H0 and conclude \\nthat the fit is good .(In other words, with only 5% risk of committing Type -I error, we conclude that the distribution of \\nour random variable X can be regarded as a binomial distribution with n = 5 and   p = 0.398.) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 335}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       331                                                                                                                                           \\nLECTURE NO. 45 \\n \\n\\uf0b7 Chi-Square Test of Goodness of Fit   (in continuation of the last lecture) \\n\\uf0b7  Chi-Square Test of Independence \\n\\uf0b7  The Concept of Degrees of Freedom \\n\\uf0b7  p-value \\n\\uf0b7  Relationship Between Confidence;  Interval and Tests of Hypothesis \\n An Overview of the Science of Statistics  in Today’s World (including Latest  Definition of Statistics) \\nThe students will recall that, towards the end of the last lecture, we discussed the chi-square test of goodness of fit. We \\napplied the test to the example where we had fitted a binomial distribution to real data, and, since the computed value of \\nour test statistic turned out to be insignificant, therefore we concluded that the fit was good. \\nLet us consider another example: \\n \\nEXAMPLE \\n \\nThe platform manager of an airline’s terminal ticket counter wants to determine whether customer arrivals can be \\nmodelled by using a Poisson distribution. The manager is especially interested in late-night traffic.  \\n Accordingly, data for the time period of interest have been collected, as follows: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nIs the distribution Poisson? \\n \\nSOLUTION: \\n \\nFirst of all, we fit a Poisson distribution to the given data Because a mean is not specified, it must be estimated from the \\nsample data.  The mean of the frequency distribution can be found by using the formula \\n \\n \\nwhere n = \\uf053f.  \\nThus we have the following calculations: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nReplacing \\uf06d by    , the formula for the Poisson probabilities is  \\nNumber of \\nArrivals Per Minute Frequency \\n0 84 \\n1 114 \\n2 70 \\n3 60 \\n4 32 \\n5 16 \\n6 15 \\n7 4 \\n8 5 \\n 400 \\n \\nn\\nfxx \\uf0e5\\uf03d\\nNumber of \\nArrivals \\nx \\nFrequency \\n \\nf \\n \\n \\nfx \\n0 84 0 \\n1 114 114 \\n2 70 140 \\n3 60 180 \\n4 32 128 \\n5 16 80 \\n6 15 90 \\n7 4 28 \\n8 5 40 \\n 400 800 \\n \\n2400\\n800\\n:\\n\\uf03d\\uf03d\\uf03d\\uf03d \\uf0e5\\nn\\nfxxMean\\nHence'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 336}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       332                                                                                                                                           \\n \\n \\nHence, we obtain: \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, we apply the chi-square test of goodness of fit according to the following procedure: \\n \\nHYPOTHESIS-TESTING PROCEDURE \\n \\nStep-1:  \\nH0 : Arrivals are Poisson-distributed. \\nH1 : The distribution is not Poisson. \\n \\nStep-2: \\nLevel of Significance:  \\uf061 = 0.05 \\n \\nStep-3: Test-Statistic: \\n \\n \\nwhich, if H0 is true, follows the chi-square distribution having k - 1 - r degrees of freedom; (where k = No. of x-values \\n(after having carried out the necessary mergers), and  r = number of parameters that we estimate from the sample data) \\nStep-4:Computations: \\n The necessary calculations are shown in the following table: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf028 \\uf029 !\\n2\\n!\\n2\\nx\\ne\\nx\\nxexf\\nxxx \\uf02d\\uf02d\\n\\uf03d\\uf03d\\n \\nNumber of \\nCustomer \\nArrivals \\nObserved \\nFrequencies \\nPoisson \\nProbabilities \\nf(x) \\nExpected \\nFrequencies  \\n400 f(x) \\n0 84 0.1353 54.12 \\n1 114 0.2707 108.28 \\n2 70 0.2707 108.28 \\n3 60 0.1804 72.16 \\n4 32 0.0902 36.08 \\n5 16 0.0361 14.44 \\n6 15 0.0120 4.80 \\n7 4 0.0034 1.36 \\n8 5 0.0009 0.36 \\n9 or more 0 0.0002 0.08 \\n 400 1 400 \\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d\\uf063\\ni i\\n2\\nii2\\ne\\neo\\nNumber \\nof \\nCustomer \\nArrivals \\nObserved \\nFrequenc\\ny \\noi \\nExpected \\nFrequency  \\nei \\n(0 – e) (0-\\ne)2 (0-e)2/e \\n0 84 54.12 29.88 892.8\\n1 16.50 \\n1 114 108.28 5.72 32.72 0.30 \\n2 70 108.28 -38.28 1465.3\\n6 13.53 \\n3 60 72.16 -12.16 147.8\\n7 2.05 \\n4 32 36.08 -4.08 16.65 0.46 \\n5 16 14.44 1.56 2.43 0.17 \\n6 15 4.80    \\n7 4 1.36 17.40 302.7\\n6 45.87 \\n8 5 0.36    \\n9 or more 0 0.08    \\n 400 400  \\uf0632=78.88 \\n \\n24 6.60 '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 337}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       333                                                                                                                                           \\nWith reference to the above, it should be noted that, since some of the expected frequencies are less than the requi red \\nminimum of 5, it became necessary to combine some of those classes. Combination is best accomplished working from \\nthe bottom up.  \\n In order that we obtain a number greater than 5, the last four expected frequencies had to be combined. \\n Hence, the effective number of categories becomes 7. \\nStep-5: \\n Determination of the Critical Region:  \\nSince the effective number of categories becomes 7  \\n Therefore k = 7.  \\nAlso, since the one lone parameter of the Poisson distribution has been estimated from the sample data, hence r = 1. \\nHence: Our statistic follows the chi-square distribution having  \\nk - 1 - r = 7 - 1 - 1 = 5  \\ndegrees of freedom.  \\n The critical region is given by  \\n \\uf0632 \\uf0b3 \\uf06320.05 (5) = 11.07 \\nCRITICAL REGION: \\n \\nStep-6: \\nConclusion: \\nSince the computed value of our test statistic i.e. 78.88 is much larger than the critical value 11.07, therefore, we reject \\nH0 and conclude that the distribution is probably not a Poisson distribution with parameter 2. \\n(With only 5% risk of committing Type-1 error, we conclude that the fit is not good.) \\nIn fact, the computed value of our test statistic i.e. 78.88 is so large that it is possible that if we had set the level of \\nsignificance at 1%, even then it would have exceeded the critical value. The stude nts are encouraged to check this up \\nthemselves. If the computed value does fall in the critical region corresponding to 1% level of significance, then our \\nresult is highly significant \\n \\nRATIONALE OF THE CHI-SQUARE TEST OF GOODNESS OF FIT \\n \\nIt is clear that       will be a small quantity when all the oi’s are close to the corresponding ei’s.  \\n(In fact, if the observed frequencies are exactly equal to the expected ones, then \\uf0632 will be exactly equal to zero.) \\n The \\uf0632 - statistic will become larger when the differences between the oi’s and ei have become larger. Thus, \\n\\uf0632 measure the amount of deviation (or discrepancy) between the observed and the expected results. \\n \\nASSUMPTIONS OF THE CHI-SQUARE TEST OF GOODNESS OF FIT \\n \\nWhile applying the chi-square test of goodness of fit, certain requirements must be satisfied, three of which are as \\nfollows: \\n1. The total number of observations (i.e. the sample size) should be at least 50. \\n2. The expected number ei in any of the categories should not be less than 5. (So, when the expected frequency ei in any \\ncategory is less than 5, we may combine this category with one or more of the other categories to get  ei \\uf0b3 5.) \\n3. The observations in the sample or the frequencies of the categories should be independent. \\n Next, we begin the discussion of the Chi-Square Test of Independence: \\nIn this regard, it is interesting to note that, (since the formula of chi-square in this particular situation is very similar to \\nthe formula that we have just discussed), therefore, the chi-square test of independence can also be regarded as a kind of \\nchi-square test of goodness of fit. We illustrate this concept with the help of an example: \\nEXAMPLE \\n \\nA random sample of 250 men and 250 women were polled as to their desire concerning the ownership of personal \\ncomputers. The following data resulted: \\n \\n \\n \\n \\n \\n \\n \\n0.05 \\n11.07 78.88 0 \\n\\uf028 \\uf029\\uf0e5 \\uf02d\\uf03d\\uf063\\ni i\\n2\\nii2\\ne\\neo\\n Men Women Total \\nWant PC 120 80 200 \\nDon’t Want  \\nPC 130 170 300 \\nTotal 250 250 500 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 338}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       334                                                                                                                                           \\nTest the hypothesis that desire to own a personal computer is independent of sex at the 0.05 level of significance. \\n \\nSOLUTION \\n \\ni) H0 : The two variables of classification (i.e. gender and desire for PC) are independent, and \\n H1 : The two variables of classification are not   independent. \\nii) The significance level is set at  \\uf061 = 0.05. \\n    \\niii) The test-statistic to be used is \\n \\nThis statistic, if H0 is true, has an approximate chi-square distribution with (r - 1) (c - 1) = (2 - 1) (2 - 1) = 1 degrees of \\nfreedom. \\niv)  Computations: \\n In order to determine the value of \\uf0632, we carry out the following computations: \\nThe first step is to compute the expected frequencies. The expected frequency of any cell is obtained by multiplying the \\nmarginal total to the right of that cell by the marginal total directly below that cell, and dividing this product by the \\ngrand total. \\nIn this example,  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, we have: \\nExpected Frequencies: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNext, we construct the columns of oij - eij, (oij - eij)2 and  (oij - eij)2  eij , as shown below: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nHence, the computed value of our test-statistic comes out to be  \\nv) Critical Region:  \\n  \\uf0632 \\uf0b3 \\uf06320.05(1) = 3.84 \\nvi) \\nConclusion:  \\n\\uf028 \\uf029\\uf0e5\\uf0e5 \\uf02d\\uf03d\\uf063\\ni j\\nij\\n2\\nijij\\n2 ee0\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029\\n\\uf028 \\uf029\\uf028 \\uf029 .150500\\n250300\\n,150500\\n250300\\n,100500\\n250200\\n,100500\\n250200\\n22\\n21\\n12\\n11\\n\\uf03d\\uf03d\\n\\uf03d\\uf03d\\n\\uf03d\\uf03d\\n\\uf03d\\uf03d\\ne\\nand\\ne\\ne\\ne\\n Men Women Total \\nWant PC 100 100 200 \\nDon’t Want  \\nPC 150 150 300 \\nTotal 250 250 500 \\n \\nObserved \\nFrequency \\noij \\nExpected \\nFrequency \\neii \\noij – eij (oij – eij)\\n2 (oij – eij)2/eii \\n120 100 20 400 4.00 \\n130 150 -20 400 2.67 \\n80 100 -20 400 4.00 \\n170 150 20 400 2.67 \\n    \\uf0632 = 13.33 \\n \\n.33.132 \\uf03d\\uf063'), Document(metadata={'source': 'Statistics-book.pdf', 'page': 339}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       335                                                                                                                                           \\nSince 13.33 is bigger than 3.84, we reject H0 and conclude that desire to own a personal computer set and sex are \\nassociated. Now that we have concluded that gender and desire for PC are associated, the natural question is, “Which \\ngender is it where the proportion of persons wanting a PC is higher?” We have: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nA close look at the given data indicates clearly that the proportion of persons who are desirous of owning a personal \\ncomputer is higher among men than among women. \\nAnd, (since our test statistic has come out to be significant), therefore we can say that the proportion of men wanting a \\nPC is significantly higher than the proportion of women wanting to own a PC. \\nLet us consider another example: \\n \\nEXAMPLE \\n \\nA national survey was conducted in a country to obtain information regarding the smoking patterns of the adults males \\nby marital status.  A random sample of 1772 citizens, 18 years old and over, yielded the following data : \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nUse this data to decide whether there is an association between marital status and smoking patterns. The students are \\nencouraged to work on this problem on their own, and to decide for themselves whether to accept or reject the null \\nhypothesis.(In this problem, the null and the alternative hypotheses will be: \\n H0: Marital status and smoking patterns are statistically independent. \\n HA : Marital status and smoking patterns are not statistically independent.) \\nThis brings us to the end of the series of topics that were to be discussed in some detail for this course on Statistics and \\nProbability. For the remaining part of today’s lecture, we will be discussing some interesting and important concepts. \\nFirst and foremost, let us consider the concept of  \\n \\nDEGREES OF FREEDOM \\n \\nAs you will recall, when discussing the t-distribution, the chi-square distribution, and the F-distribution, it was \\nconveyed to you that the parameters that exists in the equations of those distributions are known as degrees of freedom. \\nBut the question is, ‘Why these parameters are called degrees of freedom?’ Let us try to obtain an answer to this \\nquestion by considering the following:  \\n Consider the two-dimensional plane, and consider a straight line segment in the plane. If one edge of the line \\nsegment is fixed at some point (x0, y0), the line segment can be rotated in the plane such that the fixed edge stays  in its \\nplace. In other words, we can say that the line segment is free to move in the plane with one restriction. Hence, if we fix \\none end-point of the line segment, then we are left with one degree of freedom for its movement. Next, consider the \\ncase when we fix both end-points of the line segment in the plane. In this case, both degrees of freedom are lost, and \\ntherefore the line can no longer move in the plane. But, if we view the above situation with reference to the three-\\ndimensional space --- the one that we live in --- we note that the whole plane (containing the fixed line segment) can \\nmove in three dimensions, and hence, we have one degree of freedom for its movement. Let us try to understand this \\nconcept in another way: Suppose we have a sample of size n = 6, and suppose that the sum of the sample values is 20. \\nThat is, we have the following situation: Our Sample: \\n \\n \\n Men Women Total \\nWant PC 120 80 200 \\nDon’t Want  \\nPC 130 170 300 \\nTotal 250 250 500 \\n \\nSMOKING PATTERN \\nMARITAL STATUS \\nTotal \\nAbstinence  \\nOnly  \\nat times \\nRegular  \\nSmoker \\nTotal \\nSingle 67 213 74 354 \\nMarried 411 63 129 1173 \\nWidowed 85 51 7 143 \\nDivorced 27 60 15 102 \\nTotal 590 957 225 1772 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 340}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       336                                                                                                                                           \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nNow, the point is that, given this total of 20, if we choose the first 5 values freely,  we are not free to choose the sixth \\nvalue. Hence, one degree of freedom is lost.  This point can also be explained in the following alternative way. Given \\nthat the sum of the six values is 20, if we have knowledge of the first five values, but the sixth va lue is missing, then we \\ncan re-generate the sixth value. This can also be expressed as follows. \\n If there are six observations and you find their sum; next, you throw away one of the six observations; then, \\nyou can re-generate that observation (because of the fact that you have already computed the sum). \\nSince, the number of values that can be re-generated is one, hence, the degrees of freedom are n minus one.  \\n(The one which can be re-generated is not the one that we can choose freely.) \\nGoing back to sampl ing distributions such as the t -distribution, the chi -square distribution and the F -distribution, \\n‘degrees of freedom’ can be defined as the number of observations in the sample minus the number of population \\nparameters that are estimated from the sample d ata (from those observations). For example, in lecture number 39, we \\nnoted that the statistic follows the t-distribution having n-1 degrees of freedom.  \\n  \\n \\n \\n \\n \\nHere n denotes the number of observations in our sample, and since we are estimating one popula tion parameter i.e. \\uf073 \\nfrom the sample data, hence the number of degrees of freedom is n-1. \\nSimilarly, referring to lecture number 42, the students will recall that it was stated that the statistic   \\n \\nFollows the F-distribution having (n1-1, n2-1) degrees of freedom  \\nHere n1 denotes the number of observations in the first sample, and since we are estimating one parameter of the first \\npopulation i.e. \\uf07312 from the sample data, hence the number of degrees of freedom for the numerator of our statistic is \\nn1 minus one. Similarly, n2 denotes the number of observations in the second sample, and since we are estimating one \\nparameter of the second population i.e. \\uf07322 from the sample data, hence the number of degrees of freedom for the \\ndenominator of our statistic is n2 minus one. In addition, in today’s lecture, you learnt that the statistic  \\n \\n \\n \\n \\n \\nfollows the chi -square distribution having (r -1)(c-1) degrees of freedom. Let us try to understand this point: Consider \\nthe 2 \\uf0b4 2 contingency table ,similar to the one that  we had in the example regarding the desire for ownership of a \\npersonal computer. In this regard, suppose that we have two variables of classification, A and B, and the situation is as \\nfollows: \\n \\n \\n \\n \\n \\n \\n \\nThe point is that, given the marginal totals and the gr and total, if we choose the frequencies of the first cell of the first \\nrow freely, we are not free to choose the frequency of the second cell of the first row. Also, given the frequency of the \\nabove-mentioned first cell, we are not even free to choose the frequency of the second cell of the first column. \\nNot only this, it is interesting to note that, given the above, we are not even free to choose the frequency of \\nthe second cell of the second row or the second column !Hence, given the marginal and grand to tals, we have only \\ndegree of freedom (i.e. 1 = 1 \\uf0b4 1 = (2 -1)(2-1) degrees of freedom).A similar situation holds in the case of a 2 x 3 \\ncontingency table. The students are encouraged to work on this point on their own, and to realize for themselves that, in \\nthe case of a 2 x 3 contingency table, there exist (2 - 1) ( 3 - 1) = 2 degrees of freedom . Next, let us consider  the \\nconcept of p-value: \\nYou will recall that, with reference to the concept of hypothesis -testing, we compared the computed value of \\nour test statistic with a critical value. For example, in case of a right -tailed test, we rejected the null hypothesis if our \\nSr. No. Value \\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\nTotal 20 \\n \\nn\\ns\\nxt 0\\uf06d\\uf02d\\uf03d\\n2\\n2\\n2\\n1\\ns\\ns\\n\\uf028 \\uf029\\uf0e5\\uf0e5\\n\\uf03d \\uf03d\\n\\uf02d\\uf03d\\uf063\\nr\\n1i\\nc\\n1j ij\\n2\\nijij2 ,e\\ne0\\n A1 A2 Total \\nB1   200 \\nB2   300 \\nTotal 250 250 500 \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 341}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       337                                                                                                                                           \\ncomputed value exceeded the critical value, and we accepted the null hypothesis if our computed value turned out to be \\nsmaller than the critical A hypothesis can also be tested by means of what is known as the p-value. \\n \\nP-VALUE \\n \\nThe probability of observing a sample value as extreme as, or more extreme than, the value observed, given that the null \\nhypothesis is true. We illustrate this concept with the help of the example concerning the hourly wages of computer \\nanalysts and registered nurses that we discussed in an earlier lecture. The students will recall that the example was as \\nfollows: \\n \\nEXAMPLE \\n \\nA survey conducted by a market-research organization five years ago showed that the estimated hourly wage for \\ntemporary computer analysts was essentially the same as the hourly wage for registered nurses. This year, a random \\nsample of 32 temporary computer analysts from across the country is taken. The analysts are contacted by telephone \\nand asked what rates they are currently able to obtain in the market-place. A similar random sample of 34 registered \\nnurses is taken.  The resulting wage figures are listed in the following table. \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nConduct a hypothesis test at the 2% level of significance to determine whether the hourly wages of the computer \\nanalysts are still the same as those of registered nurses. In order to carry out this test, the Null and Alternative \\nHypotheses were set up as follows: \\nNull and Alternative Hypotheses:  \\nH0 : \\uf06d1 – \\uf06d2 = 0  \\nHA : \\uf06d1 – \\uf06d2 \\uf0b9 0 \\n(Two-tailed test) \\nThe computed value of our test statistic came out to be 3.43, whereas, at the 5% level of significance, the critical value \\nwas 2.33, hence, we rejected H0. \\n \\nHence, we concluded that there was a significant difference between the average hourly wage of a temporary computer \\nanalyst and the average hourly wage of a temporary registered nurse. This conclusion could also have been reached by \\nusing the  \\n \\n \\nP-VALUE METHOD \\n \\nZ = 0 Z.01 = -2.33 Z.01 = +2.33 Z \\nCalculated Z = 3.43 \\n  \\n \\n21 XX \\uf02d\\n15.121 \\uf03d\\uf02dXX\\n021 \\uf03d\\uf06d\\uf02d\\uf06d\\nComputer Analysts Registered Nurses \\n$ 24.10 $25.00 $24.25 $20.75 $23.30 $22.75 \\n23.75 22.70 21.75 23.80 24.00 23.00 \\n24.25 21.30 22.00 22.00 21.75 21.25 \\n22.00 22.55 18.00 21.85 21.50 20.00 \\n23.50 23.25 23.50 24.16 20.40 21.75 \\n22.80 22.10 22.70 21.10 23.25 20.50 \\n24.00 24.25 21.50 23.75 19.50 22.60 \\n23.85 23.50 23.80 22.50 21.75 21.70 \\n24.20 22.75 25.60 25.00 20.80 20.75 \\n22.90 23.80 24.10 22.70 20.25 22.50 \\n23.20   23.25 22.45  \\n23.55   21.90 19.10  \\n '), Document(metadata={'source': 'Statistics-book.pdf', 'page': 342}, page_content='STA301 – Statistics and Probability                                                                                              \\n \\nVirtual University of Pakistan                                                                                                       338                                                                                                                                           \\nI. Looking up the probability of Z > 3.43 in the area table of the standard normal distribution yields an area of .5000 – \\n.4996 = .0004.  \\nII. To compute the p-value, we need to be concerned with the region less than –3.43 as well as the region greater than \\n3.43 (because the rejection region is in both tails). \\n  \\n \\nThe p-value is 0.0004 + 0.0004 = 0.0008. Since this value is very small, it means that the result that we have obtained in \\nthis example is highly improbable if, in fact, the null hypothesis is true.  Hence, with such a small p -value, we decide to \\nreject the null hypothesis.  \\nThe above example shows that:  The p-value is a property of the data, and it indicates “how improbable” the obtained \\nresult really is.  A simple rule is that if our p -value is less than the level of significance \\uf061, then we should reject H0, \\nwhereas if our p-value is greater than the level of significance\\uf061, then we should accept H0. (In the above example, \\uf061 = \\n0.02 whereas the p-value is equal to 0.0008, hence we reject H0.) \\n \\n RELATIONSHIP BETWEEN CONFIDENCE INTERVAL AND TESTS OF HYPOTHESIS \\n \\nSome of the students may already have an idea that there exists some kind of a relationship between the confidence \\ninterval for a population  parameter \\uf071 and a test of hypothesis about \\uf071. (After all: When deriving the confidence interval \\nfor \\uf06d, the area that was kept in the middle of the sampling distribution of  \\uf060X was equal to 1 -\\uf061 so that the area in each \\nof the right and left tails was equal to \\uf061/2. And, when testing the hypothesis H0 : \\uf06d = \\uf06d0 versus HA : \\uf06d \\uf0b9 \\uf06d0 at level of \\nsignificance \\uf061, the area in each of the right and left tails was again equal to \\uf061/2.)Hence, consider the following \\nproposition: Let [L, U] be a 100(1 - \\uf061)% confidence inter val for the parameter \\uf071.Then we will accept the null \\nhypothesis H0 : \\uf071 = \\uf0710 against H1 : \\uf071 \\uf0b9 \\uf0710 at a level of significance \\uf061 if \\uf0710 falls inside the confidence interval, but if \\uf0710 \\nfalls outside the interval [L, U], we will reject H0.In the language of hypot hesis testing, the (1 - \\uf061) 100% confidence \\ninterval is known as the acceptance region and the region outside the confidence interval is called the rejection or \\ncritical region.  The critical values are the end points of the confidence interval. The students are encouraged to work on \\nthis point on their own. As we approach the end of this course, we present an Overview of the Science of Statistics in \\nToday’s World: Statistics is a vast discipline! In this course, we have discussed the very basic and fundamental \\nconcepts of statistics and probability. But, there are numerous other topics that could have been discussed if we had the \\ntime. We could have talked about the Latin Square Design, we could have considered Inference Regarding Regression \\nand Correlation Coefficients, we could have discussed Non-Parametric Statistics, and so on, and so forth. \\nThe students are encouraged to study some of these concepts on their own --- as and when time permits --- in order to \\ndevelop a better understanding and appreciation of the importance of the science of Statistics. In this course, numerous \\nexamples were discussed and many numerical problems were presented.   \\n The solutions of these problems were presented in detail, and the various steps were worked out. In doing so, \\nthe purpose was to develop in the students a better understanding of the core concepts of the various techniques that \\nwere applied. But, it is interesting and useful to note that, a lot many of these numerical problems can be solved within \\nseconds by using t he wide variety of statistical packages that are available. These include SPSS, SAS, Statistica, \\nStatgraph, Minitab, Stata, S -Plus, etc. (The students are welcome to try out some of these packages on their \\nown.)Towards the end of this course, we present one of the latest definitions of Statistics: \\n \\nLATEST STATISTICAL DEFINITION \\n \\nStatistics is a science of decision making for governing the state affairs. It collects analyzes, manages, monitors, \\ninterprets, evaluates and validates information. Statistics is I nformation Science and Information Science is Statistics. It \\nis an applicable science as its tools are applied to all sciences including humanities and social sciences. \\n \\n \\n- THE END - \\nScale of z -1.96 -3.43 3.43 1.96 -1.96 \\n0.0004 \\n025.2\\n05.\\n2 \\uf03d\\uf03d\\uf061\\n025.2\\n05.\\n2 \\uf03d\\uf03d\\uf061\\n0 \\n0.0004 \\nRejection Region Rejection Region \\np-value = 0.0004+0.0004 = 0.0008 ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_pdf_rag(query):\n",
        "    query_embedding = hf_embeddings.embed_query(query)\n",
        "\n",
        "    top_matches = pinecone_index.query(vector=query_embedding, top_k=10, include_metadata=True, namespace=namespace)\n",
        "\n",
        "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
        "\n",
        "    augmented_query = \"\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
        "\n",
        "    primer = \"You are a personal assistant. Answer any questions I have about the PDF file provided.\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are an expert personal assistant. Answer any questions I have about the PDF file provided. You always answer questions based only on the context that you have been provided.\n",
        "    \"\"\"\n",
        "\n",
        "    res = openrouter_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": primer},\n",
        "        {\"role\": \"user\", \"content\": augmented_query}\n",
        "    ]\n",
        "    )\n",
        "\n",
        "    return res.choices[0].message.content"
      ],
      "metadata": {
        "id": "KX9NOiRs9-Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perform_pdf_rag(\"what is nominal scale?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "1coqlQUC-EmL",
        "outputId": "ed29ca17-30f7-4362-a26f-0d9db7035b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A nominal scale is a classification or grouping of observations into distinct, qualitative categories or classes. It involves assigning numbers or labels to categories without any inherent order or numerical significance. For example, classifying students as male or female, or rainfall as heavy, moderate, or light are examples of nominal scales. The numbers used for identification in a nominal scale do not imply any specific order or quantity.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}